,assignee,creator,description,key,reporter,summary
0,,Kwame,"We tried upgrading from Spring Boot 2.0.6 to Spring 2.1.0 and noticing a critical multi-threading bug in the WebClient.  We are using Spring WebFlux with Netty Embedded Server

In SpringBoot 2.0.6 you can see data received and published on happens on two different threads but in SpringBoot 2.1.0 all execution is happening on the same thread even data is published to same thread.  Any reason why the multi-threading behavior has changed in SpringBoot 2.1.0?  Seems like a major defect.  This flaw is preventing us from upgrading to Spring Boot 2.1.0.

It appears with Spring Boot 2.1.0 the default threading behavior of the WebClient has changed to where emissions on published on main thread as opposed to a different thread

See results below

I print the thread on the doOnRequest method of the WebClient

I also print the thread on the doOnNext of the Mono

For version 2.10 you can see emissions are published on the main thread but in earlier version

2.0.6 emissions published on a different thread.

You can see even response time increased for 2.10 because emissions are published on main thread as opposed to different thread

2.0.6.RELEASE

2018-11-15 08:49:45.626 INFO 15228 — [ctor-http-nio-5] c.c.x.n.s.handler.rest.SearchHandler : Search request received for query : 
 2018-11-15 08:49:45.630 INFO 15228 — [ctor-http-nio-5] c.c.x.n.c.s.x.impl.HttpSearchService : Request for search using query param : 
 2018-11-15 08:49:45.633 INFO 15228 — [ctor-http-nio-5] c.c.x.n.m.h.filter.RequestLoggingFilter : Executing request: GET [https://www|https://www/]
 2018-11-15 08:49:45.635 INFO 15228 — [ctor-http-nio-5] c.c.x.n.m.util.AbstractLookupService : Subscribed to request with uri [https://www|https://www/]
 2018-11-15 08:49:45.635 INFO 15228 — [ctor-http-nio-5] c.c.x.n.m.util.AbstractLookupService : Request received for uri [https://www|https://www/] [Thread[reactor-http-nio-5,5,main]]
 2018-11-15 08:49:47.069 INFO 15228 — [ctor-http-nio-4] c.c.x.n.s.f.RequestProcessingTimeFilter : Request processing time for GET 34291c26-8419-4cf9-8c50-eea84bf59d48 is 17 ms with http status null
 2018-11-15 08:49:47.253 INFO 15228 — [ctor-http-nio-8] c.c.x.n.m.util.AbstractLookupService : Time taken for request [http://www|http://www/] is : [1624] ms Thread[reactor-http-nio-8,5,main]]

2.1.0.RELEASE

2018-11-15 09:07:15.886 INFO 5932 — [ctor-http-nio-6] c.c.x.n.s.handler.rest.SearchHandler : Search request received for query : 
 2018-11-15 09:07:15.906 INFO 5932 — [ctor-http-nio-6] c.c.x.n.c.s.x.impl.HttpSearchService : Request for search using query param :
 2018-11-15 09:07:15.912 INFO 5932 — [ctor-http-nio-6] c.c.x.n.m.h.filter.RequestLoggingFilter : Executing request: GET [https://www|https://www/]
 2018-11-15 09:07:15.914 INFO 5932 — [ctor-http-nio-6] c.c.x.n.m.util.AbstractLookupService : Subscribed to request with uri [https://www|https://www/]
 2018-11-15 09:07:15.915 INFO 5932 — [ctor-http-nio-6] c.c.x.n.m.util.AbstractLookupService : Request received for uri [https://www|https://www/]  [Thread[reactor-http-nio-6,5,main]]
 2018-11-15 09:07:18.356 INFO 5932 — [ctor-http-nio-6] c.c.x.n.m.util.AbstractLookupService : Time taken for request [https://www|https://www/] is : [2447] ms  [Thread[reactor-http-nio-6,5,main]]",XD-3769,Kwame,Upgrade to Spring Boot 2.1.0
1,,abhineet kumar,"The jobs that appear under Executions section of Jobs in spring xd admin ui, has restart button disabled. How do I enable this ?",XD-3768,abhineet kumar,How do I make a job restartable in spring xd
2,,Manuel Jordan,"Working with Spring-XD version 1.3.2.RELEASE

Starting the server with {{xd-singlenode}} command, the following happens for the shell

{code}
xd:>admin config
admin config info        admin config server      admin config timezone
xd:>admin config info
  -------------  -------------------------------------------
  Result         Successfully targeted http://localhost:9393
  Target         http://localhost:9393
  Timezone used  Colombia Time (UTC -5:00)
  -------------  -------------------------------------------

xd:>admin config server
Successfully targeted http://localhost:9393/
xd:>admin config timezone
Command 'admin config timezone' not found (for assistance press TAB)
xd:>
{code}

How you can see the {{admin config timezone}} command shows {{Command 'admin config timezone' not found (for assistance press TAB)}}.

Seems a bug because in the previous output this command appears how a third valid option: 

{code}
xd:>admin config
admin config info        admin config server      admin config timezone
{code}",XD-3767,Manuel Jordan,admin config timezone command does not work
3,,Keerthi kanth Nagaraj,"My project 7 node cluster and in that 2 node are Admin containers and remaining are non admin containers. When i applied module upload command it created jar with md5 in custom_modules/jobs path only in admin nodes but not in other nodes. I am able to create job based on the uploaded module but job status is shown as ""Failed"" and the reason behind is jars are not placed in all nodes custom_modules/jobs/test_module.jar.
Can you anyone let us know the exact reason why module upload is pushing jars only to admin nodes but not all other nodes.",XD-3766,Keerthi kanth Nagaraj,Module Upload command not pushing jar to all containers
4,Janne Valkealahti,Mark Pollack,See https://github.com/spring-projects/spring-xd/issues/1924,XD-3765,Mark Pollack,Fix stream failover 
5,,Pavan Srikar,"I'm trying to run a Job on SpringXD and the job has 7 steps, When I reach step 4 i'm shutting down the XD server. When I look into the Metadata of SpringXD I'm saving on OracleDB. I see that the Step 4 is in executing status and it will never change to failed. After restarting the server, I still see that the status of the Job is still executing and it never gets finished. If I launch the job it create a new job and the new one gets finished.

My config.xml for jdbc:

    <jdbc:initialize-database data-source=""dataSource"" 
                      enabled=""false"">
        <jdbc:script location=""org/springframework/batch/core/schema-oracle10g.sql"" />
</jdbc:initialize-database>

From org/springframework/batch/core/schema-oracle10g.sql, I see that the sql queries are for creating a table. But when the tables are already existing, as i didn't drop them from my previous job. There was no error which said tables already exist. The new job got appended to previous existing table. HOW?
How can I force the job to fail when the XD server suddenly goes down?
How can I resume the same job that was stopped from the step where it stopped?
Thank you :)",XD-3764,Pavan Srikar,SpringXD Job is still executing even after forceful Server shutdown
6,,Krzysztof Noga,"Hello,

I have encountered following problem while using Spring XD in DIRT (distributed) mode. I have one xd-admin and two xd-containers, Redis as transportation, and SQL Server 2016 as the database. After deploying a job from UI to all available containers sometimes I get two same entries in table {{XD_JOB_REGISTRY}} for the job:
!select.png!

As a result the JOBS -> Deployments page shows nothing but an error _Error fetching data. Is the XD server running_.

There is following exception in the xd-admin log:
{noformat}
2017-01-23T11:13:11+0100 1.3.1.RELEASE ERROR qtp1854907975-29 rest.RestControllerAdvice - Caught exception while handling a request
org.springframework.dao.IncorrectResultSizeDataAccessException: Incorrect result size: expected 1, actual 2
        at org.springframework.dao.support.DataAccessUtils.requiredSingleResult(DataAccessUtils.java:74) ~[spring-tx-4.2.4.RELEASE.jar:4.2.4.RELEASE]
        at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:791) ~[spring-jdbc-4.2.4.RELEASE.jar:4.2.4.RELEASE]
        at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:814) ~[spring-jdbc-4.2.4.RELEASE.jar:4.2.4.RELEASE]
        at org.springframework.xd.dirt.plugins.job.DistributedJobLocator.isIncrementable(DistributedJobLocator.java:203) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
{noformat}

..because in {{DistributedJobLocator.java}} the query is expected to return exactly one record:
{code:java}
	public Boolean isIncrementable(String jobName) {
		return jdbcTemplate.queryForObject(JOB_INCREMENTABLE, Boolean.class, jobName);
	}
{code}

The code that adds a job in {{DistributedJobLocator.java}} seems to be susceptible to race conditions:
{code:java}
	protected void addJob(String name, boolean incrementable, boolean restartable) {
		Collection<String> jobNames = this.getJobNames();
		// XD admin server will prevent any REST client requests create a job definition with an existing name.
		// ...
		if (!jobNames.contains(name)) {
			addJobName(name, incrementable, restartable);
		}
		else {
			updateJobName(name, incrementable, restartable);
		}
	}

	private void addJobName(String name, boolean incrementable, boolean restartable) {
		jdbcTemplate.update(ADD_JOB_REGISTRY, incrementable, restartable, name);
	}
{code}

...and there are no any unique constraints on the table columns:
{code:sql}
CREATE TABLE XD_JOB_REGISTRY(
    JOB_NAME VARCHAR(100) NOT NULL,
    IS_INCREMENTABLE VARCHAR(10) NOT NULL,
    IS_RESTARTABLE VARCHAR(10) NOT NULL
);
{code}",XD-3763,Krzysztof Noga,Duplicate entries in table XD_JOB_REGISTRY
7,,Issam,"According to the documentation we can load jars dynamically at module creation time by exploiting the attribute module.classloader in the .properties file :

http://docs.spring.io/spring-xd/docs/1.3.1.RELEASE/reference/html/#module-class-loading

I spent two days trying to test this feature. It does not work. The option module.classloader seems to be simply ignored

I did not find any string named module.classloader in the XD code. But I found another one called module.classpath in this class:

https://github.com/spring-projects/spring-xd/blob/master/spring-xd-module/src/main/java/org/springframework/xd/module/options/ModuleUtils.java

The code in the above class seems to match the documentation. But unfortunalletely it does not work too. My classes are not found and I get java.lang.ClassNotFoundException

I have module option named dir4jars where I put the jars to load at creation time (when I issue job create --name xx --defintion ..). It's a directory, and I have tested the following possibilities, with both module.classpath and module.classloader :

{code:java}

module.classpath=${dir4jars}/*.jar
module.classloader=${dir4jars}/*.jar
.
.
job create --name jobName --definition ""myJobModuleName --dir4jars=C:/ELS/Flash/libxd"" --deploy

and

job create --name jobName --definition ""myJobModuleName --dir4jars=file:C:/ELS/Flash/libxd"" --deploy 

{code}

I need the dir4jars to be absolute and outside XD home.

What's the right option to use for this dynamic load? module.classpath or module.classloader ? Is't a bug in the documentation ?

How can I set an absolute directory as I mentioned above?

Many thanks.",XD-3762,Issam,Spring XD Dynamic Module ClassLoader Issue
8,,Urban Krieg,"Hi, 

We use spring config server 1.0.4-RELEASE with spring boot 1.2.5-RELEASE without any problems.

Now i update to spring boot 1.4.0.RELEASE and config 1.2.0.RELEASE.

Since then i have problems with the configserver. In the log you can see that the config server loads different configs. This is done from a start-script file to extract ports. This works fine. 
then i start my spring boot app and at the same time i see these errors (RejectedExecutionException) see attachment.

Question:
- is the config read from the configserver only read once at startup?
- could there be a concurrent issue in the config server?

I have just tested spring boot 1.3.7 with config 1.2.0 and got the same problem.
Did just another test: See ConfigServerLogV1.1.3_SpringBoot1.3.7.txt that has the same problem
",XD-3761,Urban Krieg,java.util.concurrent.RejectedExecutionException in InetUtils.convertAddress
9,,Chua Yew Wee,"Hi,

I'm using LDAP to a Windows Active Directory as the authentication method for SpringXD. But after the user is authenticated in the SpringXD, the user is not authorized to do anythin.

Based on the guides and the configuration files, it is unclear where the authorization rules for each user should be put, ROLE_VIEW, ROLE_CREATE, ROLE_ADMIN.

Can the SpringXD team guide me to where will the authorization rules be created? In SpringXD servers.yml file or in Active Directory?

Regards,
Yew Wee
 ",XD-3760,Chua Yew Wee,SpringXD authenication and authorization using LDAP
10,,Sabby Anandan,"More details in the support ticket: https://issuetracker.springsource.com/browse/VESC-679

Following entires should be added to {{application.yml}} file.

{code}
        - POST   /tools/parseJobToGraph                      => hasRole('ROLE_CREATE')
        - POST   /tools/parseJobToGraph.*                   => hasRole('ROLE_CREATE')
        - POST   /tools/convertJobGraphToText            => hasRole('ROLE_CREATE')
        - POST   /tools/convertJobGraphToText.*          => hasRole('ROLE_CREATE')
{code}",XD-3759,Sabby Anandan,Composed job endpoint is missing from the defined authorization rules
11,,cloudoo,"i  unzip flo-spring-xd-admin-ui-client-1.3.1.RELEASE.jar to replace the existing spring-xd-admin-ui-client-1.3.1.RELEASE.jar,and clear my browser cache
then restart the  xd-singlenode，but i can't access Flo for Spring XD at the following URI endpoints :http://HOST_NAME:PORT/admin-ui/#/streams/create , i can't find the ""flo"" page!
",XD-3758,cloudoo,flo don't work
12,,GERVAIS Mickaël,"Hi,

If I use the module.[name].producer.paritionKeyExpression, and the module as also autoBindDLG enabled, the creates RabbbitMQ queues do not have the DeadLetter policy.
The first queue has it (xdbus.<stream>.0-0) but others do not have it (xdbus.<stream>.0-N).

Thanks

Mickaël

",XD-3757,GERVAIS Mickaël,Dead Letter is not created on all RabbitMQ queues for partionned stream
13,,haihua liang,"I download the spring XD example projects, and run through the steps acccording the README file for the project. I tried to change the hadoop-site.xml, server.yml and wordcount.xml files, but I failed get the . I am blocked by this issue. Thank you very much in advance for help. Best Regards.",XD-3756,haihua liang,wordcount failed to run in cloudera VM 5.7
14,,Gary Russell,"{code}
xd:>module compose foo --definition ""time --fixedDelay=5 | t1:transform --expression=payload+'a' | t2:transform --expression=payload.toUpperCase()
{code}

Produces {{2016-05-02 17:27:20aa}} - the first transform is applied twice.
",XD-3755,Gary Russell,Composed Modules Can't Have Duplicate Processors
15,,Gary Russell,"{{module compose foo --definition ""time --fixedDelay=5 | shell --command=my.sh""}}

{code}
xd:>stream create bar --definition ""foo | log"" --deploy
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module foo of type source:
    command: may not be empty
    command: may not be null
{code}

The problem stems from the fact that the options metadata validation is performed on the shell module before the property from the composed module is injected.

Disabling the validation annotations on the metadata avoids the problem.

{code}
//	@NotEmpty
//	@NotNull
public String getCommand() {
	return command;
}
{code}",XD-3754,Gary Russell,Composed Module Child Module Validated Too Early
16,,Thomas Risberg,"The MapReduce samples should have ""yarn.resourcemanager.scheduler.address"" since it might be needed in a multi node production cluster.",XD-3753,Thomas Risberg,"Add ""yarn.resourcemanager.scheduler.address"" to mapreduce samples"
17,,Manjunath Desappa,"When i use the admin-ui web portal which runs on port 9393, there is a load timeout issue by require.js, failing to load the login screen. Could the team please look into this issue ASAP, or give me some other alternative !sping-ui-issue.png|thumbnail!",XD-3752,Manjunath Desappa,Admin UI login Page failing to load due to require.js timeout - FE
18,Janne Valkealahti,Janne Valkealahti,"In a case where reactor's ringbuffer is full and thus handling backpressure by blocking `onNext`, shutdown phase where `onComplete` is send will cause a deadlock.

This is shown by a thread dump during a shutdown. This will basically break further deployments for this stream in distributed mode while single node will show more errors during undeployment.

{code}
""pool-7-thread-1"" #58 prio=5 os_prio=0 tid=0x979fe800 nid=0x54de runnable [0x986ad000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)
	at reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:122)
	at reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:97)
	at reactor.jarjar.com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)
	at reactor.core.processor.util.RingBufferSubscriberUtils.onNext(RingBufferSubscriberUtils.java:30)
	at reactor.core.processor.RingBufferProcessor.onNext(RingBufferProcessor.java:575)
{code}

{code}
""main-EventThread"" #19 daemon prio=5 os_prio=0 tid=0x9b93a400 nid=0x54b1 runnable [0x9aefe000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)
	at reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:122)
	at reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:97)
	at reactor.jarjar.com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)
	at reactor.core.processor.util.RingBufferSubscriberUtils.onComplete(RingBufferSubscriberUtils.java:54)
	at reactor.core.processor.RingBufferProcessor.onComplete(RingBufferProcessor.java:585)
	at org.springframework.xd.greenplum.gpfdist.GPFDistMessageHandler.doStop(GPFDistMessageHandler.java:170)
{code}

I've been crafting workaround for this by trying to wait reactor stream/buffer to get drained by gpdb and finally as last resort, forcing processor in reactor to shutdown.",XD-3751,Janne Valkealahti,gpfdist may fail to shutdown with backlog
19,,Muhammad Ali,"if we put a custom module static properties in `/config/modules/job/module-name/module-name.properties` then we cannot completely remove the module -  you can delete module but you cannot upload new jar with the same name as it gives an error  - there is module already with the same name.

May be important to note that we had a zookeeper data corruption on which support asked us to upgrade. We couldn't upgrade just yet, so I cleaned up zookeeper and recreated all streams/job from original scripts. 

I have observed this behavior after the corruption - I cannot tell for sure if the behavior was there or not before the corruption. In case it is not easily reproducible then it could be environment specific issue.

I may update JIRA once i get time to try it on my local distributed mode.
",XD-3750,Muhammad Ali,Cant completely remove custom module after putting properties in /config/modules/job/xx/xx.properties
20,,Gary Russell,"Custom conversion is broken.

If the custom {{MimeType}} does not match any of those in {{MessageConverterUtils.getJavaTypeForContentType}} then the channel configuration fails with

{code}
			throw new ModuleConfigurationException(""Content type is not supported for "" +
					channel.getComponentName() + ""Type="" + contentType);
{code}

The code needs to consult custom converters to see what {{MimeType}} (s) they support - and the output Java type.


See http://stackoverflow.com/questions/35639975/adding-a-custom-type-converter-to-spring-xd",XD-3749,Gary Russell,Provisioning of Custom input/output Converters is Broken
21,Gary Russell,Daniel Garcia Perez,"If I try to use <int:message-history/> when developing a Spring XD module, it fails when try to export the JMX bean. I've seen that the naming strategy used is org.springframework.xd.dirt.module.jmx.ModuleObjectNamingStrategy

The stackTrace:
{code}
2016-02-24T10:40:39+0000 1.3.1.RELEASE ERROR DeploymentsPathChildrenCache-0 container.DeploymentListener - Exception deploying module
org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.history.MessageHistoryConfigurer@24902b5f] with key 'messageHistoryConfigurer'; nested exception is javax.management.MalformedObjectNameException: Key properties cannot be empty
	at org.springframework.integration.monitor.IntegrationMBeanExporter.registerBeanInstance(IntegrationMBeanExporter.java:375) ~[spring-integration-jmx-4.2.5.RELEASE.jar:na]
	at org.springframework.integration.monitor.IntegrationMBeanExporter.afterSingletonsInstantiated(IntegrationMBeanExporter.java:288) ~[spring-integration-jmx-4.2.5.RELEASE.jar:na]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:792) ~[spring-beans-4.2.4.RELEASE.jar:4.2.4.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:213) ~[spring-xd-module-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:334) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) [curator-recipes-2.6.0.jar:na]
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) [curator-recipes-2.6.0.jar:na]
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) [curator-framework-2.6.0.jar:na]
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) [guava-16.0.1.jar:na]
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) [curator-framework-2.6.0.jar:na]
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) [curator-recipes-2.6.0.jar:na]
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) [curator-recipes-2.6.0.jar:na]
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) [curator-recipes-2.6.0.jar:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_72]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_72]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]
Caused by: javax.management.MalformedObjectNameException: Key properties cannot be empty
	at javax.management.ObjectName.construct(ObjectName.java:483) ~[na:1.8.0_72]
	at javax.management.ObjectName.<init>(ObjectName.java:1382) ~[na:1.8.0_72]
	at javax.management.ObjectName.getInstance(ObjectName.java:1273) ~[na:1.8.0_72]
	at org.springframework.jmx.support.ObjectNameManager.getInstance(ObjectNameManager.java:62) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]
	at org.springframework.xd.dirt.module.jmx.ModuleObjectNamingStrategy.getObjectName(ModuleObjectNamingStrategy.java:50) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]
	at org.springframework.jmx.export.MBeanExporter.getObjectName(MBeanExporter.java:751) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]
{code}",XD-3748,Daniel Garcia Perez,Unable to register the JMX bean MessageHistory from Spring Integration
22,Gary Russell,Gary Russell,http://stackoverflow.com/questions/35563064/processing-messages-through-namedchannels-with-prefetch-1/35584333#35584333,XD-3747,Gary Russell,Rabbit Bus: Expose ChannelCacheSize on CachingConnectionFactory
23,Gary Russell,Mark Pollack,,XD-3746,Mark Pollack,Update Spring Framework to 4.2.4
24,Gary Russell,Mark Pollack,Update to amqp-client 3.6.0 and spring-amqp 1.5.4,XD-3745,Mark Pollack,"Update Spring-AMQP to 3.6, RabbitMQ Client to 1.5.4"
25,Gary Russell,Gary Russell,"Related to XD-2567 which fixed this problem, but only in the bus.

{quote}
2016-02-19T18:25:24-0500 1.2.1.RELEASE WARN SimpleAsyncTaskExecutor-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]
{quote}",XD-3744,Gary Russell,Suppress DeliveryMode Header in RabbitMQ Source
26,Artem Bilan,Gary Russell,See INT-3956,XD-3743,Gary Russell,Update to Spring Integration 4.2.5 When Available (Fix Metrics)
27,David Turanski,David Turanski,"The following XD components have been identified to support SSL via an `sslProperties` property which points to the location of a properties file. The properties encryption extension for 1.3.1 does not currently apply to these:

  * Rabbit Message Bus
  * Rabbit Source
  * Rabbit Sink
  * Http Source (NettyHttpInboundChannelAdapter). 

This can be made to work in the case of Rabbit since the latest RabbitConnectionFactoryBean supports individual SSL properties settings as an alternative to the properties file. The http source may be extended to use the same approach.",XD-3742,David Turanski,Enable in line SSL properties as an alternative to external properties files
28,,Stefano Massera," As a Flo for Spring XD user, I would like to be able to create a new stream using the graphicat UI. 

This flow should be shown in a graphical way also in definition tab.
!http://example.com/image.png!
Right now it doesn't happen due to a javascript error.

{code}
TypeError: this.node.getTransformToElement is not a function
    at Object.VElement.bbox (http://localhost:9393/admin-ui/lib/joint/src/vectorizer.js:323:36)
    at joint.dia.ElementView.joint.dia.CellView.extend.positionRelative (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2740:51)
    at null.<anonymous> (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2710:18)
    at http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1177:23
    at eval (eval at createIterator (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1:0), <anonymous>:10:9)
    at Function.forEach (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:3645:9)
    at joint.dia.ElementView.joint.dia.CellView.extend.update (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2700:11)
    at bound [as update] (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1005:21)
    at joint.dia.ElementView.joint.dia.CellView.extend.render (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2903:14)
    at joint.dia.Paper.Backbone.View.extend.addCell (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:5004:14)(anonymous function) @ :9393/admin-ui/lib/angular/angular.js:11500
:9393!attachment-name.jpg|thumbnail!
{code}
",XD-3741,Stefano Massera,[Flo] Stream creation/definitions doesn't show any component
29,Ilayaperumal Gopinathan,Daniel Garcia Perez,"The maxWait property from server.yml in the message bus section for kafka is not propagated through the code, it is ignored.",XD-3740,Daniel Garcia Perez,Kafka message bus maxWait property is not set up
30,Gary Russell,David Geary,"All modules that allow groovy implementations (filter, script, transform, router, tcpclient) allow automatic refresh of the script when it changes. In the XD documentation it is stated that this refresh occurs every minute eg for filter at http://docs.spring.io/spring-xd/docs/1.3.0.RELEASE/reference/html/#filter ""The script is checked for updates every 60 seconds, so it may be replaced in a running system. "" 

This set up can be seen in the spring xml for the modules - eg (again for filter)

{code:xml}
<filter input-channel=""to.script"" output-channel=""output"">
	<int-groovy:script location=""${script:filter.groovy}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/>
</filter>
{code}

However from the spring integration documentation http://docs.spring.io/spring-integration/docs/4.2.4.RELEASE/reference/html/messaging-endpoints-chapter.html#scripting-config
it specifies that the refresh-check-delay parameter is actually in milliseconds - ie the above XD configuration would recheck the script every 60 milliseconds which may be a performance concern as it will be checking the lastmodified time of the script file. 

Ideally this parameter would be configurable - in our case we would usually eliminate the refresh check altogether (set to -1) as our scripts will not change (or if they did a redeploy of the module would pick it up)

",XD-3739,David Geary,Incorrect refresh period for groovy scripts
31,David Turanski,David Turanski,"Spring XD keeps passwords in text files such sas servers.yml, properties files, and module configuration files. Some users have requested a way to store encrypted values rather than clear text.  XD should provide a ""hook"" for users to provide a custom component to detect encrypted property values and decrypt them during container, admin, and module initialization.",XD-3738,David Turanski,Encrypt secret information in XD configuration files
32,Gunnar Hillert,Gunnar Hillert,"In the following PR we removed the *RestLogoutSuccessHandler*. 

https://github.com/spring-projects/spring-xd/pull/1562

This is necessary, though, for REST calls and the Admin UI. Otherwise some weird UI behavior might occur due to the HTTP redirect.",XD-3737,Gunnar Hillert,REST - Do not redirect after logout
33,Gary Russell,Gary Russell,"PubSub consumers can support concurrency since the threads are competing consumers on the queue.

",XD-3736,Gary Russell,Rabbit Pub/Sub Consumers Should Support Concurrency
34,,David Turanski,Add option to write to Splunk named index as an alternative to tcp.,XD-3735,David Turanski,Splunk sink - add option to write to index 
35,Gary Russell,Gary Russell,See http://stackoverflow.com/questions/34817906/spring-xd-rabbitmq-partitioned-stream-deployment-in-failure,XD-3734,Gary Russell,AutoBindDLQ Incompatible with Partitioned Streams (Producer Side).
36,Gary Russell,David Turanski,"Add spring.redis.pool.*  properties to server.yml, commented out to show default values., e.g., 

   maxIdle: 8,
   minIdle: 0, 
   maxActive: 8,
   maxWait: -1
",XD-3733,David Turanski,Document redis pool properties in servers.yml
37,,Sabby Anandan,"As a developer, I'm adding new overrides to {{server.yml}} file; however, the overridden properties do not reflect even after the restart of server. ",XD-3732,Sabby Anandan,Overrides to servers.yml file aren't taken into account
38,Gary Russell,Gary Russell,"{noformat}
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:96: warning: [rawtypes] found raw type: DomainRepository
			DomainRepository instanceRepository, String jobName,
			^
  missing type arguments for generic class DomainRepository<T,ID>
  where T,ID are type-variables:
    T extends Object declared in interface DomainRepository
    ID extends Serializable,Comparable<ID> declared in interface DomainRepository
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:116: warning: [rawtypes] found raw type: DomainRepository
			DomainRepository instanceRepository, String jobName,
			^
  missing type arguments for generic class DomainRepository<T,ID>
  where T,ID are type-variables:
    T extends Object declared in interface DomainRepository
    ID extends Serializable,Comparable<ID> declared in interface DomainRepository
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:127: warning: [unchecked] unchecked conversion
		this.instanceRepository = instanceRepository;
		                          ^
  required: DomainRepository<JobDefinition,String>
  found:    DomainRepository
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/ModuleException.java:23: warning: [serial] serializable class ModuleException has no definition of serialVersionUID
public class ModuleException extends RuntimeException {
       ^
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/support/ModuleDefinitionService.java:130: warning: [try] explicit call to close() on an auto-closeable resource
			target.close();
			      ^
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/StreamException.java:23: warning: [serial] serializable class StreamException has no definition of serialVersionUID
public class StreamException extends RuntimeException {
       ^
/Users/grussell/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/1.0.0/512563fec38547cf446fbd221069799df1ab158d/kite-data-core-1.0.0.jar(org/kitesdk/data/DatasetDescriptor.class): warning: Cannot find annotation method 'value()' in type 'SuppressWarnings': class file for edu.umd.cs.findbugs.annotations.SuppressWarnings not found
/Users/grussell/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/1.0.0/512563fec38547cf446fbd221069799df1ab158d/kite-data-core-1.0.0.jar(org/kitesdk/data/DatasetDescriptor.class): warning: Cannot find annotation method 'justification()' in type 'SuppressWarnings'
3 warnings
/Users/grussell/Development/spring-xd/spring-xd-tuple/src/test/java/org/springframework/xd/tuple/TupleJsonMarshallerTests.java:77: warning: [unchecked] unchecked cast
		List<Tuple> body = (List<Tuple>) tuple.getValue(""body"");
		                                               ^
  required: List<Tuple>
  found:    Object
:api
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/job/dao/XdJdbcSearchableJobExecutionDao.java:151: warning - @return tag has no arguments.
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/job/dao/XdJdbcSearchableJobExecutionDao.java:166: warning - @return tag has no arguments.
/Users/grussell/Development/spring-xd/spring-xd-rest-domain/src/main/java/org/springframework/xd/rest/domain/JobExecutionInfoResource.java:252: warning - @return tag cannot be used in method with void return type.
/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer
{noformat}",XD-3731,Gary Russell,Clean Up Compiler/Javadoc Warnings
39,,Virgile Devaux,as stated in https://jira.spring.io/browse/INT-3908 sprint-integration in springxd can't use kafka as message bus in most case. Could it spring-xd integrat this fix for us to use it?,XD-3730,Virgile Devaux,NPE in spring-integration when using kafka as message bus when using aggrzgation module
40,,Arne Schmitz,"Requirements: Make the class loader of the custom XD module available to the code of the custom module.

Javassist's toClass method uses the thread's local class loader to [load classes|https://jboss-javassist.github.io/javassist/html/javassist/CtClass.html#toClass--]. This is most definitely inappropriate in the case of Spring XD modules, since many classes come from the lib/ directory of the module. Those will produce a ClassDefNotFound exception in javassist.

Currently the ModuleFactory basically ""throws away"" the class loader, after generating it:

{code}
	private Module createSimpleModule(ModuleDescriptor moduleDescriptor, ModuleOptions moduleOptions,
			ModuleDeploymentProperties deploymentProperties) {
		if (log.isInfoEnabled()) {
			log.info(""creating simple module "" + moduleDescriptor);
		}
		SimpleModuleDefinition definition = (SimpleModuleDefinition) moduleDescriptor.getModuleDefinition();
		ClassLoader moduleClassLoader = ModuleUtils.createModuleRuntimeClassLoader(definition, moduleOptions, this.parentClassLoader);

		Class<? extends SimpleModule> moduleClass = determineModuleClass((SimpleModuleDefinition) moduleDescriptor.getModuleDefinition(),
				moduleOptions);
		Assert.notNull(moduleClass,
				String.format(""Required module artifacts are either missing or invalid. Unable to determine module type for module definition: '%s:%s'."",
						moduleDescriptor.getType(), moduleDescriptor.getModuleName()));
		return SimpleModuleCreator
				.createModule(moduleDescriptor, deploymentProperties, moduleClassLoader, moduleOptions, moduleClass);
	}
{code}

I think it would be sufficient if either the current module or the class loader itself could be injected into the custom classes of the custom XD module. As far as I can see I cannot get a grip on the Module instance in the current state of XD system.",XD-3729,Arne Schmitz,Make module class loader or module available to implementation of custom module 
41,,Nachiket Bondale,"***Version
	Spring XD Version : spring-xd-1.3.0.RELEASE, spring-xd-1.3.0.RELEASE-yarn
	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64 
	Java Version: java version ""1.7.0_65""

***Description
	The batch-hive job in the spring-xd-samples project (link: https://github.com/spring-projects/spring-xd-samples/tree/master/batch-hive ) is failing with inline error message.

***Steps to recreate the problem
1. Created a jar for batch-hive job.
	2. Once the final jar was ready, uploaded using ""module upload --name test_hive_module --type job --file /home/user/jar/batch_hive.jar""
3. After that created and deployed job using ""job create --name test_hive_job --definition test_hive_module --deploy""
	4. Finally launched using ""job launch test_hive_job"" which failed with inline error.

***Describe XD Deployment : Distributed 

Deployment Type : Distributed - YARN ( on AWS EC2 cloud )
Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers 


***Describe Other Components

Transport: Redis 3.0.1
ZooKeeper: Version 3.4.6.2.3.2.0-2950


Hadoop deployment
Data Platform : Hortonworks HDP 2.3.2.0-2950
RDBMS: MySQL 


***Error Message: 

*****************************************************
INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'test_hive_job': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'hive': Cannot resolve reference to bean 'hive-tasklet' while setting bean property 'tasklet'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'hive-tasklet': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/hive/service/HiveClient
        at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)
        at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1481)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1226)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:753)
        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:835)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:537)
        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
        at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
        at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:213)
        at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
        at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
        at org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365)
        at org.springframework.xd.dirt.server.container.DeploymentListener.deployJobModule(DeploymentListener.java:291)
        at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)
        at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)
        at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
        at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
        at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
        at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
        at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
        at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
        at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'hive-tasklet': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/hive/service/HiveClient
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196)
        at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
        ... 37 more
Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/service/HiveClient
        at java.lang.Class.getDeclaredMethods0(Native Method)
        at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
        at java.lang.Class.getDeclaredMethods(Class.java:1975)
        at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:606)
        at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:518)
        at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:504)
        at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:241)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1069)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196)
        at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
        at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1481)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1226)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543)
        ... 43 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.service.HiveClient
        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 63 more
}
*****************************************************
",XD-3728,Nachiket Bondale,batch-hive module from spring-xd-samples project is not working
42,,Gary Russell,"Two separate reports of problems with this property:

http://stackoverflow.com/questions/34439296/spring-xd-stream-deployment-failure

http://stackoverflow.com/questions/34514393/issue-in-spring-xd-cluster-when-deploying-my-module",XD-3727,Gary Russell,xd.module.sequence Property Missing
43,,sridhar," The processor module which is failing to load castor classes from the module path.The code works fine with eclipse DIRT based test cases. I am attaching the code to this email. The jar that it built has the jars that it need at runtime in /module../lib folder. 

The code worked fine when i put all the custom jars and application jar in xd/lib. Spoke to Thomas Risberg and confirm this is broken and need to be fixing.[^attachment-name.zip]",XD-3726,sridhar,Processor module does not load classes from custom module package
44,Gary Russell,Gary Russell,See https://github.com/spring-projects/spring-xd/issues/1871,XD-3725,Gary Russell,EmbeddedHeadersMessageConverter Buffer Overflow
45,,Yuwei Sung,"Spring XD Ambari plugin only supports HDB as job db. HDB is not good in production environment. It will be great if we can specify RDB in spring xd installation/config process. 
",XD-3724,Yuwei Sung,Add Job RDBMS config in Ambari plugin
46,,Frank,"I understand Kafka natively does not have the concept of message headers. However, Spring Integration messages do and a lot of SI components are built specifically for dealing with message headers (header-enricher, header-filter, header-value-router, etc...). In addition, message headers are very useful for tracking meta-information about messages as they progress through a system.

With the implementation of https://jira.spring.io/browse/XD-3621; Spring XD has limited support for custom headers when using Kafka as a transport. I say limited, because it is required to list all custom headers explicitly in servers.yml in order for the headers to be retained by the MessageBus.

This is less than ideal because it means that it is necessary to know all potential custom header values a user will require before starting the environment.

It would be nice to extend this functionality so that it is not necessary to list custom headers in the configuration. Instead, when operating in mode=embeddedHeaders, Spring XD will simply embeds ALL headers in the Kafka message. Or alternatively, allow for a wildcard in the 'headers' configuration option so that it is not necessary to exhaustively list all possible custom header values prior to starting the system.",XD-3723,Frank,Improve support for custom headers when using Kafka Message Bus
47,,Muhammad Ali,I have IE 11. The XD admin UI stops responding after the login prompt and I have to kill the browser every time. It's not functional. I have not tried it with security turned off. Attach is the screenshot of the version.,XD-3722,Muhammad Ali,Admin UI does not respond after login in IE 11 
48,Gunnar Hillert,Muhammad Ali,"I am using XD 1.2.1.RELEASE. I have following environment variables 

XD_CONFIG_NAME = mycompany
And 
SPRING_PROFILE_ACTIVE= prod, admin

i have XD configuration file (mycompany-prod.yml) with following security configuration

# Config to enable security on administration endpoints (consider adding ssl)
spring:
  profiles: prod
security:
  basic:
    enabled: true # false to disable security settings (default)
    realm: SpringXD
xd:
  security:
    authentication:
      file:
        enabled: true 
        users:
          xdadmin: pwd, ROLE_ADMIN,ROLE_VIEW,ROLE_CREATE

I get a login screen, login works alright. When i logout - i still see all the tabs and contents in all the tabs. See the attached screenshot.
",XD-3721,Muhammad Ali,XD Admin UI log out does not function properly
49,,GERVAIS Mickaël,"Hi,

I've develop a custom Job which have to publish message on RabbitMq when it's finished.

To develop this module, I'veto include this libraries:
* com.rabbitmq:amqp-client:jar
* org.springframework.amqp:spring-rabbit:jar
* org.springframework.amqp:spring-amqp:jar

My job use this writer: org.springframework.batch.item.amqp.AmqpItemWriter

I've this error log:
{noformat}
 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]
{noformat}

This is typically due to a library loaded several times.

What is the solution to resolve this?

I'd like to use the same libraries has RabbitMq Source/Sink or the transport bus.

Does module classloader isolated from others?

Thanks

Mickaël",XD-3720,GERVAIS Mickaël,Custom job with RabbitMq dependencies 
50,,fadzi ushewokunze,In Flo when creating a stream if you use asterisk you get an error. See the image attached.,XD-3719,fadzi ushewokunze,Spring flo issue with unexpected char
51,Marius Bogoevici,Marius Bogoevici,"As a user, I want to be able to provide the partitioning logic for a named destination, so that I can control the ordering of outbound messages.",XD-3718,Marius Bogoevici,Kafka message bus must accept partitioning properties for named queues
52,,Derek OKeeffe,"I would like to be able to use the SpringXDTemplate to find all executions for a specific job

Currently I use xdTemplate.jobOperations().listJobExecutions() then loop through all executions filtering the ones for the job I'm interested in.

It would be nice if JobOperations had something like this

{code:java}
/**
 * List all Job Executions.
 * @param jobInstanceId The instance of the job to get all executions for.
 */
public PagedResources<JobExecutionInfoResource> listJobExecutions(long jobInstanceId);
{code}",XD-3717,Derek OKeeffe,Improvement to SpringXDTemplate to enable getting executions for a specific job
53,Gary Russell,Gary Russell,http://stackoverflow.com/questions/34053997/passing-headerinformation-as-jsonobject-in-header-in-spring-xd,XD-3716,Gary Russell,Support Configuring the RabbitMessageBus MessagePropertiesConverter LongString Limit
54,Eric Bottard,Sabby Anandan,"As a developer, I'd like to move k8s SPI to it's own repo.",XD-3715,Sabby Anandan,Move k8s SPI to a separate repo
55,Janne Valkealahti,Sabby Anandan,"As a developer, I'd like to upgrade Spring XD's ambari plugin to 1.3 release.",XD-3714,Sabby Anandan,Upgrade XD Ambari release to 1.3 
56,Thomas Risberg,Nachiket Bondale,"***Version
	Spring XD Version : spring-xd-1.3.0.RELEASE, spring-xd-1.3.0.RELEASE-yarn
	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64 
	Java Version: java version ""1.7.0_65""

***Description
	The batch-hashtag-count example from spring-xd-samples ran using spring xd is failing with inline error message.

***Steps to recreate the problem
	1. Followed steps present in README.asciidoc present at the Git repository link given below 
		https://github.com/spring-projects/spring-xd-samples/tree/master/batch-hashtag-count
	

	

***Describe XD Deployment : Distributed 

Deployment Type : Distributed - YARN ( on AWS EC2 cloud )
Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers 


***Describe Other Components

Transport: Redis 3.0.1
ZooKeeper: Version 3.4.6.2.3.2.0-2950


Hadoop deployment
Data Platform : Hortonworks HDP 2.3.2.0-2950
RDBMS: MySQL 


***Error Message: 

*****************************************************
2015-11-23 17:56:16,527 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: java.lang.ClassNotFoundException: Class or
g.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found
        at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)
        at org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:186)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:745)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found
        at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)
        at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)
        ... 8 more
*****************************************************",XD-3713,Nachiket Bondale,The batch-hashtag-count example from spring-xd-samples is giving java.lang.ClassNotFoundException Exception
57,,wenjie zhu,"XD spring deployment capabilities are supported by the active/standby?

example:
module.log.criteria=groups.contains('group1')

Above example is random selection? ",XD-3712,wenjie zhu,spring xd  supported active/standby mode?
58,,GERVAIS Mickaël,"XD container loose connection with Zookeeper.

I'm in a distributed environnement:
- 3 XD container nodes (1.2.1)
- 1 XD admin
- 3 Zookeeper
- 3 RabbitMQ
- 3 Redis/Sentinel

Logs:

*zookeeper.log*
{noformat}
2015-11-25 06:53:07,235 [myid:3] - INFO  [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:ZooKeeperServer@617] - Established session 0x251250651910006 with negotiated timeout 40000 for client /172.20.1.9:58070
2015-11-25 06:54:08,525 [myid:3] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@357] - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x251250651910006, likely client has closed socket
        at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
        at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
        at java.lang.Thread.run(Thread.java:745)
2015-11-25 06:54:08,621 [myid:3] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.20.1.9:58070 which had sessionid 0x251250651910006
{noformat}

*container.log*
{noformat}
2015-11-25T06:53:37+0100 1.2.1.RELEASE ERROR main-EventThread curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181,172.20.1.8:2181,172.20.1.9:2181) and timeout (30000) / elapsed (34187)
org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss
        at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]
        at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]
        at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.getZooKeeper(CuratorFrameworkImpl.java:474) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) [curator-client-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41) [curator-framework-2.6.0.jar:na]
        at org.springframework.xd.dirt.server.container.DeploymentListener$StreamModuleWatcher.process(DeploymentListener.java:596) [spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]
        at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67) [curator-framework-2.6.0.jar:na]
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) [zookeeper-3.4.6.jar:3.4.6-1569965]
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) [zookeeper-3.4.6.jar:3.4.6-1569965]
2015-11-25T06:53:37+0100 1.2.1.RELEASE ERROR CuratorFramework-0 curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181,172.20.1.8:2181,172.20.1.9:2181) and timeout (30000) / elapsed (34189)
org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss
        at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]
        at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]
        at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:793) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:779) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$400(CuratorFrameworkImpl.java:58) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:265) [curator-framework-2.6.0.jar:na]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_60]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_60]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]
2015-11-25T06:53:39+0100 1.2.1.RELEASE ERROR CuratorFramework-0 curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181,172.20.1.8:2181,172.20.1.9:2181) and timeout (30000) / elapsed (36191)
org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss
        at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]
        at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]
        at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:793) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:779) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$400(CuratorFrameworkImpl.java:58) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:265) [curator-framework-2.6.0.jar:na]
[...]
2015-11-25T06:54:34+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 26 seconds)...
2015-11-25T06:55:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 57 seconds)...
2015-11-25T06:56:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 117 seconds)...
2015-11-25T06:57:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 177 seconds)...
{noformat}

*admin.log*
{noformat}
2015-11-25T06:54:23+0100 1.2.1.RELEASE ERROR DeploymentSupervisor-0 cache.PathChildrenCache -
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/b1de9530-1837-42c0-a6bc-840b1b15aefc/JOB_TRIGGER.source.trigger.1
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[zookeeper-3.4.6.jar:3.4.6-1569965]
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[zookeeper-3.4.6.jar:3.4.6-1569965]
        at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155) ~[zookeeper-3.4.6.jar:3.4.6-1569965]
        at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302) ~[curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291) ~[curator-framework-2.6.0.jar:na]
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[curator-client-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287) ~[curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279) ~[curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41) ~[curator-framework-2.6.0.jar:na]
        at org.springframework.xd.dirt.server.admin.deployment.zk.DepartingContainerModuleRedeployer.deployModules(DepartingContainerModuleRedeployer.java:116) ~[spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]
        at org.springframework.xd.dirt.server.admin.deployment.zk.ContainerListener.childEvent(ContainerListener.java:140) ~[spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]
        at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) [curator-recipes-2.6.0.jar:na]
        at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) [curator-recipes-2.6.0.jar:na]
        at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) [curator-framework-2.6.0.jar:na]
        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) [guava-16.0.1.jar:na]
        at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) [curator-framework-2.6.0.jar:na]
        at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) [curator-recipes-2.6.0.jar:na]
        at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) [curator-recipes-2.6.0.jar:na]
        at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) [curator-recipes-2.6.0.jar:na]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_60]
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_60]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_60]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_60]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]
{noformat}

If a module is deployed on the node which has lost the connection, it's not redeployed on one of the two others.

The only difference between node, is that the node in error has less memory.

When this occurs, node doesn't appear anymore on the admin ui. And deployed streams do not appear as incomplete, but they should if a node has disappear and deployment property _module.*.count_ is set to the number of nodes.

Thanks.

Mickaël",XD-3711,GERVAIS Mickaël,XD  / Zookeeper connection lost.
59,Thomas Risberg,Nachiket Bondale,"***Version
	Spring XD Version : spring-xd-1.3.0.RELEASE, spring-xd-1.3.0.RELEASE-yarn
	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64 
	Java Version: java version ""1.7.0_65""

***Description
	The simple word count map reduce job using spring xd is failing with inline error message.

***Steps to recreate the problem
	1. Created a jar for simple word count map reduce job.
	2. Created jar using information given in ( http://docs.spring.io/spring-hadoop/docs/2.0.2.RELEASE/reference/html/hadoop.html#hadoop:tasklet )
	3. Once the final jar was ready, uploaded using ""module upload --name test_mr_module --type job --file /home/user/jar/samplemrjob.jar""
	4. After that created and deployed job using ""job create --name test_mr_job --definition test_mr_module --deploy""
	5. Finally launched using ""job launch test_mr_job"" which failed with inline error.

***Describe XD Deployment : Distributed 

Deployment Type : Distributed - YARN ( on AWS EC2 cloud )
Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers 


***Describe Other Components

Transport: Redis 3.0.1
ZooKeeper: Version 3.4.6.2.3.2.0-2950


Hadoop deployment
Data Platform : Hortonworks HDP 2.3.2.0-2950
RDBMS: MySQL 


***Error Message: 

*****************************************************
05:29:52,673   INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'test_mr_job'
05:29:53,655   INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@6e5af900 moduleName = 'test_mr_module', moduleLabel = 'test_mr_module', group = 'test_mr_job', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]]
05:30:24,351  ERROR inbound.job:test_mr_job-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step teststep in job test_mr_job
java.lang.IllegalArgumentException: Unable to parse '/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework' as a URI, check the setting for mapreduce.application.framework.path
        at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:443)
 	.
	.	
	.
        at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:54)
        at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:323)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.URISyntaxException: Illegal character in path at index 11: /hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework
        at java.net.URI$Parser.fail(URI.java:2848)
        at java.net.URI$Parser.checkChars(URI.java:3021)
        at java.net.URI$Parser.parseHierarchical(URI.java:3105)
        at java.net.URI$Parser.parse(URI.java:3063)
        at java.net.URI.<init>(URI.java:588)
        at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:441)
*****************************************************",XD-3710,Nachiket Bondale,Facing issue while running Spring XD batch job on HDP version 2.3.2.0-2950
60,Gary Russell,Gary Russell,"For some reason, the Integration {{MBeanExporterHelper}} is not preventing the standard context {{MBeanExporter}} from exporting the {{AbstractMessageRouter}}. This should be suppressed (when an IMBE is present) because it's annotated {{@IntegrationManagedResource}}.

Causes {{InstanceAlreadyExistsException}}.

Workaround in the stack overflow answer.

http://stackoverflow.com/questions/33838502/error-deploying-more-than-one-stream-with-a-router-1-3-0

Could be an SI issue, but investigation needed. However, we should probably include the stream/job name in all MBeans for the stream (as is done for the integration exporter).",XD-3709,Gary Russell,Duplicate MBean Names With router Sink
61,Michael Minella,Sabby Anandan,"As a developer, I'd want to document the limitations of HSQL DB when using composed jobs. ",XD-3708,Sabby Anandan,Document limitations with HSQL when using composed jobs
62,Gunnar Hillert,Sabby Anandan,"As a user, I'm trying to get all job definitions, but the first 20 alone are returned.

Job samples:
{code}
job create aaa --definition ""hello"" --deploy
job create bbb --definition ""hello"" --deploy
job create ccc --definition ""hello"" --deploy
job create ddd --definition ""hello"" --deploy
job create eee --definition ""hello"" --deploy
job create fff --definition ""hello"" --deploy
job create ggg --definition ""hello"" --deploy
job create hhh --definition ""hello"" --deploy
job create iii --definition ""hello"" --deploy
job create jjj --definition ""hello"" --deploy
job create kkk --definition ""hello"" --deploy
job create lll --definition ""hello"" --deploy
job create mmm --definition ""hello"" --deploy
job create nnn --definition ""hello"" --deploy
job create ooo --definition ""hello"" --deploy
job create ppp --definition ""hello"" --deploy
job create qqq --definition ""hello"" --deploy
job create rrr --definition ""hello"" --deploy
job create sss --definition ""hello"" --deploy
job create ttt --definition ""hello"" --deploy
job create uuu --definition ""hello"" --deploy
job create vvv --definition ""hello"" --deploy
job create www --definition ""hello"" --deploy
job create xxx --definition ""hello"" --deploy
job create yyy --definition ""hello"" --deploy
job create zzz --definition ""hello"" --deploy
job create aaa1 --definition ""hello"" --deploy
job create bbb1 --definition ""hello"" --deploy
job create ccc1 --definition ""hello"" --deploy
job create ddd1 --definition ""hello"" --deploy
job create eee1 --definition ""hello"" --deploy
{code}

Request:
{{http://localhost:9393/jobs/definitions.json}} - returns top 20; the other experiments with page size of either 0 or -1 still brings the top 20.",XD-3707,Sabby Anandan,Job definitions request limits 20 results by default
63,Eric Bottard,Sabby Anandan,"As a user, I'm trying to use {{counter}} sink with {SpEL}} expression, but I'm not able to use them in combination. It [throws|https://github.com/spring-cloud/spring-cloud-stream-modules/blob/master/counter-sink/src/main/java/org/springframework/cloud/stream/module/metrics/CounterSinkProperties.java#L77] {{exactly one of 'name' and 'nameExpression' must be set}} as error message.

",XD-3706,Sabby Anandan,Counter sink does not accept SpEL expressions
64,Gary Russell,Sabby Anandan,"As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.",XD-3705,Sabby Anandan,Bump Boot and spring-cloud-build Versions
65,,David Turanski,"See the attatched log (xd.out) showing :
{{
Caused by: java.lang.IllegalStateException: A connection to a distributed system already exists in this VM.  It has the following configuration:
  ack-severe-alert-threshold=""0""
  ack-wait-threshold=""15""
  archive-disk-space-limit=""0""
  archive-file-size-limit=""0""
  async-distribution-timeout=""0""
  async-max-queue-size=""8""
  async-queue-timeout=""60000""
  bind-address=""""
  cache-xml-file=""cache.xml""
  cluster-ssl-ciphers=""any""
  cluster-ssl-enabled=""true""
  cluster-ssl-keystore=""/Users/dturanski/trusted.keystore""
  cluster-ssl-keystore-password=""password""
  cluster-ssl-keystore-type=""jks""
  cluster-ssl-protocols=""any""
  cluster-ssl-require-authentication=""true""
  cluster-ssl-truststore=""/Users/dturanski/trusted.keystore""
  cluster-ssl-truststore-password=""password""
...
}}

Steps to reproduce:

Refer to: http://gemfire.docs.pivotal.io/latest/managing/security/ssl_example.html

1) Install the the attached keystore
2) Install attached gemfire.properties in $XD_INSTALL/xd/config
3) Install a copy of gemfire.properties in the server path,  e.g., if using the gemfire server app installed with the distribution,  $XD_INSTALL/gemfire,  and run bin/gemfire
4) Start the gemfire server
5) Start xd singlenode
6) Start the shell and deploy a stream using a gemfire module (this was reported with gemfire-json-server sink, but in theory it will affect any since it occurs during client cache creation). 

Note: I verified this SSL configuration works with a simple SDG client against the XD server. (Use SDG 1.6.2, and gemfire 8.0.0).  Also, the gemfire-json-server example in the XD reference works as expected without the SSL configuration. 

This may to be related to the module using a its own class loader. `java.lang.IllegalStateException: A connection to a distributed system already exists in this VM` happens because there are 2 instances of DistributedSystem created (one for each class loader?). This happens even when all the module jars are moved to xd/lib to force all gemfire classes to be loaded in the parent class loader.  
 ",XD-3704,David Turanski,Gemfire modules fail to deploy when SSL enabled
66,,Franck MARCHAND,Add SSL and attachments to Mail sink module. see XD-2076 & XD-2498.  ,XD-3703,Franck MARCHAND,Add SSL and attachments to mail sink
67,Marius Bogoevici,Marius Bogoevici,"As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module, so that I can take advantage of the native Kafka partitioning and message ordering support.",XD-3702,Marius Bogoevici,Support partitioning for Kafka even if count == 1
68,Gary Russell,Gary Russell,"When a problem occurs connecting to admin, we just get {{Unable to contact Data Flow Admin}} even if the connection is successful and some problem occurs when interpreting the result.

The exception is eaten.

Log an error including the exception.

Currently investigating an NPE in DataFlowTemplate @ line 77.",XD-3701,Gary Russell,Improve Shell Connection Diagnostics
69,,Derek OKeeffe,"In our system we have built quite a few custom modules. It is currently possible for the end user to mess up the configuration of these custom modules when creating multiple streams. They can create conflicting configuration in multiple streams. The conflicting config is nothing to do with spring-xd itself, it is related to our data flow and business process.

It would be nice to have some sort of StreamDeployValidator that I could implement and write my custom validation code. If this decides that the stream definition is not valid (according to my rules) then it could stop the deployment of a stream. The validator would need to be aware of the other streams somehow.

",XD-3700,Derek OKeeffe,Stream deployment validation
70,Eric Bottard,Sabby Anandan,"As a developer, I'd like to remove the hardcoded buildpack reference since the latest 1.6.2 ER release includes all the features required by Data Flow. ",XD-3699,Sabby Anandan,Remove hardcoded buildpack commit reference
71,Gunnar Hillert,Sabby Anandan,"As a user, I created a composed job with over 10 child jobs in the workflow; I expected to see 'a' job in the execution list page without any pagination, but instead I noticed empty pagination to skip to next page.",XD-3698,Sabby Anandan,Execution list page includes child jobs in pagination scope
72,Gary Russell,Daniel Garcia Perez,"If the output module is connected to a named channel, cannot be set up the property minPartitionCount, it is giving an exception.

Streams:
stream create f --definition ""queue:foo > transform --expression=payload+'-foo' | log"" 
stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log""
stream deploy --name f --properties ""module.transform.count=2""
stream deploy --name b --properties ""module.transform.count=2""

stream create r --definition ""time | router --expression=payload.contains('10')?'queue:foo':'queue:bar'""
stream deploy --name r --properties ""module.router.producer.minPartitionCount=20""

The error is:
Caused by: java.lang.IllegalArgumentException: KafkaMessageBus does not support producer property: minPartitionCount for queue:bar.
at org.springframework.xd.dirt.integration.bus.MessageBusSupport.validateProperties(MessageBusSupport.java:781) ~[spring-xd-messagebus-spi-1.2.1.RELEASE.jar:1.2.1.RELEASE]",XD-3697,Daniel Garcia Perez,Output modules cannot use minPartitionCount when sending to named channels
73,Gary Russell,Sabby Anandan,"As a developer, I'd like to upgrade to SI 4.2.2.GA release, so I can leverage the latest improvements.",XD-3696,Sabby Anandan,Upgrade to SI 4.2.2.GA
74,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to upgrade to 2.2.1 GA release, so I can leverage the latest improvements without breaking backwards compatibility. SHDP 2.3.0 uses Boot 1.3 and HDP and CDH versions that drop older Hive support. To avoid breaking changes we should instead use SHDP 2.2.1 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones.",XD-3695,Sabby Anandan,Upgrade to SHDP 2.2.1.GA
75,,Eric Bottard,"With the inclusion of https://github.com/spring-cloud/spring-cloud-stream/commit/80b1d28be1c8b9a23099b145fe2dcf472bfa9697, any module that explicitly injected/looked up the SI EC don't need to do so anymore.

This issue is about simplifying those",XD-3694,Eric Bottard,Remove unnecessary SI EvalCtx injection in modules
76,Gary Russell,Gary Russell,"I don't recall why [this commit | https://github.com/garyrussell/spring-xd/commit/ba15a1390f7e448dbc723ee76a45c2e239e0994e] was not applied to master but having the timestamp for each step in the history will be useful.

See [this github issue | https://github.com/spring-projects/spring-xd-modules/issues/24#issuecomment-154436643].
",XD-3693,Gary Russell,Add Timestamp to XD Message History
77,Janne Valkealahti,Sabby Anandan,"As a developer, I'd like to optimize YARN deployer, so I can deploy stream and the modules part of the definition rapidly.",XD-3692,Sabby Anandan,Optimize YARN deployer
78,Gunnar Hillert,Glenn Renfro,"If using the definition <aaa || bbb> where the definition starts with a ""<"" and ends with a "">"" the definition for the composed job does not appear on the definition page.",XD-3691,Glenn Renfro,Ensure Job definitions are escaped in UI
79,Thomas Risberg,Thomas Risberg,Make it more clear what drivers need to be copied where. See - https://github.com/spring-projects/spring-xd/issues/1653,XD-3690,Thomas Risberg,"Improve ""Server Configuration - Database Configuration"" section"
80,Glenn Renfro,Glenn Renfro,"Users want the ability to use Composed Jobs (specifically parallel Jobs) without having to update the configurations for the hsqldb and the Isolation Level for spring batch.  These should be set by default.
",XD-3689,Glenn Renfro,Update default configs to support Composed Jobs
81,,Gary Russell,"As a developer, I'd like to be able to clean Rabbit binder broker artifacts using the REST API.

When the Rabbit Bus was ported from XD, the bus cleaner was ported as {{RabbitBindingCleaner}} but the REST API to invoke it was not ported over.",XD-3688,Gary Russell,Rabbit Binder Cleaner REST API
82,Glenn Renfro,Glenn Renfro,"Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs:
1) uncomment and change the following from  :
```spring:
  batch:
# Configure other Spring Batch repository values.  Most are typically not needed
    isolationLevel: ISOLATION_SERIALIZATION
```
to
```spring:
  batch:
# Configure other Spring Batch repository values.  Most are typically not needed
    isolationLevel: ISOLATION_READ_COMMITTED
```  
And update the hsqldb datasource to:
spring:
  datasource:
    url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob};sql.enforce_strict_size=true;hsqldb.tx=mvcc",XD-3687,Glenn Renfro,Update Docs to add configs changes for Composed jobs
83,,Janne Valkealahti,"I got below error when executing modules on yarn and it was written in appmaster stderr output.
{code}
Exception in thread ""Thread-2"" java.lang.NoClassDefFoundError: org/apache/log4j/spi/ThrowableInformation
        at org.apache.log4j.spi.LoggingEvent.<init>(LoggingEvent.java:165)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.slf4j.impl.Log4jLoggerAdapter.log(Log4jLoggerAdapter.java:595)
        at org.apache.commons.logging.impl.SLF4JLocationAwareLog.warn(SLF4JLocationAwareLog.java:192)
        at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:969)
        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.doClose(EmbeddedWebApplicationContext.java:150)
        at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:893)
{code}

`LoggingEvent` is found from both `log4j-over-slf4j-1.7.12.jar` and `log4j-1.2.17.jar`. I suppose it depends on which one is used first to load this class.

Here's what we have in admin and appmaster jar files(spring-cloud-dataflow-yarn-build-tests is my local new sub-project to run tests on a hadoop minicluster):
{code}
unzip -l target/spring-cloud-dataflow-yarn-build-tests/spring-cloud-dataflow-yarn-appmaster-1.0.0.BUILD-SNAPSHOT.jar|grep jar|grep -i log
    62050  2013-05-16 22:04   lib/commons-logging-1.1.3.jar
   489884  2012-05-06 13:24   lib/log4j-1.2.17.jar
     8860  2015-03-26 21:56   lib/slf4j-log4j12-1.7.12.jar
     2234  2015-09-03 16:30   lib/spring-boot-starter-logging-1.3.0.M5.jar
    24567  2015-03-26 21:57   lib/log4j-over-slf4j-1.7.12.jar
    40824  2015-08-18 12:39   lib/tomcat-embed-logging-juli-8.0.26.jar
    66802  2015-05-28 09:49   lib/jboss-logging-3.3.0.Final.jar
{code}

{code}
unzip -l spring-cloud-dataflow-admin/target/spring-cloud-dataflow-admin-1.0.0.BUILD-SNAPSHOT.jar |grep jar|grep -i log
    62050  2013-05-16 22:04   lib/commons-logging-1.1.3.jar
   489884  2012-05-06 13:24   lib/log4j-1.2.17.jar
    40824  2015-08-18 12:39   lib/tomcat-embed-logging-juli-8.0.26.jar
    66802  2015-05-28 09:49   lib/jboss-logging-3.3.0.Final.jar
     2234  2015-09-03 16:30   lib/spring-boot-starter-logging-1.3.0.M5.jar
   280928  2015-03-24 12:06   lib/logback-classic-1.1.3.jar
   455041  2015-03-24 12:05   lib/logback-core-1.1.3.jar
    24567  2015-03-26 21:57   lib/log4j-over-slf4j-1.7.12.jar
{code}

Error went away when I removed `log4j-over-slf4j-1.7.12.jar` from maven deps for yarn appmaster jar. I suppose we have same issue with admin server.
",XD-3686,Janne Valkealahti,log4j/log4j-over-slf4j logging issue
84,Gunnar Hillert,Glenn Renfro,"In this scenario we created 30 jobs that can be used for a composed job.  
if the composed job uses jobs in its composition that are not present on the first page of the of the result set the following exception is thrown.  

{noformat}
2015-11-02T14:47:17-0500 1.3.0.SNAP ERROR qtp1587928736-26 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.IllegalStateException: Not all instances were looked at: fff
	at org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:244) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:209) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.rest.JobsController.list(JobsController.java:128) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]
	at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source) ~[na:na]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]
	at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:735) [javax.servlet-3.0.0.v201112011016.jar:na]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:207) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]
	at java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]
{noformat}",XD-3685,Glenn Renfro,Job Definitions page fails to display definitions if page 
85,Michael Minella,Sabby Anandan,"As a user, I'm trying to create a composed job with >20 steps/transitions using Rabbit as the message bus and it doesn't complete successfully.",XD-3684,Sabby Anandan,Job composition fails for large transitions
86,Glenn Renfro,Sabby Anandan,"As a user, I'm trying to compose a job just with one definition; however, I'm getting the following error message, which could be misinterpreted.

{code}
xd:>job create salsa --definition timestampfile
Successfully created job 'salsa'
xd:>job create foo --definition ""salsa || salsa""
Successfully created job 'foo'
xd:>job create foo222 --definition ""salsa""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'salsa' and type 'job'
{code}",XD-3683,Sabby Anandan,Fix composed job error message
87,,Sabby Anandan,"As a developer, I'd like to add {{undeployed}} status for Mesos SPI, so I can represent the correct status instead of the current {{unknown}} state.",XD-3682,Sabby Anandan,Add 'undeployed' status for Mesos SPI
88,,Sabby Anandan,"As a developer, I'd like to add {{undeployed}} status for k8s SPI, so I can represent the correct status instead of the current {{unknown}} state.",XD-3681,Sabby Anandan,Add 'undeployed' status for k8s SPI
89,Eric Bottard,Sabby Anandan,"As a developer, I'd like to add support for {{undeployed}} status consistently across all the deployers, so I can present the correct status instead of the current {{unknown}}. This is applicable for existing streams without any deployment context associated with it. ",XD-3680,Sabby Anandan,"Add consistent support for ""undeployed"" state across the deployers"
90,,Sabby Anandan,"As a developer, I'd like to add {{undeployed}} status for Lattice SPI, so I can represent the correct status instead of the current {{unknown}} state.",XD-3679,Sabby Anandan,Add 'undeployed' status for Lattice SPI
91,,Sabby Anandan,"As a developer, I'd like to add {{undeployed}} status for CF SPI, so I can represent the correct status instead of the current {{unknown}} state.",XD-3678,Sabby Anandan,Add 'undeployed' status for CF SPI
92,,Sabby Anandan,"As a developer, I'd like to create separate repo for Mesos SPI, so I don't have to bundle all SPI variants under one admin project.
",XD-3677,Sabby Anandan,Create admin artifact and CI build for Mesos
93,,Sabby Anandan,"As a developer, I'd like to create separate repo for K8s SPI, so I don't have to bundle all SPI variants under one admin project.
",XD-3676,Sabby Anandan,Create admin artifact and CI build for K8s
94,,Sabby Anandan,"As a developer, I'd like to create separate repo for Lattice SPI, so I don't have to bundle all SPI variants under one admin project.",XD-3675,Sabby Anandan,Create admin artifact and CI build for Lattice
95,Mark Fisher,Sabby Anandan,"As a developer, I'd like to create separate repo for CF SPI, so I don't have to bundle all SPI variants under one admin project.",XD-3674,Sabby Anandan,Create admin artifact and CI build for CF
96,Marius Bogoevici,Sabby Anandan,"As a follow-up from [XD-3613|https://jira.spring.io/browse/XD-3629], we would want to fix this experience for Kafka message bus.",XD-3673,Sabby Anandan,Multiple module instances produces duplicate messages 
97,Eric Bottard,Sabby Anandan,"As a developer, I'd like to submit a PR for existing work on Mesos SPI. ",XD-3672,Sabby Anandan,Move Mesos SPI to a separate repo
98,,Sabby Anandan,"As a user, I'd like to have direct shell commands to scale up/down a given module instance, so I can avoid SPI specific CLI commands that needs run outside of data flow.",XD-3671,Sabby Anandan,Spike: Explore options to scale modules from shell
99,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to revisit the existing design and identify known limitations and/or the gaps. ",XD-3670,Sabby Anandan,Spike: Revisit the core design and document gaps
100,Sabby Anandan,Sabby Anandan,"As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL, so it will be easy for me to relate to concepts. ",XD-3669,Sabby Anandan,Add Flo screenshots to Batch DSL section
101,,Sabby Anandan,"As a user, I'd like to see the version and SPI type in the `about` section, so I can confirm which build of {{admin-ui}} I'm currently using. ",XD-3668,Sabby Anandan,UI: Add SPI type and version to about section
102,,Sabby Anandan,"As a developer, I'd like to troubleshoot and fix {{root}} level access over CF SPI REST calls; they're broke at the moment. 

Access for following calls fail:

{code}

href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/streams""
href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/tasks""
href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters""
href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters/{name}"",
href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/modules""
href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/completions/stream{?start,detailLevel}"",
{code}",XD-3667,Sabby Anandan,CF SPI REST calls are not working 
103,,Sabby Anandan,"As a user, I'd like to use the admin-ui and flo with consistent look and feel. ",XD-3666,Sabby Anandan,UI: [Spike] Study PUI theming scope
104,,Sabby Anandan,"As a user, I'm trying to load Task, Task Deployment, and Task Executions page, but I'm seeing an error {{(Error fetching data. Is the XD server running?)}} instead. ",XD-3665,Sabby Anandan,UI: Task deployment page is not loading
105,,Sabby Anandan,"As a developer, I'd like to replace all {{Job(s)}} references with {{Task(s)}}. ",XD-3664,Sabby Anandan,UI: Replace Job references with Task
106,,Sabby Anandan,"As a user, I'm trying to load Job - Modules page in admin-ui, but I'm seeing exceptions in console and the page wouldn't load. 

{code}
Failed to convert value of type 'java.lang.String' to required type 'org.springframework.cloud.dataflow.core.ArtifactType'; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @org.springframework.web.bind.annotation.RequestParam org.springframework.cloud.dataflow.core.ArtifactType for value 'job'; nested exception is java.lang.IllegalArgumentException: No enum constant org.springframework.cloud.dataflow.core.ArtifactType.job
{code}",XD-3663,Sabby Anandan,UI: Job modules page wouldn't load
107,Gunnar Hillert,Sabby Anandan,"As a developer, I'd like to replace all references of Spring XD with Spring Cloud Data Flow. ",XD-3662,Sabby Anandan,UI: Replace XD with Data Flow
108,,Sabby Anandan,"As a developer, I'd like to upgrade to {{0.6.0}} release of Lattice, so I can demonstrate data flow on the latest Lattice improvements. ",XD-3661,Sabby Anandan,Upgrade to Lattice 0.6.0 release
109,Mark Fisher,Sabby Anandan,"As a developer, I'd like to create separate repo for YARN SPI, so I don't have to bundle all SPI variants under one admin project.",XD-3660,Sabby Anandan,Create admin artifact and CI build for YARN
110,,Sabby Anandan,"As a developer, I'd like to split {{admin}} artifact packaged with hadoop distro specific libraries, so I could avoid adding all variations of hadoop libraries under one project. ",XD-3659,Sabby Anandan,Create admin artifact for each Hadoop distro
111,,Manikantan,"org.apache.sqoop.validation.Validator interface doesn't contain any job information and it has only ValidationContext object reference. I am trying to write custom class that implements Validator class and trying to store the source count and destination count into data base. But I need some reference about Job like job ID, name, start time, end time etc. I think we can have org.apache.hadoop.mapreduce.Job instance or any other reference to the Job would help.",XD-3658,Manikantan,"Validator interface doesn't contains any Job details like ID, name etc"
112,,Manikantan,"I am able to run a Sqoop Job to copy data from oracle to Hadoop and I can relaunch the job manually through shell command or admin UI. But I don't see option to set some number or auto retry option, so that when ever failure happens, system will automatically retry some number of times that we specify.",XD-3657,Manikantan,Unable to find an option for restart Sqoop Job automatically when it is failed
113,,Sabby Anandan,"As a developer, I'd like to add {{undeployed}} status for YARN SPI, so I can represent the correct status instead of the current {{unknown}} state.",XD-3656,Sabby Anandan,Add 'undeployed' status for YARN SPI
114,Gunnar Hillert,Sabby Anandan,,XD-3655,Sabby Anandan,Document admin-ui improvements
115,Glenn Renfro,Sabby Anandan,"As a user, I'd like to refer to 'job orchestration' documentation, so I can use it as guideline for building batch workflows.  ",XD-3654,Sabby Anandan,Documentation: Flo for XD Batch
116,,Sabby Anandan,"As a user, I cannot use {{admin-ui}} on the master build. It won't come up. ",XD-3653,Sabby Anandan,Admin UI does not load on master build
117,Patrick Peralta,Marius Bogoevici,"Both lifecycle and send/receive methods are synchronized, so if the shell command processor is blocked reading from the script's input - e.g. when no proper terminator is sent by the script, the stop() method can't acquire the object lock and proceed stopping the instance, and therefore the module. ",XD-3652,Marius Bogoevici,The shell processor module cannot be stopped while blocked in receive()
118,Thomas Risberg,Thomas Risberg,As a module developer I would like the JsonStringToTupleConverter in the Spring Cloud Streams project to maintain the types provided in the JSON string and not convert everything to a String representation.,XD-3651,Thomas Risberg,The JsonStringToTupleConverter converts all values to String
119,,GERVAIS Mickaël,"Hi,

I'm trying to create a composed module with two _transform_ processors:


{noformat}
module compose --name my-module-prepare --definition ""filter-events:transform --script=myscript.groovy --propertiesLocation=myscript.properties | transformer | change-body:transform --expression=payload.getValue()"" --force
{noformat}

After I use this module into my stream:
{noformat}
stream create --name MY_STREAM --definition ""topic:MY_TOPIC > my-module-prepare | mongodb""
{noformat}

But when I'm trying to deploy I get this error: 


{code:java}
Field error in object 'target' on field 'valid': rejected value [false]; codes [AssertTrue.target.valid,AssertTrue.valid,AssertTrue.boolean,AssertTrue]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.valid,valid]; arguments []; default message [valid]]; default message [the 'script' and 'expression' options are mutually exclusive]
{code}

After some investgiation, it appears that module properties for both transform module seems to be merged so I've this in the instance of __ExpressionOrScriptMixin__ :
{noformat}
expression	""payload.getValue()"" (1) 	
propertiesLocation	""myscript.properties"" (2)	
script	""myscript.groovy"" (2)	
{noformat}

*1* : correspond with change-body:transform properties
*2* : correspond with filter-events:transform properties
*3* : correspond with filter-events:transform properties

So the method _org.springframework.xd.module.options.mixins.ExpressionOrScriptMixin.isValid()_ cannot succeed.

I'm using Spring XD in a distributed environment with Zookeeper, RabbitMq & Redis for analytics.

Is there a way to deploy this king of composite module?

Thanks for any help

Mickaël

P.S: is this rlated to [https://jira.spring.io/browse/XD-3010] ?",XD-3650,GERVAIS Mickaël,Unable to compose XD module with several transform processors
120,,Sabby Anandan,"As a user, I'd like to use SpEL expressions inline at the stream definition level, so I can operate on the payload consistently while using any OOTB, including the custom modules. ",XD-3649,Sabby Anandan,Make SpEL usage consistent across all including custom modules
121,Gunnar Hillert,Gunnar Hillert,,XD-3648,Gunnar Hillert,Job Executions without Deployed Job (deleted) shall not be restartable
122,,Thomas Risberg,We currently support HDP 2.3.0. The most recent HDP version is 2.3.2. This latest HDP release also changes Spark version to 1.4.1.,XD-3647,Thomas Risberg,Update support for Hortonworks to HDP 2.3.2
123,,David Geary,"This would allow multiple individual sink modules to be combined via the shell DSL so that each message sent to the composite sink module will be sent to each of the individual sink modules in turn. 
Internally this would probably use a recipient list router to send to each individual sink.

Module options for each individual sink would be combined to create the overall options for the composite sink module in a similar way to existing composite modules.

This would allow construction of streams with less communication with the message bus for example as an alternative to using a named topic in the message bus.

Using this in conjunction with sinks built using existing composite module functionality (as a combination of processors and a sink) would allow more sophisticated combinations to be constructed and deployed as a single module (with no message bus communication).

One particular application of this would be with tap and counter functionality. If multiple fields in a message need counted this currently needs to be done as separate streams tapping the original with the overhead of the tapped message being read from the message bus multiple times potentially on different nodes, this enhancement would allow all the counters to be combined to make a more cohesive composite counter module so that the tapped message would only need to be read once.
",XD-3646,David Geary,Composite Multiple Sink Module
124,Mark Pollack,Martin Dam,"Serializing a tuple object with that have a nested array which contains objects (as a tuple) fails to serialize. The error is:

{noformat}
Caused by: com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.springframework.xd.tuple.DefaultTupleConversionService and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: java.util.ArrayList[0]->org.springframework.xd.tuple.DefaultTuple[""values""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.xd.tuple.DefaultTuple[""conversionService""])
	at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:2881) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2338) ~[jackson-databind-2.4.5.jar:2.4.5]
	at org.springframework.xd.tuple.TupleToJsonStringConverter.convert(TupleToJsonStringConverter.java:37) ~[spring-xd-tuple-1.3.0.M1.jar:1.3.0.M1]
{noformat}
when the input string (read from a Kafka topic in my case) looks something like:

{noformat}
{
    ""body"": [
        {
            ""dataType"": ""har"",
            ""har"": {
                ""log"": {
                    ""browser"": {
                        ""name"": ""Google Chrome"",
                        ""version"": ""44.0.2403.155""
                    },
                    ""creator"": {
                        ""name"": ""My extension"",
                        ""version"": ""0.23.6""
                    },
                    ""pages"": [
                        {
                            ""_requestTimings"": {
                                ""blocked"": -1,
                                ""connect"": -1,
                                ""dns"": -1,
                                ""receive"": 11,
                                ""send"": -1,
                                ""ssl"": -1,
                                ""wait"": 244
                            },
                            ""_requestUrl"": ""https://google.com""
                        },
                        {
                            ""_requestTimings"": {
                                ""blocked"": -1,
                                ""connect"": -1,
                                ""dns"": -1,
                                ""receive"": 11,
                                ""send"": -1,
                                ""ssl"": -1,
                                ""wait"": 244
                            },
                            ""_requestUrl"": ""https://google.com""
                        }
                    ],
                    ""version"": ""1.2""
                }
            },
            ""testId"": 1
        }
    ],
    ""bodyType"": ""models.MultiMessage"",
    ""headers"": {
        ""appInstance"": ""localhost/127.0.0.1:8080"",
        ""clientIp"": ""0:0:0:0:0:0:0:1"",
        ""host"": ""localhost:8080"",
        ""requestId"": ""27acf948-33ff-491c-8be7-1beb4b8c95d9"",
        ""requestMethod"": ""POST"",
        ""requestUrl"": ""http://localhost:8080/har"",
        ""timestamp"": 1445914510549,
        ""userPrincipal"": ""235""
    }
}
{noformat}
If the inner array (the Pages array) is just an object, it works, when it is an array, it fails. 

The stream used:
kafka --topic=agent_mixed --outputType=application/x-xd-tuple | splitter --expression=payload.body | log",XD-3645,Martin Dam,Tuple unable to serialize objects with nested arrays of objects
125,Andy Clement,Sabby Anandan,"As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ",XD-3644,Sabby Anandan,Add test coverage for batch DSL and XML generation variants
126,,David Geary,"Currently it’s possible to do this via 
{code}
source | router --expression=''queue:queue1,queue:queue2''
{code}
but this involves an additional hop to the message bus for the pipe between the source and router.

It would be better if this was supported directly with the existing named channel syntax to remove this pipe ie
{code}
source > queue:queue1,queue:queue2
{code}
This would be useful as a possible solution in the scenario described in XD-3613 as an alternative to using topics on the Redis message bus which don’t support having multiple instances of the same consumer.
",XD-3643,David Geary,Allow sending to multiple named channels at once
127,,Hector Lagos,"Hey Guys,

We are facing an annoying problem and I can't figure out how solve it. For some reason when we run a step that takes long time (4 hours or more), spring XD is unable to save the metadata and throws the following error. 

2015-10-25T09:49:10-0400 1.2.0.RELEASE ERROR task-scheduler-2 step.AbstractStep - Encountered an error executing step ingest-logs in job ingest-logs-flow
org.springframework.orm.jpa.JpaSystemException: commit failed; nested exception is org.hibernate.TransactionException: commit failed
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:244) ~[na:na]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:155) ~[na:na]
	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:521) ~[na:na]
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:757) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:150) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:368) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) [spring-core-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]
	at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at com.sun.proxy.$Proxy53.run(Unknown Source) [na:na]
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50) [spring-batch-integration-3.0.3.RELEASE.jar:3.0.3.RELEASE]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]
	at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:129) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) [spring-core-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292) [spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) [spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81) [spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_67]
	at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_67]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_67]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) [na:1.7.0_67]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_67]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_67]
	at java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]
Caused by: org.hibernate.TransactionException: commit failed
	at org.hibernate.engine.transaction.spi.AbstractTransactionImpl.commit(AbstractTransactionImpl.java:187) ~[na:na]
	at org.hibernate.jpa.internal.TransactionImpl.commit(TransactionImpl.java:77) ~[na:na]
	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[na:na]
	... 97 common frames omitted
Caused by: org.hibernate.TransactionException: unable to commit against JDBC connection
	at org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.doCommit(JdbcTransaction.java:116) ~[na:na]
	at org.hibernate.engine.transaction.spi.AbstractTransactionImpl.commit(AbstractTransactionImpl.java:180) ~[na:na]
	... 99 common frames omitted
Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Communications link failure during commit(). Transaction resolution unknown.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:389) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at com.mysql.jdbc.Util.getInstance(Util.java:372) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:958) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:937) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:872) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at com.mysql.jdbc.ConnectionImpl.commit(ConnectionImpl.java:1616) ~[mysql-connector-java-5.1.34.jar:5.1.34]
	at org.apache.commons.dbcp.DelegatingConnection.commit(DelegatingConnection.java:301) ~[commons-dbcp-1.4.jar:1.4]
	at org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.commit(PoolingDataSource.java:200) ~[commons-dbcp-1.4.jar:1.4]
	at org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.doCommit(JdbcTransaction.java:112) ~[na:na]
	... 100 common frames omitted
2015-10-25T09:49:10-0400 1.2.0.RELEASE ERROR task-scheduler-2 step.AbstractStep - Encountered an error saving batch meta data for step ingest-logs in job ingest-logs-flow. This job is now in an unknown state and should not be restarted.
org.springframework.dao.OptimisticLockingFailureException: Attempt to update step execution id=8 with wrong version (1), where current version is 2
	at org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.updateStepExecution(JdbcStepExecutionDao.java:255) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]

We are using a MySQL database with the following configurations. 

spring:
  datasource:
    url: jdbc:mysql://hosttomysql:3306/singnode
    username: admin
    password: admin
    driverClassName: com.mysql.jdbc.Driver
    validationQuery: select 1
    testOnBorrow: true


If you guys know this issue or have some ideas how solve, please let me know. Thanks in advance.
Héctor",XD-3642,Hector Lagos,Spring XD unable to save metadata for long steps
128,Gary Russell,Sabby Anandan,"As a developer, I'd like to review and refactor {{JobLaunchingTasklet}}, so I can improve performance characteristics. ",XD-3641,Sabby Anandan,Job composition improvements
129,,Eric Bottard,"Following merge of https://github.com/spring-cloud/spring-cloud-dataflow/commit/5cb81c49a240304be14bcf5d724cfd36df403d39, the following changes need to happen at shell/REST level:

{{module list}} should not show libraries
{{library list}} should be added to show libs
{{module register}} should not accept type=library
{{library register}} should be added
{{module info}} should not accept libs
{{library info}} should be added",XD-3640,Eric Bottard,Library support changes at shell level
130,,Eric Bottard,"See https://github.com/spring-cloud/spring-cloud-dataflow/issues/128

This is needed to support ""channel > channel"" type constructs",XD-3639,Eric Bottard,Create bridge processor
131,,Gary Russell,"The {{FieldValueCounterHandler}} handles {{POJO}}, {{Tuple}}, and {{JSON}}.

{{#jsonPath}} emits a {{LinkedHashMap}}.

The handler should natively support a {{Map}}.

See http://stackoverflow.com/questions/33270926/springxds-field-value-counter-doesnt-work-after-splitting-json-object-array-in/33281783#33281783",XD-3638,Gary Russell,Support Map Payloads in field-value-counter
132,Gary Russell,Sabby Anandan,"As a developer, I'd like to upgrade to SI 4.2.1 release, so I can take advantage of the latest improvements.",XD-3637,Sabby Anandan,Upgrade to SI 4.2.1
133,Andy Clement,Sabby Anandan,"As a Flo user, I'd like to have {{timeout}} and {{pollInterval}} as global options at the DSL level, so I can override the defaults at will. ",XD-3636,Sabby Anandan,"Add support for global ""options"" in DSL"
134,Mark Pollack,Sabby Anandan,"As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.",XD-3635,Sabby Anandan,Resolve remaining gaps with CI
135,,Eric Bottard,See discussion at https://github.com/spring-cloud/spring-cloud-stream/issues/159,XD-3634,Eric Bottard,Allow support for authentication to maven repos (AetherModuleResolver)
136,Eric Bottard,Sabby Anandan,"As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on: {{module list}} and as well as the module bits are not available in [maven repo|http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/module/]. ",XD-3633,Sabby Anandan,Add SFTP source to default registry
137,Mark Pollack,Steven Swor,"(copied from https://github.com/spring-projects/spring-xd/issues/1810):

While testing a reactive processor that I was building, I saw the following in my test environment's logs:

{noformat}
2015-10-19 18:33:22.594 +1100 INFO/MetadataDrivenFlatFileSplitter:114 - Start splitting file=/tmp/junit8525530428026993137/junit6584105040601814728.tmp
2015-10-19 18:33:22.612 +1100 INFO/MetadataDrivenFlatFileSplitter:86 - Done splitting file=/tmp/junit8525530428026993137/junit6584105040601814728.tmp
2015-10-19 18:33:23.833 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.834 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.835 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.839 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.839 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.840 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
{noformat}

Completions don't really seem like error events. Perhaps this could be changed to INFO?

(will open a PR shortly)",XD-3632,Steven Swor,Reactor message handlers log completions at error level
138,,Sabby Anandan,"As a user, I'd like to use the latest release of {{gemfire}} sink, so I can create a streaming pipeline to land data in gemfire. ",XD-3631,Sabby Anandan,Upgrade GF sink to 8.2
139,,Sabby Anandan,The comments in [22|https://github.com/spring-cloud/spring-cloud-stream-modules/pull/22] indicate that we also need to run a gemfire cache server in order for the tests to pass. We should create an embedded cache server since it would be much easier not have to have an XD or gemfire install in order to test the sink.,XD-3630,Sabby Anandan,Launch GF cache server for integration tests
140,Janne Valkealahti,Sabby Anandan,"As a user, I'd like to enable HA on {{namenode}} without having to enable custom configuration. 

More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].",XD-3629,Sabby Anandan,Turning on HA via Ambari plugin requires custom configuration
141,Janne Valkealahti,Sabby Anandan,"It seems like springxd_shell will pull jhs principal and keytab from mapred-site.xml. When springxd_shell is installed in edge node, Amabri returns ""can't find jhs keytab"" and failed.

Details [here|https://github.com/spring-projects/spring-xd-ambari/issues/8].",XD-3628,Sabby Anandan,Ambari plugin doesn't work with security_enabled
142,Mark Pollack,Sabby Anandan,"As a developer, I'd like to get rid off {{XDRuntimeException}} from XD.",XD-3627,Sabby Anandan,Get rid of XDRuntimeException
143,Patrick Peralta,Patrick Peralta,"Using these as a starting point, support the standard binder partitioning properties:

https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/BinderProperties.java#L69

https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupport.java#L663",XD-3626,Patrick Peralta,Support partitioning properties
144,Patrick Peralta,Patrick Peralta,Move project out of https://github.com/pperalta/geode-scdf into https://github.com/spring-cloud/spring-cloud-stream,XD-3625,Patrick Peralta,Move binder to SCS project
145,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to break the build lifecycle to bundle SPI deployers individually, so I don't have to build {{admin}} with all the deployer variations as one whole thing.",XD-3624,Sabby Anandan,Add support to build Admin with individual SPI deployers
146,,Hector Lagos,"Hello guys,

I hope you are doing good. I found a problem when I try run long sqoop imports (4 hours or more). For some reason when the sqoop step finish the system is not able to save the meta data for the current sqoop step however the sqoop import finish without problems.

2015-10-17T03:04:03-0400 1.2.0.RELEASE ERROR SimpleAsyncTaskExecutor-4 step.AbstractStep - Encountered an error saving batch meta data for step import-logs in job ingestion-flow. This job is now in an unknown state and should not be restarted.

Please see attached log file for more details. 
Could you please let me know if you need other details to find what is the problem? 

Thanks in advance
Héctor

",XD-3623,Hector Lagos,Job in unknown state after run long sqooptasklet
147,Gary Russell,Sabby Anandan,"As a developer, I'd like to port {{file}} module from XD to s-c-s repo, so I can use it as {{source}} module to build streaming pipeline.",XD-3622,Sabby Anandan,Port File as s-c-s source
148,Marius Bogoevici,Marius Bogoevici,"Currently, the Kafka Message Bus does not have the ability to configure a set of custom headers to persist in the `embeddedHeaders` mode (only the message-bus specific) message headers are persisted. ",XD-3621,Marius Bogoevici,Add support for custom headers with the Kafka bus
149,,Thomas Risberg,"We are seeing JDBC connection pool errors when running 'jdbchdfs' jobs and 'jdbc' streams. The exception is:

{code}
Caused by: java.sql.SQLException: Failed to validate a newly established connection.
        at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:802)
        at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:617)
        at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:186)
        at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)
        at org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:204)
        ... 21 more
{code}

A workaround is to specify ""--testOnBorrow=false"" when creating the job.

This has also been reported on SO (http://stackoverflow.com/questions/33148929/springxd-issue-in-mysql-as-source-failed-to-validate-a-newly-established-connec).",XD-3620,Thomas Risberg,JDBC connection pool errors
150,Janne Valkealahti,Sabby Anandan,"As a s-c-d user, I'd like to deploy data flow on YARN, so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.",XD-3619,Sabby Anandan,Study YARN SPI gaps
151,Eric Bottard,Sabby Anandan,"As a s-c-d user, I'd like to have {{runtime info}} as shell command, so I can use this to list the details about the module such as {{host}}, {{port}} and the like.",XD-3618,Sabby Anandan,"Add ""runtime info"" shell command"
152,Thomas Risberg,Thomas Risberg,,XD-3617,Thomas Risberg,Update build to use SHDP 2.3.0.RC1
153,Ilayaperumal Gopinathan,Eric Bottard,"There is a need to customize the ModuleLauncher behavior (itself, NOT pass options to modules that are launched, which is already supported) for example to set the location of the maven repository.

",XD-3616,Eric Bottard,Add standardized way to pass props from Deployers/Admin to ModuleLauncher
154,,Eric Bottard,"Currently, s-c-s modules all come with baked in support for multiple cloud binding technologies:

{code:xml}
		<!-- Lattice core dependency that activates cloud,lattice profiles when running on Lattice -->
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-lattice-core</artifactId>
			<version>${spring-cloud-lattice.version}</version>
			<optional>true</optional>
		</dependency>
		<!-- Cloud connector dependencies -->
		<!-- Lattice connector dependency to create services info from lattice -->
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-lattice-connector</artifactId>
			<version>${spring-cloud-lattice.version}</version>
			<optional>true</optional>
		</dependency>
		<!-- CF connector dependency to create services info from CF -->
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-cloudfoundry-connector</artifactId>
			<optional>true</optional>
		</dependency>
		<!-- dependency to connect to detected cloud services -->
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-spring-service-connector</artifactId>
			<optional>true</optional>
		</dependency>
{code}

Should the deployers add those at runtime instead?",XD-3615,Eric Bottard,"Modules/SCD Deployers: How to provide ""cloud connector"" support"
155,,Eric Bottard,"Most, if not all, of the deployers have some concept of customization of the deployed modules: be it memory, or cpu, disk, etc.

This ticket is about harmonizing the handling of such properties, with the assumption that we want a per-deployer set of defaults and overridability at deployment time.",XD-3614,Eric Bottard,Harmonize common deployer runtime properties applied to modules
156,Marius Bogoevici,David Geary,"If I deploy more than one instance of a module (eg using module.name.count > 1 or module.name.count =0) that consumes from a tap or topic then I get duplicate messages if I’m using Redis as the message bus. It looks like this is the same issue as XD-3100 but the fix for that only fixed Rabbit as the message bus.

This is easy to reproduce on a 2 container cluster using a Redis Message Bus:

Create and deploy streams as follows:

{code}
stream create --definition ""http | log"" --name httpLog
stream deploy --name httpLog --properties ""module.*.count=0""
stream create --definition ""tap:stream:httpLog > transform --expression='payload.toString() + \"" TAPPED\""' | log"" --name httpLogTap 
stream deploy --name httpLogTap --properties ""module.*.count=0""
{code}

On container 1 send a message:

{code}
curl --data ""test message 001"" http://localhost:9000/httpLog
{code}

Container 1 logs are then:

{code}
2015-10-13 14:16:28.853  INFO 22774 --- [ol-28-thread-18] xd.sink.httpLog                          : test message 001
2015-10-13 14:16:28.855  INFO 22774 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED
{code}

and container 2:

{code}
2015-10-13 14:16:28.859  INFO 22719 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED
{code}

Ie the tapped message is duplicated (picked up by both tap module instances)

Similarly for topics create and deploy these streams:

{code}
stream create --definition ""http > topic:mytopic"" --name httpTopic
stream deploy --name httpTopic --properties ""module.*.count=0""
stream create --definition ""topic:mytopic > transform --expression='payload.toString() + \"" TOPIC CONSUMER 1\""' | log"" --name topicConsumer1
stream deploy --name topicConsumer1 --properties ""module.*.count=0""
stream create --definition ""topic:mytopic > transform --expression='payload.toString() + \"" TOPIC CONSUMER 2\""' | log"" --name topicConsumer2
stream deploy --name topicConsumer2 --properties ""module.*.count=0""
{code}

On container 1 send a message:

{code}
curl --data ""test message 002"" http://localhost:9000/httpLog
{code}

Container 1 logs are then:

{code}
2015-10-13 14:34:23.168  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2
2015-10-13 14:34:23.172  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1
{code}

and container 2:

{code}
2015-10-13 14:34:23.173  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2
2015-10-13 14:34:23.177  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1
{code}

Ie the topic message is picked up by each instance of the module in each stream. In this case I would expect each stream to pick up the message once 
ie I would get a single output for each stream 

test message 002 TOPIC CONSUMER 2  once (on either container)
test message 002 TOPIC CONSUMER 1  once (on either container)",XD-3613,David Geary,Multiple module instances consuming from taps or topics get duplicate messages on redis Message Bus
157,,David Geary,"I have a distributed XD Cluster with one admin and two containers using Redis as the message bus. In certain cases I want to use direct binding to remove communication with the message bus and deploy all modules to all containers with the aim of improving performance. I’ve found that even when using direct binding, XD still communicates with Redis when it shouldn’t need to. This could have an impact on performance.

This is easily reproducible in our 2 container cluster as follows:

Use the redis-cli monitor command to monitor Redis.

Create and deploy a simple stream with direct binding:

{code}
stream create --definition ""http | log"" --name httpLog
stream deploy --name httpLog --properties ""module.*.count=0""
{code}

As expected both modules get deployed to both nodes. Testing shows messages sent to the http endpoint of one container always come out in the log for that container implying direct binding is in play as expected.

However once the streams are deployed the Redis monitor starts showing a Redis queue being accessed from both XD conatiners:

{code}
1444731527.086325 [0 10.0.1.8:57454] ""brpop"" ""queue.httpLog.0"" ""1""
1444731528.086304 [0 10.0.1.4:37337] ""brpop"" ""queue.httpLog.0"" ""1""
1444731529.086341 [0 10.0.1.8:57454] ""brpop"" ""queue.httpLog.0"" ""1""
1444731530.086317 [0 10.0.1.4:37337] ""brpop"" ""queue.httpLog.0"" ""1""
1444731531.086340 [0 10.0.1.8:57454] ""brpop"" ""queue.httpLog.0"" ""1""
1444731532.086505 [0 10.0.1.4:37337] ""brpop"" ""queue.httpLog.0"" ""1""
{code}

This shouldn’t need to happen in direct binding. These messages stop once the stream is undeployed.
",XD-3612,David Geary,Redis Message Bus still accessed when using direct binding
158,,Hector Lagos,"Hey Guys,

I have been using the sqoopTasklet for a while but I found an unexpected problem. Basically I'm not able to configure kerberos authentication from hadoop.properties file as follow:

<util:properties id=""hadoopProperties"" location=""${xd.config.home}/hadoop.properties"" />

        <bean id=""sqoopTasklet"" class=""org.springframework.xd.sqoop.SqoopTasklet"">
                <property name=""arguments"">
                        <list>
                                <value>import</value>
                                <value>--connect otheroptions</value>
                        </list>
                </property>
                <property name=""hadoopProperties"" ref=""hadoopProperties"" />
        </bean>

hadoop.properties file:

fs.defaultFS=hdfs://hdfshost:8020
yarn.resourcemanager.hostname=host001
yarn.resourcemanager.address=host001:8032
yarn.resourcemanager.scheduler.address=host001:8030
mapreduce.jobhistory.address=host003:10020
yarn.application.classpath=$HADOOP_CLIENT_CONF_DIR,$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*
mapreduce.framework.name=yarn
spring.hadoop.security.authMethod=kerberos
spring.hadoop.security.userPrincipal=user1@COMPANY.COM
spring.hadoop.security.userKeytab=/home/user1/user1.keytab
spring.hadoop.security.namenodePrincipal=hdfs/_HOST@COMPANY.COM
spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@COMPANY.COM
spring.hadoop.security.jobHistoryPrincipal=mapred/_HOST@COMPANY.COM

or 

fs.defaultFS=hdfs://hdfshost:8020
yarn.resourcemanager.hostname=host001
yarn.resourcemanager.address=host001:8032
yarn.resourcemanager.scheduler.address=host001:8030
mapreduce.jobhistory.address=host003:10020
yarn.application.classpath=$HADOOP_CLIENT_CONF_DIR,$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*
mapreduce.framework.name=yarn
security.authMethod=kerberos
security.userPrincipal=user1@COMPANY.COM
security.userKeytab=/home/user1/user1.keytab
security.namenodePrincipal=hdfs/_HOST@COMPANY.COM
security.rmManagerPrincipal=yarn/_HOST@COMPANY.COM
security.jobHistoryPrincipal=mapred/_HOST@COMPANY.COM

Running the job I'm getting the following error:

Encountered IOException running import job: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS

So it means the sqooptasklet isn't setting the kerberos authentication, this basically because in the SqoopTasklet class is adding some prefix to the configurations (SPRING_HADOOP_CONFIG_PREFIX)

https://github.com/spring-projects/spring-xd/blob/master/extensions/spring-xd-extension-sqoop/src/main/java/org/springframework/xd/sqoop/SqoopTasklet.java

Really doesn't make sense for me add those prefix and remove it later in the next call in the SqoopRunner class. 

https://github.com/spring-projects/spring-xd/blob/master/extensions/spring-xd-extension-sqoop/src/main/java/org/springframework/xd/sqoop/SqoopRunner.java

If I inject  the security.* configurations directly to the list arguments it works. 

I'm sure you guys have a good reason to add the prefix  but I don't see why. Unfortunately is  annoying when you are developing in a local VM where you can test the  simple authentication and after move the job to dev/prod environments with kerberos auth, the above because you must change your sqooptasklet configuration injecting the new parameters. If the SqoopTasklet allows inject those parameters directly from the hadoop.properties file you don't need change tasklet  configurations to run your jobs with different authentication methods. 

Thanks in advance. 
Héctor",XD-3611,Hector Lagos,SqoopTasklet doesn't use keytab configuration from hadoop.properties file
159,Marius Bogoevici,Marius Bogoevici,"The Kafka sink should not make use of the message headers sent by the Kafka receivers in the Kafka bus. 

Similarly, the headers received from the Kafka source should not be propagated when sending to the Kakfa bus. 

https://github.com/spring-projects/spring-xd/issues/1804",XD-3610,Marius Bogoevici,Kafka source and sink headers shouldn't interfere with bus functionality
160,,Sabby Anandan,"As a data scientist, I'd like to have the option to process data using {{flink}} processor, so I can take advantage of the streaming machine learning abstractions implemented on top of Flink. ",XD-3609,Sabby Anandan,Spike: Study integration operations with Flink
161,,Sabby Anandan,"As a developer, I'd like to port {{rich-gauge}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",XD-3608,Sabby Anandan,Port rich-gauge as s-c-s sink
162,,Sabby Anandan,"As a developer, I'd like to port {{gauge}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",XD-3607,Sabby Anandan,Port Gauge as s-c-s sink
163,,Sabby Anandan,"As a developer, I'd like to port {{aggregate-counter}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",XD-3606,Sabby Anandan,Port aggregate-counter as s-c-s sink
164,,Sabby Anandan,"As a developer, I'd like to port {{field-value-counter}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",XD-3605,Sabby Anandan,Port field-value-counter as s-c-s sink
165,Gunnar Hillert,Swagata Roy,"In my test case, I have security enabled. I tested this on distributed mode. I have a few Streams deployed.
* Started 3 XD containers. 
* Issue *Shutdown* from UI
* The containers don't show up on the UI any more
* jps lists the process id of 2 ContainerServerApplication(there should be none listed)

I have noticed different test results every time, like at times 2 out of 3 containers are terminated and at times 1 out of 3 are terminated. Please let me know if you have issues replicating this.
",XD-3604,Swagata Roy,Container process id's still showing after shutting them down
166,Andy Clement,Sabby Anandan,"As a XD user, I'd like to have job DSL as an option, so I can leverage the DSL to create comprehensive workflows and orchestrate jobs. ",XD-3603,Sabby Anandan,Implement parser for Job DSL
167,Gary Russell,Sabby Anandan,"As a developer, I'd like to port {{Log}} module from XD to s-c-s repo, so I can use it as {{sink}} modules to build streaming pipeline.",XD-3602,Sabby Anandan,Port Log as s-c-s sink
168,Ilayaperumal Gopinathan,Eric Bottard,"We need to make sure that JMX MBean names are unique, even in the case of labeled modules.

The following stream fails for example: ""http | filter | filter2: filter | log""

A good candidate could be stream name (group) + module label.",XD-3601,Eric Bottard,JMX MBean name clash when using labels with s-c-d deployment
169,,Sabby Anandan,"As a s-c-s user, I'd like to use {{kinesis}} module, so I can use it as {{sink}} module to build streaming pipeline.",XD-3600,Sabby Anandan,Add Kinesis as s-c-s sink
170,,Sabby Anandan,"As a s-c-s user, I'd like to use {{kinesis}} module, so I can use it as {{source}} module to build streaming pipeline.",XD-3599,Sabby Anandan,Add Kinesis as s-c-s source
171,Gary Russell,Gary Russell,{{LocalMessageBus}} and {{CompositeModule}}.,XD-3598,Gary Russell,Set Bean Name in ConsumerEndpointFactoryBean
172,Marius Bogoevici,Marius Bogoevici,"Described in https://github.com/spring-cloud/spring-cloud-stream/issues/144

As a developer, I want Input enpoints to be started after all the beans in the context, so that received messages can be delivered to components. 
",XD-3597,Marius Bogoevici,Separate Lifecycle of Input and Output adapter endpoints
173,Mark Fisher,Sabby Anandan,"As a s-c-d user, I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time. ",XD-3596,Sabby Anandan,Prevent streams with duplicate name
174,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to add test coverage for {{StreamController}}, so I can verify API contracts at build time. ",XD-3595,Sabby Anandan,Add test coverage for StreamController
175,Mark Fisher,Sabby Anandan,"As an s-c-d user, I'd like to have the option to use _named channels_, so I can create streaming pipelines without source or sink modules. ",XD-3594,Sabby Anandan,Add support for named channels
176,Eric Bottard,Sabby Anandan,"As a SCDF user, I want to be able to register artifacts as libraries, so that I can reference them in include and exclude statements.",XD-3593,Sabby Anandan,Add support to register artifacts as libraries
177,,Sabby Anandan,"As an s-c-d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",XD-3592,Sabby Anandan,Harmonize REST features between deployment profiles
178,,Sabby Anandan,"As an s-c-d user, I'm trying to access {{admin}} REST endpoints running on CF but I'm getting SSL authentication errors.
",XD-3591,Sabby Anandan,Accessing Admin REST APIs on CF returns unexpected results
179,,Sabby Anandan,"As a XD developer, I'd like to reproduce and fix anomalies as listed [here|https://github.com/spring-projects/spring-xd-admin-ui-client/issues/9].",XD-3590,Sabby Anandan,Fix datatype mismatch on admin-ui
180,Glenn Renfro,Glenn Renfro,"h2. Narrative
As an XD developer, I need to be able to create a composed job module as XML from the DSL an store it in the Module File repository. 
While the user uses the composed job as if it is a normal job including seeing only the DSL.  In the background the JobFactory will deploy the composed job module.  
* When the user destroys the job the module will be deleted from the file module repository.
* When the user creates the job a module will be created in the file Module repository.
h2. Back story
For the composed job story, we need to create a ""real"" job module to be expressed in XML, so that we can take advantage of the job execution tasklet in XD-3556, so that each job can be executed as a step in the composed job.",XD-3589,Glenn Renfro,Create Composed Job Module 
181,,Sabby Anandan,,XD-3588,Sabby Anandan,Summary of features to support Lattice based deployment
182,,Sabby Anandan,"As an s-c-d developer, I'd like to move rabbit {{@Rule}} to a separate repo, so I can consume the test fixtures in different projects.",XD-3587,Sabby Anandan,Move Rabbit @Rule to a separate repo
183,,Sabby Anandan,"As an s-c-d developer, I'd like to move kafka {{@Rule}} to a separate repo, so I can consume the test fixtures in different projects.",XD-3586,Sabby Anandan,Move Kafka @Rule to a separate repo
184,,Sabby Anandan,"As an s-c-d developer, I'd like to move redis {{@Rule}} to a separate repo, so I can consume the test fixtures in different projects.",XD-3585,Sabby Anandan,Move Redis @Rule to a separate repo
185,,Swagata Roy,"When the following format is specified  -
{noformat}
 home: file://hadoop/xd/custom-modules
{noformat}
There is no root-path ('/') following the 'file://' scheme. That makes the Hadoop job launcher interpret what follows as a host name and will look for '/xd/custom-modules' on the host 'hadoop'. This results in ""java.net.UnknownHostException: hadoop"".

This format works for module upload though. The module upload relies on resource location resolution from Spring Framework which is more lenient [1]. The MapReduce job submission uses code from the Apache Hadoop project and uses a more stringent resolution. 

This results in ambiguity 'file://my/directory' and requires the root path to be specified.
[1] http://docs.spring.io/autorepo/docs/spring/4.2.x/spring-framework-reference/html/resources.html#resources-filesystemresource-caveats",XD-3584,Swagata Roy,Have consistent file format requirements in Spring XD and Hadoop
186,,Sabby Anandan,"As an s-c-d user, I'd like to deploy s-c-d on Mesos.",XD-3583,Sabby Anandan,Implement Mesos SPI
187,Eric Bottard,Sabby Anandan,"As an s-c-d user, I'd like to have tab completion on shell, so I can interact with the modules and its available options.",XD-3582,Sabby Anandan,Add support for tab completion in shell
188,Mark Fisher,Sabby Anandan,"As a spring-cloud-stream user, I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.",XD-3581,Sabby Anandan,Add support for Tuple and JSON SpEL property accessors in spring-cloud-stream
189,Thomas Risberg,Sabby Anandan,"As a s-c-d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s-c-d's bare metal deployment.",XD-3580,Sabby Anandan,Spike: Explore options to setup bare-metal deployment of s-c-d using Lattice
190,,Sabby Anandan,"As an s-c-d developer, I'd like to investigate integration options with the 0.9 release of Kafka, so I can identify areas of improvements. ",XD-3579,Sabby Anandan,Spike: Explore integration options with Kafka 0.9 release
191,,Sabby Anandan,"As an XD user, I'd like have support restart an existing composed job, so I could re-launch it at will.",XD-3578,Sabby Anandan,Add support to restart job composition
192,,Sabby Anandan,"As an XD user, I'd like to see an aggregated progress bar for a job that is embeds multiple jobs within itself. ",XD-3577,Sabby Anandan,Compute progress information for job composition
193,Gunnar Hillert,Sabby Anandan,"As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.",XD-3576,Sabby Anandan,Add support to retrieve job details 
194,Gunnar Hillert,Sabby Anandan,"As an XD user, I'd like to be able to visually differentiate between job-composition workflow and single job.",XD-3575,Sabby Anandan,Add visual representation of job workflow in executions list page
195,Gunnar Hillert,Sabby Anandan,"As an XD user, I'd like to have a REST endpoint that returns job composition graph, so I can use it to build visual representation of parent-child relationship. 
",XD-3574,Sabby Anandan,Include job-composition graph in REST endpoint
196,Gunnar Hillert,Sabby Anandan,"As an XD user, I'd like to have a REST endpoint that returns job composition {{flag}}, so I can use it to differentiate visual representation between parent-child relationship and standalone jobs.
",XD-3573,Sabby Anandan,Include job-composition flag in REST endpoint
197,Eric Bottard,Sabby Anandan,"As a Spring XD developer, I'd like to port {{analytic-pmml}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3572,Sabby Anandan,Port analytic-pmml as s-c-s processor
198,Thomas Risberg,Sabby Anandan,"As a Spring XD developer, I'd like to move {{cassandra}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",XD-3571,Sabby Anandan,Port Cassandra as s-c-s sink
199,Paul Harris,Paul Harris,"In https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/README.md#running-on-cloud-foundry the section starting 'Now we can configure the app' needs to be revised - the information is both out of date and, even if up-to-date, misleading (it includes some values as if they are universal, when they are really just examples).",XD-3570,Paul Harris,Readme has conflicting CF information
200,Janne Valkealahti,Thomas Risberg,"As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. 

We had an issue filed in the `spring-xd-ambari` project:

""It seems like custom module doesn't pickup namenode HA? and still use NameNodeProxies.createNonHAProxy?""

see: https://github.com/spring-projects/spring-xd-ambari/issues/14",XD-3569,Thomas Risberg,ResourceModuleRegistry doesn't support HA namenode for hdfs custom module location
201,Thomas Risberg,Thomas Risberg,"Submitting XD on YARN for HDP 2.3 fails due to some Solr issue in Boot - https://github.com/spring-projects/spring-boot/issues/2795

The xd-admin sysout is:

{code}
Started : AdminServerApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki

02:51:36,624  ERROR main boot.SpringApplication - Application startup failed
java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:58)
	at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:102)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:178)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:333)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:98)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:673)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:519)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)
Caused by: java.lang.IllegalArgumentException: @ConditionalOnMissingBean annotations must specify at least one bean (type, name or annotation)
	at org.springframework.util.Assert.isTrue(Assert.java:68)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition$BeanSearchSpec.<init>(OnBeanCondition.java:223)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:92)
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:45)
	... 17 more
02:51:36,628   WARN main annotation.AnnotationConfigApplicationContext - Exception thrown from LifecycleProcessor on context close
java.lang.IllegalStateException: LifecycleProcessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.AnnotationConfigApplicationContext@1cf1df22: startup date [Fri Oct 02 02:51:31 UTC 2015]; root of context hierarchy
	at org.springframework.context.support.AbstractApplicationContext.getLifecycleProcessor(AbstractApplicationContext.java:414)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:966)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:925)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:342)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)
02:51:36,642  ERROR main admin.AdminServerApplication - Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer
{code}
",XD-3568,Thomas Risberg,AdminServer fails on HDP 2.3
202,Thomas Risberg,Thomas Risberg,"Several issues with 1.3.0.M1 staged version

- we now use Tomcat instead of Jetty which prevent s xd-admin from starting on YARN

- we now have Guava 18.0 on classpath instead of 16.0.1

- xd-yarn push doesn't work, hadoop client for 2.7.1 needs Servlet API 

- updating Hadoop to 2.7.1 instead of 2.6.0
  -- this causes Curator to also update to 2.7.1 which throws exception on startup
",XD-3567,Thomas Risberg,Fix classpath and servlet container issues
203,Glenn Renfro,Glenn Renfro,XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.,XD-3566,Glenn Renfro,TwitterStream test must use unique name to prevent test collision
204,Marius Bogoevici,Sabby Anandan,"As a developer, I want to be able to connect to multiple external systems for the same binding type, so that I can read data from a system and write it to another.",XD-3565,Sabby Anandan,Add support for multiple binders per binder type
205,Marius Bogoevici,Sabby Anandan,"As a developer, I want to be able to connect to multiple types of transports in an application, so that I can receive and send messages to different transport types.",XD-3564,Sabby Anandan,Add support for registering multiple BinderFactories 
206,Marius Bogoevici,Sabby Anandan,"As a developer, I want to have a {{BinderFactory}} abstraction, so that I can support multiple binder types in the future.",XD-3563,Sabby Anandan,Create BinderFactory abstraction
207,,Enrique Medina,"Currently, if a module in a stream throws an exception, the stream flow is broken, but the stream's creator is not notified or warned about the issue, unless a direct monitoring of the logs is performed.

This could work when an administrator is taking care of the whole life cycle of any stream, but it doesn't work when Spring XD is being used by external services with no human intervention.

It would be necessary some sort of notification mechanism so when any issue raises in the execution of a stream, its creator can react and decide on how to handle it.

For instance, I have an application that uses Spring XD to load data from different sources into HDFS. In my application, you simply define a type of source and the destiny in HDFS, without the user knowing that Spring XD is under the hoods. If the user defines, for example, a Twitter source, then I define a ""twitterstream"" as a source for a new stream with a sink in HDFS. However, if anything goes wrong, I have no way to let my user know about the issue: an authentication issue, the dreaded 420 response from the Twitter API, etc. If I could somehow be notified about the issue, then I could provide that information to my user so she could fix the issue or at least understand what is going on.

I've seen that the REST API will support an endpoint to check the current status of a stream, but it is not yet available and it would require my application to be polling constantly the stream, with all the disadvantages compared to a pushing mechanism.",XD-3562,Enrique Medina,Be aware of exceptions thrown in a stream
208,,David Geary,"We have a use case where we need the HTTP source module to return a 204 status instead of the 200 status that is currently returned. There may be other status codes that it would be useful to be able to return. A simple additional option on the module would allow this to be configured.
",XD-3561,David Geary,Configurable response status code in HTTP Source
209,Eric Bottard,Eric Bottard,"When a default value is an array, the current behavior (using toString()) not only produces useless results (like `[Ljava.lang.String;@2638011`) but also constantly changing results.",XD-3560,Eric Bottard,Better printing of array default valuesin documentation
210,Gunnar Hillert,Sabby Anandan,"h2. Narrative
As a XD user, I'd like to restart the composed job workflow from Shell/UI. ",XD-3559,Sabby Anandan,Add support to restart job composition
211,Gunnar Hillert,Sabby Anandan,"h2. Narrative
Verify that the job launch works as we expect for the composed job.
",XD-3558,Sabby Anandan,Add ability to launch job composition
212,,Sabby Anandan,"h2. Narrative
As the xd user, I would like a way obtain the result of each child job as it is represented as a step in the parent job's graph.

h2.  Back story
Each child job will have a completion status of its own that will be displayed in the Spring XD UI as well as the shell's job execution list. 
",XD-3557,Sabby Anandan,Expose status for each job within the composition
213,Michael Minella,Sabby Anandan,"h2. Narrative
As the system, I would like a way to launch a previously deployed job module from another job module.

h2.  Back story
For the composed job story, we will have a driver job that consists of each step that represents the execution of a job.  This story is the creation of a {{Tasklet}} that will launch the child job, and upon it's completion, set the results of the driver's step to that of the slave job's results.
",XD-3556,Sabby Anandan,Develop tasklet to execute a Job
214,,Sabby Anandan,"As an XD developer, I'd like to explore options to save composed job definition in ZK metadata, so I can use the repository to recreate jobs to recover from failure scenarios.",XD-3555,Sabby Anandan,Spike: Store DSL definition in ZK
215,,Sabby Anandan,"As an XD developer, I'd like to explore options to remove composed job, so I can clean-up unused resources and memory footprints. ",XD-3554,Sabby Anandan,Spike: Destroy composed job
216,Glenn Renfro,Sabby Anandan,"h2. Narrative
As an XD developer, I'd like to explore options to represent composed job, so I can create a workflow to orchestrate multiple jobs.

h2.  Back story
For the composed job story, we need to create a ""real"" job module to be expressed in XML, so that we can take advantage of the job execution tasklet in XD-3556, so that each job can be executed as a step in the composed job.  
",XD-3553,Sabby Anandan,Spike: Create composed job module
217,,Mark Pollack,"For example the generated value for the cassandra sink results in 

{{-$$entityBasePackages$$:: $$the base packages to scan for entities annotated with Table annotations$$ ($$String;$$, default: `[Ljava.lang.String;@2638011`)}}

where the default value changes each time the build is run.
",XD-3552,Mark Pollack,Improve automated documentation generation process for modules to handle array arguments
218,,Ilayaperumal Gopinathan,"The spark app test on spark standalone cluster is currently commented out:
https://github.com/spring-projects/spring-xd/blob/9307f1fba347adf59c8b489ae7fe0aa9bfd9b6a6/spring-xd-integration-test/src/test/java/org/springframework/xd/integration/test/SparkAppTests.java#L74

We need to add it back once the cluster is setup on acceptance test environment.",XD-3550,Ilayaperumal Gopinathan,Re-add Spark job acceptance test with spark standalone cluster 
219,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{splitter}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3549,Sabby Anandan,Port Splitter as s-c-s processor
220,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{shell}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3548,Sabby Anandan,Port Shell as s-c-s processor
221,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{script}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3547,Sabby Anandan,Port Script as s-c-s processor
222,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{object-to-json}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3546,Sabby Anandan,Port Object to JSON as s-c-s processor
223,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{json-to-tuple}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3545,Sabby Anandan,Port JSON to Tuple as s-c-s processor
224,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{http-client}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3544,Sabby Anandan,Port HTTP-Client as s-c-s processor
225,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{aggregator}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3543,Sabby Anandan,Port aggregator as s-c-s processor
226,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{jdbc}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.
",XD-3542,Sabby Anandan,Port JDBC as s-c-s source
227,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{tcp}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3541,Sabby Anandan,Port TCP as s-c-s sink
228,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{splunk}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3540,Sabby Anandan,Port Splunk as s-c-s sink
229,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{shell}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3539,Sabby Anandan,Port Shell as s-c-s sink
230,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{null}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3538,Sabby Anandan,Port NULL as s-c-s sink
231,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mqtt}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3537,Sabby Anandan,Port MQTT as s-c-s sink
232,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mongo}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3536,Sabby Anandan,Port MongoDB as s-c-s sink
233,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mail}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3535,Sabby Anandan,Port Mail as s-c-s sink
234,Thomas Risberg,Sabby Anandan,"As a Spring XD developer, I'd like to move {{hdfs-dataset}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3534,Sabby Anandan,Port HDFS DataSet as s-c-s sink
235,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{gpfdist}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.
",XD-3533,Sabby Anandan,Port GPFDIST as s-c-s sink
236,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{tcp-client}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.
",XD-3532,Sabby Anandan,Port TCP Client as s-c-s source
237,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{tcp}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",XD-3531,Sabby Anandan,Port TCP as s-c-s source
238,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mail}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",XD-3530,Sabby Anandan,Port Tail as s-c-s source
239,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{syslog}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.
",XD-3529,Sabby Anandan,Port syslog as s-c-s source
240,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{stdout}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",XD-3528,Sabby Anandan,Port STDOUT as s-c-s source
241,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{reactor-ip}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",XD-3527,Sabby Anandan,Port ReactorIP as s-c-s source
242,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mqtt}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.
",XD-3526,Sabby Anandan,Port MQTT as s-c-s source
243,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mongo}} module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.
",XD-3525,Sabby Anandan,Port MongoDB as s-c-s source
244,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{mail}} module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.
",XD-3524,Sabby Anandan,Port Mail as s-c-s source
245,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{jms}} module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.
",XD-3523,Sabby Anandan,Port JMS as s-c-s source
246,,Sabby Anandan,"As an s-c-d user, I'd like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell/rest-api's. 

Currently the registry isn't flexible, as it is pretty much [hard-coded at registry bootstrap level|https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-admin/src/main/java/org/springframework/cloud/dataflow/admin/config/ModuleRegistryPopulator.java#L75]. ",XD-3522,Sabby Anandan,Add dynamic addition to module registry
247,,Sabby Anandan,"As an s-c-d user, I'd like to upload custom modules using shell/rest-api, so I can contribute modules and create streaming/batch pipelines. ",XD-3521,Sabby Anandan,Add support to upload custom modules 
248,,Sabby Anandan,"As an s-c-d user, I'd like to have {{tap}} support in s-c-dataflow DSL/Shell, so I can fork the same data and do some ad-hoc analysis without impacting the original stream.",XD-3520,Sabby Anandan,Add TAP support in DSL/Shell
249,Gary Russell,Sabby Anandan,"As an s-c-d user, I'd like to {{tap}} the primary pipeline, so I can fork the same data and do some ad-hoc analysis without impacting the original stream.",XD-3519,Sabby Anandan,Add TAP support for Rabbit binder
250,,Sabby Anandan,"As a s-c-d user, I'd like to continue to use XD features in Spring Cloud Data Flow.
",XD-3518,Sabby Anandan,List of existing features to port from XD to Data Flow
251,,Sabby Anandan,"As an s-c-d user, I'd like to refer to documentation on ""direct binding"", so I can use it as a reference to deploy a stream that includes directly bound modules. 

Example:
{code}
java -jar spring-cloud-stream-module-launcher/target/spring-cloud-stream-module-launcher-1.0.0.BUILD-SNAPSHOT.jar --modules=org.springframework.cloud.stream.module:time-source:1.0.0.BUILD-SNAPSHOT,org.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT,org.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT --args.0.fixedDelay=7 --args.1.expression='payload.contains(""6"")' --aggregate=true --spring.cloud.stream.bindings.output=filtered
{code} ",XD-3517,Sabby Anandan,Document direct binding 
252,,Sabby Anandan,"As an s-c-d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on {{partitions}}. I'd like to understand how streams withe  
",XD-3516,Sabby Anandan,Document partitioning through deployment properties
253,,Sabby Anandan,"As a s-c-d user, I'd like to have the option of {{Gemfire}} as module registry, so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.",XD-3515,Sabby Anandan,Add support for Gemfire as module registry
254,,Sabby Anandan,"As a s-c-d user, I'd like to have the option of {{Gemfire}} as stream repository, so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.",XD-3514,Sabby Anandan,Add support for Gemfire as stream repository
255,,Sabby Anandan,"As a s-c-d user, I'd like to have the option of {{Gemfire}} SPI, so I can use {{Gemfire}} and the infrastructure to orchestrate s-c-d data microservices. ",XD-3513,Sabby Anandan,Implement Gemfire SPI
256,Patrick Peralta,Sabby Anandan,"As a s-c-s user, I'd like to have {{Gemfire}} message-channel binder, so I can use {{Gemfire}} as the messaging middleware for low latency use-cases. ",XD-3512,Sabby Anandan,Implement Gemfire message-channel binder
257,,Sabby Anandan,"As a user, I'd like to use {{Gemfire}} to orchestrate data pipelines using Spring Cloud Data Flow. ",XD-3511,Sabby Anandan,Support for Gemfire as module deployer
258,,Gary Russell,2 Exchanges left behind.,XD-3510,Gary Russell,Spark Tap Tests Do Not Clean Up RabbitMQ
259,Gunnar Hillert,Ian Mortimer,"When I'm trying to send a json object to spring-xd I get the following error even though I opened up requests to allow all. 

XMLHttpRequest cannot load http://localhost:9000/. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:3000' is therefore not allowed access.

Config: 
spring:
  profiles: singlenode
xd:
  transport: local
  ui:
     allow_origin: ""*""",XD-3509,Ian Mortimer,CORS issue when trying to use HTTP in singlenode
260,Gary Russell,Sabby Anandan,"As a XD developer, I'd like to refactor and replace {{codec}} code from XD with SI library, so I don't have to maintain duplicate code.",XD-3508,Sabby Anandan,Refactor to replace codec implementation with SI library
261,,David Turanski,Upgrade dependencies to Spring Boot 1.3.x,XD-3507,David Turanski,Upgrade to spring boot 1.3
262,Gunnar Hillert,Gunnar Hillert,,XD-3506,Gunnar Hillert,UI - Container List - Module Properties - Escape Passwords
263,Paul Harris,Sabby Anandan,"As a s-c-d user, I'm unable to push admin app to CF due to SSL certification errors while bootstrapping. 

Consider adding [CF trusted certificate|https://github.com/pivotal-cf/cloudfoundry-certificate-truster] as a CF SPI dependency.

Adding CF trusted certificate as dependency doesn't help either:

{code}
> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387)
> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)
> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.Validator.validate(Validator.java:260)
> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)
> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229)
> Fri Sep 25 2015 12:55:32 GMT-...
{code}",XD-3505,Sabby Anandan,Admin app crashes with SSL certification errors
264,,Sabby Anandan,"As a s-c-s user, I'd like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data. 

More details [here|https://github.com/spring-cloud/spring-cloud-stream/issues/140].",XD-3504,Sabby Anandan,Support for multiple connections to the same binder implementation
265,Gunnar Hillert,Gunnar Hillert,"We do set a default value in: xd/lib/spring-xd-dirt-1.2.1.RELEASE.jar/application.yml

{code}
...
xd:
  data:
    home: file:${XD_HOME}/data
  config:
    home: file:${XD_HOME}/config
  module:
    home: file:${XD_HOME}/modules
  customModule:
    home: file:${XD_HOME}/custom-modules
  ui:
    home: file:${XD_HOME}/spring-xd-ui/dist/
    allow_origin: http://localhost:9889
...
{code}

We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using **servers.yml**",XD-3503,Gunnar Hillert,Document the setting of the CORS allow_origin property
266,Thomas Risberg,Thomas Risberg,,XD-3502,Thomas Risberg,Upgrade SCSM hdfs sink to SHDP 2.3.0.M3
267,Gunnar Hillert,Sabby Anandan,"As a user, I'm not able to shutdown {{container}} from Admin UI with the following stream definition deployed.

{code}
stream create swagataTestIssue --definition ""jdbc --query='select employee_id, employee_name, employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy 
{code}

More details [here|https://issuetracker.springsource.com/browse/VESC-504].",XD-3501,Sabby Anandan,Admin UI container shutdown not working
268,Janne Valkealahti,Sabby Anandan,"As a s-c-d developer, I'd like to enhance unit test coverage for {{YARN}} SPI, so I can continuously evaluate functionalities via CI pipeline.
",XD-3500,Sabby Anandan,[Unit Tests] Enhance test coverage for YARN SPI
269,,Sabby Anandan,"As a s-c-d developer, I'd like to enhance unit test coverage for {{Lattice}} SPI, so I can continuously evaluate functionalities via CI pipeline.
",XD-3499,Sabby Anandan,[Unit Tests] Enhance test coverage for Lattice SPI
270,Janne Valkealahti,Sabby Anandan,"As a s-c-d developer, I'd like to enhance integration test coverage for {{YARN}} SPI, so I can continuously evaluate functionalities via CI pipeline.
",XD-3498,Sabby Anandan,Spike: Explore options to support YARN integration tests
271,,Sabby Anandan,"As a s-c-d developer, I'd like to enhance integration test coverage for {{CC}} SPI, so I can continuously evaluate functionalities via CI pipeline.
",XD-3497,Sabby Anandan,[Int Tests] Enhance test coverage for CC SPI
272,,Sabby Anandan,"As a s-c-d developer, I'd like to enhance integration test coverage for {{Lattice}} SPI, so I can continuously evaluate functionalities via CI pipeline.",XD-3496,Sabby Anandan,[Int Tests] Enhance test coverage for Lattice SPI
273,,Sabby Anandan,,XD-3495,Sabby Anandan,"Support for unit, integration and acceptance test coverage for SPIs"
274,Marius Bogoevici,Sabby Anandan,"As a s-c-d developer, I'd like to document the use of BOM templates, so the general audience can use it as a reference to include external libraries dynamically.",XD-3494,Sabby Anandan,Document how to use to BOM template
275,David Turanski,Sabby Anandan,"As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies, so I can take advantage of the latest improvements. ",XD-3493,Sabby Anandan,"Update SI, Spring, and AMQP dependencies"
276,David Turanski,Sabby Anandan,"As a XD developer, I'd like to move header-enricher from modules repo to XD proper. ",XD-3492,Sabby Anandan,Move header-enricher to XD proper
277,Thomas Risberg,Sabby Anandan,,XD-3491,Sabby Anandan,Move Cassandra sink to XD proper
278,,Glenn Renfro,Migrate load-generator and throughput to SCS.  ,XD-3490,Glenn Renfro,Port load-generator & throughput modules to SCS-Modules
279,Thomas Risberg,Sabby Anandan,"As a s-c-d user, I'd like to have the option to choose Hadoop distribution of choice, so I can load the right Hadoop libraries in the CP. 
",XD-3489,Sabby Anandan,Add support to load Hadoop distribution of choice
280,Eric Bottard,Sabby Anandan,"As a s-c-d developer, I'd like to refactor CC SPI deployer with CF java-client, so I can improve the overall design and performance. ",XD-3488,Sabby Anandan,Refactor CF SPI with CF java-client library
281,,Sabby Anandan,"As a s-c-d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations. (ex: module resolution from a different maven coordinate). ",XD-3487,Sabby Anandan,Add property override support for modules via external config file
282,Marius Bogoevici,Sabby Anandan,"As a s-c-d developer, I'd like to add support for having different binder types for module's channels, so I can plug {{rabbit}}, {{redis}}, or {{kafka}} as the source or sink to read and write respectively.",XD-3486,Sabby Anandan,Spike: Study support for different binder-types for module channels
283,,Sabby Anandan,"As a s-c-d developer, I'd like to move {{rabbit}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",XD-3485,Sabby Anandan,Port Rabbit as s-c-s sink
284,,Sabby Anandan,"As a s-c-d developer, I'd like to move {{kafka}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",XD-3484,Sabby Anandan,Port Kafka as s-c-s sink
285,,Sabby Anandan,"As a s-c-d developer, I'd like to move {{kafka}} module from XD to s-c-s repo, so I can use it as {{source}} to build streaming pipeline.",XD-3483,Sabby Anandan,Port Kafka as s-c-s source
286,Eric Bottard,Sabby Anandan,"As a s-c-s-m developer, I'd like to move {{jdbc}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.


See also XD-2250",XD-3482,Sabby Anandan,Port JDBC as s-c-s sink
287,,Sabby Anandan,"As a s-c-s developer, I'd like to support XD-like features where modules bind to incoming messages via expressions or other mechanism, so I can bind message properties to every microservice modules. ",XD-3481,Sabby Anandan,Bind message properties to modules
288,,Sabby Anandan,"As a s-c-d developer, I'd like to add test coverage to test {{shell}} commands in isolation, so I don't have to run end-to-end full stream deployment based functional tests.

More details [here|https://docs.google.com/document/d/18uNqRAgVGO0BHdvDsVg3X78gDBeqXA_LN_C6jJ0YpKw/edit#].",XD-3480,Sabby Anandan,Unit test shell commands in isolation
289,Michael Minella,Sabby Anandan,"As a XD user, I'd like to orchestrate composed jobs, so I can bring multiple jobs into single workflow and operationalize.",XD-3479,Sabby Anandan,Orchestrate job composition
290,,Sabby Anandan,"As a XD developer, I'd like to explore repository options for ""composed jobs"", so I have the leverage to read/write composed job definitions.",XD-3478,Sabby Anandan,Spike: Investigate options for composed jobs repository
291,,Sabby Anandan,"As an XD user, I'd like to compose multiple jobs via Flo, so I don't have to write a custom job module to orchestrate them.",XD-3477,Sabby Anandan,Support to compose batch jobs
292,,Aaron Loes,It would be extremely nice to have the various property sources available in the Spring Environment bean for a module to use.,XD-3476,Aaron Loes,Add the various property sources to the Spring Environment bean
293,,Aaron Loes,"Created a stream with definition:
{code}
mySourceModule | myProcessorModule | log
{code}
This stream worked fine, but when created composed module with definition
{code}
mySourceModule | myProcessorModule
{code}
Then stream definition
{code}
myComposedModule | log
{code}

get an error stating that the output channel of mySourceModule has no subscribers. Looking at previous bugs, this appears to be a module binding order in which the source is started before the processor has subscribed to the output channel of the source.",XD-3475,Aaron Loes,Composed modules destination binding order incorrect
294,,Aaron Loes,"When composing two or more modules together, if any output or input type is specified between modules, it is ignored. 

I created a stream with definition:
{code}
mySourceModule --outputType=application/json | myProcessorModule
{code}
that worked fine as expected. When i composed this definition as a composed module, I got errors stating that the processors message handler had no handler method for the object the source module emitted. The process was only configured to accept JSON as string. I simply had to create a second handler method but if i didnt own the module, this could be an issue.",XD-3474,Aaron Loes,Composing modules ignores output/input type specified in definition
295,,José Carlos Valero Sánchez,"When opening manager webapp, if the internet connection is slow enough to make one of the biggest javascript dependencies to make requirejs throw a timeout the webapp becomes unusable, displaying only the loading gif, and showing a javascript error saying:

Uncaught Error: Load timeout for modules: angular

It typically takes ~ 10 seconds to throw that error.",XD-3473,José Carlos Valero Sánchez,Web Admin app not loading for slow connections
296,,David Turanski,See http://stackoverflow.com/questions/32525290/spring-xd-processor-module-classloader-issue-classnotfoundexception,XD-3472,David Turanski,Spring XD processor module classloader issue: ClassNotFoundException
297,Paul Harris,Paul Harris,"The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.",XD-3471,Paul Harris,Improve resilience of route creation/removal
298,,Aaron Loes,"What is the functional justification for enforcing this validation on modules? Is it really necessary to enforce that the short description must start with a capitol letter and end with a period? Seems a bit unnecessary and opinionated to me.

Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors
Field error in object 'info' on field 'shortDescription': rejected value [...snip...]; codes [Pattern.info.shortDescription,Pattern.shortDescription,Pattern.java.lang.String,Pattern]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescription,shortDescription]; arguments []; default message [shortDescription],[Ljavax.validation.constraints.Pattern$Flag;@3984374e,^\p{IsUppercase}.*\.$]; default message [Short description must start with a capital letter and end with a dot]
",XD-3470,Aaron Loes,Add maxWait property to set in kafka message bus
299,Ilayaperumal Gopinathan,Thomas Risberg,The new SCSM twitterstream module uses a different format than XD 1.x source module. It should match what Twitter uses so existing processors etc. will continue to work.,XD-3469,Thomas Risberg,The new SCSM twitterstream module should produce same json as old XD source
300,Thomas Risberg,Thomas Risberg,"Creating a stream like this:

  stream create --name myhdfsstream1 --definition ""time | hdfs --closeTimeout=5000"" --deploy

causes:

java.lang.IllegalArgumentException: Task executor must be set
        at org.springframework.util.Assert.notNull(Assert.java:115) ~[spring-core-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.data.hadoop.store.support.PollingTaskSupport.init(PollingTaskSupport.java:105) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]
        at org.springframework.data.hadoop.store.support.StoreObjectSupport.onInit(StoreObjectSupport.java:97) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]
        at org.springframework.data.hadoop.store.support.OutputStoreObjectSupport.onInit(OutputStoreObjectSupport.java:81) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]
        at org.springframework.data.hadoop.store.support.LifecycleObjectSupport.afterPropertiesSet(LifecycleObjectSupport.java:67) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]
        at org.springframework.cloud.stream.module.hdfs.sink.DataStoreWriterFactoryBean.afterPropertiesSet(DataStoreWriterFactoryBean.java:175) ~[hdfs-sink-1.0.0.BUILD-SNAPSHOT-exec.jar!/:1.0.0.BUILD-SNAPSHOT]
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1637) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        ... 35 common frames omittedWrapped by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataStoreWriter' defined in class path resource [org/springframework/cloud/stream/module/hdfs/sink/HdfsSinkConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Task executor must be set
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1578) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBea",XD-3468,Thomas Risberg,Unable to set --closeTimeout on SCSM hdfs sink module
301,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to add support for hadoop commands in shell, so I can use it to query the hadoop file system.",XD-3467,Sabby Anandan,Spike: Study scope to add support for hdfs commands in shell
302,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to add _hdfs_ sink to module registry, so I can use this module to build streaming pipeline and write to Hadoop.",XD-3466,Sabby Anandan,Add hdfs sink to module registry
303,,Gary Russell,"When the {{BroadcasterMessageHandler}} is defined as a {{@ServiceActivator}} {{@Bean}} , the output channel must be set on the handler, not in the annotation.

The handler should detect a {{null}} {{outputChannel}}.

See http://stackoverflow.com/questions/32462059/spring-xd-reactor-streams-with-configuration-npe",XD-3465,Gary Russell,NPE in AbstractReactorMessageHandler
304,Paul Harris,Paul Harris,"(From Eric)

Deploying using the following stream fails (probably because of issues around quoting):

`stream create foo --definition ""time | filter --expression=payload.contains('0') | log"" --deploy`

When you try to destroy the stream the destroy fails, which shouldn't happen whether the stream was valid or not.",XD-3464,Paul Harris,Stream Destroy fails if stream deploy failed
305,Eric Bottard,Sabby Anandan,"As a s-c-d developer, I'd like to document [Running on Cloud Foundry|https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry] section in README, so it can be publicly available as deployment guideline.",XD-3463,Sabby Anandan,Complete 'Running on Cloud Foundry' section in README
306,Gunnar Hillert,Sabby Anandan,"As a s-c-d user, I'd like to create a new banner, so I can embed and display the banner when the shell server boots-up. 

Perhaps use this [banner generator|http://patorjk.com/software/taag/#p=display&f=Standard&t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20]?",XD-3462,Sabby Anandan,Create a new banner for spring-cloud-data-flow
307,Janne Valkealahti,Janne Valkealahti,We currently use fixed paths like `spring-cloud-data-yarn/spring-cloud-data-yarn-appmaster/target/spring-cloud-data-yarn-appmaster-1.0.0.BUILD-SNAPSHOT.jar` in yml files. Need to make define version during a build and allow to override location of those files.,XD-3461,Janne Valkealahti,Remove hardcoded yarn app version jars
308,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"If the module launcher's module arg is delimited by underscore (--args_0_fixedDelay=1), then boot ignores that property. It is important to support the underscore delimited property arguments as we set environment properties of these in CF and lattice environment.

The spring boot fix (https://github.com/spring-projects/spring-boot/commit/5a287455273270a20742f03e4546acde9e857bee) doesn't resolve the property if the value type of the Map is Map itself.",XD-3460,Ilayaperumal Gopinathan,Support underscore delimited module args for module launcher
309,,Tzachi Ezra Torf-Fulton,"I am trying to use Presto JDBC driver with Spring-XD JDBC source but I as soon as I deploy the stream I get SQLFeatureNotSupportedException. This is because org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin function tries to call setAutoCommit(false) which is not supported by PrestoConnection.

Reading some other related issues I tried to set testOnBorrow=false and validationQuery='select 1', but it did not seem to work. Also, I created a small test in Java and managed to query the table (added the code at the end), so the driver seems to work fine.

In the mean while, I would like to know if there is any workaround for this issue.

I am using spring-xd-1.2.1.RELEASE with Java 1.8.0_51 on Ubuntu 12.04.5 precise.

*JDBC driver jar*
I added the driver jar to xd/lib from here: https://prestodb.io/docs/current/installation/jdbc.html

*This is how I create the stream*
stream create foo --definition ""jdbc --fixedDelay=30 --split=1 --url=jdbc:presto://localhost:8080/hive --query='SELECT * FROM fooTable limit 10' --driverClassName=com.facebook.presto.jdbc.PrestoDriver --testOnBorrow=false --validationQuery='select 1'|log"" --deploy

*Stack trace*
2015-09-02T14:15:59-0700 1.2.1.RELEASE ERROR task-scheduler-1 handler.LoggingHandler - org.springframework.transaction.CannotCreateTransactionException: Could not open JDBC Connection for transaction; nested exception is java.sql.SQLFeatureNotSupportedException: Disabling auto-commit mode not supported
	at org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:245)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:373)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:463)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:276)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy119.call(Unknown Source)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLFeatureNotSupportedException: Disabling auto-commit mode not supported
	at com.facebook.presto.jdbc.PrestoConnection.setAutoCommit(PrestoConnection.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126)
	at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:108)
	at org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:81)
	at com.sun.proxy.$Proxy120.setAutoCommit(Unknown Source)
	at org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:225)
	... 21 more

*Test Class*
public class Test {
    public static final String DB_URL = ""jdbc:presto://localhost:8080/hive"";
    public static final String Template = ""SELECT * FROM  fooTable limit 10"";

    public static void main(String[] args) throws SQLException, IOException {
        Connection conn = null;
        Statement stmt = null;
        conn = DriverManager.getConnection(DB_URL, ""test"", null);
        stmt = conn.createStatement();
        ResultSet rs = stmt.executeQuery(Template);
    }
}",XD-3459,Tzachi Ezra Torf-Fulton,JDBC Source java.sql.SQLFeatureNotSupportedException when using Facebook Presto driver
310,Glenn Renfro,Glenn Renfro,,XD-3458,Glenn Renfro,Create CI Build for SCTM
311,Glenn Renfro,Glenn Renfro,,XD-3457,Glenn Renfro,Remove Timestamp task from SCSM
312,Glenn Renfro,Glenn Renfro,"Create Parent pom file for build
Create .settings file
Migrate Timestamp task from SCSM to SCTM.
",XD-3456,Glenn Renfro,Create infrastructure for Spring cloud task modules
313,Janne Valkealahti,Sabby Anandan,,XD-3455,Sabby Anandan,Remove hard-coded 'app' name from config file
314,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a module author, I would like to apply RxJava processor module with spring cloud stream. ",XD-3454,Ilayaperumal Gopinathan,Add RxJava processor module
315,,Steve Powell,"Upload of module launcher bits is slow because we do not take into account the
CC cache. To fix this we need to use an async upload, and to somehow generate
the SHA, etc, for the Module Launcher so that CC can pre-empt uploading all
the bits every time.",XD-3453,Steve Powell,Speed up upload of Module Launcher jar
316,,Steve Powell,"Currently we handle only a single page response from CC SPI list requests, but potentially there could be multiple ones.",XD-3452,Steve Powell,Handle paginated responses
317,Steve Powell,Steve Powell,"Currently only the STARTED application (and application instance) status is recognised. This issue will look at the other possible states and report them as module instance states.

This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",XD-3451,Steve Powell,Correctly report state of module instances
318,Paul Harris,Steve Powell,"Currently we deploy a single instance, and ignore the ModuleDeploymentRequest instances setting.

It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.",XD-3450,Steve Powell,Deploy multiple instances of a module
319,Glenn Renfro,Michael Minella,"h2. Narrative
As a user I need to be able to query the current state of a task that has been launched.

h2. Back story
Given the fact that tasks are intended to go away, we need to record the state of them as well as their end result in a repository for a user to be able to query.  This repository will be the system of record when reporting the state of an executing/executed task.",XD-3449,Michael Minella,Task Repository
320,Paul Harris,Sabby Anandan,"As a s-c-d developer, I'd like to study [Concourse CI|http://concourse.ci/] so I can understand how to use it for s-c-d going forward. ",XD-3448,Sabby Anandan,Spike: Evaluate Concourse for CI pipelines
321,Thomas Risberg,Sabby Anandan,"As a s-c-d developer, I'd like to produce ref. documentation for s-c-d architecture, so I could define 1.x and 2.x deployment differences. ",XD-3447,Sabby Anandan,Document s-c-d architecture and deployment variants
322,Gunnar Hillert,Swagata Roy,"Deploying a Stream with HDFS sink and JDBC as source displays incorrect information on the tooltip for the JDBC source. The issue occurs when there are more than 1 containers deployed and the source is deployed on one container and the sink is deployed on another container. I have checked the REST endpoints and they seem to show the correct information. (http://localhost:9393/runtime/containers.json)

In my test case, say if there are 2 containers and source and sink are deployed on the same container, the tooltip's show correct information. The Stream I used for testing purposes is as follows -
{noformat}
 stream create swagataTestIssue --definition ""jdbc --query='select employee_id, employee_name, employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy 
{noformat}

I will attach the screenshots. This issue has also been reported when using Gemfire as source and HDFS as sink.

Thanks,
Swagata",XD-3446,Swagata Roy,The tooltip for source displays incorrect information when using HDFS as sink
323,Marius Bogoevici,Sabby Anandan,"As a s-c-s developer, I'd like to fix the {{Kafka}} binder, so I can create messaging microservices apps and successfully bind them to an operational Kafka broker. ",XD-3445,Sabby Anandan,Fix Kafka Binder for s-c-s modules
324,Gunnar Hillert,Sabby Anandan,"As a s-c-d developer, I'd like to setup {{gh_pages}} branch for s-c-d and s-c-s-m repos, so I can start pushing documentation with PR commits.",XD-3444,Sabby Anandan,Create gh_pages for s-c-d and s-c-s-m repos
325,,Glenn Renfro,,XD-3443,Glenn Renfro,User wants a task status command to retrieve all task & Job info for the running or completed job
326,,Glenn Renfro,"User wants to restart a failed Job via the CLI.   
i.e.
task relaunch job-instance id",XD-3442,Glenn Renfro,User wants to restart failed job from SCD
327,,Glenn Renfro,"User should be able to execute a task cancel <task name>.  Which will terminate a running task.  And set the state of the task to ""cancelled"".

",XD-3441,Glenn Renfro,User wants ability to cancel a running task from SCD CLI
328,,Glenn Renfro,"Need infrastructure to capture the state from the environment (lattice, local) running the task.  
Task Launcher needs ability to map the task state as it is reported from the cloud environment (lattice, local) to the enumerated state as specified [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].

The state information needs to be recorded in the task_execution table enumerated [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].",XD-3440,Glenn Renfro,Tasks Launcher should be able to record status to a central repository
329,Michael Minella,Glenn Renfro,,XD-3439,Glenn Renfro,User wants the ability to check the status of a job or task from the CLI
330,Thomas Risberg,Glenn Renfro,"SCD Admin will have connection information for a task and job repository.  This information will need to be transferred to the Task Launcher.

The scope is to study the following options:
* Would the default place for configurations be in the YAML file?
* {{config-server}} should be an option?
* If nothing specified, the default is always YAML?",XD-3438,Glenn Renfro,Spike: Study options for loading reusable configurations 
331,,Glenn Renfro,"The state of a task or job should be recorded such that it can be monitored by a user.
",XD-3437,Glenn Renfro,The state of a task or job should be recorded such that it can be monitored by a user
332,Glenn Renfro,Glenn Renfro,"Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs.  
",XD-3436,Glenn Renfro,Create a spring cloud stream timestamp task module
333,,Eugene Bell,"If there is a large number of deployments it would be helpful to have a quick search filter in place to enable users to find deployments faster, as can be done in the Definitions page.",XD-3435,Eugene Bell,Add search box to the Admin UI for Deployments page
334,,Berti Jalon,"In JOBS tab; Quick-filter search box paging functionality is not working as expected. Items stay in the page they were first loaded after filtering. 
ex. If there were 500 pages of jobs and you are filtering for a job which was in 345. page, after the filtering you have to navigate to that page in order to see the job. It needs to be rendered on the first page. 

",XD-3434,Berti Jalon, Issue with pagination in web UI
335,,vignesh,"The Chrome UI Interface for flo stream creation stops responding after some time. It starts working once the browser history/ cookies etc. are cleaned up. 

. The drop down stops working,  
. i'm unable to look at or edit module properties, 
. connecting different modules doesn't work either
. Drag and drop operations still work
. command line stream creation still works

is anyone else facing these issues ? 

Thanks ! ",XD-3433,vignesh,[Flo] UI unresponsive after some time
336,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The s-c-s-module-launcher document requires update for running it on standalone, docker, lattice.
Also, the docker-compose yml requires fix so that modules in there are bound together.",XD-3432,Ilayaperumal Gopinathan,Update documentation for module launcher
337,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Instead of using real `moduleDeployer`, try using mocks so that the module deployer downloading the maven co-ordinates from repo can be avoided (for module deployment case).

Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.",XD-3431,Ilayaperumal Gopinathan,Use mocks in shell tests
338,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to provide optional key-value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed. 

_The scope of this story is to specifically support {{count}} to represent {{N}} instances of modules that share the same environment variables._",XD-3430,Sabby Anandan,"Add support for ""deployment properties"""
339,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to have {{module unregister}} shell command, so I can unregister an existing module from the {{ModuleRegistry}}.",XD-3429,Sabby Anandan,"Add ""module unregister"" command"
340,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to have {{module register}} shell command, so I can register new modules in the {{ModuleRegistry}}.",XD-3428,Sabby Anandan,"Add ""module register"" command"
341,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to have {{module list}} shell command, so I can query and list all the modules supported within the {{ModuleRegistry}}.",XD-3427,Sabby Anandan,"Add ""module list"" command"
342,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to have {{module info}} shell command, so I can query each of the module specifics such as description and support options. ",XD-3426,Sabby Anandan,"Add ""module info"" command"
343,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to have {{module info}}, {{module list}}, {{module register}}, and {{module unregister}} commands, so I can interact with {{ModuleRegistry}}.",XD-3425,Sabby Anandan,Support shell commands to interact with module registry
344,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"This JIRA addresses couple of issues:
1) When the modules are deployed into cloud environment there is an issue where local configuration beans collide with cloud service beans. We witnessed an issue where there are two `RedisConnectionFactory` beans registered in the same application context.
We need to have a control the way in which the auto configuration gets invoked and service beans are created.
2) We need to align the cloud connector dependencies into a common place so that we don't have to specify them at various places like (SCS, SCS-Binder, SCS-modules) etc.,
It is a good idea to have these dependencies specified in SCS-modules so that it get used subsequently by SCS when the module is assembled at runtime.",XD-3424,Ilayaperumal Gopinathan,Fix Cloud connector dependencies and service resolution
345,Glenn Renfro,Michael Minella,"h2. Narrative
As a user, I need to be able to deploy a task (boot jar) via the CLI.

h2.  Back story
Since the concept of jobs as an explicit primitive within Spring XD is going away in spring-cloud-data, the shell needs to be updated to reflect that.",XD-3423,Michael Minella,Update Shell to support tasks
346,,Mark Pollack,,XD-3422,Mark Pollack,Create unit tests for CounterSinkProperties in s-c-s-m
347,Eric Bottard,Mark Pollack,"Can take from previous implementation in XD/SI/Boot.
Should have a way to enforce not skipping tests based on an environment variable.

Consider moving this coverage to SI ""commons"" or equivalent. ",XD-3421,Mark Pollack,Create a Rabbit|Kafka Available Rule in s-c-s-m
348,,Mark Pollack,,XD-3420,Mark Pollack,RedisSink to support in-memory store
349,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to create {{ModuleRegistry}} implementation, so I can use this infrastructure to lookup module coordinates by name.",XD-3419,Sabby Anandan,Add registry to lookup module coordinates by name
350,David Turanski,Sabby Anandan,"As a s-c-s developer, I'd like to enable {{offline}} mode for {{AetherModuleResolver}}, so I can pull the module artifacts from local instead of remote maven repo.",XD-3418,Sabby Anandan,"Enable ""offline"" mode for AetherModuleResolver"
351,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Make ChannelBindingAdapter implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.,XD-3417,Ilayaperumal Gopinathan,Add SmartLifecycle to ChannelBindingAdapter
352,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to create foundation to support _processor_ as OOTB modules, so I can use the processor modules from {{s-c-s-m}} repo to build streaming pipeline.",XD-3416,Sabby Anandan,Create foundation to support s-c-s 'processor' modules
353,,David Turanski,"Ultimately module IntegrationTest classes should themselves be a module so that testing a Source for example would use a TestSink and the message verified on the sink input().  This is currently a placeholder which includes:
* SCS enhancements to support proxying of Pollable or Subscribable MessgeChannels
* Corresponding Changes to the s-c-s-test-support to eliminate MessageCollector and provide support for easily using the test's PollableChannel(s) if necessary, e.g. test-specific annotations
* Related to or may depend on implementing direct binding (composed modules) in s-c-s 
* Refactor existing module test code",XD-3415,David Turanski,[SCS]Replace MessageCollector with generic SI Components
354,Eric Bottard,Sabby Anandan,"As a s-c-d developer, I'd like to create a new project to contain all the rules associated {{@RedisRule}} contract, so it is isolated from core functionalities and reusable by test coverage as needed.  

Consider moving this coverage to SI ""commons"" or equivalent. ",XD-3414,Sabby Anandan,Create a new project for @RedisRule
355,,Sabby Anandan,"h2. Narrative
As Spring XD, I will be able to launch Spring Boot jar files as Diego Tasks.

h2. Back story
The {{TaskLauncher}} will be responsible for listening for launch requests, looking up the definition in the {{TaskDescriptorRepository}}, and launching it.  The first implementation of this would be a Receptor based implementation. 

*See:* https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit",XD-3413,Sabby Anandan,Enhance TaskLauncher
356,Gary Russell,Sabby Anandan,"As a Spring XD developer, I'd like to port SFTP module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.
",XD-3412,Sabby Anandan,Port SFTP as s-c-s source module
357,,Sabby Anandan,"As a s-c-d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s-c-d repo.",XD-3411,Sabby Anandan,Move external library resolver to its own project
358,,Sabby Anandan,"As a s-c-d developer, I'd like to enforce external libraries from overriding any existing library in the uber-jar.",XD-3409,Sabby Anandan,Prevent external libraries from overriding uber-jar dependencies
359,Marius Bogoevici,Sabby Anandan,"As a s-c-d developer, I'd like to add support to add external libraries, so I can consume such dependencies for modules in an uniform way.",XD-3408,Sabby Anandan,Support adding new libraries
360,,Sabby Anandan,"As a s-c-d developer, I'd like to complete documentation and test-cases on resolving and adding JAR's to Boot loader, so we could use this as a reference while porting modules with external dependencies. ",XD-3407,Sabby Anandan,Document the process of resolving and adding JARs to Boot loader
361,,Sabby Anandan,"As a s-c-s developer, I'd like to refactor the current {{ModuleLauncher}} contract with Boot's {{JarLauncher}} API, so we don't have to maintain duplicate functionality.",XD-3406,Sabby Anandan,Refactor to use Boot's JarLauncher
362,,Sabby Anandan,"As a s-c-d developer, I'd like to experiment how do we resolve and then add module dependent JAR's to Boot loader, so I have an approach to handle external libraries required by OOTB modules. ",XD-3405,Sabby Anandan,Spike: Study how to resolve and add JARs to Boot loader
363,Janne Valkealahti,Sabby Anandan,"As a s-c-d developer, I'd like to make the deployer work asynchronously, so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.",XD-3404,Sabby Anandan,Refactor YARN deployer to deploy asycnhrounously
364,Janne Valkealahti,Sabby Anandan,"As a s-c-d developer, I'd like to support multiple app instances:
* This is simply to make controlling app instances more clever. Potentially we could use deployment properties to define different yarn app instances like:

{code}
cloud-data:>stream deploy --name ticktock --properties ""module.*.yarn.app.name=app"" 

cloud-data:>stream deploy --name ticktock --properties ""module.time.yarn.app.name=app""
{code}

* Motivation to this is that different yarn apps can have different queues and priorities. Yarn administrator can define that some app queues have higher priority to reserve resources from

* Using deployment properties like this allows to customize runtime parameters like how much we try to reserve mem/cpu for modules, etc.",XD-3403,Sabby Anandan,Add support to spin-up multiple App instances
365,Janne Valkealahti,Sabby Anandan,"As an s-c-d developer, I'd like to add support to negotiate with the ResourceManager REST-APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as  {{appType=CLOUDDATA}} and {{appName=spring-cloud-data-yarn-app}}.
",XD-3402,Sabby Anandan,Add support to start Apps in YARN automatically by type
366,Janne Valkealahti,Sabby Anandan,"As a s-c-d developer, I'd like to add support to deploy YARN App into HDFS automatically, so I can have the {{xd-admin}} orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.",XD-3401,Sabby Anandan,Add support for deploying YARN app into HDFS
367,Janne Valkealahti,Sabby Anandan,"As a s-c-d user, I'd like to have the option to support passing definition parameters into YARN container, so I can effectively use those _params_ within the module running inside the container.",XD-3400,Sabby Anandan,Add support for passing parameters to YARN container
368,Glenn Renfro,Glenn Renfro,"Build SCS and SCD projects upon change in github repo.
Push docker image for SCD-Admin to docker hub",XD-3399,Glenn Renfro,Create CI Builds for SCD and Receptor Client
369,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a s-c-s developer, I'd like to create auto configuration for {{singlenode}} binder configuration/properties, so I can automatically configure the Spring application based on the dependencies.",XD-3398,Ilayaperumal Gopinathan,Create auto configuration/properties for Local Binder
370,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations.,XD-3397,Ilayaperumal Gopinathan,Port admin web UI to Spring Cloud Data admin
371,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Spring-cloud-data admin requires lattice connector and `spring-cloud-spring-service-connector` dependencies so that the admin controllers get access to any services while running on lattice.

One example is, CounterContoller using `redis` service for MetricRepository.",XD-3396,Ilayaperumal Gopinathan,Add cloud connector dependencies for spring-cloud-data admin
372,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Improve Spring Cloud Stream module launcher/resolver properties:

1) Support comma separated remoteRepositories
2) Classify/group the properties",XD-3395,Ilayaperumal Gopinathan,Module Launcher properties improvments
373,Sabby Anandan,Gary Russell,"Spring Integration 4.2 changed the default SFTP session factory to *not* accept keys from unknown hosts by default. This is more secure.

You either have to provide a pre-populated {{known_hosts}} file or set {{allowUnknownKeys}} to true.

If you do both, the keys will be automatically added to the known hosts file.

When updating XD to 4.2.0.RC1 I simply set the boolean to true, to retain the previous behavior.

Add properties to the SFTP source to allow configuration of these properties at the stream level.
",XD-3394,Gary Russell,Known Hosts Configuration for SFTP Source
374,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to upgrade {{receptor-client}} to comply with latest {{Receptor}} API changes, so I can sync-up and take advantage of the recent improvements. ",XD-3393,Sabby Anandan,Upgrade receptor-client to comply with latest Receptor APIs
375,,José Carlos Valero Sánchez,"At the moment, a custom module can not be upgraded at all, it's not only a desired story, as stated in [XD-2889|https://jira.spring.io/browse/XD-2889]. It's indeed a major issue, since the only way to upgrade a module is by destroying the previous version first.

However a module can not be destroyed if it's being used in existing streams, which means there is no way (at least using shell utilities) to upgrade once spring-xd is in production. Because destroying streams is simply not an option.

What is even more annoying, if some default configuration is included in conf folder. The module can't be upgraded unless that configuration is previously removed, which makes everything even more inconvenient, because in order to upgrade custom modules, SpringXD requires you to:

# Remove all streams using that module
# Remove existing configuration
# Destroy the existing module
# Upload the new version
# Re-create the previously removed configuration
# Re-create all destroyed streams
# Re-deploy all previously deployed streams.",XD-3392,José Carlos Valero Sánchez,Upgrading custom module issues
376,,Eric Bottard,"See discussion at https://github.com/spring-cloud/spring-cloud-data/pull/37#discussion_r36849117

Also relevant: http://docs.spring.io/spring-hateoas/docs/current/reference/html/#client",XD-3391,Eric Bottard,Come up with a consistent Link consumption scheme on the REST client side
377,,Gunnar Hillert,"Accessing REST endpoint using the "".json"" file extension causes maintenance issues for the authorization rules and is not necessary. Remove any usage for the Admin UI and the Shell. 

At the same time the "".json"" endpoint shall be deprecated or removed ultimately.",XD-3390,Gunnar Hillert,"UI + Shell: Remove any usage of REST endpoints using the "".json"" notation"
378,,Sabby Anandan,"As a Spring XD user, I'd like to use redis/sentinel cluster as the 'message bus', so I could create streams and batch pipelines.",XD-3389,Sabby Anandan,Add Boot config to support user/pass combination for redis/sentinel cluster
379,,Sabby Anandan,"As a Spring XD developer, I'd like to move {{trigger}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.
",XD-3388,Sabby Anandan,Port Trigger as s-c-s source
380,Gunnar Hillert,sridhar,"Hi,
Passwords are visibly when using custom modules.

Attached is example custom module code and xd-shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE.
 
Compile with Maven (mvn clean install) and run xd-shell script (xd-shell --cmdfile ./runme.cmd).
",XD-3387,sridhar,Hide the passwords in custom modules from being displayed.
381,,Ayyappan,"I am parsing Json(source)  into CSV  in Transform function
All of my Json records may not have all the fields.
Some records have only Field1,field2.. some other records have all 3 fields.
if the specific field is not exists in specific record, that record got rejected.(by saying field is not exist)
Could you please let me know how to check the field exists or not.
Here my expression part of the stream
transform --expression=#jsonPath(payload,'$.field1').concat('|').concat(#jsonPath(payload,'$.field2')).concat('|').concat(#jsonPath(payload,'$.field3'))

My Spring XD version is  1-0-0-m7",XD-3386,Ayyappan,check whether the field exists or not in  #jsonpath evaluation
382,Thomas Risberg,Thomas Risberg,"Building and then running spring-cloud-data-rest app on Ubuntu fails when trying to create the first stream. The configuration ends up with a CloudFoundryConfig instead of LocalConfig for the moduleDeployer.

Env:
Ubuntu 15.04
java version ""1.8.0_51""
Java(TM) SE Runtime Environment (build 1.8.0_51-b16)
Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode)

Error:
{code}
2015-08-10 11:43:47.199 ERROR 11062 --- [nio-9393-exec-1] o.s.c.d.r.c.RestControllerAdvice         : Caught exception while handling a request
java.lang.UnsupportedOperationException: null
	at org.springframework.cloud.data.module.deployer.cloudfoundry.CloudFoundryModuleDeployer.deploy(CloudFoundryModuleDeployer.java:30) ~[spring-cloud-data-module-deployer-cloudfoundry-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]
	at org.springframework.cloud.data.rest.controller.StreamController.deployStream(StreamController.java:213) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]
	at org.springframework.cloud.data.rest.controller.StreamController.save(StreamController.java:140) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:111) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:648) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-embed-websocket-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:235) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:69) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1521) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1478) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_51]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]
2015-08-10 11:43:47.284  WARN 11062 --- [nio-9393-exec-1] .m.m.a.ExceptionHandlerExceptionResolver : Handler execution resulted in exception: null
{code}",XD-3385,Thomas Risberg,Can't build and run singlenode spring-cloud-data-rest app on Ubuntu
383,Janne Valkealahti,Sabby Anandan,"As an s-c-d developer, I'd like to investigate the distributed deployment of s-c-s modules on YARN, so I can experiment the implementation of YARN SPI and derive the strategy for {{YARNModuleDeployer}}.",XD-3384,Sabby Anandan,Spike: Investigate distributed deployment of s-c-s modules via YARN SPI
384,,Sabby Anandan,"As an s-c-d user, I'd like to have the option to deploy s-c-s modules in YARN, so I can leverage this implementation to spin-up OOTB modules as Apps in YARN.",XD-3383,Sabby Anandan,Distributed deployment of s-c-s modules in YARN
385,Eric Bottard,Eric Bottard,"The `@ConfigurationProperties` class for Rabbit binder has some props related to RetryTemplate, but those are not used",XD-3382,Eric Bottard,RetryTemplate props in Rabbit binder are not used
386,Eric Bottard,Eric Bottard,"As a module author, I want to be able to test my code in ""next to real world"" conditions (ie Integration Testing, but not really):
- I want all my module wiring to be testable
- I want all my module configuration (@ConfigurationProperties) to be in effect, and I want to be able to test various combination of props
- I want to be able to send data to my module and assert what is coming at the other end
- I want an idiomatic way of asserting the above (eg integration with Hamcrest, etc)
- I DONT want to have to send data to an actual bus (redis, rabbit, etc)",XD-3381,Eric Bottard,Provide test infrastructure for module authors
387,Eric Bottard,Eric Bottard,"Currently, @EnableModule hardcodes references to both the redis and rabbit configuration classes, which trigger or don't trigger based on the presence of another jar (which itself has the meat of the configuration).
This is typically what boot AutoConfiguration is for.

Moreover, adding a new binding (eg Kafka or a stub for module testing) would require to crack open @EnableModule",XD-3380,Eric Bottard,Refactor Binder @Configuration to use AutoConfiguration
388,,Sabby Anandan,"As a Spring XD developer, I'd like to create a section on migration strategy from {{1.2}} to {{1.3}} releases, so I can document new improvements and backward incompatibility specifics.",XD-3379,Sabby Anandan,[Ambari] Document migration strategy from 1.2 to 1.3 
389,Thomas Risberg,Sabby Anandan,"As a Spring XD user, I'd like to use the latest releases of {{HDP}}/{{PHD}} distros, so I can leverage the latest features to create pipelines involving {{HDFS}}.",XD-3378,Sabby Anandan,Upgrade HDP/PHD distrubutions
390,Patrick Peralta,Michael Minella,Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules).  This results in a lot of duplication.  This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.,XD-3377,Michael Minella,Refactor Task parsing 
391,David Turanski,Sabby Anandan,"As a Spring XD developer, I'd like to move {{gemfire}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",XD-3376,Sabby Anandan,Port gemfire-server sink as s-c-s module
392,,Sabby Anandan,"As a s-c-d developer, I'd like to move {{rabbit}} module from XD to s-c-s repo, so I can use it as {{source}} to build streaming pipeline.",XD-3375,Sabby Anandan,Port Rabbit as s-c-s source
393,Eric Bottard,Sabby Anandan,"As a Spring XD developer, I'd like to move {{redis}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",XD-3374,Sabby Anandan,Port Redis as s-c-s sink
394,Thomas Risberg,Thomas Risberg,"Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently.

The error is: 
  Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

which indicates that the yarn-site.xml file never made it to the classpath.

Un-deploying and re-deploying the job seems to fix the problem.",XD-3373,Thomas Risberg,First deploy/launch of Pig job that includes yarn-site.xml file fails
395,,José Carlos Valero Sánchez,"At the moment, the correlation expression in the aggregator module only takes into consideration the incoming message rather than the whole existing collected messages so far + the incoming message.

It would be great to gain access to the whole collection apart from the incoming message so messages could be correlated in a way such as:

Collect 1 (and only one) message of each type, if we have fruits, for example we may want to get one pear, and one banana aggregated per basket, and we want to release a basket once it's ready. If we receive 100 bananas, we want to prepare 100 baskets and wait for pears to arrive so our fruity baskets can be released.

There is no way to do such a thing if the correlation key only takes into consideration the incoming message.",XD-3372,José Carlos Valero Sánchez,Aggregator module refinements
396,,José Carlos Valero Sánchez,It would be tremendously useful to include an optional description for a given stream/job so a high level explanation of what's the purpose of a specific stream can be detailed in a human friendly way.,XD-3371,José Carlos Valero Sánchez,Optional description for streams
397,Gary Russell,Sabby Anandan,"As a Spring XD developer, I'd like to port {{FTP}} module from XD to s-c-s repo, so I can use it as {{sink}} modules to build streaming pipeline.",XD-3370,Sabby Anandan,Port FTP as s-c-s sink module
398,Mark Fisher,Sabby Anandan,"As a Spring XD developer, I'd like to port {{file}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",XD-3369,Sabby Anandan,Port File as s-c-s sink
399,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{router}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",XD-3368,Sabby Anandan,Port Router as s-c-s sink
400,Eric Bottard,Sabby Anandan,"As a Spring XD developer, I'd like to port {{transform}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3367,Sabby Anandan,Port Transform as s-c-s module
401,Eric Bottard,Sabby Anandan,"As a Spring XD developer, I'd like to port {{filter}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",XD-3366,Sabby Anandan,Port Filter as s-c-s module
402,Ilayaperumal Gopinathan,Sabby Anandan,"As a Spring XD developer, I'd like to move {{twittersearch}} module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.
",XD-3365,Sabby Anandan,Port Twittersearch as s-c-s module
403,Ilayaperumal Gopinathan,Sabby Anandan,"As a Spring XD developer, I'd like to move {{twitterstream}} module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.
",XD-3364,Sabby Anandan,Port Twitterstream as s-c-s module
404,,Sabby Anandan,"As a Spring XD developer, I'd like to port {{tcp}} module from XD to s-c-s repo, so I can use it as {{source}} module to build streaming pipeline.
",XD-3363,Sabby Anandan,Port TCP as s-c-s module
405,Eric Bottard,Sabby Anandan,"As a Spring XD developer, I'd like to port {{http}} module from XD to s-c-s repo, so I can use it as {{source}} module in streaming pipeline.
",XD-3362,Sabby Anandan,Port HTTP as s-c-s module
406,,Glenn Renfro,,XD-3361,Glenn Renfro,Create a standard way to configure Spring Cloud Data and Stream projects
407,,Glenn Renfro,"Enable spring cloud config for all modules 
* Add spring cloud config client to pom dependencies. 
* Add bootstrap.yml to scs project
",XD-3360,Glenn Renfro,Add Spring Cloud Config to SPI Module Parent
408,Glenn Renfro,Glenn Renfro,"User can configure spring cloud data via  via Spring Cloud Config, data-admin.yml or Spring Cloud Connector
* Add bootstrap.yml to spring cloud data
* create a default data-admin.yml and configure spring data to look for this vs application.yml.
* Spring Cloud Data will have Spring Cloud Config enabled by default
** User has the ability to disable it via the bootstrap.yml",XD-3359,Glenn Renfro,Standardize Spring Cloud Data configuration
409,Gary Russell,Thiago Souza,"When deploying a job through admin UI with a count of 0 the module is actually deployed with count 1.

More info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties]",XD-3358,Thiago Souza,Admin UI deploys job with wrong module count
410,Thomas Risberg,Sabby Anandan,"As a Spring XD user, I'm trying to use a custom MongoDB Batch job; however, I'm getting an error running it against 1.2.0/1.2.1 release, while the same works with older releases of Spring XD. More details in this [SO thread|http://stackoverflow.com/questions/31838720/mongodb-batch-job-broken-in-spring-xd-1-2-0].
",XD-3357,Sabby Anandan,MongoDB Batch Job Broken
411,,José Carlos Valero Sánchez,"It could be useful to have the possibility to define tags for streams so streams can be filtered out later using these tags both in the UI and REST api.

The reason being for that is once you start creating multiple small streams in XD the environment becomes a bit unmanageable. And having basic tagging would definitely bring a mechanism to organize streams in a clear way, providing also the possibility to build nice apps around XD querying certain relevant streams in different ways.",XD-3356,José Carlos Valero Sánchez,Create tags for streams
412,Eric Bottard,Sabby Anandan,"As a s-c-d developer, I'd like to derive a strategy for module metadata via {{@ConfigurationProperties}}, so I can implement {{module info}} command in shell to list all the module properties. 
",XD-3355,Sabby Anandan,Add support for 'module info' to list module properties
413,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,This could focus only on the subset (Stream operations),XD-3354,Ilayaperumal Gopinathan,Move shell integration tests to spring-cloud-data shell 
414,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,As a user I would like to have shell interface to the spring-cloud-data rest API. The scope for this JIRA could be limited to stream commands.,XD-3353,Ilayaperumal Gopinathan,Add shell as a rest client to the spring-cloud-data REST API
415,David Turanski,David Turanski,Create Confguration and ConfigurationProperties. Configuration must support replacing the default Kryo Codec implementation with something else.,XD-3352,David Turanski,[SCS] - Replace Binder XML config with @Configuration
416,David Turanski,David Turanski,,XD-3351,David Turanski,[SCS]- Replace codec impl in spring-cloud-stream-codec with SI-Codec
417,Eric Bottard,Sabby Anandan,"As a s-c-d developer, I'd like to add support to expose counter (metrics) endpoints, so I can consume to feed the dashboards to demonstrate {{firehose | counter}} pipe.",XD-3350,Sabby Anandan,Add support to expose counter metrics for dashboarding
418,Mark Pollack,Sabby Anandan,"As an s-c-s developer, I'd like to brainstorm and design the foundation to port XD modules as s-c-s modules, so I can use it as the base and start migrating the modules.",XD-3349,Sabby Anandan,Design the foundation to port XD modules to s-c-s
419,,Sabby Anandan,"As a s-c-d developer, I'd like to add support for _profiles_ to the core {{Admin}} application, so I can back the stream repository with respective backend strategy. For example: {{local}} profile would use in-memory strategy to store the metadata.",XD-3348,Sabby Anandan,Add profile support for stream repositories
420,Gunnar Hillert,Gunnar Hillert,Apply the same strategy for the Module Command Tests also to all other Shell integration tests.,XD-3347,Gunnar Hillert,Run all shell integration tests also with enabled security
421,Gunnar Hillert,Sabby Anandan,"As a XD user, I'm trying to access URI (- GET /jobs/executions//steps//progress => hasRole('ROLE_VIEW')), but it fails with 403 forbidden error for the role with view access. More details [here|https://issuetracker.springsource.com/browse/VESC-475].

Another URL with the same error: http://<HOST>:9393/streams/definitions.json?page=0&size=10",XD-3346,Sabby Anandan,Accessing step progress via REST fails with 403
422,,Swagata Roy,"Running Spring-XD in singlenode using Pivotal HD 2.1 as the Hadoop Distribution. 

xd-singlenode --hadoopDistro phd21

I was testing  jdbchdfs job definitions. I am seeing this error that the job exists when in reality, there is no job with that jobName. 

xd:>job create testEmployeeJobAgain1 --definition ""jdbchdfs --sql='select employee_id, employee_name, employer from EMPLOYEE' --url=jdbc:oracle:thin:@//localhost:1521/orcl --driverClassName=oracle.jdbc.OracleDriver  --username=springxd --password=xdpwd --testOnBorrow=false --directory=/usr/swatest1"" 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name testEmployeeJobAgain1 already exists

xd:>job list
  Job Name  Job Definition  Status
  --------  --------------  ------",XD-3345,Swagata Roy,Job creation fails saying it exists (there isn't any job with that jobName)
423,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to implement _undeploy_ operation for {{singlenode}} (single JVM), so I can use this target to undeploy a running stream. More details in [this PR|https://github.com/spring-cloud/spring-cloud-data/pull/19].

*Note:* Its a prerequisite to determine consistent _undeploy_ strategy for both {{jobs}} and {{streams}}. ",XD-3344,Sabby Anandan,Implement undeploy operation for singlenode SPI 
424,Mark Fisher,Sabby Anandan,"As a s-c-s developer, I'd like to create a public screencast of {{firehose| counter}} pipe, so I can demonstrate s-c-s and the development experience.",XD-3343,Sabby Anandan,Create a public screencast of 'firehose | counter'
425,,Sabby Anandan,,XD-3342,Sabby Anandan,Singlenode implementation of Admin SPI
426,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to publish the s-c-d image to DockerHub, so I can incrementally push the latest commits to the remote location.",XD-3341,Sabby Anandan,Publish s-c-d image to DockerHub
427,,Sabby Anandan,,XD-3340,Sabby Anandan,Distributed implementation of Receptor SPI
428,,Sabby Anandan,"As a s-c-d developer, I'd like to add support for dependency resolution, so when two or more modules use different version of jars (ex: direct binding of two modules that include different versions of spring data), I have the capability to resolve and include the right bits at runtime.",XD-3339,Sabby Anandan,Dependency resolution support for modules with different versions
429,Marius Bogoevici,Sabby Anandan,"As a s-c-d developer, I'd like the 'includes' feature of the module launcher not to include optional dependencies, so that I can have better control over what gets added to the class path.",XD-3338,Sabby Anandan,Do not include optional dependencies automatically via 'includes'
430,,Sabby Anandan,"As a s-c-d developer, I'd like to investigate how to include/exclude msg bus/binding jars, so I can decide the binding selection and fallback mechanism when there is none setup.",XD-3337,Sabby Anandan,Spike: Investigate the inclusion of message bus binding libaries
431,,Sabby Anandan,,XD-3336,Sabby Anandan,Tasks related to handling jars for the ModuleLauncher
432,Marius Bogoevici,Marius Bogoevici,"If the value is not set, the source may start before being bound to the bus, throwing a ""Dispatcher has no subscribers"" error",XD-3335,Marius Bogoevici,Kafka Source must set autoStartup=false on KafkaMessageDrivenChannelAdapter
433,Steve Powell,Paul Harris,"The current implementation makes use of cf-java-client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See https://github.com/Zteve/test-cc-oauth for sample code.",XD-3334,Paul Harris,Refactor to use RestOperations
434,,Paul Harris,This class should not know what the test app is. This means changing the constructors on CloudFoundryApplication.,XD-3333,Paul Harris,Refactor CloudFoundryApplicationFactory
435,,Paul Harris,As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.,XD-3332,Paul Harris,Obtain username and password credentials for CloudFoundry
436,Steve Powell,Paul Harris,The current ModuleRunner is test app used for validation. This should be replaced by a real app.,XD-3331,Paul Harris,Add real ModuleRunner application
437,Steve Powell,Paul Harris,Currently undeploy is a no-op.,XD-3330,Paul Harris,Implement undeploy operation for CC SPI
438,Steve Powell,Paul Harris,Currently there is no ModuleInstanceStatus returned. This issue will fill in the details.,XD-3329,Paul Harris,Return full ModuleInstanceStatus information
439,Steve Powell,Paul Harris,Remove all stubs and check all required information is returned accurately.,XD-3328,Paul Harris,Return full ModuleStatus information
440,,Paul Harris,"Test Converter, Configuration, Definition and Status objects.",XD-3327,Paul Harris,[Unit Tests] Add test coverage for CC SPI
441,Steve Powell,Paul Harris,"A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application's environment. This issue will verify they are correctly named.",XD-3326,Paul Harris,Add parameter information to application definition
442,Steve Powell,Paul Harris,ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application's environment.,XD-3325,Paul Harris,Add binding information to application definition
443,,Sabby Anandan,"As a CF user, I'd like to use Spring XD on CloudFoundry, so I can leverage the benefits of CloudFoundry while running streaming and batch pipes using Spring XD.",XD-3324,Sabby Anandan,Distributed implementation of CloudController SPI
444,Ilayaperumal Gopinathan,Marc Navarro,"A test for a java spark module managed by maven, with parent *spring-xd-module-parent* launch a _*java.lang.NoClassDefFoundError*_.

I've forked the example repo [https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor|https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor] the samples project and created the *pom* file for the *spark-streaming-wordcount-java-processor* project and the corresponding test.

Partial stack trace:

{code:title=StackTrace}
2015-08-04 09:30:07,211 ERROR [DeploymentsPathChildrenCache-0] listen.ListenerContainer (ListenerContainer.java:run(96)) - Listener (org.springframework.xd.dirt.server.container.DeploymentListener@729c251b) threw an exception
java.lang.NoClassDefFoundError: org/eclipse/jetty/util/component/AggregateLifeCycle
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.apache.spark.HttpServer.org$apache$spark$HttpServer$$doStart(HttpServer.scala:74)
{code}

When the *WordCountTest* test is launched the exception is launched.

Is there a problem with the  *spring-xd-module-parent* module ? Are some dependencies left?",XD-3323,Marc Navarro,Test Spark Module with maven spring-xd-module-parent java.lang.NoClassDefFoundError
445,Mark Pollack,Sabby Anandan,"As a s-c-s developer, I'd like to setup CI infrastructure for {{spring-cloud-stream-modules}} (s-c-s-m) repo, so I can build the project continuously on every commits.
",XD-3322,Sabby Anandan,Create CI infrastructure for s-c-s-m repo
446,David Turanski,Sabby Anandan,"Post 1.2 upgrade, the custom modules no longer show up by just copying the jars to the {{xd.customModule.home}} directory. Instead I have to use the 'module upload' command to install the modules. This is because an MD5 file is required. More details in [SO thread|http://stackoverflow.com/questions/31792220/spring-xd-1-2-0-custom-module-deployment]. ",XD-3321,Sabby Anandan,Make requirement for MD5 hash files configurable for the custom module registry 
447,Patrick Peralta,Sabby Anandan,"As a s-c-d user, I'd like to add REST support for stream commands, so I can maneuver streaming pipeline backed by StreamController.",XD-3320,Sabby Anandan,Migrate StreamController from XD 1.0
448,Thomas Risberg,Sabby Anandan,"As a s-c-s developer, I'd like to investigate the right approach to port {{PHD}} as the provider to support {{HDFS}} module from XD, so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime. ",XD-3319,Sabby Anandan,Add PHD HDFS as s-c-s module
449,Marius Bogoevici,Sabby Anandan,"As a s-c-s developer, I'd like to _bootify_ {{ModuleLauncher}}, so I can use Spring Boot's support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation.
",XD-3318,Sabby Anandan,Bootify ModuleLauncher
450,Marius Bogoevici,Sabby Anandan,"As a s-c-d developer, I'd like to resolve and then add module dependent JAR's to Boot loader, so I have an approach to handle external libraries (ex: database drivers) required by OOTB modules.
",XD-3317,Sabby Anandan,Add support to resolve and add JARs to Boot loader
451,Mark Pollack,Sabby Anandan,"As a s-c-d developer, I'd like to setup CI infrastructure for [s-c-d repo|https://github.com/spring-cloud/spring-cloud-data], so I can build the project continuously on every commits. ",XD-3316,Sabby Anandan,Create CI infrastructure for s-c-d repo
452,Eric Bottard,Sabby Anandan,"As a s-c-s developer, I'd like to adapt redis {{counter}} from XD to s-c-s, so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards. ",XD-3315,Sabby Anandan,Port Redis counter as s-c-s sink
453,Patrick Peralta,Sabby Anandan,"As a s-c-d developer, I'd like to invoke REST APIs via shell, so I can validate {{StreamController}} operations.",XD-3314,Sabby Anandan,Validate stream commands from shell
454,Patrick Peralta,Sabby Anandan,"As a spring-cloud-data developer, I'd like to use an in-memory stream definition repository, so I don't have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience.
",XD-3313,Sabby Anandan,Add in-memory stream definition repository
455,Mark Fisher,Sabby Anandan,"As a s-c-s developer, I'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo, so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.",XD-3312,Sabby Anandan,Move spring-cloud-stream-modules to spring-cloud repo
456,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to create {[ModuleRegistry}} stubs, so I can create mock streams by interacting with the registry APIs.",XD-3311,Sabby Anandan,Create ModuleRegistry stubs
457,Mark Fisher,Sabby Anandan,"As a s-c-d developer, I'd like to establish the foundation to expose REST-APIs to interact with the {{xd-admin}} and likewise perform CRUD operations to maneuver streaming and batch pipelines. ",XD-3310,Sabby Anandan,Add REST support for spring-cloud-data
458,Marius Bogoevici,Sabby Anandan,"As a s-c-s user, I'd like to have the option to direct bind _modules_, so I don't have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases. 

",XD-3309,Sabby Anandan,Add direct binding option for s-c-s modules
459,Gunnar Hillert,Gunnar Hillert,"Once security is enabled, one cannot upload modules using the shell any longer.",XD-3308,Gunnar Hillert,With Security - Unable to upload module
460,Michael Minella,Michael Minella,"h2.  Narrarive
As a developer, I need to be able to test modules without pushing them to a remote maven repository.  I should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams.",XD-3307,Michael Minella,Add support for offline module resolution
461,Andy Clement,José Carlos Valero Sánchez,"Trying to create streams from the flo UI may end up in weird exceptions, whereas doing the same thing (copying/pasting the stream) directly from XD shell works smoothly.

This simple stream is an example, but this situation happens in multiple scenarios (for example using the same module several times with labels).


{code:java}
trigger --cron='0 05 14 ? * MON-FRI' | mail --from='''xd@mycompany.com''' --to='''a-wise-guy@mycompany.com''' --bcc='''me@mycompany.com'''
{code}
",XD-3306,José Carlos Valero Sánchez,[Flo] Some streams can't be created using FLO
462,,Glenn Renfro,"Currently Admin & Container only support latest, 1.0.x and 1.1.0 while singlenode only has tags for 1.0.x and latest.   
We need to have a tags for 1.1.0, 1.2.0, 1.2.1 for all XD Docker images.

",XD-3305,Glenn Renfro,Spring XD Docker Hub site needs to have images for all XD versions
463,,Jason Hubbard,"If an exception occurs during the deployment of a module within the ModuleRedeployer.redeployModule, the exception will cause the process to break out of the for loops in DepartingContainerModuleRedeployer and ContainerMatchingModuleRedeployer leaving other failed/undeployed modules still undeployed.  This is particularly bad for ContainerMatchingModuleRedeployer as a module with an issue deploying will be retried next time a container starts breaking all modules after it.",XD-3304,Jason Hubbard,Exception during ModuleRedeployer causes additional modules to not deploy
464,Thomas Risberg,Mark Pollack,"As a user, I'd like to refer to documentation while migrating to 1.3 release.",XD-3303,Mark Pollack,Update 1.3 installation instructions
465,,Dave Protasowski,HdfsOutboundChannelAdapterParser supports having a request-handler-advice-chain but it's not available via XML since the XSD for hdfs-outbound-channel-adapter doesn't have a  xsd:complexContent tag.,XD-3302,Dave Protasowski,hdfs-outbound-channel-adapter xml schema missing nested xsd:complexContent tag
466,,Thomas Risberg,We need better controll over how config files are preserved during upgrades. The RPM process handles that better for files that are designated as %config and they should reside outside of the directory where the software is installed so they can be kept around during version upgrades.,XD-3301,Thomas Risberg,Move config files in RPM install to /etc/spring-xd directory
467,Glenn Renfro,Michael Minella,"h2. Narrative
As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state.

h2. Back story
The XD containers each used a {{BatchConfigurer}} implementation ({{RuntimeBatchConfigurer}}) to add a consistent configuration for the job repository.  This functionality needs to be replicated in some way in just a regular Spring Boot application.",XD-3300,Michael Minella,Spike: Determine best way to centrally configure the job repository for batch jobs.
468,,Michael Minella,"h2. Narrative
As a developer, I need to be able to create a partitioned batch job that uses Diego Tasks for partition slaves.

h2. Back story
A new partition handler should be created that uses the Receptor API to launch tasks for each of the slaves (configurable via grid size).",XD-3299,Michael Minella,Create a Receptor PartitionHandler and related StepExecutionRequestHandler
469,Michael Minella,Michael Minella,"h2. Narrative
As Spring XD, I will be able to launch Spring Boot jar files as Diego Tasks.

h2. Back story
The {{TaskLauncher}} will be responsible for listening for launch requests, looking up the definition in the {{TaskDescriptorRepository}}, and launching it.  The first implementation of this would be a Receptor based implementation. The scope here is to produce a _basic_ version of {{TaskLauncher}} and incrementally evolve into comprehensive launch capabilities.

*See:* https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit",XD-3298,Michael Minella,Create basic TaskLauncher
470,,Michael Minella,"h2. Narrative
As a developer, when running a batch job on Diego/Lattice as a task, I want to be able to receive events based on the job lifecycle.

h2. Back story
XD 1.x provides exposure to all of the main listeners Spring Batch supports via streams so they can be listened to.  This needs to be supported in the new spring-cloud-streams model.

*Note:* We may want this to depend on XD-2841?",XD-3297,Michael Minella,Spike: Determine how to integrate job events into spring-cloud-streams
471,Glenn Renfro,Michael Minella,"h2. Narrative
As a developer, I'd like to be able to run a boot jar as a task on CF and obtain the result reliably.

h2. Back story
Currently Lattice/Diego's tasks implementation provides the ability to run things as short lived tasks.  However, obtaining the result of said task can be an issue.  There are two ways to do so:

# Poll for the result.
# Register a callback URL to be called once the task completes.

Since a task is only available for a short time after its completion before it is deleted, polling can run the risk of missing the result completely.  When you consider the fact that the provided GUIDs that identify tasks can be re-used polling becomes a precarious option.

Registering a callback URL would be a better option, however there are no good guarantees that the message will be delivered.  The service will try to execute the callback until it's successful or the task is cleaned up.  ""Successful"" is defined in this case as anything other than a 502 or a 503 return code.

In order for Spring XD to be able to support Diego tasks, a more durable option for maintaining the result of tasks will need to be developed.

*Note:* The outcome of this spike may be feature requests for the CF/Diego team.",XD-3296,Michael Minella,Spike: Design a tasks repository
472,,Michael Minella,"h2. Narrative
As a developer, I'd like to be able to configure common dependencies for the entire environment.  An example could be that I use MySql for my databases.  I want to be able to configure the MySql driver once and have all modules use it.

h2. Back story
Spring Batch uses a database to store job state (the job repository).  This is a shared resource across all jobs (both custom developed and OOTB).  In order to support OOTB jobs, we'll need to have a way for users to provide the db driver to each module.  Ideally this would be possible without requiring that each of our OOTB modules be repackaged.
",XD-3295,Michael Minella,Spike: Determine options for configuring shared module dependencies
473,,Sabby Anandan,"As an operator, I'd like to upgrade to the latest releases of Spring XD and yet not lose the older installation {{dirs}}/{{files}}, so I can copy and reuse the previously used {{servers.yml}} configurations. ",XD-3294,Sabby Anandan,RPM upgrades should not to wipe-out previous installation configs/settings
474,Mark Pollack,Sabby Anandan,"As a Spring XD user, I'd like to have IPython Notebook integration, so I can perform interactive data computations in real-time.
",XD-3293,Sabby Anandan,Spike: Investigate integration options with ipython
475,,Sabby Anandan,"As a Azure user, I'd like to read/write data from Azure Event Hubs. so I can leverage the pub-sub service to process and analyze large volumes of data.",XD-3292,Sabby Anandan,Add Azure Event Hubs integration
476,,Sabby Anandan,,XD-3291,Sabby Anandan,Collection of stories to integrate with Azure services
477,,Sabby Anandan,"As a Spring XD user, I'd like to have [IPython Notebook|http://ipython.org/notebook.html] integration, so I can perform interactive data computations in real-time.",XD-3290,Sabby Anandan,Add IPython notebook integration through Flo
478,,Sabby Anandan,,XD-3289,Sabby Anandan,Collection of stories to add notebook support
479,Glenn Renfro,Sabby Anandan,"As a s-c-s developer, I'd like to setup a CI workflow to build, bundle and upload the {{module-launcher}} image to DockerHub, so I don't have to worry about having a local-private docker registry for development/testing.

It could be nice to have the image uploaded to existing [spring-cloud|https://registry.hub.docker.com/repos/springcloud/] DockerHub location. ",XD-3288,Sabby Anandan,"Add CI workflow to build, bundle and upload module-launcher image to DockerHub"
480,Janne Valkealahti,Sabby Anandan,"As a user, I'm trying to setup HA cluster using Ambari installed Spring XD; however, I'm running into issues with the overrides. More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].",XD-3287,Sabby Anandan,Add HA support for NameNode when installed using Ambari
481,,Sabby Anandan,"As a Spring XD developer, I'd like to port OOTB modules from XD to s-c-s model, so I can reuse and build messaging microservices.

Prioritized list [here|https://docs.google.com/spreadsheets/d/1Tn8wFZgfs1cAZSs_xUQzEIOFPZxY0w5x0bU7byYK0iY/edit#gid=757719252].",XD-3285,Sabby Anandan,Migrate OOTB modules from XD to s-c-s repo
482,,Sabby Anandan,"As a Spring XD user, I'd like to persist module (aka: {{cf apps}}) metrics directly, so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.

Currently, SBoot's {{export()}} API allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). This could be something to explore as part of this scope.",XD-3284,Sabby Anandan,Add support to persist captured module (App) metrics
483,David Turanski,Sabby Anandan,"As a Spring XD developer, I'd like to port {{FTP}} modules from XD to s-c-s repo, so I can use them as {{source}} modules to build streaming pipeline.",XD-3283,Sabby Anandan,Port FTP as s-c-s source module
484,Glenn Renfro,Sabby Anandan,"As a s-c-s developer, I'd like to setup CI builds for s-c-s builds, so I can incrementally build and test code commits automatically.",XD-3282,Sabby Anandan,Create CI infrastructure for s-c-s
485,,Sabby Anandan,"As a Spring XD developer, I'd like to self-register {{xd-admin}} server with {{Eureka}}, so I could have admin server exposed as discoverable endpoint. ",XD-3281,Sabby Anandan,Self-register xd-admin server with Eureka
486,,Glenn Renfro,Occasionally 2 acceptance tests are running simultaneously and the filepollhdfs tests writes their data to the same hdfs directory.  This will cause the test to fail sporadically.  By creating a unique directory each time we can share the hadoop instance and not have a conflict.   ,XD-3280,Glenn Renfro,FilePollHdfsTest needs to write to a unique directory vs. the default
487,,Eric PErez,"Expected result: Spring XD shell does not crash on autocomplete when network connection is lost but rather detects the condition and handles it.

Actual result: Spring XD shell crashes when the ""module info --name"" command is autocompleted and the network connection to the server is lost/gone.

The 'version' shell command reports: 2.0.0-SNAPSHOT (built from git e19dde0ecf91a268fb95895071717d05427b8ddd)

I don't see a 'Relates To' Field in this JIRA but this bug is similar to this one:
https://jira.spring.io/browse/XD-1938


Steps to reproduce:
-Open Spring XD Shell
-Connect to a sever e.g. ""admin config server http://hadoop1.example.com""
-Disable all network connections (turn off Wi-Fi, unplug, however you want to do it)
-Type ""module info --name [tab]""

Stack Trace:

{{xd:>module info --name 

Exception in thread ""Spring Shell"" org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://hadoop1.example.com:34549/modules?size=10000"":hadoop1.example.com; nested exception is java.net.UnknownHostException: hadoop1.example.com
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:584)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:529)
	at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:236)
	at org.springframework.xd.rest.client.impl.ModuleTemplate.list(ModuleTemplate.java:75)
	at org.springframework.xd.rest.client.impl.ModuleTemplate.list(ModuleTemplate.java:37)
	at org.springframework.xd.shell.converter.QualifiedModuleNameConverter.getAllPossibleValues(QualifiedModuleNameConverter.java:89)
	at org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)
	at org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)
	at jline.console.ConsoleReader.complete(ConsoleReader.java:3077)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)
	at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)
	at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.UnknownHostException: hadoop1.example.com
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:178)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:180)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:81)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:568)
	... 14 more}}",XD-3279,Eric PErez,Spring XD shell crashes when network connection is lost and module info command autocompletes
488,,Sabby Anandan,"As a Spring XD user, I'd like to capture module (aka: {{cf apps}}) metrics directly, so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.

Currently, there are two different ways we could consume this information from applications. SI's {{channel()}} and SBoot's {{actuator()}} APIs are the few to explore as part of this scope.",XD-3278,Sabby Anandan,Add support to capture module (App) metrics directly
489,,Sabby Anandan,"As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment. 

*Controllers to Refactor*
* ContainersController
* StreamsController
* ModulesController
* JobsController
",XD-3277,Sabby Anandan,Replace controller calls with respective SPI implementation
490,,Sabby Anandan,"As a s-c-s user, I'd like to have my modules add/update it's current state to Eureka, so I can use the repository to discover the current sate of the module as needed. 
",XD-3276,Sabby Anandan,Add state to Eureka when deploying s-c-s modules
491,,Sabby Anandan,"As a s-c-s user, I'd like to store module metadata in {{Eureka}}, so I can use the repository to determine the current state.",XD-3275,Sabby Anandan,Add support to store metadata in Eureka
492,,Sabby Anandan,"As a s-c-s user, I'd like to search the modules by it's name aside from the default {{spring.application.name}} offered by boot, so I can also fetch modules by it's name.",XD-3274,Sabby Anandan,Make s-c-s modules searchable by it's name
493,,Sabby Anandan,"As a s-c-s user, I'd like to have the modules self-register itself with {{Eureka}} whenever they're installed, so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines. ",XD-3273,Sabby Anandan,Add support for modules to register itself to Eureka
494,Mark Fisher,Sabby Anandan,"As a Spring XD user, I'd like to make SPI implementation profile aware, so I can run {{java -jar admin}} or {{cf push}} admin or {{ltc create admin}} and the corresponding implementation gets wired-in automatically.",XD-3271,Sabby Anandan,Add automatic wiring of profile-driven SPI implementations
495,David Turanski,Sabby Anandan,"As a Spring XD developer, I'd like to create initial version of the new module registry abstraction, so we could leverage the foundation to make progress and test the respective SPI ({{receptor}} or {{cloudcontroller}}) implementations.",XD-3270,Sabby Anandan,Create module registry abstraction
496,Patrick Peralta,Sabby Anandan,"As a Spring XD developer, I'd like to have a permanent location of SPI implementations, so I could use the common repo every time I contribute or enhance the test coverage.
",XD-3269,Sabby Anandan,Find a permanent home for SPI
497,,Sabby Anandan,"As a Spring XD on CF user, I'd like to use {{cloudController}} implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics.

*Possible APIs:*
{code}

ModuleStatus getStatus(ModuleDescriptor descriptor);

Collection<ModuleDescriptor> listModules();

Map<ModuleDescriptor.Key, ModuleStatus>

{code}",XD-3268,Sabby Anandan,Add support for CloudController SPI to query module status
498,Patrick Peralta,Sabby Anandan,"As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics.

*Possible APIs:*
{code}

ModuleStatus getStatus(ModuleDescriptor descriptor);

Collection<ModuleDescriptor> listModules();

Map<ModuleDescriptor.Key, ModuleStatus>

{code}",XD-3267,Sabby Anandan,Add support for Receptor SPI to query module status
499,Gunnar Hillert,Karol Dowbecki,"After successfully deploying 12 jobs the Jobs / Deployments page still shows only 10 results.

It looks like {{http://localhost:9393/jobs/configurations.json?page=0&size=10}} always returns {{content.page.totalPages}} of 1 regardless of the {{size}} parameter.",XD-3266,Karol Dowbecki,No pagination for Jobs / Deployments page in Admin UI
500,Paul Harris,Sabby Anandan,"As a Spring XD user, I'd like to use {{CloudController}} based implementation of XD Admin SPI (based on ModuleLauncher), so I can run data pipeline use-cases running on CF.

Relevant repos: [spring-cloud-data|https://github.com/spring-cloud/spring-cloud-data/tree/master/spring-cloud-data-module-deployers] | [spring-cloud-stream|https://github.com/spring-cloud/spring-cloud-stream]

Please refer to XD-3194 or XD-3229 as sample spike-deliverables (_google doc_) that were completed in the last sprint. ",XD-3265,Sabby Anandan,Spike: Investigate distributed implementation of CloudController Admin SPI
501,,Karol Dowbecki,"{{spring-data-commons}} 1.10.0.RELEASE introduced an improved instantiation strategy based on byte code generation. It's now the default instantiation strategy however it can't be used in custom Spring XD modules due to class loader issues.

Please see attached custom module source code which can be build with Maven. You might want to change MongoDB connection parameters in {{custom-mongo-processor.xml}}.

Execute following xd-shell commands

{code}
module upload --name custom-mongo-processor --type processor --file [location]
stream create --name k2 --definition 'time --fixedDelay=10 | custom-mongo-processor | log' --deploy
{code}

The stream will output following message when the MongoDB collection is empty:
{code}
2015-07-17T11:09:38+0100 1.2.0.RELEASE INFO task-scheduler-3 sink.k2 - {""content"":[],""count"":0}
2015-07-17T11:09:48+0100 1.2.0.RELEASE INFO task-scheduler-3 sink.k2 - {""content"":[],""count"":0}
{code}

After documents are inserted into collection by executing {{db.karolWidgets.insert(\{ ""name"": ""bulbator"", ""color"": ""red"" \})}} following exception will be thrown:

{code}
2015-07-17T11:09:59+0100 1.2.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: ; nested exception is java.lang.IllegalStateException: Cannot process message
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalStateException: Cannot process message
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:292)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	... 59 more
Caused by: java.lang.NoClassDefFoundError: com/test/mongodb/MongoWidget
	at com.test.mongodb.MongoWidget_Instantiator_monxdt.newInstance(Unknown Source)
	at org.springframework.data.convert.BytecodeGeneratingEntityInstantiator$EntityInstantiatorAdapter.createInstance(BytecodeGeneratingEntityInstantiator.java:193)
	at org.springframework.data.convert.BytecodeGeneratingEntityInstantiator.createInstance(BytecodeGeneratingEntityInstantiator.java:76)
	at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:250)
	at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:231)
	at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:191)
	at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:187)
	at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:78)
	at org.springframework.data.mongodb.core.MongoTemplate$ReadDbObjectCallback.doWith(MongoTemplate.java:2191)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:1873)
	at org.springframework.data.mongodb.core.MongoTemplate.findAll(MongoTemplate.java:1286)
	at com.test.mongodb.MongoService.processWidgets(MongoService.java:21)
	at sun.reflect.GeneratedMethodAccessor83.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:102)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276)
	... 61 more
Caused by: java.lang.ClassNotFoundException: com.test.mongodb.MongoWidget
	at java.lang.ClassLoader.findClass(ClassLoader.java:531)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 85 more
{code}

This exception affects both custom stream and job modules. One workaround is to force {{ReflectionEntityInstantiator}} in {{MappingMongoConverter}} however this has to be done in every custom module.

Perhaps that's an issue with Spring XD custom module classloaders (or DATACMNS-710)?",XD-3264,Karol Dowbecki,Spring Data BytecodeGeneratingEntityInstantiator throws ClassNotFoundException when mapping custom classes
502,Gunnar Hillert,sridhar,"Hi ,

Customer has 48 containers, but it only shows 20 containers. We need pagination to browse all containers.",XD-3263,sridhar,"Pagination for containers, it is limited to only 20"
503,,Gunnar Hillert,Add Pagination to Containers Page,XD-3262,Gunnar Hillert,UI: Add Pagination to Containers Page 
504,Thomas Risberg,Thomas Risberg,"There is a vulnerability in Groovy that is fixed in 2.4.4:

CVE-2015-3253: Remote execution of untrusted code

See:

http://groovy-lang.org/security.html

http://mail-archives.apache.org/mod_mbox/incubator-groovy-users/201507.mbox/%3CCADQzvmmYC7RbZnsQ8O63XN4HCMYh9RGRdMiuWupVt=u=pjH8+g@mail.gmail.com%3E


",XD-3261,Thomas Risberg,Update Groovy to 2.4.4
505,,Sabby Anandan,"As a developer, I'd like to move 'serialization codec' from Spring XD repo into SI, so I can update Spring XD to inherit the features/functionalities via maven dependency.",XD-3260,Sabby Anandan,Move serialization codec from XD to Spring Integration
506,David Turanski,Sabby Anandan,replace with xd.messagebus prefix with spring.cloud.stream.binder,XD-3259,Sabby Anandan,[SCS] Rename xd.messagebus binder properties 
507,Thomas Risberg,Thomas Risberg,"We need to have some jars as part of the Sqoop job submission to YARN:

for Avro we need:
  avro-1.7.6.jar
  avro-mapred-1.7.6.jar

for Snappy we need:
  snappy-java-1.0.5.jar (note: the 1.1.0.1 version from xd/lib doesn't work)
  commons-compress-1.4.1.jar

We can either have these included using the --libjars option or automatically include them.
",XD-3258,Thomas Risberg,Add jars for Avro and Snappy compression to Sqoop job submission
508,,Karol Dowbecki,"After connecting to admin endpoint over HTTPS xd-shell will use plain HTTP for all further calls, which fails if HTTPS is mandatory:

{code}
server-unknown:>admin config server https://my-host/
Successfully targeted https://my-host/
xd:>job list
Command failed org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://my-host/jobs/definitions?size=10000&deployments=true"":Connection refused; nested exception is java.net.ConnectException: Connection refused
{code}

In above example {{my-host}} is a proxy that provides load balancing and enforces HTTPS for users. It forwards the traffic to to spring-xd-admin service REST API over regular HTTP and port 9393. Admin service is returning {{_links}} with plain HTTP because it's unaware of the network proxy.

Can this be solved without employing server side HTTP->HTTPS url rewrite? Is enabling SSL in spring-xd-admin the only way?",XD-3257,Karol Dowbecki,xd-shell doesn't work with SSL proxy
509,,Sabby Anandan,"As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo, so I could define the module {{artifactId}} from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.",XD-3256,Sabby Anandan,Spike: Investigate installation of XD modules from maven repo
510,,David Turanski,,XD-3255,David Turanski,SCS - split kryo implementation to spring-cloud-streams-codec-kryo
511,,David Turanski,,XD-3254,David Turanski,SCS-  Rename codec packages
512,,Thomas Risberg,"Looking at the online docs the code listings have inconsistent  syntax highlighting and when you hover the mouse over some of them there is a language  prefix like ruby or javascript inserted at the beginning of the first line. Very strange.

To see this go to http://docs.spring.io/spring-xd/docs/1.2.0.RELEASE/reference/html/#_server_configuration and scroll down to the HSQLDB section. The listing for HSQLDB looks fine, but scroll down further and put the mouse pointer on the MySQL or PostgreSQL listings and you should see 'javascript' being inserted on the first line.
",XD-3253,Thomas Risberg,Strange language prefix shown on some code listings when hovering the mouse over them
513,,Eric Bottard,"This is to get rid of (ultimately) ModuleOption, ModuleOptionsMetadataResolver etc in favor of classes written by Stéphane Nicoll (currently here: https://github.com/snicoll-scratches/spring-boot-config/blob/master/spring-boot-config-metadata/src/main/java/org/springframework/configurationmetadata/)",XD-3252,Eric Bottard,Refactor XD to use boot's options metadata internally
514,,Eric Bottard,This allows incremental adoption of boot @ConfigurationProperties as a way of being recognized as XD options,XD-3251,Eric Bottard,A a boot ConfigurationPropertiesModuleOptionsResolver
515,Eric Bottard,Eric Bottard,"The spring-cloud-streams samples have module options classes copied over from XD.
They should use a pure @ConfigurationProperties approach, making sure metadata is generated/hand written as appropriate.

@Mixins are still referenced there but obviously can't work, so provide an equivalent",XD-3250,Eric Bottard,Refactor s-c-s samples to use @ConfigurationProperties
516,Eric Bottard,Eric Bottard,"This better aligns with boot. Moreover, using Class was a bad design choice (one can always get a Class from a String [modulo knowing which CL to use], while to converse is not always easy [CL not being available])
",XD-3249,Eric Bottard,Change module option type from Class to String
517,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"These tests fail inconsistently:

org.springframework.xd.spark.streaming.LocalTransportSparkStreamingTests > testTapSparkProcessor FAILED
   java.lang.AssertionError

org.springframework.xd.spark.streaming.RedisTransportSparkStreamingTests > testTapSparkProcessor FAILED
   java.lang.AssertionError

java.lang.AssertionError: 
Expected: an existing metric, trying at most 20 times
    but: failed after 20*100=2000ms:
counter named 'random5656' did not exist,",XD-3248,Ilayaperumal Gopinathan,Investigate inconsistent Spark streaming test failure
518,,Eric Bottard,"Working with rich structured messages is currently painful when we have modules that know how to handle some sub-part of the structure.

Case in point:
I have a Tuple made of {document: byte[], metadata: Map}
and I have a module that knows how to extract textual content from the document byte[].

If I want to extract the document but still retain metadata, I need to either
- rewrite the extract content module to accept a tuple (urghh)
- fork the stream to extract the document field, apply module, aggregate with metadata (that comes from side channel)

",XD-3247,Eric Bottard,Support transparent boxing/unboxing of Tuples (or other containers)
519,,Eric Bottard,"It would be nice if either one of the two options would come ""for free"" when you're authoring a module.
Currently, it has been a pain, including handling exclusivity of options at the module options level.

Also, it would be nice if XD/S-C-S provided ease of creation of xxExpression style options (ie not having the author have to deal with ExpressionParser, etc)",XD-3246,Eric Bottard,Automatic support for --fooExpression style options
520,,David Turanski,XD 2.0 will not have direct dependency on the s-c-s Binder (as MB has been renamed).  The message bus code is obsolete/orphaned in XD 2.0 but some is required to support current integration tests. We can look at pruning it some more but complete removal likely depends on integrating the s-c-s enabled Admin SPI.  MB will remain in XD 1.x.,XD-3245,David Turanski,Replace spring-xd-messagebus-* dependencies with SCS
521,David Turanski,David Turanski,,XD-3244,David Turanski,Copy spring-xd-messagebus-* to SCS as spring-cloud-binding-*
522,David Turanski,David Turanski,replace with spring-cloud-streams (or spring-cloud-streams-codec) dependency,XD-3243,David Turanski,Remove spring-xd-codec from Spring XD source tree and build
523,David Turanski,David Turanski,Create the equivalent library in spring-cloud-streams,XD-3242,David Turanski,Copy spring-xd-codec to SCS as spring-cloud-streams-codec
524,Janne Valkealahti,Janne Valkealahti,"Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",XD-3241,Janne Valkealahti,Add support for update in gpfdist sink
525,Janne Valkealahti,Janne Valkealahti,Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.,XD-3240,Janne Valkealahti,Add better support for using control file with gpfdist
526,,Sabby Anandan,"As a developer, I'd like to move 1.2.x branch to EC2 infrastructure, so I can reliably run CI test suites.",XD-3239,Sabby Anandan,Move 1.2.x branch to EC2 CI infrastructure
527,David Turanski,Sabby Anandan,"As a developer, I'd like to complete the remaining Kryo optimization changes, so I can polish and get the guidelines documented appropriately. ",XD-3238,Sabby Anandan,Complete remaining Kryo optimization changes
528,,Thomas Risberg,"I see the following error from the Admin UI:

GET http://localhost:9393/jobs/executions/4/steps/4/progress.json 403 (Forbidden)",XD-3237,Thomas Risberg,Additional REST endpoint not working with security enabled
529,,Sabby Anandan,,XD-3236,Sabby Anandan,New features and improvements for spring-cloud-streams
530,Glenn Renfro,Glenn Renfro,"Currently the testFileJdbcJobMultipleInvocations fails on line 156 stating data is different in table that what is expected.  Currently this is failing on the single admin/container deployment using redis as a transport.  

Also seeing the following exception in the attached log:
{noformat}
2.0.0.SNAP ERROR xdbus.job:ec2Job3.0.requests-1 step.AbstractStep - Encountered an error executing step step1 in job ec2Job3
org.springframework.batch.item.ItemStreamException: Failed to initialize the reader
...
Caused by: java.lang.IllegalStateException: Input resource must exist (reader is in 'strict' mode): URL [file:/tmp/xd/output/filejdbctest/filejdbctest1.out]
{noformat}
The file is should be present and data present for the test.  At least according to the checker on EC2 and local deployments.



",XD-3235,Glenn Renfro,FileJdbc Job throws exception during Acceptance Tests 
531,Eric Bottard,Gunnar Hillert,"The XML REST endpoints:

* are not working correctly
* interfere with security
* are not used


",XD-3234,Gunnar Hillert,Remove XML REST Endpoints
532,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to create an annotation ({{@EnableModule}}) driven programming model for modules, so instead of explicitly defining I/O channels as beans on the module, for classes annotated with {{@EnableModule}}, the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types.

The {{@Input}} and {{@Output}} annotations will be used to indicate the input and output channels of the module. ",XD-3233,Sabby Anandan,Enable component model for spring-cloud-streams
533,Gary Russell,Gary Russell,"Also Spring Framework 4.2.0.RC2, Spring AMQP 1.5.0.M1

Also Batch 3.0.4",XD-3232,Gary Russell,Update Spring Integration to 4.2.0.M2 (4.1.6 on 1.2.x)
534,Janne Valkealahti,Sabby Anandan,"As a developer, I'd like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers, so it is setup for HA. ",XD-3231,Sabby Anandan,Add support to Ambari install multiple XD Admin's 
535,Mark Pollack,Sabby Anandan,"As a developer, I'd like to upgrade to Reactor 2.0.4 release, so I could leverage the latest improvements and bug-fixes.",XD-3230,Sabby Anandan,Update to Reactor 2.0.4
536,Gunnar Hillert,Sabby Anandan,"As a s-c-s user, I'd like to investigate the possibility of s-c-s modules self-registering themselves to service discovery, so I could use Spring XD runtime (running on CF) to discover and orchestrate such modules through streams.",XD-3229,Sabby Anandan,Spike: XD Admin SPI to discover s-c-s modules
537,Patrick Peralta,Sabby Anandan,"As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI (based on ModuleLauncher), so I can run data pipeline use-cases running on CF Lattice/Diego. 
",XD-3228,Sabby Anandan,Spike: Kickoff distributed Receptor implementation of Admin SPI
538,Mark Fisher,Sabby Anandan,"As a developer, I'd like to develop a “singlenode” (in a single JVM) implementation of XD Admin SPI (based on Module Launcher), so I can run data pipeline use-cases locally.
",XD-3227,Sabby Anandan,Spike: Kickoff singlenode implementation of Admin SPI
539,David Turanski,Sabby Anandan,"As a developer, I'd like to move 'serialization codec' from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency.",XD-3226,Sabby Anandan,Move serialization codec from XD to spring-cloud-stream [Phase #1]
540,Ilayaperumal Gopinathan,Sabby Anandan,"As a developer, I'd like to move input/output type conversion from Spring XD repo to spring-cloud-dataflow, so I can implement a custom module which produces or consumes a custom domain object.",XD-3225,Sabby Anandan,Move input/output type-conversion from XD to spring-cloud-stream
541,David Turanski,Sabby Anandan,"As a developer, I'd like to move message-bus from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency. 
",XD-3224,Sabby Anandan,Move message-bus implemenation from XD to spring-cloud-streams [Phase #1]
542,,Thomas Risberg,"As a user I would like to be able to configure the logging directory to be outside of what is defined as xd.home. The logging directory is currently hard coded as {code}${xd.home}/logs{code}.

This would be useful for RPM installations where the logs really should be going to `/var/logs/spring-xd` instead of the current `/opt/pivotal/spring-xd/xd/logs` location.
",XD-3223,Thomas Risberg,Configure logging directory outside of xd.home
543,Thomas Risberg,Thomas Risberg,"As a user I would like to connect the Sqoop batch job to Teradata for import jobs. 

I have tried the Teradata JDBC driver directly using:

{code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""
{code}

but that results in an NPE.

The only way so far is to use the Hortonworks Connector for Teradata - http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz

That one allows me to use the following:

{code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""
{code}",XD-3222,Thomas Risberg,Find a way to connect Sqoop job to Teradata
544,,Karol Dowbecki,"After enabling security in {{XD_HOME/config/servers.yml}}

{code}
spring:
  profiles: admin
security:
  basic:
    enabled: true # false to disable security settings (default)
    realm: SpringXD
  user: # valid only if security.basic.enabled=true
    name: johndoe
    password: johndoe
    role: ADMIN, VIEW, CREATE
{code}

It's no longer possible to connect to admin server through xd-shell

{code}
server-unknown:>admin config server --username johndoe --password johndoe
Unable to contact XD Admin Server at 'http://localhost:9393/'.
server-unknown:>admin config info
  -------------  --------------------------------------------------------------
  Credentials    [username='johndoe, password=****']
  Result         Unable to contact XD Admin Server at 'http://localhost:9393/'.
  Target         http://localhost:9393/
  Timezone used  Greenwich Mean Time (UTC 0:00)
  -------------  --------------------------------------------------------------
-------------------------------------------------------------------------------
An exception ocurred during targeting:
org.springframework.web.client.HttpClientErrorException: 403 Forbidden
    at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
    at org.springframework.xd.rest.client.impl.VndErrorResponseErrorHandler.handleError(VndErrorResponseErrorHandler.java:50)
    at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:614)
    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:570)
    at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:545)
    at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:253)
    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:114)
    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:102)
    at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:112)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:202)
    at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)
    at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:57)
    at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)
    at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:533)
    at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)
    at java.lang.Thread.run(Thread.java:745)
{code}

It looks like admin base URL (http://localhost:9393/) is not defined in security section of {{application.yml}} so {{SpringXDTemplate}} can't be initialized.",XD-3221,Karol Dowbecki,Enabling security breaks xd-shell
545,Gunnar Hillert,Karol Dowbecki,"After enabling security (see XD-3214) and granting user {{ROLE_VIEW, ROLE_CREATE, ROLE_ADMIN}} privileges it's not possible to launch jobs from Admin UI. 

For {{bdl-sqoop-combo-lukasz-MONGO-DEV}} job, 403 error is returned when Admin UI attempts to access following URL after ""Launch Job"" button is pressed:
{code}
http://ilabphd12.isus.emc.com:9393/jobs/executions?jobParameters=%7B%7D&jobname=bdl-sqoop-combo-lukasz-MONGO-DEV
{code}

Please see attached screenshot.",XD-3220,Karol Dowbecki,Enabling security breaks job launching from Admin UI
546,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Since the SecuredShellTests initialize singlenode app in a static way, the random configuration needs to be setup statically as well.",XD-3219,Ilayaperumal Gopinathan,Fix random configuration in SecuredShellTests
547,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The admin leader election fails when the stream/job module definitions doesn't exist in `module-registry` but still some of the references still exist in ZK (via some of the previous deployments that had this module in module registry). 

Though this is expected, this behavior will make *all* the subsequent deployments in *deploying* state because the admin leader isn't elected.

",XD-3218,Ilayaperumal Gopinathan,[Backport] Handle stream/job deployment status recalculation failures
548,Marius Bogoevici,Sabby Anandan,"As a user, I'm trying to connect to {{xd-admin}} server with basic security enabled; however, I'm unable to successfully connect to the server and I get the following error message.


{code:java}
server-unknown:>admin config server --uri http://localhost:9393 --username bob --password bobspwd
Unable to contact XD Admin Server at 'http://localhost:9393'.
{code}",XD-3217,Sabby Anandan,Cannot connect to admin server with basic security enabled
549,Marius Bogoevici,Marius Bogoevici,https://github.com/spring-projects/spring-xd/issues/1727,XD-3216,Marius Bogoevici,"On specific shutdown scenarios, the stream resumes from the start of the bus topic"
550,,Thomas Risberg,"As a user, I'd like to have the option to specify system properties that will be passed in to the Sqoop job which runs in it's own Java process. This is needed for defining memory usage and also for defining some options for various connector implementations.",XD-3215,Thomas Risberg,Add a way to specify system properties for Sqoop job
551,Gunnar Hillert,Karol Dowbecki,"After enabling Spring XD security in {{XD_HOME/config/servers.yml}}:

{code}
spring:
  profiles: admin
security:
  basic:
    enabled: true
    realm: SpringXD
xd:
  security:
    authentication:
      file:
        enabled: true
        users:
          user: password, ROLE_VIEW
          admin: password, ROLE_VIEW, ROLE_CREATE, ROLE_ADMIN
{code}

after logging in as {{user}} with only {{ROLE_VIEW}} privilege, Jobs admin page is broken and is not displaying data. 403 error code is returned for following URLs:

{code}
http://localhost:9393/jobs/configurations.json?page=0&size=10
http://localhost:9393/jobs/definitions.json?page=0&size=10
{code}

Looks like {{/jobs/configurations.\*}} and {{/jobs/definitions.\*}} URLs are not covered in security section of applications.yml file.",XD-3214,Karol Dowbecki,Enabling security breaks Jobs page in Admin UI
552,,Glenn Renfro,"When profiling metrics we noticed a small improvement when using Deque instead of LinkedList in ExponentialMovingAverageRatio, ExponentialMovingAverageRate...

",XD-3213,Glenn Renfro,Use Deque instead of LinkedList when gathering metrics
553,,David Turanski,"Should be renamed as well. org.springframework.integration.transformer.MessageTransformationException: ; nested exception is org.springframework.messaging.MessageHandlingException: ; nested exception is org.springframework.expression.spel.SpelEvaluationException: EL1004E:(pos 8): Method call: Method toObject(java.util.LinkedHashMap) cannot be found on org.springframework.integration.x.gemfire.JsonStringToObjectTransformer type
	at org.springframework.integration.transformer.MessageTransformingHandler.handleRequestMessage(MessageTransformingHandler.java:74) ~[spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99) ~[spring-integration-core-4.1.5.RELEASE.jar:na]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) ~[spring-integration-core-4.1.5.RELEASE.jar:na]
(...)
with 1.2 RELEASE when trying to persist a JSON payload using the GemFire-json-server sink.. It works  great on 1.1.RELEASE and 1.2 Build snapshot 2015-04-23.001857 


The demo repository is open, so I can definitely share it with your developers, but wondered if we changed something recently on that sink that could cause an issue.",XD-3212,David Turanski,JSonStringToObject transformer used for GemFire JSON sink should accept a Map
554,,Muhammad Ali,"As a user I would like to use fsUri = file:// to use Hadoop LocalFileSystem instead of a running cluster. In my use case my data scientist team requested to provide me a local CSV of data that is being loaded using jdbchdfs job. The quickest way to solve this was to change the fsUri to file://. and it should have just worked.
 
This will work alright for singlenode setups, for multiple containers hosted on multiple machines will split the file across different machines - but then I believe it is fair to assume that the developer must know what he is doing.",XD-3211,Muhammad Ali,HdfsTextItemWriter does not work with Hadoop LocalFileSystem fsUri:file://
555,,Gary Russell,"This deprecated in SI 4.2.

Use 

{{this.evaluationContext = ExpressionUtils.createStandardEvaluationContext(getBeanFactory());}}

in {{afterPropertiesSet()}} instead.

Not that this can safely be done in 1.2.x - the preferred mechanism is available in SI 4.1.x too.",XD-3210,Gary Russell,Remove Usage of IntegrationEvaluationContextAware
556,,Karol Dowbecki,"Custom Spring XD modules are packaged into a JAR file with 3rd party libraries packaged into {{lib}} folder.

Let's say we have a {{my-job}} custom job module, packaged as JAR and deployed with {{module upload}} shell command. It wants to use {{org.springframework.xd.sqoop.SqoopTasklet}} provided by {{spring-xd-extension-sqoop}} library. Unfortunately {{org.springframework.batch.step.tasklet.x.ClasspathEnvironmentProvider}} will only add {{my-job.jar}} to {{SqoopRunner}} classpath (code in {{ClasspathEnvironmentProvider#createClassPath()}} method).

{{ClasspathEnvironmentProvider}} should add all 3rd party JARs packaged in custom job module to classpath.

This works with {{sqoop}} module shipped with Spring XD because it's deployed as ""exploded"" module under $XD_HOME/modules/job. In such case {{ClasspathEnvironmentProvider}} correctly adds all JARs from $XD_HOME/modules/job/sqoop/lib to classpath.",XD-3209,Karol Dowbecki,ClasspathEnvironmentProvider should support packaged Spring XD modules
557,,Mark Acquistapace,"With version 1.2.0 the option ref of the file source was removed and a new option mode was introduced.  see XD-2850 and PR  https://github.com/spring-projects/spring-xd/pull/1624.

This means you have to destroy all streams using the ref option before you do an upgrade.

It would have been much better to leave the ref option in the code and emit a deprecation warning if it is still used. This way an upgrade would be possible without interruption.




",XD-3208,Mark Acquistapace,Change in file source breaks backward compatibility 
558,,Karol Dowbecki,"As per [Chapter 3: Logback configuration|http://logback.qos.ch/manual/configuration.html] only XML configuration can be overidden with {{-test}} file. It's impossible to do this with groovy configuration.

There are Spring XD modules that are packaging {{logback.groovy}} e.g. {{spring-xd-extension-sqoop}}. If a custom module depends on those libraries it becomes impossible to nicely override log settings for tests\[1\]. The configuration is taken from classpath because {{logback.groovy}} is always prioritized over {{logback-test.xml}}.

If those modules would switch to {{logback.xml}} there will be no such problem and custom modules would be easier to set up.

\[1\] One can put own {{logback.groovy}} file under {{src/test/resources}} but this setup will output a number of warning into console. Forcing logback configuration path with {{-D}} option is not nice either.",XD-3207,Karol Dowbecki,spring-xd-extension-sqoop dependency overrides test logger setup
559,Ilayaperumal Gopinathan,Franck MARCHAND,"Here is an error I got using the header-enricher from spring-xd-modules :


{code:java}
Field error in object 'info' on field 'shortDescription': rejected value [A Header Enricher to set message headers in a stream]; codes [Pattern.info.shortDescription,Pattern.shortDescription,Pattern.java.lang.String,Pattern]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescription,shortDescription]; arguments []; default message [shortDescription],[Ljavax.validation.constraints.Pattern$Flag;@11eeec65,^\p{IsUppercase}.*\.$]; default message [Short description must start with a capital letter and end with a dot]
{code}

And if I look the config properties, indeed, short description doesn't end with a dot.
{code:java}
info.shortDescription = A Header Enricher to set message headers in a stream
{code}",XD-3206,Franck MARCHAND,An error message occurs about the shortDescription (header-enricher)
560,Thomas Risberg,Sabby Anandan,"As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.",XD-3205,Sabby Anandan,Investigate the steps to Ambari upgrade Spring XD
561,Mark Fisher,Sabby Anandan,"As a spring-bus lead, I'd like to review the current spring-bus architecture and the design specs, so I can address any foundation level gaps.",XD-3204,Sabby Anandan,Review spring-bus design specs
562,,Sabby Anandan,"As a developer, I'd like to measure the baseline serialization characteristics in XD, so I can determine the areas of performance improvements. ",XD-3203,Sabby Anandan,Measure serialization baseline
563,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to investigate channel performance issues in SI 4.2, so I can determine the bottlenecks and take corrective actions to improve overall channel performance. ",XD-3202,Sabby Anandan,Investigate performance of channel metrics in SI 4.2 
564,,Paul Harris,"According to the documentation at: http://docs.spring.io/spring-xd/docs/current/reference/html/#reactor-ip one of the options available for this source is {{transport}}. It's listed as having no default, but the sample definition doesn't provide it yet appears to default to {{tcp}}. The two should match up.

It might also be useful if the possible values for {{transport}} were listed (I assume {{TCP}} and {{UDP}})",XD-3201,Paul Harris,Documentation for reactor-ip source has conflicting information
565,David Turanski,Sabby Anandan,"As a user, I'm trying to delete the custom module using the {{module delete}} command via shell; though the command is successfully, I'm still seeing the associated artifact (_.jar file_) present in the custom_modules folder. Refer to [SO thread|http://stackoverflow.com/questions/30984922/springxd-module-delete-command-does-not-delete-the-uploaded-jar-file] for more details.

",XD-3200,Sabby Anandan,Module delete command on windows does not delete the module entirely
566,,Sabby Anandan,"As a developer, I'd like to split up spring-xd dependencies to more fine-grained, so I can get the ones ""below the line"" down to spring-bus-* instead of spring-xd-* bundle. ",XD-3199,Sabby Anandan,Split core dependencies between spring-cliud-dataflow and XD proper
567,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to use spring-cloud-config server for spring-bus modules, so I can centrally manage external properties.",XD-3198,Sabby Anandan,Spike: Investigate the use of config server for spring-cloud-stream modules 
568,,Sabby Anandan,"As a developer, I'd like to add an option to support Apache Ambari installed Spring XD on YARN, so I can easily establish the cluster up and running.",XD-3197,Sabby Anandan,Add support for Ambari installed Spring XD on YARN
569,Mark Pollack,Sabby Anandan,"As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances, so I can manage them all in one-place reliably.",XD-3196,Sabby Anandan,Move MASTER branch CI builds to EC2 based infrastructure
570,,Sabby Anandan,"As a developer, I'd like to troubleshoot the performance issues with Rabbit as message bus implementation, so I can isolate the bottleneck and fix as appropriate.",XD-3195,Sabby Anandan,Investigate Rabbit performance issues
571,Ilayaperumal Gopinathan,Sabby Anandan,"As a developer, I'd like to have a central place to manage external properties for applications across all the environments, so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers. ",XD-3194,Sabby Anandan,Spike: Investigate spring-cloud-config and the XD fit
572,Eric Bottard,Sabby Anandan,"As a developer, I'd like to handle module options via pure boot property source management, so I can leverage Boot's module [METADATA|http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#configuration-metadata] option to inject module options as opposed to maintaining them in core Spring XD runtime CP.
",XD-3193,Sabby Anandan,Spike: Investigate bootification of module options
573,Gunnar Hillert,Sabby Anandan,"As a user, I'd like to have the module/app specific metrics consumed directly from Boot actuator [export()|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/MetricRepositoryAutoConfiguration.java] API, so I can have insight on how it is performing, being used and that it works etc.

",XD-3192,Sabby Anandan,Spike: Investigate Boot export metrics and the XD fit
574,,Sabby Anandan,,XD-3191,Sabby Anandan,App metrics and operational functioanlities
575,,Muhammad Ali,"I am trying to deploy a job I destroyed after running a few times. I removed all the jobs using job all destroy. When i try to recreate the same name job it is saying it already exists. JobController.java save() method is throwing the exception if job exists in Job Repository database, but they are gone from job definition list. These jobs were originally created using XD Template REST client dynamically, but that should not make any difference.

This leaves me in an inconsistent state between XD definitions/job repository. How do I get rid of the job without having to log in to the database and play with the job repository tables.

I had to delete data folder for myself to continue development. 

There should be a force mechanism to recreate a job with the same name, a flag that by passes this validation against the repository or overwrites the information in the repository.

",XD-3190,Muhammad Ali,No way to remove a job from Job repository if its gone from job definitions
576,Glenn Renfro,Glenn Renfro,User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.  ,XD-3189,Glenn Renfro,Testers need ability to wait for a file to be created in XD directory
577,Michael Minella,Michael Minella,"In the {{filejdbc}} job, there is the option to delete the imported files.  This functionality is created using a listener called the {{FileDeletionStepExecutionListener}}.  When you run the job the first time with the {{--deleteFiles=true}}, everything works as expected.  The second time you run the job, the files are not deleted.

I believe the issue here is that since the {{FileDeletionStepExecutionListener}} is a singleton, the resources are resolved only once (the first time the job runs) and so it works the first time, but if the job is run again later and new files match the expression, they are not picked up.  I believe the fix is to make the {{FileDeletionStepExecutionListener}} used in this job step scoped.",XD-3188,Michael Minella,FileDeletionListener resolves resources once
578,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,The admin leader starts cleaning up the deployments for the container(s) that is/are no longer connected to the ZK. This clean up needs to happen after the container path cache is started by the admin leader. ,XD-3187,Ilayaperumal Gopinathan,XD admin leader should cleanup deployment after initializing the container path cache
579,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,There are cases where it would be required to load the options metadata classes from the parent classloader *first* than the module's ParentLastURLClassLoader. It would be nice to have a configuration option in DefaultModuleOptionsResolver to set which classloader to use.,XD-3186,Ilayaperumal Gopinathan,DefaultModuleOptionsResolver to use parent classloader to load options metadata classes
580,,Mark Pollack,It isn't obvious from looking through the table of contents on the left hand side that reactor-ip does both tcp and udp.  Breaking up the section into two  would make it more clear - even though they would still use the same module.,XD-3185,Mark Pollack,Create separate doc sections for reactor-ip's tcp and udp functionality
581,Thomas Risberg,Thomas Risberg,We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.,XD-3184,Thomas Risberg,Update spring-xd-yarn servers.yml with settings for HDP 2.2.6.0
582,Gary Russell,Paul Harris,"Spring Boot 1.2.4 (and earlier) does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of (for example) {{vcap.services.rabbitmq.credentials.protocols.amqp.ssl}} it will fail, as that value returns a boolean.

Spring Boot 1.2.5 (as yet unreleased) contains a fix for this issue (https://github.com/spring-projects/spring-boot/pull/3237)",XD-3183,Paul Harris,Upgrade to Spring Boot 1.2.5
583,,David Turanski,"https://github.com/spring-projects/spring-xd/blob/master/modules/common/gemfire-connection.groovy#L8 is syntactically incorrect. It looks like the intention was to pass this a property, but it appears it is treated as a literal value which Groovy coerces to true. Thus subscription-enabled is always true. It should be configurable  although some modules require subscription-enabled to be true. ",XD-3182,David Turanski,Fix minor bug with Gemfire sources
584,,nebhale,"Currently when running the {{p-spring-xd}} stream tests, we run into an issue where the XD Container starts throwing errors because it cannot open the module configuration file.  This happens reliably after 3-4 days of running and always fails on the same {{modules.yml}} configuration file.  This is not to say that the file leak is guaranteed to be related to the {{modules.yml}}, but it's certainly a place to start looking.  A restart of the container (only) causes the error to go away for 3-4 days at which point it reappears, indicating that the problem is definitely in the XD Container and not in the operating system's configuration.

Failure stack trace:
{noformat}
[XD ADMIN] 1.2.0.RC1 INFO DeploymentSupervisor-0 zk.ZKStreamDeploymentHandler - Deployment status for stream 'end-to-end-http-9630': DeploymentStatus{state=failed,error(s)=java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files) 
 at org.springframework.beans.factory.config.YamlProcessor.handleProcessError(YamlProcessor.java:186) 
 at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:178) 
 at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:138) 
 at org.springframework.boot.env.YamlPropertySourceLoader$Processor.process(YamlPropertySourceLoader.java:100) 
 at org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:57) 
 at org.springframework.boot.env.PropertySourcesLoader.load(PropertySourcesLoader.java:126) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.loadIntoGroup(ConfigFileApplicationListener.java:381) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:369) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:339) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener.addPropertySources(ConfigFileApplicationListener.java:174) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$1.apply(EnvironmentAwareModuleOptionsMetadataResolver.java:229) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.loadPropertySources(EnvironmentAwareModuleOptionsMetadataResolver.java:219) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.lookupEnvironment(EnvironmentAwareModuleOptionsMetadataResolver.java:181) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.access$000(EnvironmentAwareModuleOptionsMetadataResolver.java:61) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.<init>(EnvironmentAwareModuleOptionsMetadataResolver.java:144) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:132) 
 at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:206) 
 at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122) 
 at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84) 
 at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101) 
 at org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:331) 
 at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181) 
 at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) 
 at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) 
 at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) 
 at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) 
 at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) 
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) 
 at java.util.concurrent.FutureTask.run(FutureTask.java:266) 
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) 
 at java.util.concurrent.FutureTask.run(FutureTask.java:266) 
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 
 at java.lang.Thread.run(Thread.java:745) 
Caused by: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files) 
 at java.io.FileInputStream.open0(Native Method) 
 at java.io.FileInputStream.open(FileInputStream.java:195) 
 at java.io.FileInputStream.<init>(FileInputStream.java:138) 
 at java.io.FileInputStream.<init>(FileInputStream.java:93) 
 at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90) 
 at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188) 
 at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168) 
 at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:158) 
 ... 36 more 
; java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files) 
 at org.springframework.beans.factory.config.YamlProcessor.handleProcessError(YamlProcessor.java:186) 
 at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:178) 
 at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:138) 
 at org.springframework.boot.env.YamlPropertySourceLoader$Processor.process(YamlPropertySourceLoader.java:100) 
 at org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:57) 
 at org.springframework.boot.env.PropertySourcesLoader.load(PropertySourcesLoader.java:126) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.loadIntoGroup(ConfigFileApplicationListener.java:381) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:369) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:339) 
 at org.springframework.boot.context.config.ConfigFileApplicationListener.addPropertySources(ConfigFileApplicationListener.java:174) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$1.apply(EnvironmentAwareModuleOptionsMetadataResolver.java:229) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.loadPropertySources(EnvironmentAwareModuleOptionsMetadataResolver.java:219) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.lookupEnvironment(EnvironmentAwareModuleOptionsMetadataResolver.java:181) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.access$000(EnvironmentAwareModuleOptionsMetadataResolver.java:61) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.<init>(EnvironmentAwareModuleOptionsMetadataResolver.java:144) 
 at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:132) 
 at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:206) 
 at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122) 
 at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84) 
 at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101) 
 at org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:331) 
 at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181) 
 at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) 
 at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) 
 at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) 
 at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) 
 at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) 
 at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) 
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) 
 at java.util.concurrent.FutureTask.run(FutureTask.java:266) 
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) 
 at java.util.concurrent.FutureTask.run(FutureTask.java:266) 
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 
 at java.lang.Thread.run(Thread.java:745) 
Caused by: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files) 
 at java.io.FileInputStream.open0(Native Method) 
 at java.io.FileInputStream.open(FileInputStream.java:195) 
 at java.io.FileInputStream.<init>(FileInputStream.java:138) 
 at java.io.FileInputStream.<init>(FileInputStream.java:93) 
 at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90) 
 at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188) 
 at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168) 
 at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:158) 
 ... 36 more 
}
{noformat}",XD-3181,nebhale,XD Container not closing file descriptors
585,,wenjie zhu,"spring xd Can drag way to configure flow in the form of figure?

Similar to configure a workflow graphical interface


Looking forward to reply",XD-3180,wenjie zhu,"Spring xd, to configure the stream drag and graphic "
586,,Gary Russell,"Now that Boot (1.3) supports SSL (and other settings), we can remove the {{ConnectionFactorySettings}} {{@Configuration}}.",XD-3179,Gary Russell,Remove ConnectionFactorySettings (after move to Boot 1.3)
587,Thomas Risberg,Thomas Risberg,"If we export HADOOP_DISTRO env var instead of using --hadoopDistro parameter then the logging message is wrong, it always says

Hadoop Distro: hadoop26

even if we set HADOOP_DISTRO to something else

The classpath is built correctly. Maybe we should just remove this logging message since we log the actual version used in the next log message.
",XD-3178,Thomas Risberg,Hadoop Distro log message shows wrong version when set via env var
588,Gary Russell,Gary Russell,"When the bus is used outside of the XD container (e.g. spring-bus), the inheritance from Spring Boot configuration is broken (no application.yml or servers.yml on the cp).

Make the bus properties optional (Add "":"")",XD-3177,Gary Russell,Make RabbitMessageBus RabbitMQ Config Properties Optional
589,Thomas Risberg,Thomas Risberg,"I tried setting the xd.customModule.home property to point to a Kerberized Hadoop cluster with all usual security config settings provided. It failed with the following exception:

{code}
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1139) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	... 22 common frames omitted
Caused by: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2755) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2724) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:870) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:859) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817) ~[hadoop-common-2.6.0.jar:na]
	at org.springframework.xd.dirt.module.ExtendedResource$HdfsExtendedResource.mkdirs(ExtendedResource.java:127) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:79) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1633) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1570) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	... 25 common frames omitted
Caused by: org.apache.hadoop.ipc.RemoteException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at org.apache.hadoop.ipc.Client.call(Client.java:1468) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.ipc.Client.call(Client.java:1399) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.6.0.jar:na]
	at com.sun.proxy.$Proxy79.mkdirs(Unknown Source) ~[na:na]
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:539) ~[hadoop-hdfs-2.6.0.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]
	at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[hadoop-common-2.6.0.jar:na]
	at com.sun.proxy.$Proxy80.mkdirs(Unknown Source) ~[na:na]
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2753) ~[hadoop-hdfs-2.6.0.jar:na]
	... 37 common frames omitted
2015-06-10T14:49:20-0400 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed
{code}",XD-3176,Thomas Risberg,Using HDFS for custom module home doesn't work with Kerberized Hadoop cluster
590,,Mark Pollack,"In 
{noformat}
BroadcasterMessageHandler.handleMessageInternal
{noformat}
, the call


{code:java}
} else if (ClassUtils.isAssignable(inputType, message.getPayload().getClass())) {
            //TODO handle type conversion of payload to input type if possible
            ringBufferProcessor.onNext(message.getPayload());
{code}

could try to invoke a conversion service
        ",XD-3175,Mark Pollack,Consider using the ConversionService to convert incoming message payload to Reactor based processor's input type.
591,Sabby Anandan,Gunnar Hillert,"Even for relatively large resolutions, e.g. 1024px the graph breaks the browser window. We should ensure that the graphs work on smaller screens.",XD-3174,Gunnar Hillert,UI: Analytics Tab - Ensure that graphs are responsive
592,,Gary Russell,"As a user I'd like to be able to understand the root cause of an error on the {{http}} shell command.

When an exception occurs on an {{http}} shell command, the user gets

{{""Failed to access http endpoint %s"", target}}

No information from the exception is conveyed to the user (nor is it logged by the admin).",XD-3173,Gary Russell,Improve User Experience on HTTP Shell Commands
593,Gunnar Hillert,Gunnar Hillert,Depends on INT-3727,XD-3172,Gunnar Hillert,Provide a source option to enable the SOF/EOF markers when splitting a file into lines
594,Eric Bottard,Ilayaperumal Gopinathan,"From https://github.com/spring-projects/spring-xd/issues/1704

I am trying to use composed modules when running on YARN.  

In ZK, each child module definition of the composed module gets serialized as follows:

```
{""@class"":""org.springframework.xd.module.SimpleModuleDefinition"",""name"":""transform"",""type"":""processor"",""location"":""file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1433789137218_0001/filecache/17/spring-xd-yarn-1.1.2.RELEASE.zip/modules/processor/transform/""}
```

When I try to use the composed module on YARN, it may be deployed to a different container where the ""location"" file path is not valid.  In this case I get the following exception:

```
java.lang.IllegalArgumentException: File must exist
	at org.springframework.boot.loader.data.RandomAccessDataFile.<init>(RandomAccessDataFile.java:67)
	at org.springframework.boot.loader.data.RandomAccessDataFile.<init>(RandomAccessDataFile.java:51)
	at org.springframework.boot.loader.jar.JarFile.<init>(JarFile.java:95)
	at org.springframework.boot.loader.archive.JarFileArchive.<init>(JarFileArchive.java:61)
	at org.springframework.boot.loader.archive.JarFileArchive.<init>(JarFileArchive.java:57)
	at org.springframework.xd.module.support.ModuleUtils.createModuleClassLoader(ModuleUtils.java:54)
	at org.springframework.xd.module.support.ModuleUtils.createModuleClassLoader(ModuleUtils.java:47)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:186)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveComposedModuleMetadata(DefaultModuleOptionsMetadataResolver.java:175)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:167)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174)
```

I think the issue may be related to the following line in ArchiveModuleRegistry:

```
String filename = resource.getFile().getCanonicalFile().getName();
```

",XD-3171,Ilayaperumal Gopinathan,Composed modules not working on YARN
595,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated.
The documentation also needs some more information on `Reliable` receiver.",XD-3170,Ilayaperumal Gopinathan,Update Spark streaming documentation
596,Michael Minella,Sabby Anandan,"As a developer, I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.",XD-3169,Sabby Anandan,Spike: Explore options for batch modules to be short lived
597,,David Turanski,"See
http://stackoverflow.com/questions/30714828/spring-xd-http-client-processor-sends-text-plain-instead-of-application-json",XD-3168,David Turanski,Type conversion should set Content-Type header
598,,Gunnar Hillert,"How to reproduce:

* Menu: File -> Import --> Gradle Project
* Press Next
* Select the Spring XD Root Folder
* Press button *Build Model* 

This fails with the following log output:

{code}

FAILURE: Build failed with an exception.

* Where:
Script '/Users/hillert/dev/git/spring-xd/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle' line: 32

* What went wrong:
A problem occurred evaluating script.
> dependencies.properties (No such file or directory)

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 29.05 secs

{code}

If I comment out / remove in *spring-xd-starters/spring-xd-module-parent/publish-maven.gradle* the following lines, everything works:

{code}
diff --git a/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle b/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle
index 6dea47f..202f884 100644
--- a/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle
+++ b/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle
@@ -28,10 +28,6 @@ def getAllDependentProjects(project) {

 // load versions
 def versions = new Properties()
-def propertiesFile = new File('dependencies.properties')
-propertiesFile.withInputStream {
-       versions.load(it)
-}

 def customizePom = {
{code}",XD-3167,Gunnar Hillert,STS import using Gradle Plugin broken
599,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics, so the users can use it as a reference while setting up Spring XD cluster.
",XD-3166,Sabby Anandan,Publish performance benchmarks
600,,Sabby Anandan,"As a PM, I'd like to have XD and XD + Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.",XD-3165,Sabby Anandan,Synchronize XD and XD + Ambari RPMs into a single repo
601,Marius Bogoevici,Marius Bogoevici,"As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour. 

Such properties should include
- autoCommitEnabled,queueSize,maxWait,fetchSize for consumers
- batchSize,batchTimeout for producers",XD-3164,Marius Bogoevici,Kafka bus defaults configurable at producer/consumer level
602,,Glenn Renfro,"Kafka deployments take nearly 4 times as long as other transports because of the creation of the topic an partitions.  Currently all test use the same wait time whether it is for waiting for connections or file writes.   So to get a CI build for kafka build would take a long period of time.

The goal of the Story is to allow deployments to have a different pause_time to give Kafka bus the extra time it needs but not affect the timeout for other stages of the tests.  

",XD-3163,Glenn Renfro,Modify Acceptance tests to give a pause time for deployment different than default
603,Glenn Renfro,Glenn Renfro,,XD-3162,Glenn Renfro,Update Master Environment for 2.0 CI Acceptance Tests
604,Glenn Renfro,Glenn Renfro,Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x,XD-3161,Glenn Renfro,Add CI Acceptance Test for 1.2.x
605,Eric Bottard,Eric Bottard,"Sort alphabetically, nest ""Available modules"" section appropriately. Optionally, move to a whole different ""PART"" in reference doc",XD-3160,Eric Bottard,Reorganize OOTB module list in docs
606,,Eric Bottard,"The various methods is ModuleUtils sometimes create module classloaders just for the sake of loading a single file.
URLClassLoader are now closeable, which we should try to do, but not too early.

Some of the signatures in that class are problematic (esp the ones that return a Resource) because we don't know when the client will be done with that resource. So we can't close the underlying CL for them.

Investigate other approaches:
 * callback style signatures (ie doWithClassLoader(cl) for certain cases)
 * global CL caching mechanism per module type:name  (but then issues arise when module bytecode is changed, etc)",XD-3159,Eric Bottard,Better handle the lifecycle of module classloaders
607,,Gunnar Hillert,"When querying the *ModuleMetadataRepository*, the *ModuleOptions* in class *ModuleMetadata*  are currently only provided as *properties*. This is a problem in cases where I need to determine the type of the property. 

For instance, security sensitive properties should not be exposed verbatim but rather be masked. 

Right now it seems impossible (easily) to determine whether a property is e.g. of type:

*org.springframework.xd.module.options.types.Password*  

",XD-3158,Gunnar Hillert,The ModuleOptions in ModuleMetadata should contain type information 
608,,wenjie zhu,"As a developer, I in the new development of component (source/processor/sink), how to get the module id and container id

Because components need to generate log, log information must include the unique identifier


xd:>runtime modules
",XD-3157,wenjie zhu,"How to get in the module's container ID, and module id"
609,,Muhammad Ali,"As a developer I would like to create DSL based jobs using Spring XD. 

Currently BatchJobRegistryBeanPostProcessor implementation has an assumption in postProcessAfterInitialization( ) method (line 92). It checks if the beans are instanceof StepParserStepFactoryBean which is XML based steps. Therefore any XD step listeners for tap events are not getting registered, effectively I'm not getting any Step events out of my DSL based jobs.

Apparently everything else is working alright for the Java DSL job. Java DSL jobs are far easier to write Test/Integration Tests with.

Please review issue type - I was not sure if this was a bug or improvement, i supposed it is an improvement.
",XD-3156,Muhammad Ali,Add tap notification (Step/Chunk events) support for Java DSL based Batch job creation
610,Marius Bogoevici,Phil Webb,"Use Spring XD modules with Spring Boot devtools the following SpEL errors occur:

{noformat}
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1004E:(pos 8): Method call: Method accept(demo.Vote) cannot be found on demo.CounterApplication$$EnhancerBySpringCGLIB$$8b6c5177 type
    at org.springframework.expression.spel.ast.MethodReference.findAccessorForMethod(MethodReference.java:211)
    at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:125)
    at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)
    at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)
...
{noformat}

The root cause of the error is that SpEL is using a different classloader to compare argument times to the one that loaded the object.

The actual incoming object is loaded via  {{MessageBusSupport}} which is calling {{Class.forName}}. If {{ClassUtils.forName}} is used instead then the context classloader is used and everything appears to work.",XD-3155,Phil Webb,MessageBusSupport loads classes using the wrong ClassLoader
611,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release, so I can leverage the latest improvements. ",XD-3154,Sabby Anandan,Update to Spring Hadoop 2.2.0 GA 
612,Gary Russell,Sabby Anandan,"As a developer, I'd like to update to SI Kafka extension 1.2.0, so I can leverage the latest performance improvements.",XD-3153,Sabby Anandan,Update to Spring Integration Kafka 1.2.0 GA
613,Gary Russell,Sabby Anandan,"As a developer, I'd like to update to the 4.1.5 SI release, so I can pickup the latest improvements to message channels.",XD-3152,Sabby Anandan,Update to Spring Integration 4.1.5 
614,David Turanski,David Turanski,Some info is obsolete and add more content re. dependency management,XD-3151,David Turanski,Update Modules - Build and Package sections
615,Janne Valkealahti,Thomas Risberg,"Definitions:

>job create pollHdfs --definition ""filepollhdfs --names=name,age"" --deploy true

>stream create csvStream --definition ""file --mode=ref --dir=/Users/trisberg/Test/files --pattern=*.csv > queue:job:pollHdfs"" --deploy

Here is the exception:

{code}
org.springframework.data.hadoop.store.StoreException: Error while flushing stream; nested exception is java.nio.channels.ClosedChannelException
	at org.springframework.xd.batch.item.hadoop.HdfsTextItemWriter.update(HdfsTextItemWriter.java:135)
	at org.springframework.batch.item.support.CompositeItemStream.update(CompositeItemStream.java:74)
	at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:250)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy54.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunching
{code}",XD-3150,Thomas Risberg,the 'filepollhdfs' job fails on second submission
616,,Thomas Risberg,"The stream definition example uses old style syntax, should be --mode=ref instead of --ref=true ",XD-3149,Thomas Risberg,Batch job filepollhdfs docs are outdated
617,Thomas Risberg,Thomas Risberg,There is an hadoop-core-2.5.0-mr1-cdh5.3.3.jar in the lib/cdh5 directory - we need to remove that from the dist,XD-3148,Thomas Risberg,Remove mr1 jar from cdh5 hadoop build
618,,Michael Minella,"h2. Narrative
As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams.

h2.  Back story
Streams currently provide a DSL for assembling modules into flows (streams) that consist of a source, n processors, and a sink.  While constructing the steps of jobs themselves would be difficult in this manor, creating flows of jobs (essentially a job that consists only of job steps) would be very useful.  It would allow a developer to create something like the following:

{code}
filejdbc | mycustomjob | jdbchdfs
{code}

This approach also allows the existing packaging/module registry/etc to work out of the box.  This gets us closer to what Oozie provides out of the box without the need to create custom jobs to do the orchestration.",XD-3147,Michael Minella,Composing Jobs via the DSL
619,,Michael Minella,"h2. Narrative
As a developer, when using jdbchdfs's incremental imports, I need to be notified that something went wrong in a previous run of the jdbchdfs job so that I can take the appropriate actions based on the data previously imported.

h2.  Back story
As the incremental import currently works, if the job fails half way through, there is no check on the next run to see if the last run failed or not and how to address partially imported data.",XD-3146,Michael Minella,Strict flag for jdbchdfs
620,Michael Minella,Michael Minella,"h2. Narrative
As a developer, I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.

h2. Back story
While streams are never ending, batch jobs have a true lifecycle with a beginning and and end.  By having a job bootstrapped when it's not executing, it eats up precious resources.  For example, if I have a job that creates connections to a database via a connection pool, the job module will hold those connections from the moment it's deployed to the moment it's undeployed, even if the job isn't being executed.  A more efficient use of resources would be to have the job module provide just enough to receive the launch request and then bootstrap the job's context

h2.  Notes
https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit",XD-3145,Michael Minella,Update batch modules to be short lived
621,,Karol Dowbecki,"As a developer, I would like to be able to configure which exceptions thrown by a module should be retryable within the {{RabbitMessageBus}}.

As usual, these should be configurable at the bus and/or stream deployment property level.

Also consider disabling retry for kryo deserialization problems.
----

We are running Spring XD with RabbitMQ transport and we'd like to have a way to stop retries in certain situations. In [Spring XD 1.2.0.RC1 docs|http://docs.spring.io/autorepo/docs/spring-xd/1.2.0.RC1/reference/html/], in chapter about RabbitMQ transport, in ""A Note About Retry"" section, it's written:

{quote}Message deliveries failing with a MessageConversionException (perhaps when using a custom converterClassName) are never retried; the assumption being that if a message could not be converted on the first attempt, subsequent attempts will also fail.{quote}

Following is unclear:
# Are we speaking about {{org.springframework.messaging.converter.MessageConversionException}} or {{org.springframework.amqp.support.converter.MessageConversionException}}? Based on XD-1597 and AMQP-390 it's the latter.
# Only {{org.springframework.messaging.converter.MessageConversionException}} is available for custom module developers. Attempting to throw {{org.springframework.amqp.support.converter.MessageConversionException}} which is provided by {{$XD_HOME/lib/messagebus/rabbit/spring-amqp-1.4.5.RELEASE.jar}} results in {{java.lang.ClassNotFoundException}} even after Spring XD is configured to use {{rabbit}} transport.
# Throwing  {{org.springframework.messaging.converter.MessageConversionException}} from custom processor module written with Spring Integration's {{transformer}} or {{service-activator}} doesn't stop retries.",XD-3144,Karol Dowbecki,Expose Retryable Exceptions in the RabbitMessageBus Retry Configuration
622,,Ilayaperumal Gopinathan,There are more calculations done at the RuntimeModuleDeploymentPropertiesProvider implementations and would be good to have some tests to cover them.,XD-3143,Ilayaperumal Gopinathan,Test coverage for RuntimeModuleDeploymentPropertiesProvider
623,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Spring Integration MBeans are enabled by default even though XD_JMX_ENABLED is set to false. We need to disable JMX on these MBeans as well as Spring Boot MBeans.,XD-3142,Ilayaperumal Gopinathan,Enable/Disable Boot and Integration MBeans when JMX is enabled/disabled
624,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When a custom module is uploaded to module registry, though the module registry is updated with the changed module after deleting the existing one, the module changes aren't loaded when deployed.",XD-3141,Ilayaperumal Gopinathan,Uploaded custom module requires restart to get in effect
625,David Turanski,Sabby Anandan,"As a user, I'd like to have a landing page with higher-order links for sources, processors, sinks and jobs, so I can jump to right section from one place. ",XD-3140,Sabby Anandan,Create a landing page with links for all OOTB modules
626,Gunnar Hillert,Sabby Anandan,"As a user, I'd like to refer to the analytics tab docs, so I can understand how to use various widgets from streaming pipeline.  ",XD-3139,Sabby Anandan,Document the new analytics tab features
627,,Ilayaperumal Gopinathan,This is in reference to the investigation done as part of XD-2548,XD-3138,Ilayaperumal Gopinathan,Better classloader strategy for XD admin/container
628,David Turanski,David Turanski,This addresses The plugin issue https://www.jfrog.com/jira/browse/GAP-172 to disable spring-xd/pom.xml,XD-3137,David Turanski,Upgrade to 3.1.1 of the Gradle Artifactory Plugin 
629,,Thomas Risberg,"Running XD on YARN on PHD 3.0 Ambari install.

Uploading and submitting a custom job fails with the following:

{code}
2015-06-02 16:54:15,580 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1433273561345_0009_m_000000_0: Error: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2076)
	at org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:186)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:742)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1982)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2074)
	... 8 more
{code}

Same example jar works fine when submitted from XD cluster.",XD-3136,Thomas Risberg,Example hashtag-count MR job fails when running XD on YARN with PHD 3.0
630,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When running spark streaming module on spark standalone cluster from XD distribution, I see the following error:

[Stage 3:=============================>                             (1 + 1) / 2]2015-06-02T10:05:53-0700 1.2.0.SNAP WARN task-result-getter-3 scheduler.TaskSetManager - Lost task 0.0 in stage 3.0 (TID 50, 192.168.2.8): java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/Users/igopinatha/workspace/git/ilayaperumalg/spark/assembly/target/scala-2.10/spark-assembly-1.2.1-hadoop2.2.0.jar). If you are using Weblogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml Object of class [org.slf4j.impl.Log4jLoggerFactory] must be an instance of class ch.qos.logback.classic.LoggerContext
     at org.springframework.util.Assert.isInstanceOf(Assert.java:339)
     at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:151)
     at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLogger(LogbackLoggingSystem.java:143)
     at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:89)
     at org.springframework.boot.logging.LoggingApplicationListener.onApplicationStartedEvent(LoggingApplicationListener.java:152)
     at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:139)
     at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)
     at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)
     at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:100)
     at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:54)
     at org.springframework.boot.SpringApplication.run(SpringApplication.java:277)
     at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
     at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusConfiguration.createApplicationContext(MessageBusConfiguration.java:82)
     at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.start(MessageBusSender.java:105)
     at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:58)
     at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:53)
",XD-3135,Ilayaperumal Gopinathan,Spark streaming module includes logback jar when using dist zip
631,Glenn Renfro,Ilayaperumal Gopinathan,We need to setup Spark standalone cluster on the CI environment so that the Spark streaming tests can be run on the standalone cluster along with the local mode (that we run now).,XD-3134,Ilayaperumal Gopinathan,Create a spark standalone cluster on CI to run spark streaming tests
632,Thomas Risberg,Thomas Risberg,Need to update classpath settings for PHD 3.0 and HDP 2.2 ,XD-3133,Thomas Risberg,Update YARN deployment classpath settings for HDP 2.2 and PHD 3.0
633,Thomas Risberg,Thomas Risberg,"Got this error when submitting Sqoop job:

{code}
2015-06-01 19:09:42,932 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(75)) - Sqoop command: import
2015-06-01 19:09:42,939 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(76)) - Using args: [--table, XD_JOB_REGISTRY, --target-dir, /xd/sqoop2, -m=1]
2015-06-01 19:09:42,939 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(77)) - Mapreduce home: /usr/hdp/2.2.4.2-2/hadoop-mapreduce
2015-06-01 19:09:42,977 WARN [main] conf.Configuration (Configuration.java:(646)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively
2015-06-01 19:09:42,984 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: fs.defaultFS=hdfs://hawaii:8020
2015-06-01 19:09:43,743 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.hostname=hawaii
2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.address=hawaii:8050
2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.scheduler.address=hawaii
2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: mapreduce.framework.name=yarn
2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: mapreduce.jobhistory.address=hawaii
2015-06-01 19:09:43,760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: yarn.resourcemanager.scheduler.address=hawaii:8030
2015-06-01 19:09:43,760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: mapreduce.application.classpath=$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:/usr/hdp/2.2.4.2-2/hadoop/lib/hadoop-lzo-0.6.0.2.2.4.2-2.jar:/etc/hadoop/conf/secure
2015-06-01 19:09:43,760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: mapreduce.application.framework.path=/hdp/apps/2.2.4.2-2/mapreduce/mapreduce.tar.gz#mr-framework
2015-06-01 19:09:44,141 INFO [main] sqoop.Sqoop (Sqoop.java:(92)) - Running Sqoop version: 1.4.5
2015-06-01 19:09:44,691 INFO [main] manager.SqlManager (SqlManager.java:initOptionDefaults(98)) - Using default fetchSize of 1000
2015-06-01 19:09:44,691 INFO [main] tool.CodeGenTool (CodeGenTool.java:generateORM(92)) - Beginning code generation
2015-06-01 19:09:45,057 INFO [main] manager.SqlManager (SqlManager.java:execute(749)) - Executing SQL statement: SELECT t.* FROM XD_JOB_REGISTRY AS t WHERE 1=0
2015-06-01 19:09:45,074 INFO [main] manager.SqlManager (SqlManager.java:execute(749)) - Executing SQL statement: SELECT t.* FROM XD_JOB_REGISTRY AS t WHERE 1=0
2015-06-01 19:09:45,148 INFO [main] orm.CompilationManager (CompilationManager.java:findHadoopJars(94)) - HADOOP_MAPRED_HOME is /usr/hdp/2.2.4.2-2/hadoop-mapreduce
2015-06-01 19:09:45,230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(184)) - It seems as though you are running sqoop with a JRE.
2015-06-01 19:09:45,230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(185)) - Sqoop requires a JDK that can compile Java code.
2015-06-01 19:09:45,230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(186)) - Please install a JDK and set $JAVA_HOME to use it.
2015-06-01 19:09:45,232 ERROR [main] tool.ImportTool (ImportTool.java:run(609)) - Encountered IOException running import job: java.io.IOException: Could not start Java compiler.
at org.apache.sqoop.orm.CompilationManager.compile(CompilationManager.java:187)
at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:97)
at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:478)
at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:601)
at org.apache.sqoop.Sqoop.run(Sqoop.java:143)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179)
at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218)
at org.springframework.xd.sqoop.SqoopRunner.main(SqoopRunner.java:87)
{code}
",XD-3132,Thomas Risberg,Sqoop job doesn't run when deployed on YARN on Ambari deployed HDP
634,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Since Spark streaming doesn't use ZK to keep track taps being created, we don't need the tap listener cache setup at the container startup.",XD-3131,Ilayaperumal Gopinathan,Spark streaming plugin shouldn't need tap listener cache
635,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Since `Spark-streaming` uses `BusUtils`, we need to move the bus cleaner util method that builds rest template so that spark streaming doesn't depend on `httpClient`",XD-3130,Ilayaperumal Gopinathan,Move Bus cleaner util method from BusUtils
636,,Muhammad Ali,"I have 500+ jobs configured to load different tables from my source databases. Once I do job list, it just runs me down through the list of jobs, which is ok. However, I would like an option to see the number of jobs that have been deployed successfully, or currently undeployed, or failed during deployment. Simple counts (or a better word)

xd:> job counts 
total    deployed   undeployed   failed
------    ------------    --------------    ------
..61..........24........... 35 ............2

I would also like to filter the job list by name pattern - that could be regular expression. So any job matching the expression must be listed. Something like following

xd> job list --name CRM*
",XD-3129,Muhammad Ali,"Job list/counts should have filters and metrics e.g. number of deployed, undeployed, failed jobs."
637,,Thomas Risberg,"Starting teh shell without having admin running on localhost:9393 results in the following message:

{code}
1.2.0.RC1 | Admin Server Target: http://localhost:9393
-------------------------------------------------------------------------------
Error: Unable to contact XD Admin Server at 'http://localhost:9393'.
Please execute 'admin config info' for more details.
-------------------------------------------------------------------------------
{code}

Running {code}admin config info{code} gives a nasty stacktrace though, so these instructions are misleading and should be changed",XD-3128,Thomas Risberg,Misleading instruction when admin server not running on localhost:9393
638,David Turanski,Sabby Anandan,"As a user, I'd like to refer to OOTB batch jobs and the documentation, so I can jump to the right job section and review details. ",XD-3127,Sabby Anandan,Create a landing section for OOTB batch jobs
639,David Turanski,David Turanski,"This is an enhancement to KryoClassRegistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance. Currently XD will support POJOs that implement the kryo Serializable interface to gain a 2x performance improvement, however initial benchmarks show that custom serializers are about 10% more performant than Serializable.",XD-3126,David Turanski,Support for registering custom Kryo Serializers
640,David Turanski,David Turanski,"Currently kryo class registration is hard coded in spring-xd-codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. ",XD-3125,David Turanski,Fail fast on Kryo registration conflicts
641,Marius Bogoevici,Marius Bogoevici,"`minPartitionCount` is ignored by the consumer, so downstream modules end up listening to fewer partitions",XD-3124,Marius Bogoevici,`minPartitionCount` is ignored by the consumer
642,Eric Bottard,Eric Bottard,,XD-3123,Eric Bottard,Prevent classloader leakage thru javabeans infrastructure
643,Patrick Peralta,Patrick Peralta,"Refactoring of the {{ResourceDeployer}} to split apart the concepts of repository and deployment. For reference see XD-2835, XD-2671, XD-2877 and XD-3070.",XD-3122,Patrick Peralta,Refactor deployment interfaces/class hierarchy (continued)
644,,tiger,"when use rabbit as source, always have the warn message:
skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]

similar issure is https://jira.spring.io/browse/XD-2567,  but i have no use rabbit sink.",XD-3121,tiger,"skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]"
645,,Gary Russell,Private keys do not require pass phrases; hence it's bogus for the source to require one.,XD-3120,Gary Russell,SFTP Source Requires PassPhrase with Private Key
646,,wenjie zhu,"Do as a developer, in the case of large data from the source to the sink will after multiple processors, I found that even if the processor does not do anything, message from the source to the sink of performance, with the number of processors, the message forwarding performance will decrease very much. For example:

spring xd run in  singlenode

After the tcp-client connects the socket service, receive very many text (a line of text messages)

stream definition:
tcp-client |t1:transform |t2:transform |t3:transform |t4:transform |null 

Message passing rate: 20000 per second
Transform didn't do anything.

stream definition:
tcp-client|null
Message passing rate: 170000 per second

Message is a line of text, my business requires me to a second processing 300000 pieces of data.(About 100 MB/s in a machine )

Tell me how to solve the performance bottleneck. Can stream only have source and sink to get high performance?",XD-3119,wenjie zhu,The performance of the pipe [in singlenode]
647,Thomas Risberg,Sabby Anandan,"As a user, I'd like to start multiple instances of {{xd-container}}'s through the RPM scripts, so I can easily spin-up instances on the same node/vm.",XD-3118,Sabby Anandan,Update RPM script to include number of containers to be started
648,Patrick Peralta,Gary Russell,"Occasional CI test build failures:

{quote}
Caused by: java.lang.IllegalStateException: Container cache not initialized (likely as a result of a ZooKeeper connection error)
	at org.springframework.util.Assert.state(Assert.java:385)
	at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.ensureCache(ZooKeeperContainerRepository.java:184)
	at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findOne(ZooKeeperContainerRepository.java:263)
{quote}

e.g. https://build.spring.io/browse/XD-JDK8-JOB1-1514

Add logging to {{ensureCache()}} (e.g. in {{childEvent()}} ) and {{closeCache()}} to log that the cache was closed; it appears that's the only way the ""cache not initialized"" message can be emitted.",XD-3117,Gary Russell,Add Logging to ZooKeeperContainerRepository
649,Eric Bottard,Mark Pollack,RPM scripts will need to change.,XD-3116,Mark Pollack,Update redis.tar.gz bundled in distribution to be version 3.0.1
650,Mark Pollack,Mark Pollack,Provide unit tests,XD-3115,Mark Pollack,Improve ReactorReflectionUtils.extractGeneric to support classes with inheritance
651,Mark Pollack,Mark Pollack,,XD-3114,Mark Pollack,Ensure proper lifecycle shutdown of processors in BroadcasterMessageHandler and MultipleBroadcasterMessageHandler 
652,Gary Russell,Mark Pollack,https://sonar.spring.io/drilldown/issues/org.springframework.xd:spring-xd?severity=CRITICAL,XD-3113,Mark Pollack,Review 'critical' sonar warning...
653,Gunnar Hillert,sridhar,"This type is used in password field in the jdbc sink module provided by Spring XD (defined in org.springframework.xd.jdbc.JdbcConnectionMixin class). It seems that Spring XD Admin UI is always displaying the password in plain text please see attached screen shot.
Is there a way to somehow hide the passwords used as module properties in streams from being displayed in Spring XD Admin UI?
This is similar issue as below and fixed in batch jobs but not in streams.
https://github.com/spring-projects/spring-xd/pull/1325",XD-3112,sridhar,Hide the passwords used as module properties in streams from being displayed.
654,Mark Pollack,Mark Pollack,,XD-3111,Mark Pollack,Upgrade to 1.2.0 RC1 SIK release
655,Gary Russell,Sabby Anandan,"As a developer, I'd like to clean-up compiler and javadoc warnings from the build, so we don't see  the warnings in build sysout.",XD-3110,Sabby Anandan,Clean-up compiler and javadoc warnings from the build
656,Gary Russell,Carlos Queiroz,"Having the follow messages poping up on xd log. It seems they are being generated indefinitely. 

Log files getting huge. 

[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: ssh-rsa,ssh-dss
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: diffie-hellman-group1-sha1,diffie-hellman-group-exchange-sha1
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: ssh-rsa,ssh-dss
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server->client aes128-ctr hmac-sha1 none
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client->server aes128-ctr hmac-sha1 none
[2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_KEXDH_INIT sent
[2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: expecting SSH_MSG_KEXDH_REPLY
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: ssh_rsa_verify: signature true
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: Host 'XX.XXX.XX.X' is known and mathces the RSA host key
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS sent
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS received
[2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_REQUEST sent
[2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_ACCEPT received
[2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: gssapi-with-mic,publickey,keyboard-interactive,password
[2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: gssapi-with-mic
[2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: publickey,keyboard-interactive,password
[2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: publickey
[2015-05-27 15:57:51.086] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentication succeeded (publickey).
[2015-05-27 15:57:51.113] boot - 2774  INFO [task-scheduler-1] --- jsch: Disconnecting from 10.100.103.5 port 22
[2015-05-27 15:57:51.113] boot - 2774  INFO [Connect thread XX.XXX.XXX.X session] --- jsch: Caught an exception, leaving main loop due to Socket closed",XD-3109,Carlos Queiroz,SFTP socket closed error. Infinite loop
657,,Glenn Renfro,"Identified in a stream of commits ending with:0f4d4ea6b2f16c73c0048e32d8a8753aa25a48fd
Transport: Redis
Admin: 1 
Container: 1 
Stream deployed: time|file
Attachments: Admin and container logs.
[Description]
Admin reports that File sink Module failed to deploy at 00:19:32 because ZK stated it already exists.  Container shows no deployment of the file sink.
**** This could be an artifact in that the old Acceptance tests use the same stream name, hence a previous undeploy failed to remove the file.  This is not seen in the log per se'.  The filejdbc fail above is a legitimate test verifying that a job can't be deployed twice.  
",XD-3108,Glenn Renfro,Module failed to deploy because ZK said it already exists.
658,David Turanski,Sabby Anandan,"As a XD build master, I'd like to fix (local ./gradlew dist and distZip targets) the outstanding build issues, so I can evaluate that publish builds works as expected. ",XD-3107,Sabby Anandan,Fix gradle build issues
659,Glenn Renfro,Glenn Renfro,XD-EC2 needs  to allow user to set the XD_JMX_ENABLED flag in the environment prior to admin or container  startups. ,XD-3106,Glenn Renfro,Support XD_JMX_ENABLED configuration
660,Ilayaperumal Gopinathan,Sabby Anandan,"As a developer, I'd like to have JMX turned-off by default, so I can take advantage of the performance throughput benefits. ",XD-3105,Sabby Anandan,Turn-off JMX by default
661,Mark Pollack,Sabby Anandan,,XD-3104,Sabby Anandan,Update to Reactor 2.0.3 
662,Mark Pollack,Sabby Anandan,"As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics. ",XD-3103,Sabby Anandan,Adapt to XD Reactor processor fixes and improvements
663,Glenn Renfro,Glenn Renfro,"As a developer, I'd like to rerun _baseline_, _Tuple_, and _Serialized_ payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. 

Sinks to be included in test:
In-Memory Transport > Hdfs sink
Direct Binding Transport > Hdfs Sink
Kafka > Hdfs Sink",XD-3102,Glenn Renfro,Benchmark XD RC1 using Kafka 0.8.2 as transport
664,Gunnar Hillert,Gunnar Hillert,,XD-3101,Gunnar Hillert,Fix Gradle “dist” build task
665,,Lukasz Nowanski,"Using module.name.count > 1 when deploying taps causes duplication of messages in those modules. This impacts balancing of the containers and modules in a cluster as messages should not be duplicated across modules if the same module is deployed twice to two containers in order to spread the load.

We use taps quite heavily in our project mainly for analytics of the life feed in real time but due to issue we have discovered and described in this bug we are currently facing a limitation where heavily processing modules can not be load balanced across the cluster as they are causing duplication of the messages and therefore the same module deployed to two 
containers would still process the same message twice.

To demonstrate the problem please see test case scenario set up below:

h4. 1. Environment

- Spring-XD version 1.1.1-RELEASE
- Running two spring-xd containers and one spring-xd admin

h4. 2. Set up

Stream definition is as follows:


{quote}stream create --name test-module-count --definition ""syslog-udp --port=5140 | transform | log""
stream deploy --name test-module-count --properties ""module.*.count=2""
stream create --name tap-test-module-count --definition ""tap:stream:test-module-count.syslog-udp > transform --expression='payload.toString() + \""TAPPED\""' | log""
stream deploy --name tap-test-module-count --properties ""module.*.count=2""{quote}


Please refer to the screen shots attached to see that after deploying those two streams we have:

- streams successfully deployed ( module-count-spring-xd-streams.png )
- streams successfully deployed with count=2 to both containers ( module-count-spring-xd-containers.png ) 
- 5 queues created in Rabbit ( module-count-rabbit.png ) where two were created for the syslog-udp collector as a result of using module.syslog-udp.count=2 - this is causing messages to be duplicated. Normally the expectation would be to have only one queue for the tap

h4. 3. Test input data

I have sent a very simple UDP message to the listening udp collector running on second container:


{quote}echo test-module-count >> /dev/udp/host02/5140{quote}

h4. 4. Test output data in the logs ( module-count-container01.log and module-count-container02.log )

h5. Expected result:

Below messages logged only on 1 container (it does not matter which one)
{quote}2015-05-26 09:52:21,630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count}{quote}
Below message logged only on one container (it does not matter which one)

{quote}2015-05-26 09:52:21,843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count
}TAPPED{quote}

h5. Actual result:

Stream that has been create as a tap has duplicated the same message and as a result the same message was proccessed twice on both containers by the same module ( transformer ) and logged twice to the console on both containers

Container01:
{quote}2015-05-26 14:52:21,143 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count
}TAPPED{quote}

Container02:
{quote}2015-05-26 09:52:21,630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count
}
2015-05-26 09:52:21,843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count
}TAPPED{quote}


",XD-3100,Lukasz Nowanski,module.*.count > 1 duplicates messages on taps
666,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have the option to gracefully shutdown the stream, so when it is _undeployed_ while in the middle of its operation, we would want to complete its journey to the sink before XD stops the stream.

*Use case:*
One of the streams has a custom module that performs archive extraction. When this stream is ‘undeployed’ while in the middle of extraction, It looks like the message goes to the DLQ. However we would like the message to complete its journey to the sink of the queue before xd stops the stream. Is this possible?",XD-3099,Sabby Anandan,Spike: Support graceful shutdown of modules in a stream
667,Marius Bogoevici,Marius Bogoevici,,XD-3098,Marius Bogoevici,Message Bus optimizations (Kafka + Redis)
668,,Janne Valkealahti,"As a user I'd like to have shell to automatically configure itself against an environment I have setup.

This really came up with ambari work where shell can be anywhere in a cluster. Best I was able to do for now is to build an init file for commands(ambari xd-shell deploy already knows locations/addresses for xd admin and namenode):
{code}
$ cat /etc/springxd/conf/xd-shell.init 
admin config server http://ambari-2.localdomain:9393
hadoop config fs --namenode hdfs://ambari-2.localdomain:8020
{code}

and then run those after starting xd-shell:
{code}
server-unknown:>script --file /etc/springxd/conf/xd-shell.init
admin config server http://ambari-2.localdomain:9393
Successfully targeted http://ambari-2.localdomain:9393
hadoop config fs --namenode hdfs://ambari-2.localdomain:8020
Script required 0.662 seconds to execute
xd:>
{code}
",XD-3097,Janne Valkealahti,Provide defaults for xd-shell
669,Stephane Maldini,Mark Pollack,Also provide better lifecycle (shutdown) mgmt of handler.,XD-3096,Mark Pollack,Support for BroadcasterMessageHandler to work with concurrent producing threads
670,Stephane Maldini,Mark Pollack,,XD-3095,Mark Pollack,Update to Reactor 2.0.2
671,Thomas Risberg,Ilayaperumal Gopinathan,"From the latest master, I couldn't run sparkApp as batch job. The spark application process gets launched and it doesn't complete and there are no errors at the output.",XD-3094,Ilayaperumal Gopinathan,SparkApp batch job is not running
672,Thomas Risberg,Janne Valkealahti,"Commands from docs:

xd:>job create sqoopListTables --definition ""sqoop --command=list-tables"" --deploy
xd:>job launch --name sqoopListTables

2015-05-21 19:12:36,211 1.2.0.M1 ERROR task-scheduler-1 sqoop.SqoopTasklet - Sqoop job for 'list-tables' finished with exit code: 1
2015-05-21 19:12:36,212 1.2.0.M1 ERROR task-scheduler-1 sqoop.SqoopTasklet - Sqoop err: Error: Required argument --connect is missing.

Adding --connect results

xd:>job create sqoopListTables --definition ""sqoop --command=list-tables --connect=jdbc:hsqldb:hsql://localhost:9101/xdjob"" --deploy
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module sqoop of type job:
    connect: option named 'connect' is not supported


This is with singlenode.",XD-3093,Janne Valkealahti,Sqoop list-tables doesn't work oob
673,Patrick Peralta,Patrick Peralta,"There are a range of issues (such as XD-3083, XD-2671) that are caused by asynchronous deployments issued by the REST API. The flow of events is:
* deploy/undeploy request received by REST API
* controller queues up request to be processed by supervisor
* controller returns HTTP 2xx

This proposal is to have the thread executing the deploy/undeploy request block until the request has been processed by the supervisor. This will have the side effect of deploys appearing to take longer, but when the HTTP request completes, the deployment/undeployment will have been fulfilled. ",XD-3092,Patrick Peralta,Synchronous deployment/undeployments
674,Thomas Risberg,Thomas Risberg,,XD-3091,Thomas Risberg,Update build to use SHDP 2.2.0.RC1
675,Glenn Renfro,Glenn Renfro,"Acceptance tests sporadically fail after https://github.com/spring-projects/spring-xd/pull/1623 was merged XD-2309.

Additional tests were added but used fixed timeouts.  Will replace them with waitForJob.

 ",XD-3090,Glenn Renfro,JdbcHdfsTests sporadically fail
676,Michael Minella,Thomas Risberg,The incremental load introduced with XD-2309 should be added to the batch docs,XD-3089,Thomas Risberg,Add incremental load feature to batch docs
677,,Sabby Anandan,,XD-3088,Sabby Anandan,"Includes feature requests, issues and improvements associated with Flo for Spring XD"
678,,Thomas Risberg,"I created and launched a 'jdbchdfs' job. Due to network issues the job hung. Wasn't able to cancel it so I ended up destroying it.

After that I couldn't recreate the job since XD insisted hat there already was a job with that same name. 

{code}
xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false""
Successfully created job 'jdbc1'
xd:>job deploy jdbc1 --properties ""module.jdbchdfs.count=3""
Deployed job 'jdbc1'
xd:>job launch jdbc1
Successfully submitted launch request for job 'jdbc1'

(Here the job was hung)

xd:>job destroy jdbc1
Destroyed job 'jdbc1'
xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name jdbc1 already exists

xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name jdbc1 already exists

xd:>job destroy jdbc1
Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is no job definition named 'jdbc1'

xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name jdbc1 already exists
{code}",XD-3087,Thomas Risberg,Unable to fully destroy hung batch job
679,Ilayaperumal Gopinathan,Sabby Anandan,The {{testTapSparkProcessor}} has the test that checks the contents at the output of spark streaming word count processor. It turns out that the order in which these messages are processed are not always in order.,XD-3086,Sabby Anandan,Fix random Spark streaming test failures
680,,Mark Pollack,The null sink uses a bridge and in perf testing it seemed to introduce overhead.  Verify with throughput source and a hand-crafted 'no-op' MessageProcessor impl.,XD-3085,Mark Pollack,Improve implementation of null sink
681,,Markus Bukowski,"When a stream with Spring XD 1.1.1.RELEASE is created the REST methods always replies ""/stream/_stream-name_"" as the self link. Unfortunately when this one is called a 404 is returned. So the questions is if this is really intended to work like that. I would expect to get '/stream/definitions/_stream-name_' back instead.

{code:shell}
$ curl -F ""name=ticktap"" -F ""definition=tap:stream:tick > log"" -F ""deploy=true"" http://localhost:9393/streams/definitions/
{""name"":""ticktap"",""status"":null,""definition"":""tap:stream:tick > log"",""_links"":{""self"":{""href"":""http://localhost:9393/streams/ticktap""}}}

$ curl http://localhost:9393/streams/definitions/ticktap
{""name"":""ticktap"",""status"":""deployed"",""definition"":""tap:stream:tick > log"",""_links"":{""self"":{""href"":""http://localhost:9393/streams/ticktap""}}}

$ curl http://localhost:9393/streams/ticktap
{""timestamp"":""2015-05-20T14:20:55.382Z"",""status"":404,""error"":""Not Found"",""message"":""Not Found"",""path"":""/streams/ticktap""}
{code}",XD-3084,Markus Bukowski,Wrong self link returned
682,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"I have a file that has the DSLs:
stream create a1 --definition ""http | log""
stream deploy a1

xd-shell --cmdfile test.cmd
May 19, 2015 1:49:29 PM org.springframework.shell.core.AbstractShell handleExecutionResult
INFO: Created new stream 'a1'
May 19, 2015 1:49:29 PM org.springframework.shell.core.SimpleExecutionStrategy invoke
SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is no stream definition named 'a1'",XD-3083,Ilayaperumal Gopinathan,Creating multiple Stream/Job definitions from command file is broken
683,Gunnar Hillert,Gunnar Hillert,,XD-3082,Gunnar Hillert,UI: Add Analytics Tab
684,Gunnar Hillert,Glenn Renfro,"Cluster Type: SingleNode
Machine: Mac
PR: https://github.com/spring-projects/spring-xd/pull/1624,https://github.com/spring-projects/spring-xd/pull/1626
Stream that reproduces the problem:
{noformat}
stream create foo --definition ""filein: file --dir=/tmp/xd/a0180520-c7fa-4d9d-8cc3-e36fbf59496a --pattern=de59d1b8-f99c-4c43-a8c0-2f6043546689.out --mode=contents | fileout: file --binary=true --mode=replace ""
{noformat}
Error Message:
{noformat}
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module file of type sink:
    mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found
{noformat}
Stacktrace:
{noformat}
2015-05-19 14:30:56,329 1.2.0.SNAP ERROR qtp671416633-35 rest.RestControllerAdvice - Caught exception while handling a request
org.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module file of type sink:
    mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found
	at org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)
	at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:191)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122)
	at org.springframework.xd.dirt.stream.AbstractDeployer.validateBeforeSave(AbstractDeployer.java:115)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:260)
	at sun.reflect.GeneratedMethodAccessor191.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:776)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:705)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:755)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
	at org.eclipse.jetty.server.Server.handle(Server.java:370)
	at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)
	at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)
	at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)
	at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors
Field error in object 'target' on field 'mode': rejected value [replace]; codes [typeMismatch.target.mode,typeMismatch.mode,typeMismatch.org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.mode,mode]; arguments []; default message [mode]]; default message [Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found]
	at org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)
	at org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)
	at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:168)
	at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:188)
	... 61 more
{noformat}",XD-3081,Glenn Renfro,When using file as a source and sink user can not use file sink --mode
685,,Karol Dowbecki,"When deploying streams to clustered Spring XD modules are deployed to all avilable Spring XD containers (assuming no additional deployment properties are specificed). Each container gets similar number of modules. 

When Spring XD container departs from the cluster all departing modules will be migrated to remaining containers. After container rejoins the cluster the modules are not redeployed to it and the cluster looks unbalanced and the node is not used.

!unbalanced-cluster.png!",XD-3080,Karol Dowbecki,Add support for cluster rebalancing
686,Janne Valkealahti,Cristian Giha,"Running Spring-XD singlenode with a kerberized hadoop cluster on CDH 5.3.2. with JDK 1.7 and JCE 1.7.
The kerberos ticket policies are:
* expiration: 24 hours
* renew: 7 days

I need to keep the Spring XD server running constantly because my flows are always waiting for incoming files to be ingested into the HDFS, but the kerberos session expires if there aren't jobs to run before the expiration date. The expiration policies can't be changed due internal company policies.

Is there a way which Spring XD can generate a new ticket instead of renew the current one when a job or stream start executing?

The Spring XD server has configured the hadoop.properties like:

# Use servers.yml to change URI for namenode
# You can add additional properties in this file
dfs.namenode.kerberos.principal=hdfs/_HOST@EDA.COMPANY.COM
yarn.resourcemanager.principal=yarn/_HOST@EDA.COMPANY.COM

yarn.application.classpath=/opt/cloudera/parcels/CDH/lib/hadoop/*,/opt/cloudera/parcels/CDH/lib/hadoop/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/lib/*

hadoop.security.authorization=true
hadoop.security.authentication=kerberos

spring.hadoop.userKeytab=file:///export/home/user/user.keytab
spring.hadoop.userPrincipal=user@ERS.COMPANY.COM

#Connecting to Kerberized Hadoop (Spring XD doc configuration Appendix D)
spring.hadoop.security.authMethod=kerberos
spring.hadoop.security.userKeytab=/export/home/user/user.keytab
spring.hadoop.security.userPrincipal=user@ERS.COMPANY.COM
spring.hadoop.security.namenodePrincipal=hdfs/_HOST@EDA.COMPANY.COM
spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@EDA.COMPANY.COM",XD-3079,Cristian Giha,Create a new Kerberos ticket instead of renew the current one
687,Patrick Peralta,Lukasz Nowanski,"We are running Spring XD 1.1.1 in our production environment and Zookeeper 3.4.5.  Zookeeper is running in failover mode and consists of three independent nodes set up on three separate VMs. From time to time we get ""Connection to Zookeeper Suspended"" event which causes one of the containers in the cluster to be removed from the SpringXD cluster. Modules being deployed on this removed node fail to be re-deployed to other containers in the cluster.

Affected versions:
- SpringXD 1.1.1
- Zookeeper 3.4.5 and 3.4.6

Cluster set up in PROD environment where error occurs:
- 4 Spring-XD dedicated servers
- 4 spring-xd containers (each running on designated server )
- 2 spring-xd admins ( each running alongside one spring-xd container)
- 3 Zookeeper nodes ( 3 designated servers on PAITO environment )

Cluster set up in TEST environment where error also occurred:
- 2 Spring-XD dedicated servers running one spring-xd container and one spring-xd admin each
- 3 Zookeeper nodes running on 3 dedicated servers (PAITO Test environment)

Cluster set up to reproduce error found in PROD environment:
- 1 spring-xd admin
- 3 spring xd-containers (each running on a designated VM )
- 3 zookeeper servers running on one VM

Steps to reproduce:

1)	Set up three node Zookeeper cluster. Attached is example zoo.cfg, we are using default configuration values. In this particular test case we run all Zookeeper nodes on a single VM as we were not testing network layer interruptions.
2)	Set up one Spring XD admin node. Please note that we have also observed this on two node Spring XD admin cluster. 
3)	Set up three Spring XD container nodes. All of them belong to one group (SA) and two of them also belong to second group (HA1). This is configured in $XD_HOME/config/servers.yml however so far group configuration never influenced test outcome.
4)	Create and deploy a test stream using following XD Shell commands:
stream create --name test-zookeeper-failover --definition ""syslog-udp --port=5140 | transform | file --dir='/opt/pivotal/spring-xd/xd/output'""
stream deploy --name test-zookeeper-failover --properties ""module.syslog-udp.criteria=groups.contains('HA1'),module.syslog-udp.count=2,module.file.criteria=groups.contains('SA'),module.file.count=3,module.transform.criteria=groups.contains('SA')""
5)	Ensure that test stream works and handles traffic on UDP port 5140
6)	Shutdown one of the Zookeeper nodes by issuing a stop command.
7)	Two Spring XD containers were not affected and remained in Spring XD cluster.
8)	One Spring XD container was kicked out of Spring XD cluster and was no longer visible on Spring XD admin Web UI. Modules previously deployed to this container were not redeployed to other cluster members.
9)	On the failed Spring XD container we have observed CONNECTION_SUSPEND, CONNECTION_RECONECTED and CHILD_REMOVE Zookeeper events (attached is container-log.txt). Please note that Java process is still running and we see “ConnectionStateManager-0 server.ContainerRegistrar - Waiting for supervisor to clean up prior deployments” messages.
10)	Spring XD admin failed with exception in DepartingContainerModuleRedeployer (attached is admin-log.txt). 
11)	We have observed that departing container node in Zookeeper (/sa/deployments/modules/allocated/1d3fd4cc-5a70-47ed-b4f3-22deef1f4d4f/) had no children. We did this after few minutes so we are not sure at which point it was cleared. 
12)	Restarting failed Spring XD container fixed the problem, modules were correctly redeployed.
Exception from point 10 is very similar to XD-1983 and this code was rewritten in XD-2004.
",XD-3078,Lukasz Nowanski,Spring XD admin fails to redeploy modules after Spring XD container successfully reconnectes to Zookeeper
688,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd-shell or the REST-API directly to upload the custom module bits. I would also like to remove custom-modules.zip artifact from YARN distribution.",XD-3077,Sabby Anandan,Default HDFS as custom module registry for YARN deployments
689,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to use the _Mail_ source to connect to secured IMAP and/or SMTP mail servers. 

_Mail_ source config file requires a <util:properties/> bean (with ssl/tls properties), provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].

{code:xml}
   <beans:beans profile=""default"">
        <util:properties id=""javaMailProperties"">
            <beans:prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</beans:prop>
            <beans:prop key=""mail.imap.socketFactory.fallback"">false</beans:prop>
            <beans:prop key=""mail.store.protocol"">imaps</beans:prop>
            <beans:prop key=""mail.debug"">false</beans:prop>
        </util:properties>
    </beans:beans>
{code}

[List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]",XD-3076,Sabby Anandan,Add SSL properties to the Mail source
690,Marius Bogoevici,Marius Bogoevici,"As part of XD-2958, we've changed the input type of the Kafka sink from String to byte[]. The main reason for the change was that it required an arbitrary and often unneeded (but expensive) conversion to String for the bus payloads. 

Apply the same change to 1.1 branch.",XD-3075,Marius Bogoevici,Backport Kafka Sink input fix
691,Marius Bogoevici,Marius Bogoevici,Backport stability improvements added as part of XD-2958 to the 1.1.x branch.,XD-3074,Marius Bogoevici,Backport metadata retrieval stability improvements
692,,Gary Russell,"The {{LocalMessageBus}} uses the Integration Scheduler to run batch jobs

Launching batch jobs with the {{LocalMessageBus}} uses the Integration default {{taskScheduler}} which only has 10 threads by default.

Use the {{LocalMessageBus.executor}} instead to free up the scheduler threads.

However, we need to consider whether a separate configuration is needed to limit the number of batch jobs - it's possible the existing bus executor configuration is enough.",XD-3073,Gary Russell,LocalMessageBus Will Only Run 10 Jobs by Default
693,Andy Clement,Sabby Anandan,"As a Flo developer, I'd like to add improvements to existing Flo parser endpoints, so I can streamline the error reporting strategy.",XD-3072,Sabby Anandan,Flo parser improvements
694,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to bench Rabbit on rackspace infrastructure, so I can have a sense on how it scales as we add more _xd-container_ nodes.",XD-3071,Sabby Anandan,Spike: Produce Rabbit baseline on rackspace infrastructure
695,Patrick Peralta,Patrick Peralta,"The POC for XD on Lattice uses the following interface for module deployment:

https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/ModuleDeployer.java

{code}
public interface ModuleDeployer {

	void deploy(ModuleDescriptor descriptor);

	void undeploy(ModuleDescriptor descriptor);

	ModuleStatus getStatus(ModuleDescriptor descriptor);

}
{code}

This spike is to introduce this interface and the Lattice implementation in the XD admin. The goals are to:
* Demo a POC showing simple stream deployment with the existing shell/admin to Lattice
* Learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{AbstractDeployer}} and related classes).

Note that this work will not necessarily be merged into XD itself, although some of the concepts may be included in a future PR.",XD-3070,Patrick Peralta,Spike: introduce xolpoc-admin to XD Admin
696,Eric Bottard,Eric Bottard,"Using the gemfire module as an example, there is currently at least two sources of leakage, retaining classes that are loaded by the module classloader (and hence everything from there).

One of them is because of JMX monitoring.

Another one I'm not sure about, but here is a screenshot",XD-3069,Eric Bottard,Investigate classloading leakage
697,,Ilayaperumal Gopinathan,"As a user, I would like to specify the default output channel when the channel name resolution doesn't occur. In cases where I won't prefer to lose the data and like to investigate the messages from errorChannel or that sort.",XD-3068,Ilayaperumal Gopinathan,Provide configuration option to specify the default output channel for router sink
698,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"XD Spark streaming module fails to load:

Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.springframework.xd.tuple.serializer.kryo.TupleCodec] for bean with name 'org.springframework.xd.tuple.serializer.kryo.TupleCodec#2e8f5f36' defined in class path resource [META-INF/spring-xd/bus/codec.xml]: problem with class file or dependent class; nested exception is java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodec
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1331)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:453)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)
	... 67 more
Caused by: java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodec
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:455)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:367)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:360)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.springframework.util.ClassUtils.forName(ClassUtils.java:249)
	at org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:395)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1349)
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1320)",XD-3067,Ilayaperumal Gopinathan,Spark streaming integration module fails to initialize codec
699,Gunnar Hillert,Gunnar Hillert,"If you have a an option *--mode=textLine*, presently the enum MUST be named *textLine*.

I think it would improve the user-experience if we allowed users to pass in values such as:

* --mode=textLine
* --mode=text_line
* --mode=TEXT_LINE

",XD-3066,Gunnar Hillert,Make Enum Conversions for ModuleOptions more lenient
700,,Gunnar Hillert,"Provide an option ""--delete=true"" on the File Source

If the file reading is not *ref*, an option *--delete=true* will remove the file once it was read. 
",XD-3065,Gunnar Hillert,"Provide an option ""--delete=true"" on the File Source"
701,Thomas Risberg,Glenn Renfro,"Looks to have been introduced by https://github.com/spring-projects/spring-xd/pull/1577
Deployment: single admin, 2 container deployment using +RabbitMQ+ as the transport.
Below is a partial stacktrace (please check log for full stacktrace).
Log is attached.
{noformat)
2015-05-15 10:50:15,843 1.2.0.SNAP ERROR xdbus.job:ec2Job3-1 step.AbstractStep - Encountered an error executing step readResourcesStep in job ec2Job3
org.springframework.dao.InvalidDataAccessApiUsageException: Cannot autogenerate id of type java.util.UUID for entity of type org.springframework.xd.tuple.DefaultTuple!
        at org.springframework.data.mongodb.core.MongoTemplate.assertUpdateableIdIfNotSet(MongoTemplate.java:1153)
        at org.springframework.data.mongodb.core.MongoTemplate.doSave(MongoTemplate.java:882)
        at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:837)
        at org.springframework.batch.item.data.MongoItemWriter.doWrite(MongoItemWriter.java:128)
        at org.springframework.batch.item.data.MongoItemWriter$1.beforeCommit(MongoItemWriter.java:156)
        at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCommit(TransactionSynchronizationUtils.java:95)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCommit(AbstractPlatformTransactionManager.java:928)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:740)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
{noformat)",XD-3064,Glenn Renfro,HdfsMongoDB Job failing due because of missing ID in Default Tuple
702,Gary Russell,Gary Russell,"Polled message sources return only one message per poll by default.

When polling, say, a file directory with many files, files will be emitted once per {{fixedDelay}}.

As a user I need to configure a limit for the number of messages that will be emitted per poll.",XD-3063,Gary Russell,Add Property maxMessagesPerPoll to All Polled Sources
703,Mark Pollack,Mark Pollack,"As a developer, I'd like to remove _ID_ and _TimeStamp_ attributes from the {{Tuple}} class, so I can improve performance characteristics by not having them go through _serde_; instead, we could leverage message headers to collect such information. 
",XD-3061,Mark Pollack,Remove id/timestamp from tuple and related methods on tuplebuilder
704,,Mark Pollack,"When delegating to the conversion service, the ConversionFailedException does not have the context of which key caused the failure. Should probably wrap ConversionFailedException with IllegalArgumentException and add that context back in.",XD-3060,Mark Pollack,Provide more informative error message when ConversionService fails in Tuple
705,,Ilayaperumal Gopinathan,"The story XD-2993 addresses the DSL parser to read the multi line stream definitions. We need to support adding multi line parser support for with the mixture of both stream/job definitions.

As a developer, I would setup job definition and have a stream definition that triggers the job in the same multi line content. ",XD-3059,Ilayaperumal Gopinathan,DSL parser that reads both stream and job definitions from multi line definitions
706,,Glenn Renfro,"Currently Windows EC2 (master, JDK8) test is failing 
I've attempted to replicate on my EC2 environment.  The best bet is to try and reproduce using the AMI and machine size that CI uses.  We need to check with Trevor to get this info. 
The error is:
{noformat}
java.lang.AssertionError: java.lang.AssertionError
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.springframework.xd.shell.command.StreamCommandTemplate.verifyExists(StreamCommandTemplate.java:162)
	at org.springframework.xd.shell.command.StreamCommandTemplate.doCreate(StreamCommandTemplate.java:99)
	at org.springframework.xd.shell.command.StreamCommandTemplate.create(StreamCommandTemplate.java:65)
	at org.springframework.xd.shell.command.FtpModulesTests.testRefOptionEqualsFalse(FtpModulesTests.java:70)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{noformat}",XD-3058,Glenn Renfro,Windows CI FTP based tests fail.  
707,,Ilayaperumal Gopinathan,"As a devops, I would prefer having my module registry located in centralized github repository. This would allow all the admins and containers in the cluster pointing to the same module registry. Any new module upload would be pushed to the same github repo which will make the cluster always be in sync on the Module Registry.",XD-3057,Ilayaperumal Gopinathan,Using Github repo for XD module registry
708,Thomas Darimont,Simon Tao,"This is a source module for video ingestion: the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image (encoded with JPEG) as the payload.   ",XD-3056,Simon Tao,Add a new source module to capture video frame from camera or video files
709,,Marius Bogoevici,Failure example: https://build.spring.io/browse/XD-MASTER-2152,XD-3055,Marius Bogoevici,Investigate failing tests in CI
710,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the deployment message is being validated before pushed the ZK distributed queue for deployment. When the message is consumed, there is no validation done. Since, the consumer consumes the messages asynchronously, we need validation at both sides.",XD-3054,Ilayaperumal Gopinathan,Deployment validation when processing the deployment message
711,,Ilayaperumal Gopinathan,"When the admin leader is elected, the leader recalculates the deployed stream/job states. If for some reason the stream/job couldn't be loaded with ModuleConfigurationException, then the leader fails and subsequently all the deployment requests are being queued.

We need to discuss how to handle this situation.
A possible fix could be something like this:
https://github.com/ilayaperumalg/spring-xd/commit/fa6a48072197e8c350eaebe841191e4b6310f437

The issue is that, if the stream was already successfully deployed into a container, then the stream status would still be set to 'undeployed' by the admin leader during the recalculation.

Also, this issue is very minor as the ModuleConfigException would be thrown only if someone upgrades Admin that uses different module options config than the existing stream definitions.",XD-3053,Ilayaperumal Gopinathan,Module configuration exception should not block admin leader election
712,Mark Pollack,Sabby Anandan,"As a developer, I'd like to move the project reactor based [gpfdist|https://github.com/spring-projects/spring-xd-modules/tree/master/gpfdist] from spring-xd-module repo to the core, so I can natively use this sink to write to GPDB/HAWQ.
",XD-3052,Sabby Anandan,Move gpfdist sink from spring-xd-modules repo to the core
713,Michael Minella,Michael Minella,"Spring XD has a gradle task available in the build called launch that starts a single node instance.  This is currently broken.  The command I was using for this command was:
{code}
$ ./gradlew clean build -x test -x javadoc launch
{code}",XD-3051,Michael Minella,Gradle launch task is broken
714,Jon Brisbin,Sabby Anandan,"As a developer, I'd like to move the project reactor based [data processor module|https://github.com/spring-projects/spring-xd-modules/tree/master/spring-xd-reactor] from _spring-xd-module_ repo to the core, so I can natively use Reactor's Stream API to build processor modules. ",XD-3050,Sabby Anandan,Move Reactor based processor module from spring-xd-modules to core
715,Glenn Renfro,Glenn Renfro,"Identify and report hotspots while running the load-generator source and the throughput sink on :
# Singlenode -> In Memory Transport
# Singlenode -> Kafka Transport
# Admin/Container -> Kafka Transport",XD-3049,Glenn Renfro,Profile byte array on In-Memory and Kafka Transport
716,Gary Russell,Paul Harris,"Calling the API to delete queues uses a wildcard-like behaviour unexpectedly. If I request to delete:

{{test-1}}

I expect it to delete streams named with the pattern:

{{test-1.*}}

For example, it would delete:

{{test-1.0, test-1.1, etc}}

In fact I believe it wildcards before and after the period, e.g.:

{{test-1*.*}}

And hence would delete:

{{test-1.0, test-11.0, test-123.0, etc}}

That way of working is potentially helpful, but it's also dangerous because it removes the ability to know that you're only deleting the exact queue you want to in all cases.

For the record the commit (https://github.com/spring-projects/spring-xd/commit/2d5f3f706330a6ead8e91c9a7a23d4372715614d) implies that it should work in the more restricted way above, not the less restricted way.

(Note: I've marked this as an improvement because, absent documentation, I don't know what the correct functionality is and hence can't say this is a bug)",XD-3048,Paul Harris,RabbitMQ queue cleanup uses wildcard unexpectedly
717,Patrick Peralta,Patrick Peralta,"Complete and submit DEBS 2015 paper as described here:

http://www.debs2015.org/camera-ready-instructions.html",XD-3047,Patrick Peralta,Complete Camera Ready DEBS submission
718,David Turanski,David Turanski,Samples including Singlenode tests need to update for package changes,XD-3046,David Turanski,Fix compilation errors after moving SingleNodeApplication package
719,,Sabby Anandan,"As a developer, I'd like to separate mocks vs. real repository coupling from the test infrastructure, so it is easy to test against thin layer of dependencies.",XD-3045,Sabby Anandan,Separate mocks and real repository responsibilities from test coverage
720,,Sabby Anandan,"As a user, I'd like to have an OOTB _jdbcgpfdist_ batch job, so I can read from JDBC and write to HAWQ/GPDB using _gpfdist_ protocol. 

The scope is to reuse the existing gpfdist sink code and adapt it to fit the batch model (_gpfdist_ writer). 

",XD-3044,Sabby Anandan,Add jdbcgpfdist batch job
721,David Turanski,Sabby Anandan,"As a user, I'd like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. 

See this [SC post|https://gopivotal-com.socialcast.com/messages/24377202] for more details.",XD-3043,Sabby Anandan,Document GF specific configuration properties
722,Mark Pollack,Mark Pollack,,XD-3042,Mark Pollack,Upgrade to Reactor 2.0.1
723,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"XD runtime (admin, container and singlenode) have MongoDB boot autoconfiguration enabled. This spins off MongoDB client and thereby the cleaner thread running on all these runtime.

The MongoDB based modules won't have any impact when we disable this autoconfiguration.
 ",XD-3041,Ilayaperumal Gopinathan,Disable MongoDB boot autoconfiguration at XD runtime
724,,Sabby Anandan,"As a user, I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments, so I can run XD without _xd-containers_.

Scope:
* ",XD-3040,Sabby Anandan,Create Boot based ModuleRunner (Phase III)
725,,David Turanski,See http://stackoverflow.com/questions/30112430/payload-filters-transforms-rich-gauges/30115234 for the use case. It should be possible to extract both a numeric value and a gauge name from the message.,XD-3038,David Turanski,Add value-expression to gauges
726,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a user, I want to have a documentation that shows how to configure multiple topics with Kafka source module.",XD-3037,Ilayaperumal Gopinathan,Create documentation for kafka source multiple topic support
727,Eric Bottard,David Turanski,"See:
http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26

There should be chapter/section title before this.",XD-3036,David Turanski,Fix section headers in reference TOC
728,,Ilayaperumal Gopinathan,"When the *stream* that holds the kafka source module is undeployed(but not destroyed yet), the underlying offset manager deletes the offsets associated with the steam.

When same stream is re-deployed, the offset manager reads the offsets from kafka broker (if initial offsets are *not* provided) for each partition the module is configured to listen.

If the initial offset values are provided for the stream, then I think the offset manager should delete the offsets from the XD offset topic only when the stream is *destroyed*. Since we want to re-use the offset topic data upon stream undeploy/re-deploy. 
",XD-3035,Ilayaperumal Gopinathan,Kafka source module: Handling delete offsets
729,,Buelent Zeyben,"Based on the OOTB sqoop.xml definition on GitHub we are required to provide the jdbc.url, jdbc.username and jdbc.password as a parameter definition. 

{code}
	<bean id=""sqoopTasklet"" class=""org.springframework.xd.sqoop.SqoopTasklet"">
		<property name=""arguments"">
			<list>
				<value>${command}</value>
				<value>${args}</value>
				<value>jdbc.url=${url}</value>
				<value>jdbc.username=${username}</value>
				<value>jdbc.password=${password}</value>
				<value>fs.defaultFS=${fsUri}</value>
				...
{code}

This is causing a problem if we define the the sqoop connection parameters within the args list. We are using the --password-file option in the args list and need to specify the connection info via the --connect  option with the --username within the args list. 

Our Job definition is:

{code}
job create bdl_lookup --definition ""bdl-load --command=import --args='--connect=jdbc:oracle:thin:@<hostName>:1821/<dbName> --username=<user> --password-file=/user/workspace/secure-files/gdw.password --table=MASTERDATA.W_LOOKUP_D --target-dir=/<targetFolder/lookup_d -m 1' ""
{code}

This results to an deployment:

{code}
2015-05-07 11:40:51,586 1.2.0.M1  INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'bdl_lookup': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'sqoopTasklet' defined in class path resource [config/bdl-load.xml]: Could not resolve placeholder 'url' in string value ""jdbc.url=${url}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'url' in string value ""jdbc.url=${url}""
{code}

If we skip the jdbc connection info from the module.xml file, similar to:

{code}
	<bean id=""sqoopTasklet"" class=""org.springframework.xd.sqoop.SqoopTasklet"">
		<property name=""arguments"">
			<list>
				<value>${command}</value>
				<value>${args}</value>
				<!-- Comment out jdbc info
				<value>jdbc.url=${url}</value>
				<value>jdbc.username=${username}</value>
				<value>jdbc.password=${password}</value>
				-->
				<value>fs.defaultFS=${fsUri}</value>
				...
{code}

Custom module deploys fine but get a We get a NullPointerException in the container logs:

{code}
2015-05-07 11:46:04,450 1.2.0.M1 ERROR inbound.job:bdl_lookup-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step sqoopTask in job bdl_lookup
java.lang.NullPointerException
	at org.springframework.xd.sqoop.SqoopTasklet.createCommand(SqoopTasklet.java:91)
	at org.springframework.batch.step.tasklet.x.AbstractProcessBuilderTasklet.execute(AbstractProcessBuilderTasklet.java:107)
	at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:406)
	at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:330)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133)
	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271)
	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77)
{code}",XD-3034,Buelent Zeyben,Sqoop command should not require jdbc parameters
730,Mark Pollack,Mark Pollack,"Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS (Should check minor version number in BDS).  ATM we are using gemfire 7.0.x",XD-3033,Mark Pollack,Upgrade to Spring Data Fowler Release
731,Eric Bottard,Eric Bottard,"See discussion at https://github.com/spring-projects/spring-xd/pull/1537#issuecomment-99583179

This is likely a client error, so should be in the 4xx family. This requires customization of RestControllerAdvice",XD-3032,Eric Bottard,ModuleConfigurationException should not report HTTP 500
732,,Gary Russell,,XD-3031,Gary Russell,Document the RabbitMQ Bus Cleanup REST API
733,Gary Russell,Paul Harris,"As part of p-spring-xd testing we create, deploy, exercise, undeploy and destroy a RabbitMQ to RabbitMQ stream every minute. Spring XD does not appear to be deleting the queues it creates internally for each stream. We have seen as many as ~9800 xdbus queues (via the RabbitMQ web ui) before RabbitMQ runs out of memory and blocks.",XD-3030,Paul Harris,RabbitMQ queues not being removed on stream destroy
734,,Buelent Zeyben,"We have installed the SpringXD 1.2 M1 release via the rpm and it seems that the sqoop-1.4.5-hadoop200.jar file are not part of the rpm. The sqoop jar file are not in the xd/lib directory.

This is causing a problem during customer module development if we include the sqoop-1.4.5-hadoop200 dependency as part of the pom file and forces us to redeploy the our jar as separate deployment.

Should we be referencing different dependencies or have or should the sqoop-1.4.5-hadoop200.jar be part of the rpm definition so it part of the xd/lib?

I have currently the following dependency in the pom file:

{code}
		<!-- Sqoop -->
		<dependency>
			<groupId>org.apache.sqoop</groupId>
			<artifactId>sqoop</artifactId>
			<version>1.4.5</version>
			<classifier>hadoop200</classifier>
		</dependency>
{code}

It would be great be great if the sqoop jar are part of rpm so we don't have to do any additional jar deployment.

Thanks, ",XD-3029,Buelent Zeyben,SqoopRunner class not found errror 
735,,Paul Harris,"The typo 'properites' should be replaced with the correct 'properties' in the following places:

https://github.com/spring-projects/spring-xd/search?utf8=%E2%9C%93&q=properites",XD-3028,Paul Harris,5 occurrences of the typo 'properites' in comments/readme/doc
736,Gary Russell,Gary Russell,4.1.4 and 1.4.5 respectively.,XD-3027,Gary Russell,Update Spring Integration / Spring AMQP Versions
737,,Ilayaperumal Gopinathan,"As a spring developer, I can specify the default value for the module configs at the module config xml file and if no specific overriding options given the default value should get preferred.

Currently, I see that by design we want to rely on the default option values from the ModuleOption metadata. But, the cases where some module configurations can't have the default (say, customerKey for twitterstream module) and would be tempting to just try deploying after changing the twitterstream.xml with the default value expecting it to work.",XD-3026,Ilayaperumal Gopinathan,Support specifying the default values for the module at the module config
738,Thomas Risberg,Buelent Zeyben,"The SpringXD Sqoop module is in execution status until it times out, it is hanging. 

The container logs show:

2015-05-04 15:15:45,365 1.2.0.M1  INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'sqoop_lookup'
2015-05-04 15:15:45,536 1.2.0.M1  INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@239b037a moduleName = 'sqoop', moduleLabel = 'sqoop', group = 'sqoop_lookup', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map['args' -> '--connect=jdbc:oracle:thin:@************:****/******* —username=******** --password-file=/user/zeybeb/workspace/secure-files/gdw.password --table=MASTERDATA.W_LOOKUP_D --target-dir=/user/zeybeb/workspace/ent/masterdata_src/lookup_d -m 1', 'command' -> 'import'], children = list[[empty]]]
2015-05-04 15:16:17,061 1.2.0.M1  INFO inbound.job:sqoop_lookup-redis:queue-inbound-channel-adapter1 sqoop.SqoopTasklet - Sqoop system.out: /tmp/Sqoop-948322291323951735.out

The /tmp/Sqoop-948322291323951735.out file content is:

15:16:17,612  INFO main sqoop.SqoopRunner - Sqoop command: import
15:16:17,613  INFO main sqoop.SqoopRunner - Using args: [--connect=jdbc:oracle:thin:@************:****/*******, —username=*********, --password-file=/user/zeybeb/workspace/secure-files/gdw.password, --table=MASTERDATA.W_LOOKUP_D, --target-dir=/user/zeybeb/workspace/ent/masterdata_src/lookup_d, -m, 1]
15:16:17,613  INFO main sqoop.SqoopRunner - Mapreduce home: /opt/pivotal/spring-xd-1.2.0.M1/xd/lib/phd21
15:16:17,631  INFO main sqoop.SqoopRunner - Setting configuration property: fs.defaultFS=hdfs://ilabphd07.isus.emc.com:8020
15:16:17,753  INFO main sqoop.SqoopRunner - Setting configuration property: yarn.resourcemanager.address=ilabphd08.isus.emc.com:8050
15:16:17,753  INFO main sqoop.SqoopRunner - Setting configuration property: yarn.application.classpath=/usr/hdp/2.2.0.0-2041/etc/hadoop/conf.empty,/usr/hdp/2.2.0.0-2041/hadoop/*,/usr/hdp/2.2.0.0-2041/hadoop/lib/*,/usr/hdp/2.2.0.0-2041/hadoop-hdfs/*,/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*,/usr/hdp/2.2.0.0-2041/hadoop-yarn/*,/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*,/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/*,/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*,/usr/hdp/2.2.0.0-2041/sqoop/*,/usr/hdp/2.2.0.0-2041/sqoop/lib/*,/usr/hdp/2.2.0.0-2041/flume/*,/usr/hdp/2.2.0.0-2041/flume/lib/*,/usr/hdp/2.2.0.0-2041/storm/*,/usr/hdp/2.2.0.0-2041/storm/lib/*
15:16:17,754  INFO main sqoop.SqoopRunner - Setting configuration property: mapreduce.framework.name=yarn
15:16:17,837  WARN main tool.SqoopTool - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.
15:16:17,907  INFO main sqoop.Sqoop - Running Sqoop version: 1.4.5
15:16:18,282  WARN main util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15:16:19,552  WARN main sqoop.ConnFactory - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.
15:16:19,657  INFO main oracle.OraOopManagerFactory - Data Connector for Oracle and Hadoop is disabled.
15:16:19,673  INFO main manager.SqlManager - Using default fetchSize of 1000
15:16:19,673  INFO main tool.CodeGenTool - Beginning code generation
15:16:20,639  INFO main manager.OracleManager - Time zone has been set to GMT
15:16:20,853  INFO main manager.SqlManager - Executing SQL statement: SELECT t.* FROM MASTERDATA.W_LOOKUP_D t WHERE 1=0
15:16:21,018  INFO main orm.CompilationManager - HADOOP_MAPRED_HOME is /opt/pivotal/spring-xd-1.2.0.M1/xd/lib/phd21
15:16:23,171  INFO main orm.CompilationManager - Writing jar file: /tmp/sqoop-spring-xd/compile/4e11123a52fa36d6677efdb47bcdc43b/MASTERDATA.W_LOOKUP_D.jar
15:16:23,191  INFO main manager.OracleManager - Time zone has been set to GMT
15:16:24,109  INFO main manager.OracleManager - Time zone has been set to GMT
15:16:24,825  INFO main mapreduce.ImportJobBase - Beginning import of MASTERDATA.W_LOOKUP_D
15:16:24,848  INFO main manager.OracleManager - Time zone has been set to GMT
15:16:24,876  WARN main mapreduce.JobBase - SQOOP_HOME is unset. May not be able to find all job dependencies.
15:16:25,083  INFO main client.RMProxy - Connecting to ResourceManager at ilabphd08.isus.emc.com/10.15.232.191:8050
15:16:25,977  INFO main db.DBInputFormat - Using read commited transaction isolation
15:16:26,117  INFO main mapreduce.JobSubmitter - number of splits:1
15:16:26,361  INFO main mapreduce.JobSubmitter - Submitting tokens for job: job_1429280992648_0019
15:16:26,717  INFO main impl.YarnClientImpl - Submitted application application_1429280992648_0019 to ResourceManager at ilabphd08.isus.emc.com/10.15.232.191:8050
15:16:26,782  INFO main mapreduce.Job - The url to track the job: http://http://ilabphd08.isus.emc.com:8088/proxy/application_1429280992648_0019/
15:16:26,783  INFO main mapreduce.Job - Running job: job_1429280992648_0019

The logs on the Hadoop side are:

Showing 4096 bytes. Click here for full log
mumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:04,026 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:05,033 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:06,042 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:07,049 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:08,056 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:09,062 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:10,069 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:41,093 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:42,100 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:43,107 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:44,113 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:45,120 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:46,129 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:47,136 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:48,143 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:49,150 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-05-04 15:36:50,156 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)

Even though  the maxRetries is set to 10 the process is going into several sets of retrials. 

",XD-3025,Buelent Zeyben,SpringXD sqoop module is hanging
739,Eric Bottard,Sabby Anandan,"As a user, I'd like to have a REST-API to get all the _counters_, _gauges_, and _rich-gauges_ in a single request, so I don't have to issue multiple request to fetch each one of the metrics by name/id for custom dashboards.

*Example:*
{code}
/metrics/counters/all (fetches all available counters)
/metrics/gauges/all (fetches all available gauges)
/metrics/rich-gauges/all (fetches all available rich-gauges)
{code}",XD-3024,Sabby Anandan,"Add new REST-API to get all the counters, gauges, and rich-gauges"
740,Gary Russell,Gary Russell,,XD-3023,Gary Russell,SSL Config for RabbitMessageBus Connections is Ignored
741,Marius Bogoevici,Marius Bogoevici,"This is a combination of two issues:
- the internal property `next.module.concurrency` is computed from `concurrency` when it should be computed from `consumer.concurrency`
- even if `next.module.concurrency` is set, the KafkaMessageBus rejects it, since it's not set in SUPPORTED_CONSUMER_PROPERTIES

As a result, the value used in partition calculation is always 1.

A workaround exists, by setting the `module.[moduleName].producer.minPartitionCount` property to the expected total value. ",XD-3022,Marius Bogoevici,Kafka Message Bus ignores consumer concurrency when computing partition count
742,,Jason Hubbard,Update the current docker images to 1.1.0 Release,XD-3021,Jason Hubbard,Update Docker Versions
743,Ilayaperumal Gopinathan,Jason Hubbard,"As a user I would like the ability to undeploy or suspend a module without losing the deployment properties.  Currently when temporarily suspending a module an undeploy and redeploy is executed.  During the redeploy the deployment properties need to be added again.  Instead, it would be nice if the properties are persisted so they automatically included with the deployment.",XD-3020,Jason Hubbard,Persist Deployment Properties
744,Eric Bottard,Mark Pollack,"As a user, I'd like to refer to the documentation, so I can configure HDFS backed module registry (XD-2287) as recommended. ",XD-3019,Mark Pollack,Document how to use the module registry backed by HDFS
745,Thomas Risberg,Thomas Risberg,"We should update to use spring-data-hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there (syncable writes, timeout).

A few things to keep in mind:
- this updates Cloudera CDH to 5.3.3
- Kite version is now 1.0 - need to test the hdfs-dataset sink
",XD-3018,Thomas Risberg,Update to spring-data-hadoop 2.2.0.M1
746,Ilayaperumal Gopinathan,Gunnar Hillert,"See: 

https://sonar43.spring.io/drilldown/measures/7173?metric=package_tangle_index",XD-3017,Gunnar Hillert,Fix package tangles
747,Marius Bogoevici,Mark Pollack,"For example, how to specify the partition count for topics that are created by the message bus.",XD-3016,Mark Pollack,Document Kafka message bus properties
748,David Turanski,David Turanski,"This error surfaced recently as a result of a fix to a bug in HostNotWindowsRule which disabled this test in all environments. Now the test has been reactivated it is failing on the 1.1.x branch.  The test runs OK on master.
{noformat}
Encountered an error executing step step1-master in job job
org.springframework.messaging.MessageDeliveryException: failed to send Message to channel 'null'; nested exception is java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:292)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.xd.dirt.integration.bus.local.LocalMessageBus$3.handleMessage(LocalMessageBus.java:262)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:85)
	at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:224)
	at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:161)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)
	at org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
Caused by: java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized
	at org.springframework.util.Assert.state(Assert.java:385)
	at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.getThreadPoolExecutor(ThreadPoolTaskExecutor.java:221)
	at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.execute(ThreadPoolTaskExecutor.java:252)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:89)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	... 76 more

java.lang.AssertionError: 
Expected :exitCode=COMPLETED;exitDescription=
Actual   :exitCode=FAILED;exitDescription=
   <Click to see difference>


	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:162)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)
	at org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
{noformat}",XD-3015,David Turanski,RemoteFileToHadoopTests fails on 1.1.x
749,Thomas Risberg,Thomas Risberg,,XD-3014,Thomas Risberg,Add documentation for connecting to HDFS with HA Namenode
750,Eric Bottard,Eric Bottard,"The file and ftp sources allow working with either the java.io.File or its contents.
For consistency, the sftp source should support the same mechanism.
",XD-3013,Eric Bottard,Support --ref=true/false for sftp source
751,,Dave,"I am using SpringXD to ingest tweets to a gemfire-json-server sink.

I am running into an issue where the json documents get defined as a pdx type twice.  See the reweet_count field below.  This causes problems later when using OQL to access this data.  Incompatible types.  What are the recommended ways to resolve this?  The field type should account for the largest possible value, which is unknown because it is twitter.  This would likely be a int or long.

I was asked to log this as a SXD JIRA issue, but I am not sure if the problem is in SXD or GemFire.

 
[info 2015/04/25 06:51:28.767 CST  <twitterSource-1-1> tid=0x53] Defining: PdxType[
     dsid=0typenum=1, name=__GEMFIRE_JSON, fields=[
         id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1
         from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1
         created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2
         text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3
         language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4       retweet_count:short:5:4:idx0(relativeOffset)=-3:idx1(vlfOffsetIndex)=-1
         retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]]

 
[info 2015/04/25 06:51:29.307 CST  <twitterSource-1-1> tid=0x53] Defining: PdxType[

     dsid=0typenum=2, name=__GEMFIRE_JSON, fields=[
       id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1
       from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1
       created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2
       text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3
       language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4
       retweet_count:byte:5:4:idx0(relativeOffset)=-2:idx1(vlfOffsetIndex)=-1
       retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]]",XD-3012,Dave, gemfire-json-server multiple PdxTypes Types
752,,Glenn Renfro,"Commit: 433d18f03fd7f3bf7d9aeee80ab292f9c92af5a4
Transport: Rabbit
1 Admin
2 Containers
Admin Log is attached. (Exception is at line 52)
During Acceptance Tests for  testJobCreateDuplicateWithDeployFalse failed with the following error reported from the admin.

{noformat}  org.springframework.xd.rest.client.impl.SpringXDException(KeeperErrorCode = NoNode for /xd/jobs/jobFalseDeploy
)
	at org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:67)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{noformat}",XD-3011,Glenn Renfro,Job failed to deploy (Sporadic)
753,,Karol Dowbecki,"Consider this simple stream which works out of the box because {{transform.groovy}} is shipped with Spring XD:
{code}
stream create --name ""stream1"" --definition ""time | script --script='transform.groovy' | log"" --deploy
{code}

Composing {{time}} and {{script}} modules like that

{code}
module compose --name ""cmp-time"" --definition ""time | script --script='transform.groovy'""
stream create --name ""stream2"" --definition ""cmp-time | log"" --deploy
{code}

will throw following exception in xd-shell:

{code}
Apr 29, 2015 11:28:57 AM org.springframework.shell.core.AbstractShell handleExecutionResult
INFO: Successfully created module 'cmp-time' with type source
Apr 29, 2015 11:28:57 AM org.springframework.shell.core.SimpleExecutionStrategy invoke
SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module cmp-time of type source:
    valid: 'script' cannot be null or empty
{code}

and following exception in xd-container:

{code}
2015-04-29 11:28:57,263 1.1.1.RELEASE ERROR qtp616131272-35 rest.RestControllerAdvice - Caught exception while handling a request
org.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module cmp-time of type source:
    valid: 'script' cannot be null or empty
	at org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:180)
	at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:235)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:755)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
	at org.eclipse.jetty.server.Server.handle(Server.java:370)
	at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)
	at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)
	at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)
	at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors
Field error in object 'target' on field 'valid': rejected value [false]; codes [AssertTrue.target.valid,AssertTrue.valid,AssertTrue.boolean,AssertTrue]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.valid,valid]; arguments []; default message [valid]]; default message ['script' cannot be null or empty]
	at org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)
	at org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)
	at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:167)
	at org.springframework.xd.module.options.HierarchicalCompositeModuleOptionsMetadata.interpolate(HierarchicalCompositeModuleOptionsMetadata.java:105)
	at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:167)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:177)
	... 61 more
{code}",XD-3010,Karol Dowbecki,Can't compose script processor
754,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the kafka message headers are expected to be set with acknowledgement flags to manually acknowledge the messages at the consumer side, the message headers are missing.",XD-3009,Ilayaperumal Gopinathan,Manual acknowledgement with Kafka bus doesn't work
755,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When security is enabled, the VersionController REST endpoint isn't visible.",XD-3008,Ilayaperumal Gopinathan,Version info not available when security enabled
756,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the container doesn't have any modules deployed, the jolokia response returns stacktrace with ""NoInstanceFoundException"". This exception is thrown at the admin log as:

2015-04-28 13:09:35,952 1.2.0.SNAP  WARN qtp1648225666-27 rest.ContainersController - Error getting message rate metrics for 713255e5-49b2-4158-b69c-2d203cfe50d3
org.codehaus.jettison.json.JSONException: JSONObject[""value""] not found.
	at org.codehaus.jettison.json.JSONObject.get(JSONObject.java:360)
	at org.codehaus.jettison.json.JSONObject.getJSONObject(JSONObject.java:454)
	at org.springframework.xd.dirt.rest.ContainersController.setMessageRates(ContainersController.java:134)
	at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:735)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
	at org.eclipse.jetty.server.Server.handle(Server.java:370)
	at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)
	at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)
	at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)
	at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
	at java.lang.Thread.run(Thread.java:745)",XD-3007,Ilayaperumal Gopinathan,Message rate collection throws warning level exception
757,,Jared Monast,"Created a single definition Sqoop Job --create statement. When processed through Sqoop direct (see attach image for props in repos. jobname sqoop2) 

Notice: job definition set db.require.password = false and has a propname called db.password that holds the value for password. 

When same definition is created as a batch job via Spring-XD (see image jobname lookupd_job), the db.require.password prop is set to ""TRUE"" and the db.password is not even created as a row.

This causes a password prompt when trying to execute the job in Sqoop direct, that was created via a spring-XD batch job. 

Note the job definition for Spring-XD job contains meta-connect with username and password defined as well as import jdbc: --connect username and password. When created via Sqoop (no Spring-XD) password is stored and job is able to execute with no prompt.

Please see attachment for repository job values. Highlighted in yellow is the discrepant property and value attribution. Please reach out if there are questions or need further details.

To automate Spring-XD batch job using Sqoop via Spring we can not be prompted for password.

Spring-XD Job definition:
job create sqoop_lookup_d_job_v1 --definition ""sqoop --command=job  --args='--create lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx\"" -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query \""SELECT ROW_WID, LKUP_ID, TRIM(TRANSLATE(LKUP_CD, CHR(10)||CHR(13), ''-'')) AS LKUP_CD, TRIM(TRANSLATE(LKUP_DESC, CHR(10)||CHR(13), ''-'')) AS LKUP_DESC, TRIM(TRANSLATE(LKUP_TYPE, CHR(10)||CHR(13), ''-'')) AS LKUP_TYPE, TRIM(TRANSLATE(LKUP_VAL, CHR(10)||CHR(13), ''-'')) AS LKUP_VAL, SRC_STRT_DT, SRC_END_DT, W_INSERT_DT, W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND $CONDITIONS\"" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by \""|\"" --append'""

Sqoop Direct Definition:
sqoop job --create sqoop2 --meta-connect 'jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx' -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query ""SELECT ROW_WID, LKUP_ID, TRIM(TRANSLATE(LKUP_CD, CHR(10)||CHR(13), '-')) AS LKUP_CD, TRIM(TRANSLATE(LKUP_DESC, CHR(10)||CHR(13), '-')) AS LKUP_DESC, TRIM(TRANSLATE(LKUP_TYPE, CHR(10)||CHR(13), '-')) AS LKUP_TYPE, TRIM(TRANSLATE(LKUP_VAL, CHR(10)||CHR(13), '-')) AS LKUP_VAL, SRC_STRT_DT, SRC_END_DT, W_INSERT_DT, W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND \$CONDITIONS "" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by '|' --append
",XD-3006,Jared Monast,db.password not being passed when Sqoop job --create called from Spring-XD Batch job
758,,Karol Dowbecki,"On multiple occasions we have seen that {{spring-xd-container}} and {{spring-xd-admin}} services can exit reporting {{FAILED}} state, however most of the times the Java process is correctly terminated.

{code}
$ sudo service spring-xd-container stop
Stopping xd-container:                                     [FAILED]
$ ps uax | grep [x]d-container
$
{code}

and in the container logs:

{code}
[info 2015/04/28 09:42:15.167 EDT  <Distributed system shutdown hook> tid=0x88] VM is exiting - shutting down distributed system

[info 2015/04/28 09:42:15.168 EDT  <Distributed system shutdown hook> tid=0x88] GemFireCache[id = 2029162775; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:34 EDT 2015; se

[info 2015/04/28 09:42:15.171 EDT  <Distributed system shutdown hook> tid=0x53] VM is exiting - shutting down distributed system

[info 2015/04/28 09:42:15.171 EDT  <Distributed system shutdown hook> tid=0x53] GemFireCache[id = 389249684; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:14 EDT 2015; ser

[info 2015/04/28 09:42:15.177 EDT  <Distributed system shutdown hook> tid=0x77] VM is exiting - shutting down distributed system

[info 2015/04/28 09:42:15.179 EDT  <Distributed system shutdown hook> tid=0x77] GemFireCache[id = 1768828050; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:27 EDT 2015; se

[info 2015/04/28 09:42:15.181 EDT <Distributed system shutdown hook> tid=0x63] VM is exiting - shutting down distributed system

[info 2015/04/28 09:42:15.199 EDT <Distributed system shutdown hook> tid=0x63] GemFireCache[id = 548938309; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:19 EDT 2015; serv
2015-04-28 09:42:15,410 1.1.1.RELEASE DEBUG xdbus.queue:radius-1 transform.RadiusMsgTransformer - Transformed message: GenericMessage [payload=FACILITY=22, SEVERITY=5, TIMESTAMP=Tue Apr 28 09:42:15 EDT 2015, HOST=hopisepsnprd01, Messa

[info 2015/04/28 09:42:15.626 EDT  <Distributed system shutdown hook> tid=0x53] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen

[info 2015/04/28 09:42:15.630 EDT  <Distributed system shutdown hook> tid=0x77] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen

[info 2015/04/28 09:42:15.621 EDT  <Distributed system shutdown hook> tid=0x88] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen

[info 2015/04/28 09:42:15.662 EDT <Distributed system shutdown hook> tid=0x63] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen
2015-04-28 09:42:15,854 1.1.1.RELEASE  WARN Thread-4 support.DisposableBeanAdapter - Invocation of destroy method failed on bean with name 'client-pool': java.lang.IllegalStateException: Pool could not be destroyed because it is still

[config 2015/04/28 09:42:15.857 EDT <Thread-4> tid=0x12] Destroying connection pool client-pool

[config 2015/04/28 09:42:15.897 EDT  <Thread-4> tid=0x12] Destroying connection pool client-pool

[config 2015/04/28 09:42:15.898 EDT  <Distributed system shutdown hook> tid=0x53] Destroying connection pool client-pool

[config 2015/04/28 09:42:15.908 EDT  <Distributed system shutdown hook> tid=0x88] Destroying connection pool client-pool
{code}",XD-3005,Karol Dowbecki,spring-xd services randomly report failure after correct shutdown
759,Eric Bottard,Eric Bottard,"The call to /modules?detailed=true that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there (and no caching takes place)",XD-3004,Eric Bottard,Detailed module list performance improvement
760,Thomas Risberg,Sabby Anandan,"As a user, I'd like to have the option to change the default Sqoop _metastore_, so I can implement a DB of my choice and not tied to default specifications.

Refer to this [thread|http://stackoverflow.com/questions/24078668/how-to-change-sqoop-metastore] for more details. ",XD-3003,Sabby Anandan,Add support for using Sqoop metastore
761,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the module options provided for Spark streaming processor/sink modules use the same DefaultSparkStreamingModuleOptionsMetadata. Since we start adding new module options for processor/sink specific modules, it would be better if we expose specific ModuleOption classes so that would help the implementing developers.",XD-3002,Ilayaperumal Gopinathan,Support Spark streaming processor/sink specific module options
762,Thomas Risberg,Jared Monast,"Running a (SQOOP Job --create) from within (Spring-XD JOB create) statement runs successfully.Unable to run the (Sqoop Job --exec) from within (Spring-XD Job)

CREATE DEFINITION:
job create sqoop_lookup_d_job_v1 --definition ""sqoop --command=job  --args='--create lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx\"" -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query \""SELECT ROW_WID, LKUP_ID, TRIM(TRANSLATE(LKUP_CD, CHR(10)||CHR(13), ''-'')) AS LKUP_CD, TRIM(TRANSLATE(LKUP_DESC, CHR(10)||CHR(13), ''-'')) AS LKUP_DESC, TRIM(TRANSLATE(LKUP_TYPE, CHR(10)||CHR(13), ''-'')) AS LKUP_TYPE, TRIM(TRANSLATE(LKUP_VAL, CHR(10)||CHR(13), ''-'')) AS LKUP_VAL, SRC_STRT_DT, SRC_END_DT, W_INSERT_DT, W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND $CONDITIONS\"" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by \""|\"" --append'""

Validated job definition details stored in PostgreSQL repository

Trying to run EXECUTE In Same fashion.

EXECUTION DEFINITION:
job create sqoop_lookup_d_exec_v1 --definition ""sqoop --command=job --args='--exec lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxx\""'""


Stack Trace:
batch.stepType	org.springframework.batch.core.step.tasklet.TaskletStep
batch.taskletType	org.springframework.xd.sqoop.SqoopTasklet
sqoop.command	job --exec lookupd_job --meta-connect ""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxxx&password=xxxxxxx"" -- exec
sqoop.errors	No job operation specified
Try --help for usage instructions.
Exception in thread ""main"" java.lang.RuntimeException: Sqoop failed - return code 1
at org.springframework.xd.sqoop.SqoopRunner.main(SqoopRunner.java:81)
sqoop.log	16:01:45,668 INFO main sqoop.SqoopRunner - Sqoop command: job
16:01:45,668 INFO main sqoop.SqoopRunner - Using args: [--exec, lookupd_job, --meta-connect, ""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxxxx&password=xxxxx""]
16:01:45,668 INFO main sqoop.SqoopRunner - Mapreduce home: /opt/pivotal/spring-xd-1.1.1.RELEASE/xd/lib/phd21
16:01:45,679 INFO main sqoop.SqoopRunner - Setting configuration property: fs.defaultFS=hdfs://xxxxxxxxxxxxx.com:8020
16:01:45,759 INFO main sqoop.SqoopRunner - Setting configuration property: yarn.resourcemanager.address=xxxxxxxxxxxx.com:8032
16:01:45,759 INFO main sqoop.SqoopRunner - Setting configuration property: yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$USS_HOME/*,$USS_CONF
16:01:45,759 INFO main sqoop.SqoopRunner - Setting configuration property: mapreduce.framework.name=yarn
16:01:45,817 WARN main tool.SqoopTool - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.
16:01:45,863 INFO main sqoop.Sqoop - Running Sqoop version: 1.4.5

I have tested --list, --exec,--delete they are all erroring same way. Looking at SqoopRunner not sure what makes --create any different from other saved-job functionality.

Please let me know how i can call or execute save job definition's through spring-xd Sqoop tasklet
",XD-3001,Jared Monast,Unable to call Sqoop Job commands other than --create from within Spring-Xd Job
763,David Turanski,David Turanski,Profile TupleCodec and implement performance optimizations,XD-3000,Sabby Anandan,Enhance TupleCodec performance
764,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to benchmark a stream with and without {{JMX}} enabled, so I can test in isolation, and document the differences in performance.",XD-2999,Sabby Anandan,Benchmark with and without JMX activated
765,David Turanski,Sabby Anandan,"As a developer, I'd like to handle the non-default {{ConfigurableConversionService}} tuples in an uniform manner, so they're not reset after deserialization. ",XD-2998,Sabby Anandan,TupleCode should retain custom formatting settings
766,,Sabby Anandan,"As a developer, I'd like to design and document the approach towards deploying stream in a single container, so I can have all modules within a stream colocated. 
",XD-2997,Sabby Anandan,Deploy stream in a single xd-container
767,Marius Bogoevici,Marius Bogoevici,"As a developer, I want that the Spring XD partitioning process targets Kafka bus partitions directly, so that the design of my stream processing application is easier to understand and the order of messages is not altered

Current situation
- Spring XD partitioning logic that builds on top of Kafka partitioning;
- The number of Spring XD partitions is not explicitly configured (it's inferred from the number of consumer modules)
- If the concurrency of the consumer modules is 1, then Spring XD partitions are matched 1:1 with Kafka partitions;
-  If the concurrency of the consumer modules is n, then a Spring XD partition uses n Kafka partitions, and the message bus distributes messages across the Kafka partitions that correspond to the Spring XD partitions;
- this could be confusing to the end user, especially if they are used to the Kafka partitioning process;
- this can also lead to changes of ordering between messages, as messages within the same Spring XD partitions will be sent to different Kafka partitions (this only happens if the concurrency of the receiving module is higher than 1)

Improvement:
- *For the Kafka message bus* the number of Spring XD partitions does not need to be equal to the number of modules (must be higher or equal, though, so that consumers can be created), and should be configured explicitly - using the `partitionCount` property - (as an option, the module count * concurrency can be used as a default)
 - as a result, in the case of Kafka there will always be a 1:1 match between Kafka partitions and Spring XD partitions, optionally processed by fewer modules than the partition count;",XD-2996,Marius Bogoevici,Align Spring XD partitioning with Kafka partitioning for the Kafka message bus
768,Ilayaperumal Gopinathan,Glenn Renfro,"Error Started:
Commit: 7087dc67e058edd6cbb1630ebd95b52e2c7e21e1 
https://github.com/spring-projects/spring-xd/pull/1564

This can be reproduced by running the test with a admin and single container on Mac OSX.

Issue All Jobs fail to deploy with the following exception:
{noformat}
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
1.2.0.BUILD-SNAPSHOT             eXtreme Data


Started : AdminServerApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki

2015-04-27 09:08:51,082 1.2.0.SNAP  WARN main config.IntegrationRegistrar - The '#jsonPath' SpEL function cannot be registered. The version of json-path found on the classpath is not supported. Supported json-path version is '0.9.1'. Upgrade to Spring Integration 4.2 or later to use json-path 1.0 or later.
2015-04-27 09:09:02,767 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd
2015-04-27 09:09:02,768 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: redis
2015-04-27 09:09:02,768 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop26
2015-04-27 09:09:02,771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath 2.6.0
2015-04-27 09:09:02,771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd/config//
2015-04-27 09:09:02,771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
2015-04-27 09:09:02,772 1.2.0.SNAP  INFO LeaderSelector-0 zk.DeploymentSupervisor - Leader Admin 172.31.99.83:9393 is watching for stream/job deployment requests.
2015-04-27 09:09:02,773 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd/config//modules/
2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Glenns-MacBook-Pro.local:9393/admin-ui
2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:2181
2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
2015-04-27 09:09:02,776 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: redis
2015-04-27 09:09:02,813 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Path cache event: type=INITIALIZED
2015-04-27 09:09:02,845 1.2.0.SNAP  INFO main admin.AdminServerApplication - Started AdminServerApplication in 6.777 seconds (JVM running for 14.213)
2015-04-27 09:09:04,010 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Path cache event: path=/containers/dc7692b1-979b-4fa3-a11a-3f35cdedc319, type=CHILD_ADDED
2015-04-27 09:09:04,017 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Container arrived: Container{name='dc7692b1-979b-4fa3-a11a-3f35cdedc319', attributes={groups=, host=Glenns-MacBook-Pro.local, id=dc7692b1-979b-4fa3-a11a-3f35cdedc319, managementPort=9395, ip=172.31.99.83, pid=99669}}
2015-04-27 09:09:04,018 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Scheduling deployments to new container(s) in 15000 ms
2015-04-27 09:10:35,003 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'tfphj4ffb45d5-0d6c-4f22-b407-c313ce82b449': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'objectNameProperties' defined in null: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""
	at org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:211)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.processProperties(PropertySourcesPlaceholderConfigurer.java:180)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.postProcessBeanFactory(PropertySourcesPlaceholderConfigurer.java:155)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:162)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:606)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:462)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365)
	at org.springframework.xd.dirt.server.container.DeploymentListener.deployJobModule(DeploymentListener.java:291)
	at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)
	at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:174)
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126)
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:204)
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:178)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer$2.resolveStringValue(PropertySourcesPlaceholderConfigurer.java:175)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveStringValue(BeanDefinitionVisitor.java:282)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:204)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitMap(BeanDefinitionVisitor.java:262)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:198)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitPropertyValues(BeanDefinitionVisitor.java:141)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:82)
	at org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:208)
	... 31 more
}
{noformat}",XD-2995,Glenn Renfro,Jobs are failing to be deployed
769,Glenn Renfro,Glenn Renfro,"This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings.
load-generator should be used as the foundation for this test with the following settings:
module.load-generator.count=10,module.throughput.consumer.concurrency=10

An environment should be provisioned to support the containers, Zookeeper and Kafka.
",XD-2994,Glenn Renfro,Verify module count works on 10+ Containers
770,Eric Bottard,Sabby Anandan,"As a Flo developer, I'd like to have a new DSL parser, so I can easily  detect incorrect module/option values when supplied from the Flo UI.

Example:
MyStream = mail | log
tap:stream:MyStream.bar > log

If parsed separately (which Flo UI does), the current parser endpoint will barf on the second stream because it doesn’t know about the first stream (MyStream). ",XD-2993,Sabby Anandan,Add a new variation of DSL parser for Flo
771,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to consume multiple topic-partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.",XD-2992,Sabby Anandan,Add support for multiple topics in Kafka source
772,,Sabby Anandan,"As a developer, I’d like override the partition function within my source or processor module, so I can send the data to a specific partition.",XD-2991,Sabby Anandan,Add support to override partition function
773,,Sabby Anandan,"As a user, I'd like to have the option of reliable HDFS writes (for stream pipelines), so I can get acknowledgement of actual HDFS _commits_ as opposed to just from the message bus.",XD-2990,Sabby Anandan,Spike: Research the stream support for reliable HDFS writes
774,,Aaron Loes,"SpringXD seems to think that a module exists if there is a module configuration present. There is also an issue of having to restart the node when theres been a problem with uploading/removing a module.

When using SpringXD in single node on windows, i uploaded a custom module and then added a folder and property file for it in the module configuration directory as specified in the documentation. When i went to delete the module using the command in the SpringXD admin console, it would say that it was successfull, but when then listing the modules, it would still be listed. If i tried to upload a new version of that same module, i would get an error stating that module already existed with the same name. I would check the custom modules directory and my jar would not be there. I would then have to manually delete the module configuration directory and restart SpringXD before being able to upload a new module, having to replace my module configuration each time.

Seems like there are three things wrong here:
* should the presence of a module configuration alone inform SpringXD of a modules existence?
* should one have to delete a module configuration before uploading a new version of the module?
* when getting module deletion/upload errors, should one have to restart spring xd node to get it to allow the upload again?",XD-2988,Aaron Loes,Issues with custom modules when using module configuration
775,Glenn Renfro,Glenn Renfro,the update to the JMX was introduced in XD-2941.   Also noticed that we should have been checking source and not sink .  This was also resolved.,XD-2987,Glenn Renfro,Update acceptance test to use new JMX Module name format
776,Patrick Peralta,Sabby Anandan,"As a follow up to XD-2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed.

Branch is here: https://github.com/pperalta/spring-xd/tree/deploy-refactor-2",XD-2986,Sabby Anandan,Experiment with re-parsing of streams when needed
777,,Glenn Renfro,,XD-2985,Glenn Renfro,Update spring-data-hadoop to version 2.1.2.RELEASE
778,Ilayaperumal Gopinathan,Thomas Risberg,"XD-2837 added back the --hadoopDistro option for xd-admin scripts. However, if I try to use it I get an error message saying: ""--hadoopDistro"" is not a valid option
",XD-2984,Thomas Risberg,xd-admin script fails when providing --hadoopDistro option
779,Ilayaperumal Gopinathan,Jason Hubbard,"With message rates enabled and container management enabled, if you deploy a streaming module, the container page may be blank.  Because the streaming module builds the channels outside the spring context (spark receiver is ran in the spark cluster not in xd) there is no need to setup the input and/or output channels.  When these channels aren't defined the rest call from admin UI will fail because it will not find the message rates returned in the JSON from the JMX call.

{code}
Advice - Caught exception while handling a request
org.codehaus.jettison.json.JSONException: JSONObject[""value""] not found.
        at org.codehaus.jettison.json.JSONObject.get(JSONObject.java:360)
        at org.codehaus.jettison.json.JSONObject.getJSONObject(JSONObject.java:454)
        at org.springframework.xd.dirt.rest.ContainersController.getMessageRate(ContainersController.java:146)
        at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:121)
{code}

As a work around, I have included the input and output channels for a spark streaming processor which is not used anywhere.  This gives a bad side affect of looking like the module isn't processing with message rates of 0, but everything else is now shown.",XD-2983,Jason Hubbard,Blank Container Screen from Admin UI w/ message rates
780,,David Turanski,"see http://stackoverflow.com/questions/29822845/custom-python-module-can-not-re-excute-when-raise-exception-in-module

",XD-2982,David Turanski,Shell processor cannot recover from an Exception
781,,Aaron Loes,"i've created a source module for polling a twitter timeline using the spring integration twitter inbound adapter. I've placed my api keys in the modules.yml file and verified that they are picked up by the twitterstream and twitterseach modules that come with SpringXD. However, they are not picked up by my custom module. I viewed the source for both the stream and and the search and i feel my project is near identical in configuration. Am i missing something or are these properties somehow special for just the two twitter sources that come with SpringXD?

I'd like to get this working and commit it to the project.",XD-2981,Aaron Loes,Add polling twitter source 
782,Mark Fisher,Sabby Anandan,"As a user, I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments, so I can run XD without _xd-containers_.

Scope:
* Complete the remaining deployment properties work",XD-2980,Sabby Anandan,Create Boot based ModuleRunner (phase 2)
783,Mark Fisher,Sabby Anandan,"As a user, I'd like to use the Java receptor client, so I can interact with Diego runtime using the Java receptor REST APIs.",XD-2979,Sabby Anandan,Submit java receptor client for CF incubation
784,,Sabby Anandan,,XD-2978,Sabby Anandan,"Features, issues and enhancements to support XD on Diego"
785,,Altan Gokcek,"When i create following stream i am able to route json messages. But if i send same message as an array its not working. Is it possible to do something about it?

stream create --name reference-data-import --definition ""rabbit --outputType=text/plain | router --expression=#jsonPath(payload,'$.REJECTED').contains('true')?'queue:Rejected':'queue:Accepted'"" --deploy

",XD-2977,Altan Gokcek,Routing json arrays
786,,W.H.,"Currently, each HTTP stream channel uses its own port, which is a limitation if we want to use large numbers of HTTP streams with fine granularity. It would be nice to (additionally) use URI paths to identify HTTP channels, allowing to re-use a single HTTP port for multiple channels in XD.

Example usage:

stream create --name s1 --definition ""http --port=9495 --path=/foo  | log"" --deploy

For a PoC implementation, see: https://github.com/spring-projects/spring-xd/pull/1538",XD-2976,W.H.,"Allow ""--path=..."" configuration in HTTP channel adapter"
787,,Ilayaperumal Gopinathan,"For some reason, the message bus is bound to incorrect transport (different from what is set as XD_TRANSPORT) at runtime.

This is from the container log:
2015-04-21 13:42:12,331 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: rabbit
...
2015-04-21 13:42:35,144 1.2.0.SNAP  INFO RedisMessageListenerContainer-4 sink.a2 - test",XD-2975,Ilayaperumal Gopinathan,Incorrect message bus is used at runtime
788,,ankushji,"In Hadoop, while creating Table in hive i am getting stuck in below error

15/04/21 12:35:34 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/04/21 12:35:34 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/04/21 12:35:34 INFO log.PerfLogger: <PERFLOG method=acquireReadWriteLocks from=org.apache.hadoop.hive.ql.Driver>
15/04/21 12:35:34 INFO lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
15/04/21 12:35:34 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=dkhc3013.dcsg.com:2181,dkhc3010.dcsg.com:2181,dkhc3011.dcsg.com:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@5b9e1cd4
15/04/21 12:35:34 DEBUG lockmgr.DummyTxnManager: Adding /incoming/mkt/gcdb.etl_master_account_pref to list of lock inputs
15/04/21 12:35:34 DEBUG lockmgr.DummyTxnManager: Adding database:mkt_incoming to list of lock outputs


After restart the zookeeper service i am able to successfully run the query,

But after some time again facing the same issue/error, I am stuck on the same error.

is there any solution to overcome this issue, or any tuning i can do for resolve this issue.

Please suggest on this.",XD-2974,ankushji,Getting stuck on hive error.
789,,Sabby Anandan,"As a user, I'd like to run the sqoop jobs against secured hdfs cluster, so I can restrict access to only authorized users. ",XD-2973,Sabby Anandan,Run the sqoop job against secured cluster
790,Gunnar Hillert,Gunnar Hillert,"Cannot import Spring XD into STS without compilation errors in class:

*org.springframework.xd.dirt.rest.ModulesController#list*

Error is in:

{code}
return assembler.toResource(page, detailed ? detailedAssembler: simpleAssembler);
{code}

{code}
The method toResource(Page<ModuleDefinition>, Link) in the type PagedResourcesAssembler<ModuleDefinition> is not applicable for the arguments (Page<ModuleDefinition>, (detailed ? detailedAssembler : simpleAssembler))
{code}

Seems to be an STS specific issue.",XD-2972,Gunnar Hillert,STS - Spring XD Imported with Compilation Error
791,Eric Bottard,Sabby Anandan,"As a user, I'd like to refer to the documentation to configure the properties file, so I can use it as recommended to represent the deployment manifest.",XD-2971,Sabby Anandan,Document the use of properties file as deployment manifest
792,David Turanski,David Turanski,"In XD today we use  commons-logging or slf4j  APIs bound to log4j at runtime (configured with log4j.properties).  

Boot uses slf4j APIs backed by logback. This causes some build incompatibilities building a component that depends on spring-xd-dirt and spring-boot, requiring specific dependency exclusions.  In order to simplify building and troubleshooting log dependencies, XD should standardize on 
slf4j APIs (replace any commons-logging Loggers with Slf4j). This is internal only, and would not impact users who are used to seeing log4j.properties. An additional step is to replace log4j with logback. This change would be visible to end users but will provide us greater affinity with boot and improve the developer experience. If we make this change it should go into 1.2 GA.

",XD-2970,David Turanski,Standardize XD logging to align with Spring Boot
793,Gary Russell,Sabby Anandan,"As a developer, I'd like to have the option of CoAP source module, so I can consume data using bandwidth efficient protocol that fits in constrained embedded environment.",XD-2969,Sabby Anandan,Add a CoAP source module
794,,Eric Bottard,,XD-2968,Eric Bottard,InfluxDB as an analytics backend
795,,Sabby Anandan,"As a developer, I'd like to add support to _flush_ state intelligently, so I can reliably process streams based on successful message acknowledgements from the module-producer. ",XD-2967,Sabby Anandan,Add support to flush local state
796,,Sabby Anandan,"As a developer, I'd like to add support to _flush_ offsets intelligently, so I can reliably process streams based on successful message acknowledgements from the module-producer. ",XD-2966,Sabby Anandan,Add support to flush offset management 
797,,Sabby Anandan,"As a developer, I'd like to integrate with Spring Data repository that's backed by Kafka _changelog_, so I can leverage the benefits of local data affinity (off-heap) in order to run stateful stream processing logic. ",XD-2965,Sabby Anandan,Integrate with Spring Data repository
798,,Sabby Anandan,"As a developer, I'd like to study the state management requirements, so I can brainstorm and identify the design to natively add _stateful_ stream processing support in XD. ",XD-2964,Sabby Anandan,Spike: Come up with a design for stateful stream processing
799,,Sabby Anandan,,XD-2963,Sabby Anandan,Add support for stateful stream processing
800,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to document performance benchmark results along with the infrastructure specifics, so I can publish the blog for customers/users to use it as a reference while setting up Spring XD cluster.",XD-2962,Sabby Anandan,Document performance benchmark results
801,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to rerun _baseline_, _Tuple_, and _Serialized_ payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. 

Note:
1.1.1 > Benched against 0.8.1 
1.2 > Benched against 0.8.2 

",XD-2961,Sabby Anandan,Benchmark against Kafka 0.8.2 release
802,,Sabby Anandan,"As a developer, I'd like to create a new _load-generator_, so I can use it to measure highly optimized (kryo serialized) payload to measure the performance differences. ",XD-2960,Sabby Anandan,Add a new load generator to produce serialized payloads
803,,Sabby Anandan,"As a developer, I'd like to create a Tuple _load-generator_, so I can use it to measure {{Tuple}} based payload performance. ",XD-2959,Sabby Anandan,Create a new load-generator for Tuple
804,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features in order to test the performance characteristics.",XD-2958,Sabby Anandan,Upgrade to Kafka 0.8.2
805,David Turanski,Sabby Anandan,"As a developer, I'd like to document the Kryo optimization guidelines, so the end-users can refer to it while tuning to improve performance.",XD-2957,Sabby Anandan,Create samples and document Kryo optimization guidelines
806,David Turanski,Sabby Anandan,"As a developer, I'd like revisit the design to determine the necessity for _ID_ and _TimeStamp_ attributes in {{Tuple}}, so I can refactor in order to improve performance throughput.",XD-2956,Sabby Anandan,Revisit the requirement for ID and Timestamp attributes in Tuple
807,David Turanski,Sabby Anandan,"As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized.
",XD-2955,Sabby Anandan,Refactor MessageBus to avoid unnecessary use of MessageBuilder  
808,,Sabby Anandan,,XD-2954,Sabby Anandan,"Effort to accommodate refactoring, tuning and tweaking to improve performance characteristics"
809,Eric Bottard,Eric Bottard,"Code that is in there could be moved to the SparkStreamingModule.

Then, as part of a later refactoring, that plugin should be made part of the module (and loaded by the module classloader)",XD-2953,Eric Bottard,Get rid of SparkStreamingDriverModule
810,,Muhammad Ali,"As as user I want to be able to escape delimiter character. Currently I cannot use this job oob to create CSVs that are usable in Hive/HAWQ because of unescaped delimiters.

",XD-2952,Muhammad Ali,Escape delimited characters in jdbchdfs job
811,Eric Bottard,Eric Bottard,"As the decision for directBinding may become more complicated (see eg XD-2946), move the *decision* part out of the bus, leaving only the *application* there (leveraging a pre-computed property, such as directBind=true).

The computation of that property is to be moved at the deployer level",XD-2951,Eric Bottard,Move decision logic for directBinding out of bus to deployer
812,,Gary Russell,"See https://gopivotal-com.socialcast.com/messages/24095632

However, it was set to ERROR last year to ""reduce log noise"".

I would prefer to elevate to at least WARN in XD and address the ""noise"" issue in Spring AMQP.",XD-2950,Gary Russell,SingleNode Logging for AMQP Listener Container is too Narrow (ERROR)
813,Glenn Renfro,Glenn Renfro,"When using the rest interface to create a Job with an empty description, used to generate the following exception, ""Definition can not be empty"".   Now generates ""XD112E:(pos 0): Unexpectedly ran out of input^"". 
The correct error should be, ""definition cannot be blank or null""

",XD-2949,Glenn Renfro,"Error Message for ""Missing Job Description"" needs to be updated"
814,Thomas Darimont,Thomas Darimont,"It is possible to specify the location of custom modules via the environment variable {{XD_CUSTOMMODULE_HOME}} which is provided by Spring Boot property key derivation mechanism (in this case derived from {{xd.customModule.home}}).

This allows a user to specify a custom modules location that survives a complete wipe of spring-xd installations.",XD-2948,Thomas Darimont,Document how to specify custom-modules location via Environment variable.
815,,Sabby Anandan,"As a user, I'd like to have the ability to use expressions, so I can dynamically name directories/files based on the timestamp or other intermediate data point.",XD-2947,Sabby Anandan,Add support for expressions and dynamically evaluate at runtime
816,Eric Bottard,Eric Bottard,,XD-2946,Eric Bottard,Allow direct binding even for module.count != 0
817,,Muhammad Ali,"As a user I want to be able to provide my own RowMapper<Tuple> implementation to enrich the jdbc data. 

My use case requires me to add timestamp field and a delete flag field to records before they get written to HDFS. To do it, I have to implement a ItemReaderFactory and perhaps extend NameColumnJdbcItemReader. This is to override the afterPropertySet method to change the default implementation.

Otherwise I have to write my own Processor that can add these fields to Tuples, and since tuples are immutable I would have to recreate the tuples with additional fields in the processor. For large load this could be big overhead.

I would love to know any other technique to implement such a use case.",XD-2945,Muhammad Ali,Externalized RowMapper<Tuple> from the NamedColumnJdbcItemReader
818,David Turanski,Vijay Gadwal,"The twittersearch source module picks up the same tweet in successive iterations of the REST request.
The reason for this is that the since_id value being set at the end of each iteration is the last item in the list of tweets, but not the latest value of tweet id.

Steps to reproduce:

Created a stream using below definition

stream create --name twittersearchspring --definition ""twittersearch --consumerKey=<key> --consumerSecret=<secret> --query='spring' | tweet-transformer | file"" --deploy

tweet-transformer referred here is used from the spring-xd-samples repo and is logging the tweet ID being transformed
https://github.com/spring-projects/spring-xd-samples/tree/master/tweet-transformer-processor

Below is the log

__________
2015-04-14 15:47:22,154 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'twittersearchspring': DeploymentStatus{state=deployed}
2015-04-14 15:47:22,158 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Stream Stream{name='twittersearchspring'} deployment attempt complete
2015-04-14 15:47:24,301 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256
2015-04-14 15:47:24,312 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320
2015-04-14 15:47:24,315 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873
2015-04-14 15:47:24,318 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432
2015-04-14 15:47:24,320 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305
2015-04-14 15:47:24,325 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072
2015-04-14 15:47:24,340 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888
2015-04-14 15:47:24,342 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577
2015-04-14 15:47:24,343 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680
2015-04-14 15:47:24,344 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884737307549696
2015-04-14 15:47:24,346 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884734723702784
2015-04-14 15:47:24,348 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884730059771905
2015-04-14 15:47:24,356 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884729225125888
2015-04-14 15:47:24,358 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884725802405888
2015-04-14 15:47:24,359 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884724938481665
2015-04-14 15:47:26,465 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884724938481665
2015-04-14 15:47:26,865 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481
2015-04-14 15:47:26,867 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089
2015-04-14 15:47:26,869 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544
2015-04-14 15:47:26,871 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392
2015-04-14 15:47:26,872 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712
2015-04-14 15:47:26,878 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849
2015-04-14 15:47:26,880 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256
2015-04-14 15:47:26,882 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320
2015-04-14 15:47:26,884 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873
2015-04-14 15:47:26,886 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432
2015-04-14 15:47:26,887 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305
2015-04-14 15:47:26,889 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072
2015-04-14 15:47:26,890 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888
2015-04-14 15:47:26,900 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577
2015-04-14 15:47:26,903 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680
2015-04-14 15:47:29,004 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884739387719680
2015-04-14 15:47:29,369 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884782945611776
2015-04-14 15:47:29,371 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884781305663488
2015-04-14 15:47:29,374 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884779506311169
2015-04-14 15:47:29,376 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884775895072768
2015-04-14 15:47:29,377 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771893739520
2015-04-14 15:47:29,379 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771717578753
2015-04-14 15:47:29,384 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884769138081792
2015-04-14 15:47:29,386 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481
2015-04-14 15:47:29,388 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089
2015-04-14 15:47:29,389 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544
2015-04-14 15:47:29,390 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392
2015-04-14 15:47:29,391 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712
2015-04-14 15:47:29,395 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849
2015-04-14 15:47:29,399 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256
2015-04-14 15:47:29,401 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320
2015-04-14 15:47:31,502 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884752591544320

__________

Notice that tweet ID 587884752591544320 is picked up in second iteration as well although it was picked in the first.


The issue can be fixed in the doSendLine method of  TwitterSearchChannelAdapter.java where this.sinceId is being set to the last value of id. Instead, the statuses map can be sorted on ID, and the highest ID can be set for sinceId.",XD-2944,Vijay Gadwal,twittersearch stream returns duplicate tweets
819,,Buelent Zeyben,As a users I would to be able to execute SQL Statement/Script via a Processor or Job statement.,XD-2943,Buelent Zeyben,SQL Script Processor
820,Eric Bottard,Franck MARCHAND,It would be nice to have a simple ftp source. I have to do it for one of my projects. Same as XD-2139 but for source modules.,XD-2942,Franck MARCHAND,Add ftp source to default source modules
821,Ilayaperumal Gopinathan,Alex Boyko,"Start XD distributed XD with specified management port and
xd:
  messageRateMonitoring:
    enabled: true
in servers.yml
to gather stats.

Create stream {{file | log}}, deploy it, navigate to Containers tab in Admin UI. Rates are shown correctly.
Create stream {{MYFILE: file | log}}, deploy it, navigate to Containers tab in Admin UI - none of the message rates are shown. Open browser dev tools console and note 500 error response.

spring-xd-dirt -> ContainersController lines 109-112 creates request to get message rates for modules. 
Typical request:
{{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=log.*,component=*,name=input/MeanSendRate}}

Typical response:
{code:json}
{""request"":{""mbean"":""xd.str4:component=*,module=log.1,name=input"",""attribute"":""MeanSendRate"",""type"":""read""},""value"":{""xd.str4:component=MessageChannel,module=log.1,name=input"":{""MeanSendRate"":0.0}},""timestamp"":1428675070,""status"":200}
{code}

For file module with label `MYFILE` the request is:
{{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=MYFILE.*,component=*,name=output/MeanSendRate}}

Response:
{code:json}
{""mbean"":""xd.str4:component=*,module=MYFILE.1,name=output"",""attribute"":""MeanSendRate"",""type"":""read""},""stacktrace"":""javax.management.InstanceNotFoundException: No MBean with pattern xd.str4:module=MYFILE.1,component=*,name=output found for reading attributes\n\tat org.jolokia.handler.ReadHandler.searchMBeans(ReadHandler.java:160)\n\tat org.jolokia.handler.ReadHandler.fetchAttributesForMBeanPattern(ReadHandler.java:126)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:116)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:37)\n\tat org.jolokia.handler.JsonRequestHandler.handleRequest(JsonRequestHandler.java:160)\n\tat org.jolokia.backend.MBeanServerHandler.dispatchRequest(MBeanServerHandler.java:97)\n\tat org.jolokia.backend.LocalRequestDispatcher.dispatchRequest(LocalRequestDispatcher.java:98)\n\tat org.jolokia.backend.BackendManager.callRequestDispatcher(BackendManager.java:411)\n\tat org.jolokia.backend.BackendManager.handleRequest(BackendManager.java:158)\n\tat org.jolokia.http.HttpRequestHandler.executeRequest(HttpRequestHandler.java:197)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:86)\n\tat org.jolokia.http.AgentServlet$4.handleRequest(AgentServlet.java:435)\n\tat org.jolokia.http.AgentServlet.handleSecurely(AgentServlet.java:320)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:291)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:252)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:146)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:130)\n\tat sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)\n\tat org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)\n\tat org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:370)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:744)\n"",""error_type"":""javax.management.InstanceNotFoundException"",""error"":""javax.management.InstanceNotFoundException : No MBean with pattern xd.str4:module=MYFILE.1,component=*,name=output found for reading attributes"",""status"":404}
{code}

This reponse results in JSONException in the ContainersController because it's missing 'value' property.

The module id is somewhat problematic in the request: {{xd.str4:module=log.*}} index is {{\*}} but should be index within the stream, also node type (source/sink/processor) is missing. Therefore, stream {{mail | mail}} is suffering from the same problem.

Would be nice to have some sort of a bulk request to query more than one module for input/output message rates, such that I could get all message rates for modules in the stream.",XD-2941,Alex Boyko,Failure to get message rates for modules with labels.
822,Eric Bottard,Eric Bottard,"In line with the checks we do for options documentation.

Currently made more complicated than it should because of rogue folders (such as scripts/ and analytics-pmml/ in the registry)",XD-2940,Eric Bottard,Force and validate information on OOTB modules
823,,Peter Rietzler,"We are currently running single node mode and experiencing the same problem as described here: http://stackoverflow.com/questions/28170864/spring-xd-jobs-automatic-undeployment-on-zookeeper-time-out-in-xd-singlenode-mo

I've turned on GC logs and can see that there is a 29.7 second GC pause around the time when this happens. We've already set the Zookeeper timeouts (as suggested in the stackoverflow question) - without effect - we can just see, that after the configured timeout the ConnectionLoss errors start to appear.

Sorry for the priorization - for us this currently is a major issue since we are running in singlenode mode (as a starter) and our system goes down once a day. Would this behavior change if we switch to distributed mode ?

I know that a GC pause of 29 secs is really long, however, I've already seen such pauses for batch systems pretty often. Long running jobs tend to move objects to older generations and sometimes there isn't much of a chance to do something against it. So I guess it's worth considering this in the behavior of XD ?",XD-2939,Peter Rietzler,All Modules are undeployed on Zookeeper Connection Loss / GC Pause
824,,Sean Ward,"As a user, I need to use XD Sqoop module to support the merge command.
Currently, the SqoopRunner createFinalArguments method forces the requirement for connect, username and password options which are not valid for the merge option. A check of the module type to not force these options being assigned to sqoop arg list would be preferred",XD-2938,Sean Ward,Sqoop - Unable to create job using MERGE command
825,,David Turanski,"for example:

{code}
xd:
  transport: rabbit

  messagebus:
#    local:
#      queueSize:                   2147483647
#      polling:                     1000
#      executor:
#        corePoolSize:              0
#        maxPoolSize:               200
#        queueSize:                 2147483647
#        keepAliveSeconds:          60
    rabbit:
#      compressionLevel:            1
            # bus-level property, applies only when 'compress=true' for a stream module
            # See java.util.zip.Deflater; 1=BEST_SPEED, 9=BEST_COMPRESSION, ...
      default:
#        ackMode:                   AUTO
            # Valid: AUTO (container acks), NONE (broker acks), MANUAL (consumer acks).
            # Upper case only.
            # Note: MANUAL requires specialized code in the consuming module and is unlikely to be
            # used in an XD application. For more information, see
            # http://docs.spring.io/spring-integration/reference/html/amqp.html#amqp-inbound-ack
#        autoBindDLQ:               false
#        backOffInitialInterval:    1000
#        backOffMaxInterval:        10000
#        backOffMultiplier:         2.0
#        batchBufferLimit:          10000
        batchingEnabled:           true
#        batchSize:                 100
#        batchTimeout:              5000
#        compress:                  false
#        concurrency:               1
#        deliveryMode:              PERSISTENT
#        maxAttempts:               3
#        maxConcurrency:            1
#        prefix:                    xdbus.
            # prefix for queue/exchange names so policies (ha, dle etc.) can be applied
#        prefetch:                  1
#        replyHeaderPatterns:       STANDARD_REPLY_HEADERS,*
#        requestHeaderPatterns:     STANDARD_REQUEST_HEADERS,*
#        requeue:                   true
#        transacted:                false
#        txSize:                    1

#    redis:
#      headers:
            # comman-delimited list of additional (string-valued) header names to transport
#      default:
            # default bus properties, if not specified at the module level
#        backOffInitialInterval:    1000
#        backOffMaxInterval:        10000
#        backOffMultiplier:         2.0
#        concurrency:               1
#        maxAttempts:               3
#   kafka:
#      brokers:                                 localhost:9092
#      zkAddress:                               localhost:2181
#      numOfKafkaPartitionsForCountEqualsZero:  10
#      socketBufferSize:                        2097152
#      offsetStoreTopic:                        SpringXdOffsets
#      offsetStoreSegmentSize:                  25000000
#      offsetStoreRetentionTime:                60000
#      offsetStoreRequiredAcks:                 1
#      offsetStoreMaxFetchSize:                 1048576
#      offsetStoreBatchSize:                    200
#      offsetStoreBatchEnabled:                 false
#      offsetStoreBatchTime:                    1000
#      offsetUpdateTimeWindow:                  10000
#      offsetUpdateCount:                       0
#      offsetUpdateShutdownTimeout:             2000
      default:
        batchingEnabled:           true
{code}",XD-2937,David Turanski,xd-admin silently fails if servers.yml is invalid
826,,Sabby Anandan,"As a user, I'd like to have an option to specify _timeout_, so I can expect the job to not run forever if it is in hung state.",XD-2936,Sabby Anandan,Add timeout for Sqoop jobs
827,Thomas Risberg,Sabby Anandan,"As a user, I'd like to parameterize Merge Options, so I can incrementally consume the delta with the help of megastore. 
",XD-2935,Sabby Anandan,Parameterize Merge Options
828,Thomas Risberg,Sabby Anandan,"As a user, I'd like to parameterize CodeGen Options, so I can generate code on the fly as needed. 

",XD-2934,Sabby Anandan,Parameterize codegen options
829,,Sabby Anandan,"As a user, I'd like to parameterize all Import Options, so I can eliminate the need for {{—args}} option since it gets confusing.",XD-2933,Sabby Anandan,Parameterize import options for Sqoop
830,,Yuwei Sung,"When copying those xml files to spring xd conf, spring xd doesn't pickup those classpath correctly. those classpath contains ${stack.name}, ${stack.version}. Those were processed correctly inside phd3/hdp, but not in spring xd. ",XD-2932,Yuwei Sung,yarn/mapred application class path broke.
831,Gunnar Hillert,Ilayaperumal Gopinathan,"If the admin UI is secured, the login page is displayed without any styles.",XD-2931,Ilayaperumal Gopinathan,Login page is missing style info when secured
832,,Sabby Anandan,"As a developer, I'd like to configure HADOOP_USER_NAME environment variable to implement and run-as-user for kerberos secured clusters. This would need some additional work in SHDP.",XD-2930,Sabby Anandan,Add configurable HADOOP_USER_NAME support
833,Michael Minella,Sabby Anandan,"As a developer, I'd like to document how to nest batch jobs and workflows in XD, so it will be easy for end-users to use it as reference. ",XD-2929,Sabby Anandan,Document the use of nested jobs with example
834,Thomas Risberg,Buelent Zeyben,"The Sqoop module is generating a SQL statement for --table argument that is not correct for Oracle source.

The Job definition is:

job create sqoop_lookup --definition ""sqoop --command=import --args='--connect=jdbc:oracle:thin:@XXXXXXXXX --driver=oracle.jdbc.OracleDriver --direct --username=********* --password=********* --table=W_LOOKUP_D  --target-dir=/user/zeybeb/ingest/gdw/masterdata/lookup_d --num-mappers=1'"" --deploy 

the --table=W_LOOKUP_D results in Sqoop Object generation:

13:22:59,798 INFO main manager.SqlManager - Executing SQL statement: SELECT t.* FROM W_LOOKUP_D AS t WHERE 1=0
13:22:59,861 ERROR main manager.SqlManager - Error executing statement: java.sql.SQLSyntaxErrorException: ORA-00933: SQL command not properly ended

the SQL shoudl be generate with '<table_name> t' instead of '<table_name> AS t'

The --table argument does not except a schema name. User should be able to provide schema.table_name syntax.

",XD-2928,Buelent Zeyben,Sqoop module SQL generation issue
835,,Karol Dowbecki,"Creating a custom processor module with Apache Velocity (org.apache.velocity:velocity:1.7) as dependency results in {{java.lang.ClassNotFoundException}} during stream deployment:

{code}
2015-04-08 17:35:32,595 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@144d1f50 moduleName = 'custom-velocity-processor', moduleLabel = 'custom-velocity-processor', group = 'velocity-stream', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = processor, parameters = map[[empty]], children = list[[empty]]]
2015-04-08 17:35:32,768 1.1.1.RELEASE  WARN DeploymentsPathChildrenCache-0 support.DefaultListableBeanFactory - FactoryBean threw exception from getObjectType, despite the contract saying that it should return null if the type of its object cannot be determined yet
java.lang.NoClassDefFoundError: org/apache/velocity/app/VelocityEngine
	at org.springframework.ui.velocity.VelocityEngineFactoryBean.getObjectType(VelocityEngineFactoryBean.java:69)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getTypeForFactoryBean(FactoryBeanRegistrySupport.java:66)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:795)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:542)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:436)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:404)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:398)
	at org.springframework.integration.jmx.config.JmxIntegrationConfigurationInitializer.registerMBeanExporterHelperIfNecessary(JmxIntegrationConfigurationInitializer.java:42)
	at org.springframework.integration.jmx.config.JmxIntegrationConfigurationInitializer.initialize(JmxIntegrationConfigurationInitializer.java:38)
	at org.springframework.integration.config.IntegrationConfigurationBeanFactoryPostProcessor.postProcessBeanFactory(IntegrationConfigurationBeanFactoryPostProcessor.java:48)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:177)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:606)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:462)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ClassNotFoundException: org.apache.velocity.app.VelocityEngine
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 39 more
{code}

Attached is module source code. Executing commands in {{xd-shell-commands.cmd}} file is enough to trigger the exception.

Everything works when velocity jar is placed in {{$XD_HOME/lib}} and excluded from the processor module.",XD-2927,Karol Dowbecki,Can't use Apache Velocity in custom modules
836,,Eric Bottard,,XD-2926,Eric Bottard,module info for a composite should display original definition
837,,Eric Bottard,"This creates a dependency cycle that eclipse can't handle (doesn't discern between scope like IDEA does).

I believe we can get rid of dummy() in tests that are in spring-xd-module

",XD-2925,Eric Bottard,Remove usage of dummy() MD in spring-xd-module
838,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,We need to support adding a tap stream that connects to spark streaming processor module's output channel.,XD-2924,Ilayaperumal Gopinathan,Ability to tap spark streaming processor output
839,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"If a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel), then it doesn't bind to it.

For instance, if I have a stream ""ingest"" with a definition ""http | log"" and want to create another stream as,
""tap:stream:ingest > spark-processor | count"" then this stream doesn't work.",XD-2923,Ilayaperumal Gopinathan,Not able to connect a pubsub channel to spark streaming module
840,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a Spring XD user, I'd like to create streaming pipelines, so I can take advantage of latest specs from both XD and Spark/Spark Streaming.",XD-2922,Ilayaperumal Gopinathan,Upgrade Spark version to 1.3.1
841,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to add documentation on escape quotes, so when someone using Sqoop job can double escape {{\\\\N}} instead of sending quotes {{'\N'}} to successfully submit the job.",XD-2921,Sabby Anandan,Clarify the use of escape quotes for properties in the Sqoop job
842,Ilayaperumal Gopinathan,Karol Dowbecki,"Currently dynamic router sink has to return a valid queue name. This is problematic when the message should be discarded as part of the routing process. In this case one have to define a stream with {{filter | router}} steps where part of the SpEL is duplicated between {{filter}} and {{router}} modules.

Instead the dynamic router should allow to return null to discard the message and stop further processing. Spring Integration is already providing {{resolution-required}} attribute on {{<router/>}}. ",XD-2920,Karol Dowbecki,Dynamic router should allow to discard messages
843,Eric Bottard,Sabby Anandan,"As a developer, I'd like to create persistent repository for streams, so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.",XD-2919,Sabby Anandan,Create persistent stream repository
844,,Sabby Anandan,"As a developer, I'd like to define pluggable runtime SPI, so I have the option to choose the implementation based on deployment targets such as CF, on-prem, Mesos etc.",XD-2918,Sabby Anandan,Define pluggable runtime SPI
845,,Sabby Anandan,"As a developer, I'd like to refactor stream/job definition repository, so I can decouple from module deployment concerns.",XD-2917,Sabby Anandan,Refactor stream/job definition repository
846,Mark Fisher,Sabby Anandan,"As a developer, I'd like to create a [java client|https://github.com/markfisher/receptor-client] for Receptor, so I can interact with Diego runtime via Receptor API calls from XD. ",XD-2916,Sabby Anandan,Create a Java client for Receptor
847,Mark Fisher,Sabby Anandan,"As a developer, I'd like to build isolated Boot-based {{ModuleRunner}} for use in container-managed environments, so I can run XD without the hard requirement for running _xd-containers_.",XD-2915,Sabby Anandan,Create Boot based ModuleRunner
848,Patrick Peralta,Sabby Anandan,"As a developer, I'd like to migrate module deployment from the ""repository"" abstraction (used for stream/job definitions), so I can create it as a pluggable runtime SPI.",XD-2914,Sabby Anandan,Create a pluggable runtime SPI
849,,Sabby Anandan,"As a developer, I'd like to have a simplified UX around parameters for GPDB, so I don't have to escape each parameter. The scope is also to test the Sqoop job with SQLServer and GPDB to identify the UX differences.",XD-2913,Sabby Anandan,Simplify GPDB UX around parameters for the Sqoop job
850,,Jared Monast,"Can  not get any jobs created using Scoop Module to run. Have tried both the direct implementation using module definition and job create from shell.

Job creates , deploys and goes into execution mode. Runs endlessly no return. Attaching container log and job definition:

job create sqoop96 --definition ""sqoop --command=import --args='--table INV.MTL_CATEGORY_SETS_B -m=1 --connect jdbc:oracle:thin:@xxxxx.xxx.xxx --username ****** --password *********'"" --deploy

--Container Log
2015-04-06 15:38:23,720 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1428324095255_0006_000001
2015-04-06 15:38:24,041 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-06 15:38:24,058 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2015-04-06 15:38:24,058 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 6 cluster_timestamp: 1428324095255 } attemptId: 1 } keyId: 723784990)
2015-04-06 15:38:24,213 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2015-04-06 15:38:24,811 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2015-04-06 15:38:24,864 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-04-06 15:38:24,895 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2015-04-06 15:38:24,897 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2015-04-06 15:38:24,898 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2015-04-06 15:38:24,899 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2015-04-06 15:38:24,900 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2015-04-06 15:38:24,906 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2015-04-06 15:38:24,906 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2015-04-06 15:38:24,907 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2015-04-06 15:38:24,926 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2015-04-06 15:38:24,941 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2015-04-06 15:38:24,960 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2015-04-06 15:38:24,979 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2015-04-06 15:38:25,032 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2015-04-06 15:38:25,295 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-04-06 15:38:25,353 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-04-06 15:38:25,353 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2015-04-06 15:38:25,362 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1428324095255_0006 to jobTokenSecretManager
2015-04-06 15:38:25,476 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1428324095255_0006 because: not enabled;
2015-04-06 15:38:25,489 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1428324095255_0006 = 0. Number of splits = 1
2015-04-06 15:38:25,489 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1428324095255_0006 = 0
2015-04-06 15:38:25,489 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1428324095255_0006Job Transitioned from NEW to INITED
2015-04-06 15:38:25,490 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1428324095255_0006.
2015-04-06 15:38:25,515 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-04-06 15:38:25,522 INFO [Socket Reader #1 for port 51164] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 51164
2015-04-06 15:38:25,543 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2015-04-06 15:38:25,543 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-04-06 15:38:25,543 INFO [IPC Server listener on 51164] org.apache.hadoop.ipc.Server: IPC Server listener on 51164: starting
2015-04-06 15:38:25,544 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at sandbox.hortonworks.com/192.168.3.128:51164
2015-04-06 15:38:25,598 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-04-06 15:38:25,601 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2015-04-06 15:38:25,609 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-04-06 15:38:25,614 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2015-04-06 15:38:25,614 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2015-04-06 15:38:25,616 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2015-04-06 15:38:25,616 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2015-04-06 15:38:25,624 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 38343
2015-04-06 15:38:25,624 INFO [main] org.mortbay.log: jetty-6.1.26.hwx
2015-04-06 15:38:25,662 INFO [main] org.mortbay.log: Extract jar:file:/usr/hdp/2.2.0.0-2041/hadoop-yarn/hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar!/webapps/mapreduce to /tmp/Jetty_0_0_0_0_38343_mapreduce____86ppbg/webapp
2015-04-06 15:38:25,901 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:38343
2015-04-06 15:38:25,901 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app /mapreduce started at 38343
2015-04-06 15:38:26,261 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-04-06 15:38:26,265 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1428324095255_0006
2015-04-06 15:38:26,267 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-04-06 15:38:26,267 INFO [Socket Reader #1 for port 58807] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 58807
2015-04-06 15:38:26,272 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-04-06 15:38:26,272 INFO [IPC Server listener on 58807] org.apache.hadoop.ipc.Server: IPC Server listener on 58807: starting
2015-04-06 15:38:26,300 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2015-04-06 15:38:26,300 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2015-04-06 15:38:26,300 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2015-04-06 15:38:26,343 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8030
2015-04-06 15:38:26,410 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: <memory:2250, vCores:32>
2015-04-06 15:38:26,410 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: queue: default
2015-04-06 15:38:26,415 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2015-04-06 15:38:26,417 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2015-04-06 15:38:26,428 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1428324095255_0006Job Transitioned from INITED to SETUP
2015-04-06 15:38:26,430 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2015-04-06 15:38:26,442 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1428324095255_0006Job Transitioned from SETUP to RUNNING
2015-04-06 15:38:26,457 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1428324095255_0006_m_000000 Task Transitioned from NEW to SCHEDULED
2015-04-06 15:38:26,459 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1428324095255_0006_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2015-04-06 15:38:26,459 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:1024, vCores:1>
2015-04-06 15:38:26,531 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1428324095255_0006, File: hdfs://sandbox:8020/tmp/hadoop-yarn/staging/root/.staging/job_1428324095255_0006/job_1428324095255_0006_1.jhist
2015-04-06 15:38:27,413 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2015-04-06 15:38:27,466 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1428324095255_0006: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:500, vCores:0> knownNMs=1",XD-2912,Jared Monast,Sqoop Module not running
851,Michael Minella,Sabby Anandan,"As a developer, I'd like to bench test cases around {{TupleBuilder}}, so I can identify the bottlenecks and tune for performance optimizations. ",XD-2911,Sabby Anandan,Improve performance of TupleBuilder 
852,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around _jdbchdfs_.",XD-2910,Sabby Anandan,Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs
853,Glenn Renfro,Glenn Renfro,,XD-2909,Glenn Renfro,Produce Kafka Baseline numbers on Rackspace
854,Glenn Renfro,Glenn Renfro,After the Introduction to XD-2861 the acquisition of JobResources takes more time.  We have to introduce a pause to wait for getJobDefinitionResource to be populated. ,XD-2908,Glenn Renfro,Acceptance Tests needs to wait for JobDefinitionResources to be populated 
855,,Sabby Anandan,"As a developer, I'd like to have the XD + Kafka POC published in samples repo, so I can include it as reference architecture for the XD blog.",XD-2907,Sabby Anandan,Create a reference architecture for high throughput RT analytics using XD and Kafka
856,David Turanski,Sabby Anandan,"As a developer, I'd like to add a new CI build to include _install_ target, so I can verify the target expectations, as it is often time consuming to verify it in the development environment.",XD-2906,Sabby Anandan,Create a new CI build to verify 'install' target
857,,Sabby Anandan,"As a developer, I'd like to complete the remaining work with DEBS challenge, so I can submit by the deadline.",XD-2905,Sabby Anandan,Complete remaining work for the DEBS challenge
858,Gunnar Hillert,Sabby Anandan,"As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes.

We should also sync-up the following dependency updates to [synchronize with Boot|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-dependencies/pom.xml]:
{code}
<logback.version>1.1.3</logback.version>
<jackson.version>2.5.1</jackson.version>
<gemfire.version>8.0.0</gemfire.version>
<h2.version>1.4.185</h2.version>
<javax-mail.version>1.5.3</javax-mail.version>
<undertow.version>1.2.3.Final</undertow.version>
<joda-time.version>2.7</joda-time.version>
<nekohtml.version>1.9.21</nekohtml.version>
<activemq.version>5.11.1</activemq.version>
<antlr2.version>2.7.7</antlr2.version>
<commons-dbcp2.version>2.0.1</commons-dbcp2.version>
<tomcat.version>8.0.21</tomcat.version>
<aspectj.version>1.8.5</aspectj.version>
<groovy.version>2.4.3</groovy.version>
<crashub.version>1.3.1</crashub.version>
<jetty.version>9.2.9.v20150224</jetty.version>
<elasticsearch.version>1.4.4</elasticsearch.version>
<flyway.version>3.2.1</flyway.version>
<freemarker.version>2.3.22</freemarker.version>
<jdom2.version>2.0.6</jdom2.version>
<liquibase.version>3.3.2</liquibase.version>
<mockito.version>1.10.19</mockito.version>
mongodb.version>2.13.0</mongodb.version>
<slf4j.version>1.7.11</slf4j.version>
<spring-cloud-connectors.version>1.1.1.RELEASE</spring-cloud-connectors.version>
<spring-security.version>4.0.1.RELEASE</spring-security.version>
<jedis.version>2.6.2</jedis.version>
<spring-ws.version>2.2.1.RELEASE</spring-ws.version>
{code}",XD-2904,Sabby Anandan,Upgrade to Boot 1.2.3 release
859,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to upgrade to SI Kafka release, so I can synchronize with latest improvements and bug fixes.  ",XD-2903,Sabby Anandan,Upgrade to 1.1.2 SIK release
860,Gary Russell,Sabby Anandan,"As a developer, I'd like to upgrade to SI milestone/GA release, so I can synchronize with JMX improvements.  

This is dependent on SI Milestone and GA release timelines.",XD-2902,Sabby Anandan,Upgrade to latest SI release 
861,,Sabby Anandan,"As a developer, I'd like to deploy a stream in the same container, so all modules are colocated within the container. Perhaps also consider building leader election within modules in order to automatically failover the application (stream) from one container to another. ",XD-2901,Sabby Anandan,Add support to deploy stream in a single container
862,,Sabby Anandan,"As a developer, I'd like to synchronize with the latest Gemfire version (8.1?), so I can leverage the latest Gemfire features and as well support updated BDS stack.

This effort in XD depends on Spring Data Gosling GA release, which in turn depends on Gemfire 8.1 release timelines. ",XD-2900,Sabby Anandan,Upgrade to latest Gemfire release
863,Gary Russell,Sabby Anandan,"As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.",XD-2899,Sabby Anandan,Improve HA support for Rabbit
864,,Thomas Risberg,"There doesn't seem to be a way to configure the XD shell for accessing a kerberos secured cluster.

Tried this:
>hadoop config props set --property hadoop.security.authorization=true
>hadoop config props set --property hadoop.http.authentication.type=kerberos

still getting:
>hadoop fs ls /xd
Hadoop configuration changed, re-initializing shell...
ls: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
",XD-2898,Thomas Risberg,XD Shell should be configurable for accessing secure cluster
865,,Sabby Anandan,"As a user, I'd like to have the OOTB module to consume database changes as event streams, so I can incrementally synchronize with real-time DB updates with various destinations such as Brokers, Hadoop, DB, etc.
",XD-2897,Sabby Anandan,Add support to consume database changes as event streams
866,Gary Russell,Sabby Anandan,"As a user, I'd like to have the configuration option to use an alternative DLQ, so I can publish the message this time with additional headers, including one that contains the exception (and stack trace).
",XD-2896,Sabby Anandan,Add support to capture errors/stacktrace via DLQ
867,,Buelent Zeyben,While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a '*********'.,XD-2895,Buelent Zeyben,Password for Sqoop Job definition is in the open
868,Eric Bottard,Eric Bottard,"Add early validation for cron expression
Ease validation of maxOne/atLeastOne mutually exclusive options",XD-2894,Eric Bottard,UX enhancements for trigger source
869,Eric Bottard,Eric Bottard,"Characters line \t, \n, etc. should be either escaped, or rendered as human readable variants in module info (eg <newline>)",XD-2893,Eric Bottard,"Properly render defaults for ""module info"" that use \n \t etc."
870,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to certify Spring XD against PHD 3.0, so I can synchronize with the latest ODP based bits. ",XD-2892,Sabby Anandan,Add support for PHD 3.0 
871,Eric Bottard,Mark Pollack,"When uploading a new version of a module the admin container if there is already an existing module, the behavior should be to delete the existing contents of the module directory and replace it with that of the new upload jar.

This would be an optional parameter.",XD-2891,Mark Pollack,Provide an --override option to the module upload command
872,,Sabby Anandan,"As a user, I'd like to have the option to read the file line by line, so I get the optional OOTB optimum file reading experience.",XD-2890,Sabby Anandan,Add support to ready files line by line
873,,Sabby Anandan,"As a user, I'd like to have the option to version the custom modules, so I can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly.",XD-2889,Sabby Anandan,Add support for custom module versioning 
874,,Sabby Anandan,"As a user, I'd like to also have the capability to upload the custom module through maven/gradle targets, so I can automate the installation of custom module fragments.",XD-2888,Sabby Anandan,Add a gradle/maven target to upload the custom module jar
875,Eric Bottard,Eric Bottard,"Similar to the DetailedModuleDefinitionResource that is returned when querying a single module, but would be returned when listing (provided a ?full flag has been turned on)",XD-2887,Eric Bottard,Have a version of GET /modules that returns full info
876,,Anthony Jiang,"I am using the XD shell to create a stream that pulls from an Oauth source to HDFS as my sink. Does Spring XD have some standard approach to this? Here were some thoughts 

1.Use http source with mappedRequestHeaders.(Not sure how to pass the OAuth here)
2.Create HttpOutboundGateway that will execute a GET request.
3.Code a new twitter like source and build the source code.
",XD-2886,Anthony Jiang,Stream data from fitbit API which uses Oauth to HDFS 
877,Eric Bottard,Eric Bottard,"The current build ships everything that is found in the modules directory, including build artifacts such as build/ or IDEA *.iml files.

Restrict the build to only include config/, lib/ at the moment.",XD-2885,Eric Bottard,Only ship relevant modules files
878,Eric Bottard,Eric Bottard,,XD-2884,Eric Bottard,Document dynamic classpath feature
879,,Thomas Risberg,"As a user, I'd like to have an option to have the hdfs sink not use a temporary inUseSuffix like .tmp. Instead we should write using the filename specified directly. This could be useful if we use ""Syncable"" writes and the sink fails while the file is open. Without this new option the user would have to explicitly rename the file.",XD-2883,Thomas Risberg,Provide an option for hdfs sink to not use tmp extension
880,Thomas Risberg,Thomas Risberg,"As a user, I'd like to have an option to have the hdfs sink use ""Syncable"" writes to provide better resiliency in the case of sink/container failures. I'm willing to accept the performance penalty if I choose this option.
",XD-2882,Thomas Risberg,"Provide an option for hdfs sink to use ""Syncable"" writes"
881,,Sabby Anandan,"As a developer, I need to investigate the differences in dependency versions, so when I create/deploy custom modules in XD, I don't run into CP/CL issues.",XD-2881,Sabby Anandan,Identify and fix dependency conflicts in DIRT CP
882,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to add support for dynamic partition subscription for the Kafka source module, so I can consume the payload from dynamic partitions.",XD-2880,Sabby Anandan,Add support for dynamic partition subscription for Kafka source
883,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to add support for explicit partition count configuration, so I can use this option to cleverly route the payload to the intended consumer (module).",XD-2879,Sabby Anandan,Add support for explicit partition count configuration for Kafka bus
884,,Nimrod Milo,"When creating a new module with a dependeny which has a newer version than the one Spring-xd uses (in my example I use Jedis 2.6.1 and Spring-xd uses Jedis 2.5.2) the packaging ignores the dependency.

Using the solution of spring-boot-maven-plugin, doesn't help because it will only include what you explicitly add to the include section (transitive dependencies are not included)",XD-2878,Nimrod Milo,Using a newer version of a spring-xd dependency is ignored in packaging 
885,Patrick Peralta,Patrick Peralta,"As a pre-requisite for XD-2835 and a continuation of XD-2671, split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.",XD-2877,Patrick Peralta,Refactor deployment interfaces/class hierarchy
886,Gary Russell,Gunnar Hillert,"{code}
 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
1.1.1.RELEASE                    eXtreme Data


Started : ContainerServerApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki
{code}

This should probably be changed to:

Documentation: http://docs.spring.io/spring-xd/docs/current/reference/html/

",XD-2876,Gunnar Hillert,Update Documentation Link
887,,Thomas Risberg,We need a convenient way for the shell to access a HA namenode,XD-2875,Thomas Risberg,XD Shell support for accessing HA namenode
888,,Gunnar Hillert,"Last Sync Errors: Invalid POM: /org/springframework/xd/spring-xd-module-parent/1.1.1.RELEASE/spring-xd-module-parent-1.1.1.RELEASE.pom: Developer information missing Invalid POM: /org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE/spring-xd-module-plugin-1.1.1.RELEASE.pom: Project name missing, Project description missing, Project URL missing, License information missing, SCM URL missing, Developer information missing Missing: no javadoc jar found in folder '/org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE' Missing: no sources jar found in folder '/org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE' Dropping existing partial staging repository.",XD-2874,Gunnar Hillert,Improve the enforcement of meta-properties being set in build.gradle
889,Marius Bogoevici,Glenn Renfro,"XD Version Spring XD 1.1.1.Release
1 Admin on own (on-metal) Rackspace machine
2 Containers each having own (on-metal) rackspace machine
1 zookeeper node collocated with admin

While executing XD performance testing on Rackspace using Kafka as a transport we occasionally get the following exception:
{noformat}
2015-03-26 18:36:30,677 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/4c3c9ccf-44db-4772-87c2-70c63b82c3aa/foo3.sink.throughput.1, type=CHILD_ADDED
2015-03-26 18:36:30,685 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'throughput' for stream 'foo3'
2015-03-26 18:36:30,820 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@19f0b0a6 moduleName = 'throughput', moduleLabel = 'throughput', group = 'foo3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map[[empty]], children = list[[empty]]]
2015-03-26 18:36:31,372 1.1.1.RELEASE ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
org.springframework.integration.kafka.core.TopicNotFoundException: No topic named 'foo3.0' found
	at org.springframework.integration.kafka.core.DefaultConnectionFactory.getPartitions(DefaultConnectionFactory.java:209)
	at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.createKafkaConsumer(KafkaMessageBus.java:640)
	at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindConsumer(KafkaMessageBus.java:454)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:275)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:158)
	at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)
	at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{noformat}

stream used to create the exception:
stream create foo4 --definition ""load-generator --messageSize=1000 --messageCount=10000000 | throughput"" --deploy

After failed deployment.  I destroy the stream and recreate it and it works fine.",XD-2873,Glenn Renfro,Creating Streams sporadically using Kafka as a message bus throws TopicNotFound exception
890,Gunnar Hillert,Gunnar Hillert,"How to reproduce:

1) Enable security
2) Use a user that has the following role only: ""ROLE_CREATE""
3) Make a normal REST call:

{code}
http://localhost:9393/runtime/containers
{code}

yields the *desired response*:

{code}
    {
       ""timestamp"": ""2015-03-26T16:51:17.010Z"",
       ""status"": 403,
       ""error"": ""Forbidden"",
       ""message"": ""Access is denied"",
       ""path"": ""/runtime/containers""
    }
{code}

Now try:

{code}
http://localhost:9393/runtime/containers.json
{code}

This produces:

{code}


    {
       ""links"":
       [
           {
               ""rel"": ""self"",
               ""href"": ""http://localhost:9393/runtime/containers{?page,size,sort}""
           }
       ],
       ""content"":
       [
           {
               ""containerId"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1"",
               ""groups"": """",
               ""deploymentSize"": 0,
               ""deployedModules"":
               [
               ],
               ""messageRates"": null,
               ""attributes"":
               {
                   ""ip"": ""10.0.1.119"",
                   ""host"": ""INTEGRATION.local"",
                   ""groups"": """",
                   ""pid"": ""52686"",
                   ""id"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""
               },
               ""links"":
               [
                   {
                       ""rel"": ""self"",
                       ""href"": ""http://localhost:9393/runtime/containers/86eea5aa-b18e-41c5-a3f5-42dfa10713c1""
                   }
               ]
           }
       ],
       ""page"":
       {
           ""size"": 20,
           ""totalElements"": 1,
           ""totalPages"": 1,
           ""number"": 0
       }
    }
{code}",XD-2872,Gunnar Hillert,"Able to bypass authorization checks by appending "".json"" or "".xml"""
891,Sabby Anandan,Gunnar Hillert,"Currently the shell does not automatically detect whether authentication for the targeted admin server is necessary. 

Upon start, or change of the admin server URL, the shell should check the requirements, and if necessary prompt the user to provide credentials. 

There is also a REST endpoint that could be used for that:

{code}
http://localhost:9393/security/info
{code}

See also XD-2870 for reference.
",XD-2871,Gunnar Hillert,Shell: Improve Login/Authentication Capabilities
892,Sabby Anandan,Gunnar Hillert,"If not properly logged-in you will see errors like this one: ""Command 'module list' was found but is not currently available (type 'help' then ENTER to learn about this command)""

It should possible state something like: ""You don't have the credentials to execute the respective command. Please ensure that you are properly authenticated and have the necessary security roles.""",XD-2870,Gunnar Hillert,Shell: Strange behavior when not logged in
893,Gunnar Hillert,Sabby Anandan,"As a user, I logged in with ROLE_CREATE and I get an error while trying job creation from admin_ui. I can create job from the shell successfully. Trying the same workflow with ROLE_ADMIN results with the same error as well. I don't see anything in the admin/container logs about the error itself. ",XD-2869,Sabby Anandan,Error when creating job from UI with security
894,Gary Russell,Gary Russell,"Initial support for partitioned batch jobs (initially tested with a local bus) had an {{ExecutorChannel}} in the job context to enable multiple partitions to run. Otherwise, with a local bus, only one partition would run at a time.

When further work was done to support other buses, this was removed and the bus was used to control partition concurrency.

The {{LocalMessageBus}} was changed to use an unbounded task executor; this was wrong because now all partitions ran at once.

Further changes to the local bus changed the task executor to be pooled, but with default properties that mean only one thread is used.

Further, the pool configuration is bus-wide so you can't use that configuration to select the concurrency for an individual job.

The bottom line is that the local bus is not suitable for partitioned batch jobs; it was not anticipated that it would be used for this scenario. With 1.0.x too many partitions run (all); with 1.1.x only one thread runs (by default).

In the local bus, we need to use a configurable, dedicated, bounded task executor for each batch job. ",XD-2868,Gary Russell,Support Partitioned Batch Jobs with a LocalMessageBus
895,,Gary Russell,"Dirt errors after {{cleanEclipse eclipse}} - same problem after a complete gradle reimport.

Manually adding the spring-xd-spark-streaming project to the xd-dirt classpath didn't help.

{code}
Description	Resource	Path	Location	Type
The import org.springframework.xd.spark cannot be resolved	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 33	Java Problem
The import org.springframework.xd.module.ModuleType is never used	ModuleDeploymentTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/plugins	line 33	Java Problem
The import org.springframework.batch.core.configuration.xml.JobParserJobFactoryBean is never used	BatchJobRegistryBeanPostProcessor.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job	line 31	Java Problem
The value of the field KafkaMessageBusTests.embeddedHeadersMessageConverter is not used	KafkaMessageBusTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/integration/bus/kafka	line 56	Java Problem
SparkStreamingSupport cannot be resolved	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 68	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 75	Java Problem
SparkMessageSender cannot be resolved to a type	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 38	Java Problem
The import org.springframework.beans.factory.annotation.Value is never used	MessageBusClassLoaderFactory.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server	line 27	Java Problem
The import org.springframework.xd.spark cannot be resolved	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 28	Java Problem
The method send(Message) of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 104	Java Problem
The method start() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 81	Java Problem
The method isRunning() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 123	Java Problem
The method stop() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 109	Java Problem
The import org.springframework.xd.dirt.plugins.job.support.JobLaunchingJobRepository is never used	RuntimeBatchConfigurer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch	line 37	Java Problem
Resource leak: 'cache' is never closed	TestKafkaCluster.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/integration/kafka	line 116	Java Problem
The value of the field StreamDeployer.parser is not used	StreamDeployer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream	line 42	Java Problem
The import org.springframework.batch.core.repository.support.SimpleJobRepository is never used	RuntimeBatchConfigurer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch	line 31	Java Problem
The method endPos(Iterable<Token>) from the type StreamConfigParser is never used locally	StreamConfigParser.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl	line 555	Java Problem
The method startPos(Iterable<Token>) from the type StreamConfigParser is never used locally	StreamConfigParser.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl	line 546	Java Problem
The expression of type AbstractInstancePersistingDeployer<D,I> is already an instance of type AbstractInstancePersistingDeployer	XDController.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest	line 268	Java Problem
The expression of type AbstractInstancePersistingDeployer<D,I> is already an instance of type AbstractInstancePersistingDeployer	XDController.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest	line 217	Java Problem
Resource leak: 'context' is never closed	SparkStreamingChannel.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 45	Java Problem
The value of the field StreamConfigParserTests.zooKeeperConnection is not used	StreamConfigParserTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/stream/dsl	line 63	Java Problem
The value of the field JobPluginTests.deploymentProperties is not used	JobPluginTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/plugins/job	line 94	Java Problem
The import org.springframework.xd.spark cannot be resolved	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 41	Java Problem
SparkStreamingSupport cannot be resolved	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 68	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 79	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 81	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 97	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 99	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 100	Java Problem
The value of the field ModuleTypeConversionPlugin.logger is not used	ModuleTypeConversionPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/stream	line 45	Java Problem
SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 82	Java Problem
SparkStreamingSupport cannot be resolved to a type	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 87	Java Problem
The method getComponent(Class<SparkStreamingSupport>) from the type Module refers to the missing type SparkStreamingSupport	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 90	Java Problem
SparkStreamingSupport cannot be resolved to a type	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 90	Java Problem

{code}",XD-2867,Gary Russell,STS Gradle Import Missing Dependencies without Enabling Scala
896,,Gunnar Hillert,"We have 3 reported incidents so, still working on reproducing the issue.

1) You start multiple ""nodes"" but the admin-ui does not show all of them but logs do
2) By restarting the ""missing"" nodes they eventually show up in the Admin UI

",XD-2866,Gunnar Hillert,Admin UI does not show all containers
897,Marius Bogoevici,Marius Bogoevici,"This causes the following exception to be thrown in the log (without functional adverse effects)

org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'unknown.channel.name'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:43)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$AutoAcknowledgingChannelForwardingMessageListener.doOnMessage(KafkaMessageDrivenChannelAdapter.java:172)
	at org.springframework.integration.kafka.listener.AbstractDecodingMessageListener.onMessage(AbstractDecodingMessageListener.java:50)
	at org.springframework.integration.kafka.listener.QueueingMessageListenerInvoker.run(QueueingMessageListenerInvoker.java:121)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 13 more

",XD-2865,Marius Bogoevici,Message Bus: Shut down Kafka Consumers completely before unbinding
898,David Turanski,David Turanski,"I had a custom module with a typo:
base_packages=base_packages=com.acme.config

The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",XD-2864,David Turanski,JavaConfiguredModule should throw an exception when no @Configuration class is present 
899,Sabby Anandan,Gunnar Hillert,Add the ability to provide job parameters when scheduling jobs,XD-2863,Gunnar Hillert,When Scheduling a Job I cannot provide Job parameters
900,Sabby Anandan,Gunnar Hillert,"Provide place holder text if tables don't have items. E.g.:

""No definitions found""

",XD-2862,Gunnar Hillert,UI: Provide place holder text if tables don't have items
901,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the admin is started with the different management port (default is the same as that of admin http port), then the leadership is requested when the management context is setup. The leadership election should happen only using the Admin server application context.

With this, the following exception is thrown when deployment requests are handled:

2015-03-24 21:48:26,340 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000004
org.springframework.xd.dirt.server.admin.deployment.DeploymentException: testStream
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)
	at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)
	at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:73)
	at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)
	at org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)
	at org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)
	at org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)
	at org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.
	at org.springframework.util.Assert.notNull(Assert.java:112)
	at org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161)
	... 17 more",XD-2861,Ilayaperumal Gopinathan,Admin leader election issue when using different management port
902,Eric Bottard,Mark Fisher,"This method should be replaced with a utility method in a test support class so that it is only available in a testing context.
",XD-2860,Mark Fisher,remove ModuleDefinitions.dummy()
903,Gunnar Hillert,Gunnar Hillert,*http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*,XD-2859,Gunnar Hillert,UI: Deploy Stream - Return key does not submit form
904,Eric Bottard,Sabby Anandan,"As a developer, I'd like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1). 

(0):
{code}
/lib/*.jar:lib/${distro}/*.jar
{code}

(1):
{code}
${xd.home}/lib/hadoop/${distro}/*.jar
{code}

*Example:*
{code}
http | hdfs --distro=PHD22

http | myCustomModule --classpath=/my/funky/dir

http | jpa --provider=eclipse

jpa:
/config/
/lib/something-that-is-common.jar
    /eclipse/eclipse-link-3.2.jar
    /hibernate/hibernate-core-5.0.jar

module.classpath = /lib/*.jar:/lib/${provider}/*.jar
{code}",XD-2858,Sabby Anandan,Add dynamic classpath support for modules
905,Eric Bottard,Sabby Anandan,"As a developer, I'd like to remove Hadoop dependencies from root classpath, so we don't have to incur the penalty of classloading unnecessary libraries at the startup time.

The goal is to at least try and decouple for situations when HDFS is not used for module registry. ",XD-2857,Sabby Anandan,Remove Spark/Hadoop dependencies from root classpath
906,David Turanski,Karol Dowbecki,"When Spring XD is started as a service using {{service spring-xd-container start}} the deploy-working-dir in GemFire module is resolved to the top-most directory (on Linux ""/""). This directory is not writable by spring-xd user under which the process is executed.

When a stream using GemFire is created e.g. {{stream create --name gfTest --definition ""time | gemfire-json-server ...}} following exception will be thrown:

{code}
[error 2015/03/24 15:55:20.798 GMT  <DeploymentsPathChildrenCache-0> tid=0x34] Error when attempting to deploy JAR files on load.
java.io.IOException: Unable to write to deploy directory
	at com.gemstone.gemfire.internal.JarDeployer.verifyWritableDeployDirectory(JarDeployer.java:589)
	at com.gemstone.gemfire.internal.JarDeployer.loadPreviouslyDeployedJars(JarDeployer.java:68)
	at com.gemstone.gemfire.internal.cache.GemFireCacheImpl.init(GemFireCacheImpl.java:839)
	at com.gemstone.gemfire.internal.cache.GemFireCacheImpl.create(GemFireCacheImpl.java:620)
	at com.gemstone.gemfire.cache.client.ClientCacheFactory.basicCreate(ClientCacheFactory.java:207)
	at com.gemstone.gemfire.cache.client.ClientCacheFactory.create(ClientCacheFactory.java:162)
	at org.springframework.data.gemfire.client.ClientCacheFactoryBean.createCache(ClientCacheFactoryBean.java:93)
	at org.springframework.data.gemfire.CacheFactoryBean.init(CacheFactoryBean.java:271)
	at org.springframework.data.gemfire.CacheFactoryBean.getObject(CacheFactoryBean.java:455)
	at org.springframework.data.gemfire.CacheFactoryBean.getObject(CacheFactoryBean.java:77)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:168)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1517)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:251)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1469)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1214)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:743)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{code}

deploy-working-dir should be set to a directory which writable by spring-xd user (maybe java.io.tmpdir?).",XD-2856,Karol Dowbecki,deploy-working-dir is set to to root directory when container is started as service
907,Ilayaperumal Gopinathan,Karol Dowbecki,"After enabling admin endpoint security in servers.yml using basic authentication and single user
{code}
spring:
  profiles: admin
security:
  basic:
    enabled: true # false to disable security settings (default)
    realm: SpringXD
  user: # valid only if security.basic.enabled=true
    name: myadmin
    password: myadmin
{code}

Spring XD UI is secured however xd-shell commands are resulting in a 403 error:

{code}
server-unknown:>admin config server --uri http://localhost:9393 --username myadmin --password myadmin
Successfully targeted http://localhost:9393
xd:>admin config info
  -------------  -------------------------------------------
  Credentials    [username='myadmin, password=****']
  Result         Successfully targeted http://localhost:9393
  Target         http://localhost:9393
  Timezone used  Greenwich Mean Time (UTC 0:00)
  -------------  -------------------------------------------
xd:>stream list
Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden
xd:>stream create --name ""t1"" --definition ""time | log""
Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden
{code}

This can be fixed by adding configuration explained in ""File based authentication"" docs section:

{code}
xd:
  security:
    authentication:
      file:
        enabled: true
        users:
            myadmin: myadmin, ROLE_VIEW, ROLE_ADMIN, ROLE_CREATE
{code}

Following is the problem:
# Configuration explained in ""Single user authentication"" chapter should work out of the box without additional role setup
# Docs should be more clear on authorization",XD-2855,Karol Dowbecki,Basic security makes xd-shell throw 403 Forbidden error
908,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Following exception is thrown when starting XD admin withe ZK holding the stream data:

2015-03-23 17:21:13,831 1.2.0.SNAP ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception
java.lang.NullPointerException
at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:822)
at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:896)
at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:157)
at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:56)
at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:654)
at org.springframework.xd.dirt.stream.dsl.ChannelNode.resolve(ChannelNode.java:144)
at org.springframework.xd.dirt.stream.dsl.SourceChannelNode.resolve(SourceChannelNode.java:54)
at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:125)
at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:110)
at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:121)
at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84)
at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101)
at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.recalculateStreamStates(DefaultDeploymentStateRecalculator.java:96)
at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.onSupervisorElected(DefaultDeploymentStateRecalculator.java:182)
at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:468)
at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)
at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)
at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)
at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)
at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)
at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)
at java.util.concurrent.FutureTask.run(FutureTask.java:262)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
at java.util.concurrent.FutureTask.run(FutureTask.java:262)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)",XD-2854,Ilayaperumal Gopinathan,Launching XD admin fails with ZK holding existing stream data
909,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The ZK distributed queue consumer is initialized even before the module, stream, job deployment requests path cache are started. This could lead to issue when the consumer start processing the requests before the cache are initialized.

On such scenario, the following exception could be thrown:

2015-03-23 21:00:25,919 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000002
org.springframework.xd.dirt.server.admin.deployment.DeploymentException: dataSender
        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)
        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)
        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)
        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)
        at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)
        at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:70)
        at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)
        at org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)
        at org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)
        at org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)
        at org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.
        at org.springframework.util.Assert.notNull(Assert.java:112)
        at org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)
        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161)",XD-2853,Ilayaperumal Gopinathan,XD admin ZK distributed queue consumer initialization issue
910,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to create a _gpload_ tasklet, so I can ingest data from various sources into GPDB in an efficient manner.",XD-2852,Sabby Anandan,Create a gpload batch job
911,Patrick Peralta,Patrick Peralta,"Modules are loaded in the container as such (in DeploymentListener):

{code}
try {
	module = (ModuleType.job.toString().equals(moduleType)) ?
			deployJobModule(client, unitName, moduleLabel, properties) :
			deployStreamModule(client, unitName, moduleType, moduleLabel, properties);
	if (module == null) {
		status = new ModuleDeploymentStatus(container, moduleSequence, key, ModuleDeploymentStatus.State.failed,
				""Module deployment returned null"");
	}
	else {
		status = new ModuleDeploymentStatus(container, moduleSequence, key,
				ModuleDeploymentStatus.State.deployed, null);
	}
}
catch (Exception e) {
	status = new ModuleDeploymentStatus(container, moduleSequence, key, ModuleDeploymentStatus.State.failed,
			ZooKeeperUtils.getStackTrace(e));
	logger.error(""Exception deploying module"", e);
}

try {
	writeModuleMetadata(client, module, path);
	client.setData().forPath(status.buildPath(), ZooKeeperUtils.mapToBytes(status.toMap()));
}
catch (KeeperException.NoNodeException e) {
	logger.warn(""During deployment of module {} of type {} for {} with sequence number {},"" +
					""an undeployment request was detected; this module will be undeployed."", moduleLabel,
			moduleType, unitName, moduleSequence);
	if (logger.isTraceEnabled()) {
		logger.trace(""Path "" + path + "" was removed"", e);
	}
}
{code}

The problem is if an {{Error}} is thrown, such as {{NoClassDefFoundError}} or {{NoSuchMethodError}}. We need to make a best effort when writing the deployment status to prevent the supervisor from timing out waiting for a status.",XD-2851,Patrick Peralta,Module loading error handling improvement
912,Gunnar Hillert,Sabby Anandan,"As a developer, I'd like to use an efficient approach to read files, so I don't have to read line-by-line and keep it in-memory in order to consume/write the file content. 

Would the _tasklet_ approach be better as opposed to transmitting data via message bus (as streams)? ",XD-2850,Sabby Anandan,Create a File source to efficiently read files
913,David Turanski,Sabby Anandan,"As a developer, I'd like to create a end-to-end Kafka use-case, so I can study, demonstrate, and verify kafka + xd play that's built for scale and performance.",XD-2849,Sabby Anandan,Create a POC for end-to-end Kafka use-case
914,Glenn Renfro,Glenn Renfro,"Provide design for how we are going to run XD and Kafka on Rackspace.  This includes the base design for the Kafka Perf tests environment.
This will be used to provide a budget for the cloud resources  for the performance environment.  ",XD-2848,Glenn Renfro,Design and budget Perf Env for XD on RackSpace
915,Thomas Risberg,Janne Valkealahti,"In SqoopRunner we manually set rm address, fs address and yarn classpath. YarnConfiguration.RM_SCHEDULER_ADDRESS is also needed for appmaster to function properly.

Current workaround is to use config values which gets imported automatically:
{code}
spring:
    hadoop:
        config:
            yarn.resourcemanager.scheduler.address: <host>:8030
{code}
",XD-2847,Janne Valkealahti,SqoopRunner should use resource manager scheduler option
916,,Eric Bottard,"See conversation at https://github.com/spring-projects/spring-xd/pull/1509

Several source modules leverage a poller, with `fixedDelay` being a common name for one of the options.

There is actually PeriodicTriggerMixin available, which should be applied to all modules, to make sure configuration is harmonized.

See https://github.com/spring-projects/spring-xd/pull/1384/files

At the time of writing:
{noformat}
grep -r '<poller' . --include='*.xml' | grep -v build
./modules/source/file/config/file.xml:		<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS""/>
./modules/source/jdbc/config/jdbc.xml:		<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS"">
./modules/source/mail/config/mail.xml:			<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS"">
./modules/source/sftp/config/sftp.xml:		<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS"" />
./modules/source/time/config/time.xml:		<poller trigger=""fixedDelayTrigger"" />
{noformat}
",XD-2846,Eric Bottard,Harmonize poller configuration
917,Ilayaperumal Gopinathan,Sabby Anandan,"As a developer, I'd like to setup UI infrastructure, so I can integrate admin_ui and Flo.",XD-2845,Sabby Anandan,Add support for admin-ui and Flo integration 
918,Janne Valkealahti,Sabby Anandan,"As a user, I'd like to have the OOTB _gpfdist_ sink module, so I can use this module to do ultra fast data movement from various sources into GPDB/HAWQ.",XD-2844,Sabby Anandan,Create a POC for gpfdist sink
919,Marius Bogoevici,Marius Bogoevici,"As a Spring XD user, I want to have the ability to customize the encoders and decoders used by the Kafka source, sink and bus, so that I can customize data formats and choose the most appropriate strategy",XD-2843,Marius Bogoevici,"Ability to configure encoders and decoders for the Kafka source, sink and bus"
920,Marius Bogoevici,Marius Bogoevici,"Currently, the Kafka source uses a StringDecoder by default - which is an invalid assumption if the payload is not the result of String conversion.

 ",XD-2842,Marius Bogoevici,Kafka source should not try to decode payloads as Strings
921,Michael Minella,Ilayaperumal Gopinathan,"When the job module is configured using java config, there seems to be some issue with the way out of the box job event listeners are created.

Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/1506",XD-2841,Ilayaperumal Gopinathan,Investigate job event listeners when the job is created as java config
922,,Sabby Anandan,"As a developer, I'd like to rebalance partitions as we scale the containers, so I don't have to bring down the running stream/job to reestablish dynamic partitions.",XD-2840,Sabby Anandan,Research how to accommodate dynamic partitions when scaling containers
923,,Sabby Anandan,"As a developer, I'd like to host/read Python script (file) from HDFS, so I can use the shell processor in XD (on CF) to delegate data science functionality to Py runtime and receive the feedback back in XD.",XD-2839,Sabby Anandan,Add support to host/read python script from HDFS
924,Ilayaperumal Gopinathan,Sabby Anandan,"As a developer, I'd like to update all the module docs to also include _shortDescription_ so that it's available for users to learn more about the module.",XD-2838,Sabby Anandan,"Update all the module documentation to include ""shortDescription"""
925,Ilayaperumal Gopinathan,Glenn Renfro,"When starting xd-admin getting the following exception:
{noformat}
2015-03-20 14:25:53,904 1.2.0.SNAP  WARN main annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)
	at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)
	... 22 more
Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:190)
	at org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)
	at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)
	at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)
	... 25 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 32 more
2015-03-20 14:25:53,911 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)
	at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)
	... 22 more
Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:190)
	at org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)
	at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)
	at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)
	... 25 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 32 more
2015-03-20 14:25:53,915 1.2.0.SNAP ERROR main server.AdminServerApplication - Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
{noformat}

Reproduced Locally (mac) and on EC2.
xd-singlenode works fine.
Commit: 4673b5ab97",XD-2837,Glenn Renfro,XD-Admin fails to start
926,,Eric Bottard,,XD-2836,Eric Bottard,xd-admin broken for HDFS module registry
927,,Sabby Anandan,"As a developer, I'd like to continue XD-on-Lattice/Diego PoC, and will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. ",XD-2835,Sabby Anandan,XD on Lattice POC
928,Mark Pollack,Eric Bottard,"Following the recent move of the doco to the main repo, it makes sense to have the doc generation be part of the ""main"" build, at an early stage, as an incentive for developers to push doc changes as soon as they change the code.

",XD-2834,Eric Bottard,Make doc generation part of the standard build
929,Eric Bottard,Eric Bottard,,XD-2833,Eric Bottard,Document MongoDB source
930,David Turanski,Sabby Anandan,"As a developer, I'd like to create a custom job module using Java Config so that I don't have to deal with XML configurations. While deploying/launching the following job, I get the error attached below.

{code:xml}
job create --name CDK_Global --definition ""customBatchJob"" --deploy
module upload --type job --name customBatchJob --file /Users/mminella/Documents/IntelliJWorkspace/CustomBatchModule/build/libs/CustomBatchModule-1.1.0.RELEASE.jar
job launch --name CDK_Global
{code}

*Error:*
I'm getting an exception that the job doesn't exist asking if it's deployed",XD-2832,Sabby Anandan,Add support to create custom jobs using Java Config
931,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"This is an improvement ticket to address refactoring of XD dirt classes especially XD admin(zk, deployment related) and container.",XD-2831,Ilayaperumal Gopinathan,Refactor Deployment related classes in XD DIRT
932,Gunnar Hillert,Mark Pollack,This keeps coming up as an issue that prevents us from publishing to maven central.,XD-2830,Mark Pollack,Create gradle task to check that all projects have descriptions
933,Gary Russell,Stephane Gamard,"Thanks to Gary I found this little gem of documentation to be able to use xpath expression in XD. Only hiccup is that I had to also add the spring-xml.jar to the classpath (otherwise it is missing XPathException class). 

http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload",XD-2829,Stephane Gamard,Add the Dependencies Required to Use #xpath in Streams
934,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"There are test failures running XD distributed tests. 

It looks like all the test failures are related to NPE on DeploymentProperties format:

java.lang.NullPointerException
	at org.springframework.xd.rest.domain.support.DeploymentPropertiesFormat.formatDeploymentProperties(DeploymentPropertiesFormat.java:72)
	at org.springframework.xd.rest.client.impl.JobTemplate.deploy(JobTemplate.java:71)
	at org.springframework.xd.distributed.test.JobStateTests.testJobStateTransition(JobStateTests.java:83)",XD-2828,Ilayaperumal Gopinathan,XD distributed tests are broken
935,,David Turanski,"A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify/enhance property configuration.  With @Configuration modules, these may now be beans in the module context. ",XD-2827,David Turanski,"Enable @Value, etc in Module Options Metadata"
936,Glenn Renfro,Mark Pollack,Not going to integrate with Reactor for stream processing.,XD-2826,Mark Pollack,Remove Reactor Stream processor from ref docs to spring-xd-modules
937,David Turanski,David Turanski,"This apparently is not tested or used internally, but I expect it to fail having tried a similar approach to derive the class of a generic type in a different situation. This method does not always work due to type erasure http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime.  We need to verify if this is working, if not fix it. The API may require it, so possibly UnsupportedOperationException... 

{code}
/**
   * Infers the type from this class's generic type argument
   * @param kryo
   * @param input
   * @return
 */
protected T doDeserialize(Kryo kryo, Input input) {
	Class<T> type = (Class<T>) (
				(ParameterizedType) this.getClass().getGenericSuperclass()).getActualTypeArguments()[0];
		return doDeserialize(kryo, input, type);
}
{code}",XD-2825,David Turanski,SCS - Verify/Fix AbstractKryoMultitypeCodec implementation
938,Janne Valkealahti,Thomas Risberg,"Scenario running a ""rabbit | hdfs"" stream and killing the xd-container while stream is running.

Looks like the messages get's acked before the data is flushed to hdfs.

This results in some data lost due to data either in tmp file or cached in the dfs client.

Reference: VESC-387",XD-2824,Thomas Risberg,hdfs sink loses messages/data when container killed
939,David Turanski,David Turanski,"Currently when modules are composed to a single application context, properties are not inherited.

https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules

",XD-2823,David Turanski,"Composite Modules should inherit ""xd.*"" properties"
940,,Mark Pollack,"The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop's DataStoreWriter implementations, such as partitioning.

Update the jdbchdfs job to use <int-hadoop:store-writer/> (similar to the HDFS Sink) inside a new ItemWriter implementation

",XD-2822,Mark Pollack,Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter
941,Michael Minella,Sabby Anandan,"As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. 

This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD-2486 needs reafctored. ",XD-2821,Sabby Anandan,Refactor job-launcher to not depend on execution context
942,David Turanski,Karol Dowbecki,"Composing ""transform"" and ""gemfire-json-server"" modules leads to FileNotFoundException during stream deployment when:
- xd-admin and xd-container are started as system services (after installing from RPM). 
- xd-singelonde is started outside of $XD_HOME/bin directory e.g. {code}
$ cd ""$XD_HOME""
$ bin/xd-singelonde
{code}

but it's fully working and exception is *not* thrown when:
- xd-singlenode script is started from within ""$XD_HOME/bin directory {code}
$ cd ""$XD_HOME/bin""
$ ./xd-singelonde
{code}

Then using the XD Shell:

{code}
$ xd-shell
> module compose --name ""cm-gem-sink"" --definition ""transform --outputType='application/json' | gemfire-json-server --regionName=timeRegion --keyExpression=payload.getField('location')""
> stream create --name ""cm-test-gem"" --definition ""tail --name='/tmp/time.json' | cm-gem-sink"" 
> stream deploy --name ""cm-test-gem""
{code}

Stream deployment will result in following exception

{code}
[2015-03-11 16:38:10.918] boot - 17402  INFO [DeploymentsPathChildrenCache-0] --- DeploymentListener: Deploying module [ModuleDescriptor@2095e9f9 moduleName = 'tail', moduleLabel = 'tail', group = 'cm-test-gem', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['name' -> '/tmp/time.json'], children = list[[empty]]]
2015-03-11 16:38:11,263 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'cm-test-gem': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)
Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)
Offending resource: file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/modules/sink/gemfire-json-server/config/gemfire-json-server.groovy]; nested exception is org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)
Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
	at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)
	at org.springframework.xd.module.core.CompositeModule.initialize(CompositeModule.java:105)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)
Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)
	at beans$_run_closure1.doCall(beans:4)
	at beans$_run_closure1.doCall(beans)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at groovy.lang.Closure.call(Closure.java:423)
	at groovy.lang.Closure.call(Closure.java:417)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)
	at groovy.lang.Closure.call(Closure.java:439)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)
	at beans.run(beans:1)
	at groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)
	... 30 more
Caused by: java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at java.io.FileInputStream.<init>(FileInputStream.java:101)
	at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)
	at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)
	at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)
	at org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)
	... 80 more
{code}

Exporting XD_HOME as a global variable seems to have no effect on this behavior.",XD-2820,Karol Dowbecki,Composing transformer and gemfire-json-server leads to FileNotFoundException during deployment
943,Eric Bottard,Karol Dowbecki,"Please see ""Deployment"" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/#_module_deployment page. 

!broken-link-deployment.png!

The link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/Deployment which is a 404.",XD-2819,Karol Dowbecki,"Broken ""Deployment"" link in docs"
944,,David Turanski,./gradlew install fails for spring-xd-extension-batch and spring-xd-extension-reactor. The first case is a simple update to gradle/build-extensions.gradle. The 2nd causes several compilation errors that are not trivial for a Reactor noob.  ,XD-2818,David Turanski,upgrade to io.projectreactor breaks generated POMS
945,David Turanski,Frederico Melo,"The GemFire client for SpringXD is throwing java.lang.NoClassDefFoundError for the class com/gemstone/gemfire/cache/client/internal/PingOp after a Stream sinking to gemfire-json-server is destroyed.

Issue starts after destroying a stream, which makes me think we might be unloading the jar files from the classpath while still keeping a connection to the gemfire server.

Steps to reproduce:

1) Create a region in Gemfire to test

e.g.: gfsh>create region --name=Stocks --type=REPLICATE
Member  | Status
------- | -------------------------------------
server1 | Region ""/Stocks"" created on ""server1""


2) Create a simple stream in Spring XD that writes to that region in gemfire-json-server. Deploy it for single node and let it run for a few seconds.


e.g.:

XD$ stream create streamx --definition ""trigger --fixedDelay=3 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\""MSFT\"")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote') | gemfire-json-server --useLocator=true --host=localhost --port=10334 --regionName=Stocks --keyExpression=payload.getField('Symbol')"" --deploy


3)  Destroy the stream

e.g.:
XD$  stream destroy streamx

3)  Wait a few seconds and check the xd-singlenode output.. you'll see the exception as following:

[error 2015/03/13 11:04:52.437 PDT  <poolTimer-client-pool-14> tid=0x15a] Unexpected error in pool task <com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask@635c9341>
java.lang.NoClassDefFoundError: com/gemstone/gemfire/cache/client/internal/PingOp
	at com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask.run2(LiveServerPinger.java:83)
	at com.gemstone.gemfire.cache.client.internal.PoolImpl$PoolTask.run(PoolImpl.java:1197)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at com.gemstone.gemfire.internal.ScheduledThreadPoolExecutorWithKeepAlive$DelegatingScheduledFuture.run(ScheduledThreadPoolExecutorWithKeepAlive.java:252)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)",XD-2817,Frederico Melo,Classpath issues with gemfire-json-server sink
946,,Thomas Darimont,"It should be possible to configure a (short) description for a module that is display above the module options 
via {{module info --name ....}}.

The description could contain a few lines describing the core functionality and potentially hyperlinks 
to additional information for a module.

This information should be exposed via the REST interface as well.

Currently only the module options are printed.",XD-2816,Thomas Darimont,Add 'about section' to module description.
947,Michael Minella,Sabby Anandan,"As a user, I'd like to use a _jdbchdfs_ batch job as a passthrough (without chunk processing) so that I don't have to incur the batch read/write overhead.",XD-2815,Sabby Anandan,Improve the performance of jdbchdfs batch job
948,Gary Russell,Jason Hubbard,"If automatic binding of dead letter is enabled for rabbit mq and taps are deployed, anytime the tap is undeployed, the dead letter for that tap still remains.  The tap uses a unique name and the queue for that is automatically deleted, but the dead letter queue for it is not.  This problem becomes worse when containers are running in yarn and may not live for long periods of time.  Many dead letter queues for taps can become overwhelming.",XD-2814,Jason Hubbard,RabbitMQ Dead Letter for TAP not deleted
949,,Thomas Risberg,Similar to Sqoop where we move data from RDBMS to HDFS we should look at integrating with Camus to load data from Kafka to HDFS.,XD-2813,Thomas Risberg,Investigate running Camus as a batch job
950,,Buelent Zeyben,"The Batch Jobs Deployment screen 
('http://*****************:9393/admin-ui/#/jobs/deployments') UI screen is only showing 10 items without pagination and prohibiting users from launching their deployed jobs from the UI.

The jobs can only be launched via the RESTApi call

In release 1.0.3 the deployment page has not pagination but grows beyond 10 entries.",XD-2812,Buelent Zeyben,Batch Job deployment screen only show 10 items...
951,,Buelent Zeyben,"Deployed component s are not deployed to the containers that failed and restarted. 

We have 3 containers and 3 jobs where all jobs are deployed evenly, one job per container. However, when two of the containers fail and come back up, we end up with 3 jobs on 1 container.  See attached document for detail. 
",XD-2811,Buelent Zeyben,deployed modules are not redeployed properly once the container come back online
952,Michael Minella,Buelent Zeyben,"The jdbchdfs jobs that are partitioned are running in sequence rather than in parallel. Our expectation with partition jobs is that they run in parallel.

Job configuration is:

jdbchdfs --driverClassName='oracle.jdbc.OracleDriver' --url='jdbc:oracle:thin:@=**********' --username='=**********' --password=********** --validationQuery='SELECT CURRENT_TIMESTAMP FROM DUAL' --tableName='HZ_ORGANIZATION_PROFILES' --columns='ORGANIZATION_PROFILE_ID, ..., VERSION_NUMBER' --partitions=10 --partitionColumn='ORGANIZATION_PROFILE_ID' --directory='/ingest/source/oracle11i/ar/hz_organization_profiles' --fileName=hz_organization_profiles --fileExtension=csv --delimiter=| --commitInterval=10000 --rollover=262144000 --dateFormat=yyyy-mmm-dd --partitionResultsTimeout=1800000 --testOnBorrow=false
",XD-2810,Buelent Zeyben,partition jobs (jdbchdfs) are running in sequence
953,Michael Minella,Buelent Zeyben,"The 'partitionResultsTimeout' parameter for jdbchdfs job definition cannot be set for the master step if the job has a partition definition.

The partitionResultsTimeout is set for the individual partition steps only. The master steps fails after the default timeout.",XD-2809,Buelent Zeyben,jdbdhdfs job definition parameter 'partitionResultsTimeout' issues
954,,Jason Hubbard,"When setting an active property via SPRING_PROFILES_ACTIVE environment variable the profile set ContainerServerApplication or AdminServerApplication is ignored.

ConfigFileApplicationListener in spring boot has an if else in the load method which skips adding the additional properties added to the StandardEnvironment if the environment variable exists.

This could be a bug for Spring Boot, but I wasn't sure if the mutual exclusion was intentional.  Additionally it would be nice to know when this feature is included in spring xd if it is a spring boot bug.",XD-2808,Jason Hubbard,Setting active profiles drops contiainer/admin profile
955,Eric Bottard,Eric Bottard,"The build has some inconsistencies that should be taken care of.
Amongst the one I know:

* The UI project is always getting cleaned, for no apparent reason (there might have been one before), thus triggering a rebuild of everything downstream, most notably DIRT
* The “exec"" task is not used anymore
* Lots of projects are getting the boot plugin applied to them. I'm not sure 100% what that plugin does, but we don't need the repackage bit for example.",XD-2807,Eric Bottard,Fix gradle build inconsistencies and leftovers
956,,Mark Fisher,"{code}
xd:> stream create test --definition ""http | t1:transform --expression=payload | log""
xd:>stream deploy test --properties module.t1.count=2
Deployed stream 'test'
xd:>runtime modules
  Module Id            Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status
  -------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------
  test.processor.t1.1  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=1, consumer.count=1, sequence=1}  deployed
  test.sink.log.1      f6bb3189-9c0e-44e8-962b-025e2288ffe3  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed
  test.source.http.1   f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=1, count=1, sequence=1}                                         deployed
{code}

*************************************
Works fine without the label:
*************************************
{code}
xd:>stream destroy test
Destroyed stream 'test'
xd:>stream create test --definition ""http | transform --expression=payload | log""
Created new stream 'test'
xd:>stream deploy test --properties module.transform.count=2
Deployed stream 'test'
xd:>runtime modules
  Module Id                   Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status
  --------------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------
  test.processor.transform.1  f6bb3189-9c0e-44e8-962b-025e2288ffe3  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=2, consumer.count=2, sequence=1}  deployed
  test.processor.transform.2  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=2, producer.next.module.count=1, count=2, consumer.count=2, sequence=2}  deployed
  test.sink.log.1             393d3af0-68e8-49b2-8601-da063cfbf98a  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed
  test.source.http.1          f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=2, count=1, sequence=1}                                         deployed
{code}",XD-2806,David Turanski,Module count not respected when label is used
957,,Sabby Anandan,"As a user, I'd like to add the Hadoop _namenode_ specifics in a config file so that I don't have to incur the hassle of pointing to the _namenode_ location every time I open a new DSL session, but it is automatically configured. ",XD-2805,Sabby Anandan,"Add support to include ""namenode"" address from a config file"
958,,Karol Dowbecki,"Spring XD 1.1 container will throw following exception: 
{code}
java.lang.IllegalStateException: Can't find class used for type of option 'myField': String 
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:147)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:202)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174)
	at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)
	...
{code}

when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myField.type value):

{code}
options.myField.description = this is my field
options.myField.type = String 
{code}

Can the property values be trimmed before comparing to DefaultModuleOptionsMetadataResolver#SHORT_CLASSNAMES map  to avoid this problem?",XD-2804,Karol Dowbecki,Module options are not trimmed
959,Michael Minella,Buelent Zeyben,"Allow users to submit a configuration file as part of the job definition.

The configuration file should contain all job definition parameters as well as customer parameters that can be reference during runtime.

Thanks,
Buelent
 ",XD-2803,Buelent Zeyben,Custom User Configuration file for Jobs
960,,Sabby Anandan,"As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. ",XD-2802,Sabby Anandan,Migrate wiki documentation and the chores
961,Glenn Renfro,Glenn Renfro,Mask out all properties for XD-EC2,XD-2801,Glenn Renfro,Updated XD-EC2 XD deployment for 1.2
962,Marius Bogoevici,Marius Bogoevici,,XD-2800,Marius Bogoevici,Add support for time/sequence-size windowed offset updates
963,Marius Bogoevici,Marius Bogoevici,,XD-2799,Marius Bogoevici,Expose bean settings as configuration options to the Kafka source and bus
964,Marius Bogoevici,Marius Bogoevici,,XD-2798,Marius Bogoevici,Redis and In-memory offset storage profiles for the kafka source have wrong definitions
965,Patrick Peralta,Sabby Anandan,"As a developer, I'd like to continue Lattice/Diego POC so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.",XD-2797,Sabby Anandan,Lattice Design Spike
966,,Sabby Anandan,"As a PM, I'd like to have a static _gh_pages_ to organize the collateral such as samples, tutorials, links, perf. benchmarks and ref. architectures so that it's easy for anyone to quickly get up and running on XD.",XD-2796,Sabby Anandan,"Create ""gh-pages"" to organize samples, links and tutorials"
967,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput.
",XD-2795,Sabby Anandan,Measure performance baseline for a simple stream
968,Eric Bottard,Abhinav,"As a developer, I'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo.",XD-2794,Abhinav,Add a MongoDB source
969,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to fix the offset management with Kafka _source_ module so that I can efficiently perform fetch operation from the given offsets.",XD-2793,Sabby Anandan,Fix offset management for Kafka source
970,,Sabby Anandan,,XD-2792,Sabby Anandan,Automate provisioning story for XD
971,David Turanski,Sabby Anandan,"As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime features/functionality.

The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.",XD-2791,Sabby Anandan,Complete CI setup for Windows
972,,David Turanski,"Currently it is necessary to specify mappedRequestHeaders=*  on the rabbit sink, otherwise no headers are mapped to AMQP.  This should be the default behavior.",XD-2790,David Turanski,Rabbit source and sink mappedRequestHeaders should include all headers by default
973,,Glenn Renfro,"used module upload for processor:payload-conversion (from XD samples)
All worked well until I tried to delete the module.
customModule in servers.yml was set to:
xd:
  customModule:
    home: file://c:/project/mymodulehome

StackTrace:
{noformat}
2015-03-06 01:54:33,460 1.1.0.RELEASE ERROR qtp1891077689-37 rest.RestController
Advice - Caught exception while handling a request
java.lang.IllegalArgumentException: Could not delete module 'processor:payload-c
onversion'
        at org.springframework.util.Assert.isTrue(Assert.java:65)
        at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod
uleDefinitionService.java:121)
        at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont
roller.java:155)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.springframework.web.method.support.InvocableHandlerMethod.doInvok
e(InvocableHandlerMethod.java:221)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeF
orRequest(InvocableHandlerMethod.java:137)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl
eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH
andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH
andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt
er.handle(AbstractHandlerMethodAdapter.java:85)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch
erServlet.java:943)
        at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche
rServlet.java:877)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame
workServlet.java:966)
        at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe
rvlet.java:890)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer
vlet.java:842)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684
)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1496)
        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf
iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf
iguration.java:291)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna
l(HiddenHttpMethodFilter.java:77)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter
nal(HttpPutFormContentFilter.java:87)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter
Internal(WebRequestTraceFilter.java:100)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi
lterChainProxy.java:186)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai
nProxy.java:160)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig
uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:499)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:137)
        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:557)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:231)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:1086)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
428)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:193)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:1020)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:135)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:116)
        at org.eclipse.jetty.server.Server.handle(Server.java:370)
        at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac
tHttpConnection.java:494)
        at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra
ctHttpConnection.java:971)
        at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header
Complete(AbstractHttpConnection.java:1033)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)

        at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti
on.java:82)
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn
dPoint.java:667)
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd
Point.java:52)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:608)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:543)
        at java.lang.Thread.run(Unknown Source)

{noformat}",XD-2789,Glenn Renfro,module delete on windows throws exception
974,Eric Bottard,Sabby Anandan,"As a developer, I'd like to add load receiving _sink_ module so that I can measure received throughput",XD-2788,Sabby Anandan,Add throughput receiving sink
975,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to add load generator _source_ module so that I could use it for performance testing use-cases. 
",XD-2787,Sabby Anandan,Add load generator source
976,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.",XD-2786,Sabby Anandan,Create EC2 AMI image for performance testing
977,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.
",XD-2785,Sabby Anandan,Identify the Kafka configuration for Kafka performance tests
978,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to research and Identify the EC2 infrastructure required  so that I can run performance tests on Kafka.
",XD-2784,Sabby Anandan,Research EC2 infrastructure required for Kafka performance tests
979,,Paul Harris,"{{p-spring-xd}} defines values for the following parameters in {{servers.yml}}. These values are not being retrieved, and hence have to be manually added to each stream definition.
* {{addresses}}
* {{username}}
* {{password}}
* {{virtual_host}}

(cf XD-2675, XD-2741)",XD-2783,Paul Harris,RabbitMQ server.yml options ignored
980,,Paul Harris,"{{p-spring-xd}} defines values for the following parameters in {{servers.yml}}. These values are not being retrieved, and hence have to be manually added to each stream definition.

* {{url}}
* {{username}}
* {{password}}
* {{driverClassName}}
* {{validationQuery}}

(cf XD-2675, XD-2741)",XD-2782,Paul Harris,PostgreSQL server.yml options ignored
981,,Paul Harris,"We get the following error when trying a rabbit to rabbit stream (definition as shown in the error):

{code}
[STREAM TEST] WARN  Failure during end to end test
org.springframework.xd.rest.client.impl.SpringXDException: XD143E:(pos 141): Label 'rabbit' should be unique but module 'rabbit' (at position 0) and module 'rabbit' (at position 1) both use it
rabbit --queues=cxablknzdhvpotpo-source --addresses=10.85.30.129 --username=bef4412739e7d7fe929e --password=b8ace17e56456b7753a2 --vhost=/ | rabbit --exchange=cxablknzdhvpotpo-sink --addresses=10.85.30.129 --username=bef4412739e7d7fe929e --password=b8ace17e56456b7753a2 --vhost=/
                                                                                                                                             ^
{code}",XD-2781,Paul Harris,Not possible to create a RabbitMQ to RabbitMQ stream
982,,Paul Harris,The documentation for RabbitMQ says to use the --address option to specify a port. We've tried --address=1.2.3.4:5678 (and also --port=5678 just in case) but have been unable to get a successful deployment. Running the same stream definition on a default port (i.e. without specifying a port) does work.,XD-2780,Paul Harris,Unable to define port on RabbitMQ streams
983,Thomas Risberg,Thomas Risberg,"The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception.

We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.",XD-2779,Thomas Risberg,Fix error handling in jdbchdfs job 
984,Gary Russell,Sabby Anandan,"As a developer, I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release.

Perhaps this could be part of [troubleshooting|https://github.com/spring-projects/spring-xd/wiki/Deployment#troubleshooting] section in our wiki.",XD-2778,Sabby Anandan,Document the changes to Message Headers in 1.1
985,Gary Russell,David Turanski,,XD-2777,David Turanski,Document trigger source
986,Mark Pollack,Sabby Anandan,"As a developer, I'd like to bench Kafka as message bus using in-built perf-testing producer/consumer utilities so that I can use that as a foundation to build XD use-cases and measure performance. 

I'd like to reproduce baseline performance metrics as identified by the Kafka [engineering team|https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines].",XD-2776,Sabby Anandan,Reproduce baseline numbers for Kafka
987,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to upgrade to SHDP 2.1.2 GA so that I can sync-up with latest features.",XD-2775,Sabby Anandan,Upgrade to SHDP 2.1.2 GA release
988,Thomas Risberg,Thomas Risberg,"The hdfs sink doesn't recover after error writing to hdfs.

Steps to reproduce -

create a stream using hdfs sink with a small rollover:

{code}
xd:>stream create --name errtest --definition ""time | hdfs --rollover=50"" --deploy 
{code}

stop the datanode(s) and wait for an exception like:

{code}
2015-03-03 10:41:57,832 1.1.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: failed to write Message payload to HDFS; nested exception is org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:129)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy136.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy125.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy137.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy134.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy135.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588)
{code}

start the datanode(s) again, the sink never recovers and has to be undeployed and redeployed.
",XD-2774,Thomas Risberg,Update to SHDP 2.1.1 for fixing hdfs store writer to recover after error writing to hdfs
989,,Karol Dowbecki,"Custom modules that use

{code}
<groupId>org.springframework.xd</groupId>
<artifactId>spring-xd-module-parent</artifactId>
<version>1.1.0.RELEASE</version>
{code}

as a parent will get a ""lib"" directory created in the module root source directory. This forces us to add additional ignores in version control system.

Following Maven convention all build files should be created under ""target"" folder so ""lib"" folder should be created as ""target/lib"".",XD-2773,Karol Dowbecki,spring-xd-module-parent creates resources outside of target folder
990,,Karol Dowbecki,"One can upload a module which doesn't contain ""config"" package with module configuration artifacts (e.g. XML, groovy, properties etc.) using the ""module upload"" command in Spring XD shell. During stream deployment this will result in a cryptic exception:

{code}Mar 02, 2015 10:45:48 PM org.springframework.shell.core.SimpleExecutionStrategy invoke
SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: Multiple top level module resources found :file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/jms-activemq.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/xd-container-logger.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/jms-hornetq.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/xd-singlenode-logger.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/xd-admin-logger.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/httpSSL.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/hadoop.properties]{code}

Root cause is most likely the module ClassLoader setup which delegates to parent ClassLoader which in turn scans $XD_HOME/config directory and discovers a number of properties files.

It would nice if Spring XD would validate the module during ""module upload"" command and prevent uploading of invalid modules.",XD-2772,Karol Dowbecki,No validation for module packaging during module upload
991,David Turanski,Karol Dowbecki,"Spring XD is packaging a spring-xd-dirt dependency which aims to provide runtime libraries.

spring-xd-drit-1.1.0.RELEASE is not providing all libraries from $XD_HOME/lib. See spring-xd-dirt-vs-lib.xlsx attachment generated with ""ls  $XD_HOME/lib"" and ""mvn dependency:list"" on a module with spring-xd-module-parent parent:
- 100+ JARs are not provided
- some are provided in different versions
- some are provided but not available in $XD_HOME/lib

This forces us to add and maintain missing dependencies in our own module parent e.g. to use commons-lang3 in our code which is present in $XD_HOME/lib but is not provided by spring-xd-dirt.

Why there are so many differences between $XD_HOME/lib and spring-xd-dirt?",XD-2771,Karol Dowbecki,spring-xd-dirt is not providing all $XD_HOME/lib libraries
992,Gary Russell,Sergey Shcherbakov,"A LocalMessageBus in singlenode mode has several internal properties that would be useful to monitor at runtime for example via JMX: queueSize, current size of executor's queue (and others).
All fields are currently write-only so it's hard to access them from custom code too.
Public getters would be useful as well as an MBean exposed to JMX.",XD-2770,Sergey Shcherbakov,Access to LocalMessageBus internal state
993,David Turanski,Karol Dowbecki,"In [AbstractSingleNodeNamedChannelSink|https://github.com/spring-projects/spring-xd/blob/6bd17162c8a6da0f09f6f8809f694a060c71ecc0/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/test/sink/AbstractSingleNodeNamedChannelSink.java] the receive() and receivePayload() methods  are non-blocking.

Methods without timeout parameter are usually blocking and return the first message delivered to the channel (e.g. org.springframework.integration.channel.AbstractPollableChannel#receive()). 

Integration tests based on spring-xd-test dependency and embedded xd-singlenode are asynchronous. This makes AbstractSingleNodeNamedChannelSink receive method return null in all invocations because test thread is progressing faster than container can process the message in the background.

Would it be possible to make receive methods behave like in AbstractPollableChannel?",XD-2769,Karol Dowbecki,Inconsistent API in AbstractSingleNodeNamedChannelSink 
994,Eric Bottard,Gary Russell,"Some modules inherit {{application.yml}} / {{servers.yml}} via a properties file in {{/config/modules}} ; others have the values defined in the {{...OptionsMetadata}} classes.

Switch all modules to use the latter technique for consistency.",XD-2768,Gary Russell,Inconsistent Handling of Inherited servers.yml Properties
995,Gary Russell,Gary Russell,"Since the message-driven adapter uses a {{DMLC}}, the default behavior is to lose messages on exceptions (with the DMLC, the message is ack'd before the listener is invoked).

In order to provide recovery of such situations, the source needs to expose {{acknowledge}} so it can be set to {{transacted}}.

Or, perhaps, given that we don't expose complex configuration, the source should use a {{SimpleMessageListenerContainer}} instead (where the ack is sent after the listener is successfully invoked).
",XD-2767,Gary Russell,JMS Source Does Not Expose `acknowledge`
996,Eric Bottard,Eric Bottard,"As a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).",XD-2766,Eric Bottard,Add metadata for description of a module (itself)
997,Michael Minella,Marius Bogoevici,"The current implementation of partitioned job management is entirely based on message exchange over the message bus, in a request reply scenario.
This creates challenges when it comes to using certain types of transports, as well as acknowledging crashes. 
To that effect, the option of using a different partitioned job coordination strategy, that relies on a distributed computing coordination mechanism such as ZooKeeper should be investigated. ",XD-2765,Marius Bogoevici,Spike: Research Zookeeper-based mechanism for partitioned job management
998,Marius Bogoevici,Marius Bogoevici,Test fails in CI when the topic used by the test had its initial segment removed during cleanup.,XD-2764,Marius Bogoevici,Fix failing KafkaSingleNodeStreamDeploymentIntegrationTests.verifyOnDemandQueues()
999,Glenn Renfro,Glenn Renfro,"# Setup Environment 
## Create 1.1.0 XD cluster with 1 admin and 3 containers
## Create 3 node RabbitMQ Cluster
## Associate Each XD Container to a single Rabbit Node.
## All EC2 instances in the same placement group
# Execute the following streams
{noformat}
stream create q1 --definition ""load-generator --messageCount=2000000 > queue:q1"" 
stream deploy q1 --properties ""module.load-generator.criteria=groups.contains('one')""
stream create q2 --definition ""load-generator --messageCount=4000000 > queue:q2"" 
stream deploy q2 --properties ""module.load-generator.criteria=groups.contains('two')""
stream create q3 --definition ""load-generator --messageCount=4000000 > queue:q3"" 
stream deploy q3 --properties ""module.load-generator.criteria=groups.contains('three')""
stream create q4 --definition ""load-generator --messageCount=4000000 > queue:q4"" 
stream deploy q4 --properties ""module.load-generator.criteria=groups.contains('one')""
stream create q5 --definition ""load-generator --messageCount=4000000 > queue:q5"" 
stream deploy q5 --properties ""module.load-generator.criteria=groups.contains('two')""
stream create q6 --definition ""load-generator --messageCount=4000000 > queue:q6"" 
stream deploy q6 --properties ""module.load-generator.criteria=groups.contains('three')""
{noformat}
# use the following rabbitmq perf tests to retrieve benchmark rates
{noformat}
./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q1 -p -x 0 -y 2 -q 500 -z 120 -h amqp://xx1.compute-1.amazonaws.com >q1.txt &
./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q2 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx2.compute-1.amazonaws.com >q2.txt &
./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q3 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx3.compute-1.amazonaws.com >q3.txt &
./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q4 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx1.compute-1.amazonaws.com >q4.txt &
./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q5 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx2.compute-1.amazonaws.com >q5.txt &
./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q6 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx3.compute-1.amazonaws.com >q6.txt &
{noformat}
# Reach out to SME's to identify proper configuration",XD-2763,Glenn Renfro,Create RabbitMQ environment and record baseline results.
1000,Thomas Risberg,Thomas Risberg,"As a build manager, I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. 

*Location for 1.1.0 RELEASE:*
http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/",XD-2762,Thomas Risberg,Update RHEL/CentOS yum/rpm installation instructions
1001,David Turanski,David Turanski,Currently PojoCodec calls kryo.register(Class<?> type) on every ser/deser invocation. This fails with 1.1 because instances are pooled and a different instance may be used to serialize and deserialize.  See https://github.com/EsotericSoftware/kryo#registration.  The fix is to not register classes on the fly. Classes serialized by PojoCodec will not be registered by default. This will work but is less efficient. XD should provide an easy way to register types known to be serialized on the MessageBus (passed between modules),XD-2761,David Turanski,Register only known classes with Kryo in PojoCodec
1002,,Paul Harris,"In xd-shell the command:
{code}
http post
{code}
gives the following output:
{code}
Command failed java.lang.IllegalArgumentException: One of 'file' or 'data' must be set
{code}

I believe the UI should suppress the exception (just removing ' java.lang.IllegalArgumentException') would suffice).",XD-2760,Paul Harris,"""http post"" in CLI gives IllegalArgumentException"
1003,Gary Russell,Gary Russell,"Since 1.1, {{PubSub}} channels in the {{LocalMessageBus}} run on a {{CachedThreadPoolExecutor}}.

For high volume environments, where back-pressure might occur on a {{topic:}} thread we could overwhelm the system with threads.

Add a local bus configuration to limit the thread pool used for PubSubs and queue tasks where there are no threads available.

It would be a bus-wide setting.",XD-2759,Gary Russell,LocalMessageBus PubSub Needs a Bounded Task Exectutor
1004,Eric Bottard,Sabby Anandan,"As  a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition). ",XD-2758,Sabby Anandan,Add module description to the JSON response
1005,,Sabby Anandan,"As a developer, I'd like to have the high-level description for each of the modules so that I can use the description (presumably what is captured in javadoc for the module definition) to understand the purpose of the module itself.
",XD-2757,Sabby Anandan,Return description for each module in the JSON response
1006,Eric Bottard,Paul Harris,"I'd like to use the following command to define a stream in our Spring XD for PivotalCF test environment:

{code}
stream create --name test --definition ""http --port=9999 | jdbc --username=spring-xd --password=spring-xd --driverClassName=org.postgresql.Driver --url=jdbc:postgresql://1.2.3.4:5432/spring-xd""
{code}

I have to add the following options to the definition to make it work (otherwise I get exceptions and a failed deploy):

{code}
-validationQuery='' --validatorClassName='#{null}' --connectionProperties='' --initSQL='' --jdbcInterceptors='' --initializerScript='' 
{code}

Given that they're empty anyway it seems like some or all of these should not be necessary.

_Notes_
* The validatorClassName cannot be '' like the others, it needs the null.
* Without initSQL='' stream creation fails because it can't find init_db.sql (a file I don't have in my environment), even though it won't be run anyway.",XD-2756,Paul Harris,Large number of required options in jdbc sink definition
1007,Ilayaperumal Gopinathan,Marius Bogoevici,"How to reproduce:

1. Run xd-singlenode (for which setting the Spark master URL to 'local' is a requirement). Use more than 1 worker thread. e.g. {{local[4]}}

2. Deploy the word-count example

3. Create a stream
{{stream create spark-streaming-word-count --definition ""http | word-count | log"" --deploy}}

4. Send data
{{xd:>http post --data ""a b c d e f g""}}

{{xd:>http post --data ""a b c""}}

5.Observe the result

2015-02-24 15:12:46,018 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (e,1)
2015-02-24 15:12:46,018 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (d,1)
2015-02-24 15:12:46,019 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b,1)
2015-02-24 15:12:46,020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (g,1)
2015-02-24 15:13:40,020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (a,1)
2015-02-24 15:13:40,020 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b,1)
2015-02-24 15:13:40,021 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (c,1)

(the last three results are coming from the second invocation))

Note: there seems to be a correlation between the number of values emitted and the number of workers, as, in all the attempts, there aren't more values emitted than the number of workers.",XD-2755,Marius Bogoevici,Scala processor module executor trims messages
1008,,Eric Bottard,See discussion at http://stackoverflow.com/questions/28551506/spring-xd-jms-message-bus-with-jms-sink,XD-2754,Eric Bottard,ClassLoading interaction issue between MessageBus and modules
1009,,Thomas Darimont,"Currently new modules can be installed via the module upload command, but for this to work one needs to
build the artifacts beforehand.

It would be great to have support for installing new XD modules from maven coordinates (e.g. from a public or 
controlled maven repository).
With this one would make it easy to consume community modules without much hassle.

This could also serve as some kind of starting ground for some ""special solution packages"" that provides support
for, c.f. natural language processing (via a bunch of jars that contain the modules for language detection, entity detection, sentiment analysis, topic clustering) etc. that could be consumed via some kind of .bom (bill of materials) dependency like:

module install ""pivotal:toolkits:nlp""",XD-2753,Thomas Darimont,Allow to install new XD modules from maven coordinates
1010,Thomas Risberg,Hector Lagos,"Hey Guys,

I'm trying to use a SqoopTasklet but for some reason it is not getting the hadoop configuration. In the attached sqoop job configuration using the sqooprunner class directly works without problems but the SqoopTasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log).  Could please you guys help me to solve this problem?

Thanks in advance.
Regards,",XD-2752,Hector Lagos,SqoopTasklet not using hadoop configuration
1011,,Muhammad Ali,"I am trying to create a simple JDBC|FILE stream with Split=0 at the jdbc source. following is the DSL

stream create --name test --definition ""jdbc --fixedDelay=5 --split=0 --query='select * from top_movie_companies'|file --dir=/tmp --suffix=xd --name=test"" --deploy

It throws 
org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type java.util.ArrayList<?> to type java.lang.String
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:138)

It works fine when I use LOG sink instead of FILE. 

I am assuming that if LOG sink works with JDBC then file should be similar. The converter should be registered out of the box.

It could be something basic I am missing as I'm relatively new to XD.",XD-2751,Muhammad Ali,JDBC | FILE throws ConverterNotFoundException when split=0
1012,Patrick Peralta,Sabby Anandan,,XD-2750,Sabby Anandan,Placeholder for Lattice/Diego POC #2
1013,Mark Fisher,Sabby Anandan,,XD-2749,Sabby Anandan,Placeholder for Lattice/Diego POC #1
1014,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The spark streaming message bus receiver isn't reliable yet. The receiver needs to handle data loss in case of worker node that has it running.

We currently handle the driver failure automatically by re-deploying spark streaming module. But, this is about the data loss when the worker node dies.

Please see the documents here:

https://databricks.com/blog/2015/01/15/improved-driver-fault-tolerance-and-zero-data-loss-in-spark-streaming.html

http://spark.apache.org/docs/latest/streaming-custom-receivers.html",XD-2748,Ilayaperumal Gopinathan,Implement Reliable spark streaming receiver 
1015,Mark Pollack,Sabby Anandan,"As a developer, I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.",XD-2747,Sabby Anandan,Document test scenarios for performance testing
1016,,Glenn Renfro,,XD-2746,Glenn Renfro,JDBC Source Acceptance Tests
1017,,Glenn Renfro,,XD-2745,Glenn Renfro,Spark Streaming Acceptance Tests
1018,Glenn Renfro,Sabby Anandan,,XD-2744,Sabby Anandan,Placeholder for Spring XD Lab
1019,Glenn Renfro,Sabby Anandan,"The scope is to address the sub-tasks linked with this story.
",XD-2743,Sabby Anandan,Improve acceptance testing coverage
1020,Mark Fisher,Sabby Anandan,"As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD.

[Challenge Details|http://www.debs2015.org/call-grand-challenge.html]",XD-2742,Sabby Anandan,Prep for DEBS Challenge
1021,Mark Pollack,Mark Pollack,"The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml.  The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source/sink, jdbc sink....",XD-2741,Mark Pollack,Redis sink should default to using spring.redis configuration in servers.yml
1022,,Dave Protasowski,"There are cases where hdfs-outbound-channel-adapter (from spring-xd-hadoop module) will keep a broken datawriter's stream open.

For example if the underlying HDFS stream throws a RemoteException (ie. some hadoop error occurred) there's no mitigation. Subsequent writes will always fail.

The MessageHandler could potentially try to close and re-open the stream or trigger a rollover strategy to occur (creating a new stream).",XD-2740,Dave Protasowski,HDFS StoreMessageHandlers are not very resilient
1023,Thomas Risberg,Thomas Risberg,,XD-2739,Thomas Risberg,Add a Sqoop example
1024,,Sabby Anandan,"As a user, I'd like to have an optional  arbitrary ""side channels"" created so that when creating a module channels other than the primary stream channels (input, output) could be added to the bus (i.e. creating a tap channel *within* a flow). The optional ""side channels"" can be used to trace/track module progress.",XD-2738,Sabby Anandan,"Add arbitrary ""side channels"" to track module progress"
1025,,Sabby Anandan,"As a user, I'd like to have an optional _trace_ as inline deployment properties for _stream_ so that I can declare which _module_ in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.

*Example:*

{code:xml}
xd:> stream create foo ""http | log""

xd:> stream deploy foo --properties ""module.http.trace,module.log.trace""

(or)

xd:> stream deploy foo --properties ""module.*.trace""
{code}

Wildcard wiretap config: http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap",XD-2737,Sabby Anandan,Add support for global wiretap config
1026,Eric Bottard,Eric Bottard,"Thanks to INT-3624, we don't need our specific class anymore",XD-2736,Eric Bottard,Revert XD specific support for JsonPath 1.2
1027,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the local message bus has couple of properties ""queueSize"" and ""polling"". But these properties can not be configurable via servers.yml.
Also, the property prefix needs to align with other message bus properties.",XD-2735,Ilayaperumal Gopinathan,Make local message bus properties configurable
1028,Gunnar Hillert,Sabby Anandan,"As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.
",XD-2734,Sabby Anandan,Create first-cut on reference architectures for domain specific use-cases
1029,,Glenn Renfro,"XD can not find the custom modules directory after Setting the xd.customModule.home in the windows environment 

Deployment
* xd-singlenode (embedded zookeeper)
* Java 8
* Windows 8 or Windows Server 2012 r2

Steps to reproduce:

1) Start xd-singlenode
2) Start Shell
3) Build either the payload-conversion or rss-feed-source from the spring-xd-samples
4) use the shell to execute a module upload for the custom module (rss-feed-source, payload-conversion)
5) verify it uploaded xd:>module info processor:myTupleProcessor
6) stop xd single node
7) From the command line execute set xd.customModule.home=[path to your custom modules] i.e. C:\project\spring-xd-1.1.0.RELEASE\xd\custom-modules
8) restart xd-singlenode
9) execute module info processor:myTupleProcessor
10) you will get the following error
{noformat}
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'myTupleProcessor' and type 'processor'
{noformat}",XD-2733,Glenn Renfro,Custom Modules can't be found wen using xd.customModule.home on windows 
1030,,Eric Bottard,"Since the refactoring of the module registry that does not ""look inside"" a module, it can't know that the scripts directory is not a module.

Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules/common",XD-2732,Eric Bottard,Move $XD_HOME/modules/processor/scripts out of the way
1031,Eric Bottard,Paul Harris,"During testing for Spring XD for PivotalCF we create, deploy, use, undeploy and destroy many streams. Each stream generates {{tmp}} directories (I think 2, one for source, one for sink) in the xd-admin VM's {{/tmp}} directory, e.g.

{noformat}
dummy-module4635787551932601017sinkredis
dummy-module252960009195893204sourcehttp
{noformat}

These {{tmp}} directories are not being cleared up, so our system has hit the inode limit of 32768 files for a volume:

{noformat}
Filesystem     Inodes IUsed  IFree IUse% Mounted on
/dev/loop0      32768 32768      0  100% /tmp
{noformat}

This causes a Java {{IOException}}, the immediately relevant part of which appears to be:

{noformat}
[Caught] exception while handling a request
Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  [java.lang.RuntimeException] java.io.IOException: No space left on device
Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  []    at org.springframework.xd.module.ModuleDefinitions.dummy(ModuleDefinitions.java:81)
{noformat}

This causes the test system to fail entirely.",XD-2731,Paul Harris,Temp files for stream create not being cleaned
1032,Eric Bottard,Sabby Anandan,"As a user, I'd like to include the deployment manifest from the file so that I don't have spend time typing as ""inline properties"".",XD-2730,Sabby Anandan,Add support to include deployment manifest from file
1033,Glenn Renfro,Glenn Renfro,Upload payload conversion demo such that a user can use the module upload feature against the sample.,XD-2729,Glenn Renfro,Update payload-conversion demo to latest module spec
1034,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The spark streaming processor module emits the following exception when there are more messages in the RDD partitions:

015-02-17 12:45:02,026 1.2.0.SNAP ERROR Executor task launch worker-2 executor.Executor - Exception in task 0.0 in stage 56.0 (TID 142)
org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.send(MessageBusSender.java:105)
	at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:80)
	at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:55)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 17 more
2015-02-17 12:45:02,032 1.2.0.SNAP  WARN task-result-getter-1 scheduler.TaskSetManager - Lost task 0.0 in stage 56.0 (TID 142, localhost): org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.send(MessageBusSender.java:105)
	at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:80)
	at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:55)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 17 more
",XD-2728,Ilayaperumal Gopinathan,Spark streaming processor module: Dispatcher has no subscribers
1035,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The property ""xd.messagebus.kafka.offsetStoreTopic"" was added to Kafka message bus which is not updated to Spark streaming message bus properties that will be transferred to spark cluster for streaming module deployment. 
We also need a better approach to re-use the message bus properties so that we don't have to update the properties in Connection Property Names.",XD-2727,Ilayaperumal Gopinathan,Spark streaming integration with kafka message does not respect offsetStoreTopic config option
1036,,Eric Bottard,"To be added in AbstractMetricsController, as well as the various shell commands (""counter all delete"", etc...)",XD-2726,Eric Bottard,Allow deletion of all metrics of a kind
1037,,Eric Bottard,"Stumbled upon this while having Hadoop daemons running, but simple way to repoduce:

{noformat}
nc -lp 9000

stream create foo --definition ""http | log"" --deploy
==> all seems ok

http post --data hello
==> Error 500, rightfully so
{noformat}",XD-2725,Eric Bottard,http does not report failure to bind to port
1038,,Sabby Anandan,"As a user, I'd like to have the option of editing the deployed/undeployed stream so that I don't have to destroy to just change any deployment property.",XD-2724,Sabby Anandan,Add support to edit deployed/undeployed stream
1039,Eric Bottard,Thomas Risberg,The partitionResultsTimeout is set to 300000 as default (5min). This is way to short for long running steps. We should increase this default.,XD-2723,Thomas Risberg,Increase the partitionResultsTimeout
1040,,Thomas Risberg,"Running a partitioned jdbchdfs job with 12 partitions and 3 xd-containers. Some steps fail with the jdbc connection pool exception XD-2720. I also sometimes see a serialization exception. This results in the partitioner never getting the status for some of the steps, so it keeps running until it times out even though all steps are either complete of failed.

{code}
2015-02-13 13:18:36,294 1.1.0.RELEASE ERROR inbound.files4.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'
org.springframework.messaging.MessageHandlingException: error occurred in message handler [files4.0.bridge.handler]; nested exception is com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda
Serialization trace:
stepExecutions (org.springframework.batch.core.JobExecution)
jobExecution (org.springframework.batch.core.StepExecution)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda
Serialization trace:
stepExecutions (org.springframework.batch.core.JobExecution)
jobExecution (org.springframework.batch.core.StepExecution)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:682)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.doDeserialize(PojoCodec.java:41)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec$1.execute(AbstractKryoMultiTypeCodec.java:63)
	at com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.run(KryoPoolQueueImpl.java:43)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec.deserialize(AbstractKryoMultiTypeCodec.java:60)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.deserialize(PojoCodec.java:30)
	at org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:72)
	at org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:78)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:588)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:573)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:556)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus.access$1000(RedisMessageBus.java:68)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:465)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 21 more
Caused by: java.lang.RuntimeException: Could not serialize lambda
	at com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:52)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:786)
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:116)
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:22)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)
	... 40 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: -2
	at java.util.ArrayList.elementData(ArrayList.java:418)
	at java.util.ArrayList.get(ArrayList.java:431)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)
	at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:830)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)
	at com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:49)
	... 45 more
{code} ",XD-2722,Thomas Risberg,Partitioned job throws: java.lang.RuntimeException: Could not serialize lambda
1041,Michael Minella,Michael Minella,"When viewing a job's step execution via the shell, the user is required to provide both the job execution id and the step execution id.  Since the job repository is backed by a database and the step execution id is unique across jobs, the step execution id should be enough.",XD-2721,Michael Minella,Remove requirement for executionId to display step execution in shell
1042,,Thomas Risberg,"I'm running a jdbchdfs job with 8 partitions and 2 containers. Some steps complete ok while some (3-4 on average) fail with a connection pool error (see below). This happens with a decent size table (1.8M rows).

I tried two different databases - Oracle 11g on a separate server and MySQL running locally where the XD containers where running. Same pattern with both databases.

{code}
2015-02-13 12:21:33,436 1.1.0.RELEASE ERROR inbound.files3.0-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step step1 in job files3
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.itemReader' defined in file [/home/trisberg/Test/spring-xd-1.1.0.RELEASE/xd/modules/job/jdbchdfs/config/jdbchdfs.xml]: Invocation of init method failed; nested exception is org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:342)
	at org.springframework.batch.core.scope.StepScope.get(StepScope.java:110)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:187)
	at com.sun.proxy.$Proxy90.open(Unknown Source)
	at org.springframework.batch.item.support.CompositeItemStream.open(CompositeItemStream.java:96)
	at org.springframework.batch.core.step.tasklet.TaskletStep.open(TaskletStep.java:310)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:195)
	at org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:102)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy94.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at sun.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy91.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)
	at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.
	at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:302)
	at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:329)
	at org.springframework.batch.support.DatabaseType.fromMetaData(DatabaseType.java:95)
	at org.springframework.xd.jdbc.NamedColumnJdbcItemReaderFactory.afterPropertiesSet(NamedColumnJdbcItemReaderFactory.java:101)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)
	... 90 more
Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80)
	at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:289)
	... 95 more
Caused by: java.sql.SQLException: Failed to validate a newly established connection.
	at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:802)
	at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:617)
	at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:186)
	at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:111)
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:77)
	... 96 more
{code}",XD-2720,Thomas Risberg,Frequent connection pool errors with multi-partitioned jdbchdfs jobs
1043,Gary Russell,Sabby Anandan,"As a user, I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources. ",XD-2719,Sabby Anandan,Invoke Rabbit REST-API to clean-up resources
1044,Gary Russell,Sabby Anandan,"As a user, I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.",XD-2718,Sabby Anandan,Add a separate --clean 'Admin' command to clean-up queues/topics
1045,Gunnar Hillert,Gary Russell,"As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file.

Add an alternative {{--nameExpression}} option, allowing complete control over the {{finename-generator-expression}} attribute.

See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069",XD-2717,Gary Russell,Add nameExpression Property to File Sink
1046,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to create a example to demonstrate JDBC to HDFS data movement.",XD-2716,Sabby Anandan,Create a Batch example to demonstrate JDBC->HDFS
1047,Eric Bottard,Sabby Anandan,"As a PM, I'd like to have the Smart Grid demo (from s1-2014) ported into Spring XD samples repo.",XD-2715,Sabby Anandan,Add Smart Grid demo to XD samples repo
1048,,Sabby Anandan,"As a field engineer, I'd like to have a comparison of Spark Streaming examples in Spring XD so that it is easy to relate from implementation standpoint.
",XD-2714,Sabby Anandan,Replicate Spark Streaming examples in XD
1049,Marius Bogoevici,Sabby Anandan,"As a field engineer, I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint.
",XD-2713,Sabby Anandan,Replicate Storm examples in XD
1050,David Turanski,David Turanski,Currently all message bus implementations are removed from the runtime classpath and loaded on demand from the file system according to the transport setting. Custom module projects that include in container testing must install messagebus-local on the local file system. This is currently configured as a task for module build scripts. This is also a dependency for testing in the IDE and developers need to execute the build task or configure the messagebus manually. Embedding the local MB for the singlenode application (local is not a valid transport for distributed) eliminates this step.,XD-2712,David Turanski,Embed local message bus in DIRT as default for singlenode
1051,Glenn Renfro,Glenn Renfro,"Update Hadoop, Spark, Mongo, gemfire, and ubuntu to latest versions for both CI  and Utility instances.  
",XD-2711,Glenn Renfro,CI Environment Needs test resources updated to latest versions
1052,Marius Bogoevici,Marius Bogoevici,"In `org.springframework.xd.dirt.stream.KafkaSingleNodeStreamDeploymentIntegrationTests#verifyOnDemandQueues`, when testing the queue partitions for content, the read is assumed to start at offset 0.

This is incorrect, because the topics may exist already, especially in a CI environment",XD-2710,Marius Bogoevici,Kafka Tests shouldn't assume offset 0 
1053,,David Turanski,"The error below appears to be a concurrency issue related to multiple classloaders loading the same spring XML resource.  The root cause needs further investigation, but it causes intermittent test failures in JobCommandsTests.

see https://build.spring.io/browse/XD-JDK8-1375

java.lang.AssertionError: java.lang.AssertionError: Failure.  CommandResult = CommandResult [success=false, result=null, exception=org.springframework.xd.rest.client.impl.SpringXDException: Unexpected exception parsing XML document from file [/data/bamboo-home/xml-data/build-dir/XD-JDK8-JOB1/spring-xd-shell/build/resources/test/spring-xd/xd/modules/job/jobWithParameters/config/jobWithParameters.xml]; nested exception is java.lang.NullPointerException: Inflater has been closed
]
java.lang.AssertionError: Failure.  CommandResult = CommandResult [success=false, result=null, exception=org.springframework.xd.rest.client.impl.SpringXDException: Unexpected exception parsing XML document from file [/data/bamboo-home/xml-data/build-dir/XD-JDK8-JOB1/spring-xd-shell/build/resources/test/spring-xd/xd/modules/job/jobWithParameters/config/jobWithParameters.xml]; nested exception is java.lang.NullPointerException: Inflater has been closed
]
",XD-2709,David Turanski,Investigate root cause of Spring XML parsing failures
1054,,Ilayaperumal Gopinathan,"We need to use getMessageBuilderFactory(beanFactory) to initialize MessageBuilder in Spark Streaming module executor. Please see the discussion: https://github.com/spring-projects/spring-xd/pull/1454/files#r24367825 , ",XD-2708,Ilayaperumal Gopinathan,Spark streaming Module executor use getMessageBuilderFactory(beanFactory)
1055,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, when the spark streaming ModuleExecutor iterate over the RDD partitions, it converts all the items to spring Message. If the item itself is of Message type (the conversion happened at the spark streaming processor implementation), then this is not needed. We need to add a check to see if the item is of Message type.",XD-2707,Ilayaperumal Gopinathan,Support creation of spring Message at spark processor implementation
1056,Ilayaperumal Gopinathan,Gary Russell,"{code}
logger.error(""Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'"",										context.getLastThrowable());
{code}

Should be:

{code}
logger.error(""Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:"" + name + '"",										context.getLastThrowable());
{code}

So the actual name is logged.
",XD-2706,Gary Russell,Improve Redis Bus Error Log Entry
1057,,Eric Bottard,"See original report here https://github.com/spring-projects/spring-xd/issues/1300

""I've created a module with a custom Metric, Handler and Repository patterned after the AggregateCounter but then it appears that there doesn't seem to be a way to add anything to the Admin Context.

The diagram at https://github.com/spring-projects/spring-xd/wiki/Extending-XD shows the Plugin Context as a sibling to the Admin Context which seems to verify my fears.

It would be convenient to be able to add custom Metrics/Controllers/Repositories into the Admin Context so that they can be accessed through the same REST api as the other Metrics.""",XD-2705,Eric Bottard,Add ability to add Custom Metrics/Controllers To Admin Context 
1058,Eric Bottard,Eric Bottard,"As a consequence, 
* change gradle script regarding generation of documentation
* remove pushGeneratedDocs task, etc
* remove link rewriting that is no longer needed ",XD-2704,Eric Bottard,Move documentation from wiki to main repo
1059,,Sabby Anandan,"As a developer, I'd like to build batch sample using _Sqoop_ so that we can demonstrate some of the capabilities.

*Use cases to consider:*
* JDBC to HDFS
* HDFS to JDBC ",XD-2703,Sabby Anandan,Create Sqoop example
1060,,Sabby Anandan,"As a developer, I'd like to build data pipeline using _Kafka_ as as message bus in XD so that we can demonstrate some of the capabilities.

*Use case to consider:*
* Log aggregation and analysis
* Lambda architecture
** how to avoid code duplication
** how to eliminate tight coupling of business logic
** how Kafka can be used for reliable reprocessing 
",XD-2702,Sabby Anandan,Create Kafka data pipeline example
1061,,Sabby Anandan,"As a developer, I'd like to build _Spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.",XD-2701,Sabby Anandan,Create Spark MLLib example
1062,David Turanski,David Turanski,remove spark and hadoop requirements from spring-xd-module-parent and gradle module plugin,XD-2700,David Turanski,Remove spark and hadoop dependencies from custom module classpath
1063,Gary Russell,Sabby Anandan,"As a developer, I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.",XD-2699,Sabby Anandan,Review and fix Sonar violations
1064,Marius Bogoevici,Marius Bogoevici,"As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. ",XD-2698,Marius Bogoevici,Kafka Tests should use an external broker
1065,Thomas Risberg,Thomas Risberg,"Having problems testing against the Sandbox 2.2. We need to set the following properties:

yarn.application.classpath
yarn.app.mapreduce.am.command-opts
mapreduce.application.classpath
mapreduce.application.framework.path

",XD-2697,Thomas Risberg,Make Sqoop job and MapReduce samples work with Hortonworks HDP 2.2 single-node cluster 
1066,Michael Minella,Mark Pollack,"Can revert part of the commit that went into upgrading to reactor 2.0

https://github.com/spring-projects/spring-xd/pull/1342/files
",XD-2696,Mark Pollack,Downgrade reactor based modules to reactor 1.x GA
1067,,Ilayaperumal Gopinathan,"Currently, when the module doesn't need to go through message bus binding, the Module interface provides 'shouldBind()` method to return false.

The shouldBind() is being used in other place where ModuleTypeConversionPlugin is excluded for spark streaming modules.

We need a better approach to refactor this.
Also, see the discussion here: https://github.com/spring-projects/spring-xd/pull/1438#discussion_r24150937",XD-2695,Ilayaperumal Gopinathan,Better approach to handle module execution framework
1068,David Turanski,Marius Bogoevici,"As a developer, I'd like the {{publish-maven.gradle}} script to use values for dependencies (e.g. Spring Boot and {{hadoop-common}}) from our central dependency list (in this case {{dependencies.properties}}) so that I don't have to update them manually anymore.",XD-2694,Marius Bogoevici,Spring XD module parent should use dependencies.properties for versioning
1069,,Sabby Anandan,"As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience.
",XD-2693,Sabby Anandan,Run Kafka tests with Kafka Server as separate process
1070,,Sabby Anandan,,XD-2692,Sabby Anandan,Placeholder for Kafka tests in all OS environments
1071,David Turanski,Gunnar Hillert,"Gradle 2.x is required for the latest Sonar version (sonar.spring.io)

We may need to wait for a fix in Groovy itself (2.4.1) - Please see the following links for details:

* http://forums.gradle.org/gradle/topics/after_upgrade_gradle_to_2_0_version_the_maven_pom_not_support_build_property

* http://jira.codehaus.org/browse/GROOVY-7023

",XD-2691,Gunnar Hillert,Upgrade to the latest Gradle 2.x Release
1072,David Turanski,David Turanski,see https://github.com/spring-projects/spring-boot/issues/2454,XD-2690,David Turanski,Restrict entry filter in loading module artifacts
1073,Thomas Risberg,Thomas Risberg,"Running Sqoop job against non Apache Hadoop installation

- YARN app fails

     Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

- Need to be able to set yarn.application.classpath for any distro that doesn't use the Hadoop defult classpath (Cloudera, Hortonworks, Pivotal HD)",XD-2689,Thomas Risberg,Fix Sqoop job to allow for setting yarn.application.classpath
1074,Thomas Risberg,Thomas Risberg,"Submitting jobs that submit YARN MR tasks on Cloudera 5.3.0

- job fails when submitting the YARN app

     java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream

- this is from Guava and that class was removed starting with v. 15.0

- I can get around this by including guava-14.0.1.jar in lib/cdh5 (not sure if this breaks something else)
",XD-2688,Thomas Risberg,Fix mapreduce job submission on Cloudera CDH5
1075,Eric Bottard,Eric Bottard,,XD-2687,Eric Bottard,Fix #jsonPath evaluation following JsonPath version upgrade
1076,Eric Bottard,Sabby Anandan,"As a user, I'd like to see the 'date' in logs so that I can troubleshoot issues that had occurred on a specific day and time.

Property that needs adjusted:
https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11",XD-2686,Sabby Anandan,Update log4j properties to include DATE in the logs
1077,,David Turanski,"When a user executes a module delete on a custom module it sporadically fails with the following exception below at the bottom of the description.
Deployment:
OS: Windows 8 or Windows Server 2012 R2
Java version Java 8 (build 25.31-b07, mixed mode)
XD Deployment type. XD-Singlenode (embedded zookeeper)

Steps to reproduce:
1) build either the rss-feed-source or the payload-conversion samples from the spring-xd-samples
2) start xd-singlenode
3) start shell
4) from the shell execute module upload for the custom module i.e. module upload --file C:\project\spring-xd-samples\payloadconversion\build\libs\payload-conversion-1.0.0.BUILD-SNAPSHOT.jar --name myTupleProcessor --type processor
5) Verify that the module was uploaded by executing module info processor:myTupleProcessor
6) Execute module delete processor:myTupleProcessor

{noformat}
2015-02-18 14:48:43,908 1.1.0.RELEASE ERROR qtp752571350-38 rest.RestControllerA
dvice - Caught exception while handling a request
org.springframework.xd.dirt.module.DependencyException: Cannot delete module pro
cessor:myTupleProcessor because it is used by [stream:test]
        at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod
uleDefinitionService.java:116)
        at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont
roller.java:155)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.
java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces
sorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at org.springframework.web.method.support.InvocableHandlerMethod.doInvok
e(InvocableHandlerMethod.java:221)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeF
orRequest(InvocableHandlerMethod.java:137)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl
eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH
andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH
andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt
er.handle(AbstractHandlerMethodAdapter.java:85)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch
erServlet.java:943)
        at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche
rServlet.java:877)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame
workServlet.java:966)
        at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe
rvlet.java:890)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer
vlet.java:842)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684
)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1496)
        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf
iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf
iguration.java:291)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna
l(HiddenHttpMethodFilter.java:77)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter
nal(HttpPutFormContentFilter.java:87)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter
Internal(WebRequestTraceFilter.java:100)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi
lterChainProxy.java:186)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai
nProxy.java:160)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig
uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:499)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:137)
        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:557)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:231)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:1086)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
428)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:193)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:1020)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:135)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:116)
        at org.eclipse.jetty.server.Server.handle(Server.java:370)
        at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac
tHttpConnection.java:494)
        at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra
ctHttpConnection.java:971)
        at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header
Complete(AbstractHttpConnection.java:1033)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)

        at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti
on.java:82)
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn
dPoint.java:667)
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd
Point.java:52)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:608)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:543)
        at java.lang.Thread.run(Thread.java:745)
2015-02-18 14:50:38,191 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi
stener - Undeploying module [ModuleDescriptor@14b69ddf moduleName = 'http', modu
leLabel = 'http', group = 'test', sourceChannelName = [null], sinkChannelName =
[null], index = 0, type = source, parameters = map[[empty]], children = list[[em
pty]]]
2015-02-18 14:50:38,380 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi
stener - Undeploying module [ModuleDescriptor@7c2cd32 moduleName = 'myTupleProce
ssor', moduleLabel = 'myTupleProcessor', group = 'test', sourceChannelName = [nu
ll], sinkChannelName = [null], index = 1, type = processor, parameters = map['in
putType' -> 'application/x-xd-tuple'], children = list[[empty]]]
2015-02-18 14:50:38,470 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi
stener - Undeploying module [ModuleDescriptor@30ba1084 moduleName = 'log', modul
eLabel = 'log', group = 'test', sourceChannelName = [null], sinkChannelName = [n
ull], index = 2, type = sink, parameters = map[[empty]], children = list[[empty]
]]
2015-02-18 14:50:38,527 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.Initia
lDeploymentListener - Path cache event: path=/deployments/streams/test, type=CHI
LD_REMOVED
2015-02-18 14:50:38,528 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve
r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66
35afd-7351-4ac3-baa3-3b98e74a38ca/test.source.http.1, type=CHILD_REMOVED
2015-02-18 14:50:38,530 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve
r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66
35afd-7351-4ac3-baa3-3b98e74a38ca/test.processor.myTupleProcessor.1, type=CHILD_
REMOVED
2015-02-18 14:50:38,532 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve
r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66
35afd-7351-4ac3-baa3-3b98e74a38ca/test.sink.log.1, type=CHILD_REMOVED
2015-02-18 14:50:41,486 1.1.0.RELEASE  INFO LeaderSelector-0 server.DeploymentSu
pervisor - Leadership canceled due to thread interrupt
2015-02-18 14:50:41,592 1.1.0.RELEASE  WARN NIOServerCxn.Factory:0.0.0.0/0.0.0.0
:5156 server.NIOServerCnxn - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x14b
9d2656c30000, likely client has closed socket
        at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228
)
        at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFac
tory.java:208)
        at java.lang.Thread.run(Thread.java:745)
{noformat}
",XD-2685,David Turanski,Module delete command sporadically fails on windows
1078,David Turanski,Mark Pollack,Min JDK version for XD 1.1 is 7.  Change the sourceCompatibility to 1.7 but leave targetCompatibility at 1.6.   Changes are also needed in the mdule parent pom and gradle plugins.,XD-2684,Mark Pollack,Set sourceCompatibility to JDK 1.7
1079,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,The spark streaming module needs to support inputType (for both processor and sink module) and outputType (for processor module) so that message conversion can happen at the MessageBusReceiver and MessageBusSender.,XD-2683,Ilayaperumal Gopinathan,Message conversion support for spark streaming module
1080,,Gary Russell,"Currently, you cannot suppress (or change) the {{X-}} prefix on user-defined headers.

See http://stackoverflow.com/questions/28118990/passing-http-request-header-to-restapi-from-springxd-using-http-client-processor/28153291#28153291

Add $\{userDefinedHeaderPrefix\} property.",XD-2682,Gary Russell,http-client Improvement (userDefinedHeaderPrefix)
1081,Sabby Anandan,Sabby Anandan,"As a developer, I'd like to refer to wiki so that I can configure machines with recommended _ulimit_ setting for XD's distributed setup.

*Note:*
Recommended _ulimit_ setting is 10K under ""Troubleshooting"" (new) section

*Exception:* (reason to increase _ulimit_)
8:25:52,266 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/data/packages/springxd/ee02bd3482eeb620a65862fb54e1f23fcece8022.1-bd
a341640a5de2f922fd3db906ce504b85819c1e/spring-xd-1.1.0.BUILD-SNAPSHOT/xd/config/modules/modules.yml (Too many open files)",XD-2681,Sabby Anandan,Document recommended 'ulimit' setting for XD
1082,,Thomas Risberg,,XD-2680,Thomas Risberg,Add dependencies needed for running a job using HBase
1083,Thomas Risberg,Thomas Risberg,,XD-2679,Thomas Risberg,Add dependencies needed for running a Hive job
1084,Thomas Risberg,Thomas Risberg,,XD-2678,Thomas Risberg,Add dependencies needed for running a Pig job
1085,Thomas Risberg,Thomas Risberg,"Currently jline 2.11 gets added via zookeeper dependency, we need to remove this so we can have jline 1.0 fir Pig jobs in the hadoop depndencies

This jline version should remain for xd-shell classpath though",XD-2677,Thomas Risberg,Remove jline from xd-dirt classpath
1086,Thomas Risberg,Thomas Risberg,"There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",XD-2676,Thomas Risberg,Resolve classloading issues for custom Hadoop based batch jobs
1087,Mark Pollack,nebhale,"Currently, the Redis sink appears to be unable to write to a Redis instance if it is connected via Sentinel.  Given the following XD Container {{servers.yml}} configuration:

{noformat}
# Redis properties
spring:
  redis:
#   port: 6379
#   host: localhost
    sentinel:
      master: spring-xd
      nodes: 10.85.30.133:26379,10.85.30.134:26379,10.85.30.135:26379
{noformat}

a stream of {{time | redis --key=ticktock}} results in the following:

{noformat}
Created JedisPool to master at 10.85.30.130:6379
Caused by: org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisStoreWritingMessageHandler#0]; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
Caused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:140)
    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:229)
    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:57)
Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:84)
    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:10)
    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:133)
Caused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused
    at redis.clients.jedis.Connection.connect(Connection.java:150)
    at redis.clients.jedis.BinaryClient.connect(BinaryClient.java:71)
    at redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1783)
    at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65)
    at redis.clients.jedis.Connection.connect(Connection.java:144)
{noformat}

The parts that sticks out to me is the line
bq. {{Created JedisPool to master at 10.85.30.130:6379}}

The Sentinels aren't at {{.130}}, that's a Redis and the only way that the {{JedisPool}} could know about that host is to have connected to a Sentinel instance and requested the listing of Redis nodes managed by the Sentinel.  Notably, the Redis instance that the JedisPool connects to is actually responsive.

{noformat}
$: redis-cli -h 10.85.30.130 -p 6379
10.85.30.130:6379> ping
PONG
10.85.30.130:6379> 
{noformat}

",XD-2675,nebhale,Add support for Sentinel in Redis Sink
1088,Eric Bottard,Artem Bilan,See the SO question on the matter: http://stackoverflow.com/questions/28280206/how-can-i-use-authentication-in-mongo-sink,XD-2674,Artem Bilan,Provide more options for the MongoDB Sink
1089,Thomas Risberg,Sabby Anandan,"As a user, I'd like to refer to Hive sample so that I can use that as a reference to integrate Hive to query and analyze.",XD-2673,Sabby Anandan,Create a smple to invoke Hive query from XD
1090,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a scala developer, someone could easily deploy the spark streaming module developed using scala.
  ",XD-2672,Ilayaperumal Gopinathan,Add scala support for spark streaming module
1091,Ilayaperumal Gopinathan,Glenn Renfro,"OS: Ubuntu
Deployment Admin Server.  1 Container
Transport Rabbit

* Using the shell execute the file.  ./bin/shell --cmdfile loop.txt  
** This should run successfully
* Rerun the same script ./bin/shell --cmdfile loop.txt
** it states that the stream foo1 is already deployed. 
** Open shell app and destroy foo1 and run a stream list.  No streams will display
** Exit shell and rerun the file.  
*** Another stream will fail to create stating  stream already exists.

* If you look at the modules deployed on the container some are still present.
* To clear you have to shutdown the cluster and flush the xd directories on Zookeeper.
* Note that if I shutdown the container the modules disappear.

 ",XD-2671,Glenn Renfro,Support rapid creation and deletion of streams
1092,Gary Russell,Gary Russell,When available,XD-2670,Gary Russell,Bump Spring AMQP to 1.4.3
1093,,Glenn Renfro,"We need the ability to have bamboo provision a Windows instance on EC2 and launch a XD build.  
Capture the results of the XD Build and report back to Bamboo Success or failure.
If the build is successful, shutdown the EC2 Windows instance.  Else leave it running so someone can diagnose the problem.",XD-2669,Glenn Renfro,XD Requires a CI build for Windows Platform
1094,,Hector Lagos,"Hey Guys,

We are currently trying to connect Hive by spring-xd to create a table.  Unfortunatly we are not able to do it. We are using the attached job configuration (hive.xml) trying to connect by Hive Thrift Client with the following configuration:

<hadoop:hive-client-factory host=""hive_host"" port=""10000"" />
<hadoop:hive-tasklet id=""hive-script"">
   <hadoop:script>
     USE TESTING;
     DROP TABLE IF EXITS testHiveBatchTable; 
     CREATE TABLE testHiveBatchTable (key int, value string);
   </hadoop:script>
</hadoop:hive-tasklet>

For Some reason spring XD is not finding the TTransportException class. The full log is in the singlenode_hivequery.log  file  attached. After that we tried uploading all the dependencies to the lib folder of the job, but now we are facing problems with log4j (full log is in singlenode_hivequery2.log attached) and we are unable to deploy the job in any of the two cases. Please,  Could you help us to solve this problem? 

Thanks in advance.",XD-2668,Hector Lagos,Can't execute query on Hive
1095,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits. ",XD-2667,Sabby Anandan,Upgrade to SHDP GA Release
1096,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to upgrade to Kafka's SI GA release so that I can sync -up with the latest bits. 

The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.",XD-2666,Sabby Anandan,Upgrade to SI Kafka GA release
1097,Gary Russell,Sabby Anandan,"As a PM, I'd like to have the copyright message in the reference guide (PDF) updated to include 2015 instead of 2014. ",XD-2665,Sabby Anandan,Update copyright message in PDF from 2014 to 2015
1098,Ilayaperumal Gopinathan,Sabby Anandan,"As a developer, I'd like to build _Spark Streaming_ as data processors in XD so that we can demonstrate some of the capabilities.

*Implement using:*
* Java / Java Lambdas
* Scala",XD-2664,Sabby Anandan,Create Spark Streaming example
1099,,Sabby Anandan,,XD-2663,Sabby Anandan,"Epic to account for samples, blogs and community reach"
1100,,Sabby Anandan,"As a developer, I'd like to run acceptance test coverage in Windows so that I can evaluate XD functionalities.

The scope is to provision Windows image in EC2 and run acceptance test in the environment. Potentially also try to create this as CI build.",XD-2662,Sabby Anandan,Add test coverage for Windows in EC2
1101,David Turanski,Sabby Anandan,"As a user, I'd like to build XD in Windows machine so that I can develop, test,  and contributed to OSS.",XD-2661,Sabby Anandan,Add build support for XD in Windows
1102,,Sabby Anandan,,XD-2660,Sabby Anandan,Support to run/build XD in Windows
1103,,Glenn Renfro,"At this time Kafka Message bus does not support jobs but we still need to run acceptance tests for streams.  Thus we need to exclude Jobs from the acceptance tests when using Kafka Message Bus.
",XD-2659,Glenn Renfro,Disable Batch Job Tests for Kafka Message Bus
1104,,Thomas Risberg,"The XD on YARN section of the docs needs to be updated with the ""xd-yarn admininfo"" command for detecting the ports used by admin servers.",XD-2658,Thomas Risberg,Update XD on YARN docs
1105,,Sergey Shcherbakov,"The max-messages-per-poll property of the poller used in the file source is not exposed and cannot be configured.
I think it has the default value of 1 in this configuration:

https://github.com/spring-projects/spring-xd/blob/master/modules/source/file/config/file.xml#L18

As a result it is not possible to configure the file source to pick all new files available in a single poll. 
This is a limitation in fast file ingestion scenarios.",XD-2657,Sergey Shcherbakov,Make max-messages-per-poll setting of the file source configurable
1106,Thomas Risberg,Sabby Anandan,"As a user, I'd like to refer to a Pig script/job sample so that I can use that as a reference to integrate Pig jobs in XD.",XD-2656,Sabby Anandan,Create a sample to invoke Pig script/job from XD
1107,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, ModuleDeploymentWriter uses default timeout 30s which can not be overridden. We need to make this configurable.",XD-2655,Ilayaperumal Gopinathan,Make deployment timeout configurable
1108,Eric Bottard,Mark Pollack,"Use latest version, might need to exclude version from other dependencies, e.g. SI, in build-common.gradle.",XD-2654,Mark Pollack,Update com.jayway.jsonpath to latest version
1109,Glenn Renfro,Glenn Renfro,"If a stream foo has messages in its queue when it is destroyed and another stream named foo is created of similar structure those messages will be delivered to sink.  This is seen when twitterstream runs prior to hdfssink test.  The twitters stream data is written to hdfs instead of the trigger data that was intended.
The solution is to give hdfstest its own unique name instead of the default ec2test3 name.",XD-2653,Glenn Renfro,HdfsTest picks up data from a previous run.
1110,Glenn Renfro,Sabby Anandan,"As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.",XD-2652,Sabby Anandan,Document migration strategy for custom modules (from 1.0 to 1.1)
1111,Marius Bogoevici,Mark Pollack,"The scope is to research the available options to provide request/reply support for Kafka. 

* Document findings
* POCs

Previous Desc:
The bindRequestor and bindReplier methods of the message bus need to be implemented.",XD-2651,Mark Pollack,Spike: Research request/reply support to Kafka Message Bus
1112,,Marius Bogoevici,,XD-2650,Marius Bogoevici,Add Kafka-based implementation for AbstractDistributedTransportSingleNodeStreamDeploymentIntegrationTests
1113,Marius Bogoevici,Marius Bogoevici,,XD-2649,Marius Bogoevici,Add Kafka-based implementation for AbstractSingleNodeStreamDeploymentIntegrationTests
1114,,Gary Russell,See {{RedisSingleNodeStreamDeploymentIntegrationTests}} etc.,XD-2648,Gary Russell,We Need a KafkaSingleNodeStreamDeploymentIntegrationTests
1115,Marius Bogoevici,Marius Bogoevici,"Currently, the org.springframework.xd.dirt.server.SharedServerContextConfiguration will load  everything that matches the  `""classpath*:"" + ConfigLocations.XD_CONFIG_ROOT + ""bus/*.xml""` path. 

In a normal (i.e. production) environment, there are no conflicts, since only one jar containing message bus definitions is ever on the class path. 

However, during testing, *all* the projects containing bus definitions are on the class path, which leads to potential conflicts.",XD-2647,Marius Bogoevici,Ensure that only bean definitions for the proper transport are loaded
1116,Thomas Risberg,Janne Valkealahti,"For kerberos and other security related settings we use keys like 'spring.hadoop.userPrincipal' mentioned in https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos. However when we added boot config props to shdp, we used a sub keys like 'spring.hadoop.security.userPrincipal'.

It'd be good if we'd fix these to be same in both XD and SHDP not to cause confusion.",XD-2646,Janne Valkealahti,XD should use same hadoop security keys as Spring for Apache Hadoop
1117,Thomas Risberg,Steven McNamara,"Line 295 has 2 dashes instead of 3.  There is no effect on XD unless the XD extensions block is uncommented.

I have been using the XD extensions in version 1.0.3 and have merged my servers.yaml with all of the new content in 1.1.0.M2.

The Admin JVM crahes without logging any exception and the container JVM crashes and logs the following:

/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
`--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
1.1.0.M2                         eXtreme Data


Started : ContainerServerApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki

expected '<document start>', but found BlockMappingStart
in 'reader', line 303, column 1:
    xd:
    ^

        at org.yaml.snakeyaml.parser.ParserImpl$ParseDocumentStart.produce(ParserImpl.java:225)
        at org.yaml.snakeyaml.parser.ParserImpl.peekEvent(ParserImpl.java:158)
        at org.yaml.snakeyaml.parser.ParserImpl.checkEvent(ParserImpl.java:143)
        at org.yaml.snakeyaml.composer.Composer.checkNode(Composer.java:68)
        at org.yaml.snakeyaml.constructor.BaseConstructor.checkData(BaseConstructor.java:93)
        at org.yaml.snakeyaml.Yaml$1.hasNext(Yaml.java:498)
        at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:152)
        at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:137)
        at org.springframework.boot.env.YamlPropertySourceLoader$Processor.process(YamlPropertySourceLoader.java:78)
        at org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:50)
        at org.springframework.boot.env.PropertySourcesLoader.load(PropertySourcesLoader.java:126)
        at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.loadIntoGroup(ConfigFileApplicationListener.java:378)
        at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:366)
        at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:336)
        at org.springframework.boot.context.config.ConfigFileApplicationListener.addPropertySources(ConfigFileApplicationListener.java:173)
        at org.springframework.boot.context.config.ConfigFileApplicationListener.onApplicationEnvironmentPreparedEvent(ConfigFileApplicationListener.java:144)
        at org.springframework.boot.context.config.ConfigFileApplicationListener.onApplicationEnvironmentPreparedEvent(ConfigFileApplicationListener.java:137)
        at org.springframework.boot.context.config.ConfigFileApplicationListener.onApplicationEvent(ConfigFileApplicationListener.java:126)
        at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)
        at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)
        at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:100)
        at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:59)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:286)
        at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
        at org.springframework.xd.dirt.server.ContainerBootstrapContext.<init>(ContainerBootstrapContext.java:48)
        at org.springframework.xd.dirt.server.ContainerServerApplication.run(ContainerServerApplication.java:83)
        at org.springframework.xd.dirt.server.ContainerServerApplication.main(ContainerServerApplication.java:72)
  

",XD-2645,Steven McNamara,servers.yaml has a typo that causes XD startup to fail when....
1118,Eric Bottard,Ilayaperumal Gopinathan,"Currently, the ModuleFactory needs to know about `SparkStreamingDriverModule` to create the spark streaming module. It is for this reason, the spring-xd-module has direct dependency on spark streaming. We need to refactor this code so that there is no direct dependency on spark streaming for spring-xd-module and subsequently spring-xd-dirt.",XD-2644,Ilayaperumal Gopinathan,Refactor ModuleFactory to remove direct spark dependency on XD dirt
1119,Glenn Renfro,Glenn Renfro,,XD-2643,Glenn Renfro,Acceptance tests need to create or use an existing topic prior to executing test
1120,,Hector Lagos,"Hey Guys,

Im trying to run WordCount example in kerberized cluster with the attached job configuration. The job upload the test file to the HDFS without problems but it fails in wordcount step. I am running the example on singlenode and  I configured the config/hadoop.properties file for shell and container with kerberos setting such as https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos.  The error log is attached.

Thanks in advance for the help. Regards",XD-2642,Hector Lagos,Can't run WordCount example in hadoop kerberized cluster
1121,,Marius Bogoevici,,XD-2641,Marius Bogoevici,Validate that topics used for storing offsets are compacted
1122,,Glenn Renfro,,XD-2640,Glenn Renfro,Create a CI Acceptance Tests build for XD Yarn deployment
1123,,Glenn Renfro,"In order to run Acceptance tests in their current state there had to be
* changes to the code 
** Set the location of the data node for the hdfs tests. (because the data nodes were no located with the master.)
** disable the copying of batch basic because we did not know the container location.
* Had to configure tests by hand so that we could identify the:
** admin port (with new features we should be able to write code to find it.  Should be able to set it but we had a problem.  Possible yarn bug)
** JMX Port ( We could set it for the master but not the container this was a Yarn deployBug )
** Where the build was deployed on the container node, so we could copy the batch-basic test.  
",XD-2639,Glenn Renfro,Acceptance tests updated to be able to test XD Yarn deployment
1124,Thomas Risberg,Thomas Risberg,"The spring-xd-[version]-shell.zip distribution zip doesn't include the lib/hadoop26 directory and libraries, so we get the following exception when starting the shell:

Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration
",XD-2638,Thomas Risberg,The shell distribution zip is missing hadoop26 libraries
1125,David Turanski,David Turanski,Multiple threads invoke the shell processor result in I/O errors and/or data corruption. send() and receive() should be synchronized. ,XD-2637,David Turanski,Shell processor is not thread safe
1126,,Sabby Anandan,"As a user, I'd like to either use _sql_ or _tableName_ options so that I can build a partitioned job with _where_ clause and strict table-column combo respectively. ",XD-2636,Sabby Anandan,Add support to either use 'sql' or tableName' options for partitioned jobs
1127,Thomas Risberg,Sabby Anandan,"As a user, I'd like to refer to the wiki so that I can create a job with 'partitions' that in turn expects _tableName_ and _columns_ be explicitly included in the job definition. 

It is also beneficial to call-out _sql_ and _tableName_ metadata options are mutually exclusive. Following logic in _JdbcHdfsOptionsMetadata_ needs documented.

{code:java}
@AssertTrue(message = ""Use ('tableName' AND 'columns') when using partition column"")
boolean isPartitionedWithTableName() {
	if (StringUtils.hasText(partitionColumn)) {
		return StringUtils.hasText(tableName) && !StringUtils.hasText(sql);
	}
	else {
		return true;
	}
}
{code}

",XD-2635,Sabby Anandan,Update 'partitionColumn' wiki to include mutual exclusiveness of 'sql' and 'tableName' options
1128,,Patrick Peralta,"The {{ZooKeeperModuleMetadataRepository.findAll}} method is expensive:
* It obtains the list of running containers
* For each container, it obtains the modules deployed to it
* For each module, it loads the metadata _and_ loads the deployment status

For smaller deployments this won't be an issue but it may be for larger ones. The most obvious improvement would be to parallelize the requests that can be done in parallel.",XD-2634,Patrick Peralta,Optimize ZooKeeperModuleMetadataRepository.findAll
1129,,Glenn Renfro,"In cases where I re-run a job, and during the job execution the percentage complete will tally the total runtime of the current execution and all previous executions.
See the attached image.",XD-2633,Glenn Renfro,UI Step Execution Progress will show value > than 100% 
1130,Sabby Anandan,Gunnar Hillert,"In *ZooKeeperStreamRepository#findAllInRange()* the parameters

* boolean fromInclusive
* boolean toInclusive

Don't have any effect (implicitly true)

Are they needed? Do we need to support it?",XD-2632,Gunnar Hillert,"In ""ZooKeeperStreamRepository#findAllInRange()"" the boolean parameters are not supported"
1131,Gunnar Hillert,Gunnar Hillert,,XD-2631,Gunnar Hillert,For time being checkin UI build artifacts
1132,Janne Valkealahti,Sabby Anandan,"As a developer, I'd like to use Ambari plugin so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.",XD-2630,Sabby Anandan,Add Ambari plugin (beta) to build and install Spring XD
1133,,Sabby Anandan,,XD-2629,Sabby Anandan,Add Ambari plugin support for XD
1134,Mark Pollack,Mark Pollack,"Configure Redis Cluster with Sentinal v 2.8.19.   Verify fail over, experiment with settings.  Useful reference https://code.flickr.net/2014/07/31/redis-sentinel-at-flickr/

All analytics test cases should be run as well as test that deploy streams that make use of redis analytics.   There might be some minor code changes required as mentioned in the flickr article.",XD-2628,Mark Pollack,Test Redis Sentinel setup and document recommended configuration
1135,,Marius Bogoevici,Leaving the runtime running (e.g. as singlenode) ends up in permgen errors,XD-2627,Marius Bogoevici,PermGen errors after running for a long time
1136,Sabby Anandan,Patrick Peralta,"The deployment guide https://github.com/spring-projects/spring-xd/wiki/Deployment should have instructions on turning on verbose gc for production applications.

The gc log tends to be verbose so running it in development is not desirable. However having the gc log in production is very helpful for troubleshooting slow/unresponsive applications.",XD-2626,Patrick Peralta,Update deployment guide to include verbose gc
1137,Patrick Peralta,Patrick Peralta,"The following timeout options should be added to our configuration file:

| session timeout | the number of milliseconds before the ZooKeeper session times out |
| connection timeout | the number of milliseconds before a connection to a ZooKeeper server times out |
| retry wait period | number of milliseconds to wait before attempting a connection after a failed connection |
| max retries | number of times to attempt a connection after a failed connection |

",XD-2625,Patrick Peralta,Add ZooKeeper timeout options to configuration file
1138,Marius Bogoevici,Marius Bogoevici,,XD-2624,Marius Bogoevici,Add more comprehensive tests for the simple consumer-based Kafka Message Bus
1139,Sabby Anandan,Gunnar Hillert,"Discovered Junit test failures that do not provide an assertion message. Therefore the Junit report is rather useless.

2 Classes (Maybe we should check the entire code-base):

Class org.springframework.xd.shell.command.JobCommandWithHadoopTests
testLaunchFtpHadoopJob

{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.springframework.xd.shell.command.AbstractJobIntegrationTest.checkForJobInList(AbstractJobIntegrationTest.java:213)
	at org.springframework.xd.shell.command.JobCommandWithHadoopTests.testLaunchFtpHadoopJob(JobCommandWithHadoopTests.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{code}

Class org.springframework.xd.shell.command.HttpCommandTests
testHttpPostUtfText
{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.springframework.xd.shell.command.StreamCommandTemplate.verifyExists(StreamCommandTemplate.java:162)
	at org.springframework.xd.shell.command.StreamCommandTemplate.doCreate(StreamCommandTemplate.java:99)
	at org.springframework.xd.shell.command.StreamCommandTemplate.create(StreamCommandTemplate.java:65)
	at org.springframework.xd.shell.command.HttpCommandTests.testHttpPostUtfText(HttpCommandTests.java:97)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{code}",XD-2623,Gunnar Hillert,Add assertion text to Junit Tests
1140,Marius Bogoevici,Marius Bogoevici,Include new features added by using Spring Integration Kafka M3,XD-2622,Marius Bogoevici,Update documentation for Kafka sources  
1141,Marius Bogoevici,Marius Bogoevici,,XD-2621,Marius Bogoevici,Add Kafka Native Metadata Store
1142,Sabby Anandan,Gunnar Hillert,"Looks like there is a bit of technical debt in *ZooKeeperStreamRepository*. Additionally there is not a single test for this class, yet. However, testability looks tricky.",XD-2620,Gunnar Hillert,Add tests and refactor ZooKeeperStreamRepository
1143,,Glenn Renfro,"When setting the management.port in the servers.yml all deployments should use the port specified.  Currently only admin is updated, the containers are still using 0.",XD-2619,Glenn Renfro,When setting management.port only the admin is updated
1144,Eric Bottard,Eric Bottard,,XD-2618,Eric Bottard,Update Spring Batch to 3.0.3.RELEASE
1145,Mark Pollack,Mark Pollack,,XD-2617,Mark Pollack,Create reactor module in spring-xd-modules project
1146,Marius Bogoevici,Marius Bogoevici,"Currently, `ensureTopicCreated` will invoke the creation of the topic on the brokers, however, the calls is not blocking. So, before proceeding, we should make sure that the metadata is readable (therefore propagated)",XD-2616,Marius Bogoevici,Ensure that metadata for Kafka message bus is propagated before producing/consuming
1147,,Sabby Anandan,"As a tester, I'd like to add test coverage for ""complex objects"" such protocol buffers, any object with nested variables or a tree of objects so that I can evaluate and document the performance characteristics.",XD-2615,Sabby Anandan,Add test coverage for 'complex objects' as payload
1148,,Sabby Anandan,"As a user, I'd like to have Google's [Protocol Buffer|https://code.google.com/p/protobuf/] codec option so that I can serialize/deserialize objects based on its native specifications.",XD-2614,Sabby Anandan,Add Protobuf codec implementation
1149,,Glenn Renfro,"Currently any properties files located in the ${xd.config.home}/ directory are not included in the config directory provided by the yarn deployment. And thus modules are pulling props from the  spring-xd-yarn-1.1.0.BUILD-SNAPSHOT.zip file.  
We need to include these property files in the config dir.
 ",XD-2613,Glenn Renfro,Add module properties files to yarn config directory
1150,David Turanski,David Turanski,https://github.com/EsotericSoftware/kryo#pooling-kryo-instances,XD-2612,David Turanski,Use Kryo instance pooling to reduce instantiation overhead
1151,Gary Russell,Gary Russell,http://stackoverflow.com/questions/28019801/how-to-read-throughput-sampler-sink-values-in-spring-xd/28027544#28027544,XD-2611,Gary Russell,Missing Log Configuration for throughput-sampler
1152,,lizilong,"Job definition is deleted after restart the srping xd service in single node mode

repro step:
1.start service as single node
2.create a batch module
3.create a job based on batch module
4.restart service

expect result:
job definition is displayed on the job list

actual result:
job list is empty, all job definitions are missed",XD-2610,lizilong,Job definition is deleted after restart the srping xd service in single node mode
1153,Gunnar Hillert,Sabby Anandan,"As a user, I'm trying to list streams (>20) in admin-ui to use the pagination; however, I ended up with blank page and the server-side errored with _java.lang.IllegalStateException_.

Version: 1.1.0 SNAPSHOT (master build)
Distributed: 1 admin and 2 containers

*Steps to reproduce:*
1) Deploy the following streams.
stream create foo1 --definition ""time | log"" --deploy
stream create foo2 --definition ""time | log"" --deploy
stream create foo3 --definition ""time | log"" --deploy
stream create foo4 --definition ""time | log"" --deploy
stream create foo5 --definition ""time | log"" --deploy
stream create foo6 --definition ""time | log"" --deploy
stream create foo7 --definition ""time | log"" --deploy
stream create foo8 --definition ""time | log"" --deploy
stream create foo9 --definition ""time | log"" --deploy
stream create foo10 --definition ""time | log"" --deploy
stream create foo11 --definition ""time | log"" --deploy
stream create foo12 --definition ""time | log"" --deploy
stream create foo13 --definition ""time | log"" --deploy
stream create foo14 --definition ""time | log"" --deploy
stream create foo15 --definition ""time | log"" --deploy
stream create foo16 --definition ""time | log"" --deploy
stream create foo17 --definition ""time | log"" --deploy
stream create foo18 --definition ""time | log"" --deploy
stream create foo19 --definition ""time | log"" --deploy
stream create foo20 --definition ""time | log"" --deploy
stream create foo21 --definition ""time | log"" --deploy
stream create foo22 --definition ""time | log"" --deploy

2) Go to Streams tab in admin-ui to get a blank page and the following exception in admin logs.

*Error:*
16:55:19,107 1.1.0.SNAP ERROR http-nio-9393-exec-2 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.IllegalStateException: Not all instances were looked at
	at org.springframework.util.Assert.state(Assert.java:385)
	at org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:207)
	at org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:178)
	at org.springframework.xd.dirt.rest.StreamsController.list(StreamsController.java:63)
",XD-2609,Sabby Anandan,Error when listing Streams in admin-ui
1154,Thomas Risberg,Glenn Renfro,"1 admin on slave1
1 container on slave2

Gemfire modules fail to deploy.  with the following exception:
Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy
This is because the modules require a XD_HOME environment variable and this is not set by the yarn deployment.  
{noformat}
Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
	at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: null/modules/common/gemfire-sink.groovy (No such file or directory)
Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)
	at beans$_run_closure1.doCall(beans:4)
	at beans$_run_closure1.doCall(beans)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at groovy.lang.Closure.call(Closure.java:423)
	at groovy.lang.Closure.call(Closure.java:417)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)
	at groovy.lang.Closure.call(Closure.java:439)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)
	at beans.run(beans:1)
	at groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)
	... 29 more
Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at java.io.FileInputStream.<init>(FileInputStream.java:101)
	at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)
	at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)
	at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)
	at org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)
	... 79 more
{noformat}",XD-2608,Glenn Renfro,XD Gemfire modules fail to deploy in  Yarn
1155,David Turanski,David Turanski,"This Hadoop scenario will not work in Windows. The scope is to *disable* the test for windows build.

org.springframework.batch.integration.x.RemoteFileToHadoopTaskletTests > testWrite FAILED
    java.lang.IllegalStateException
        Caused by: org.springframework.beans.factory.BeanCreationException
            Caused by: java.lang.UnsatisfiedLinkError

org.springframework.batch.integration.x.RemoteFileToHadoopTests > testSimple FAILED
    java.lang.IllegalStateException
        Caused by: org.springframework.beans.factory.BeanCreationException
            Caused by: java.lang.UnsatisfiedLinkError
Java HotSpot(TM) Client VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0

3 tests completed, 2 failed
:spring-xd-extension-batch:test FAILED

FAILURE: Build failed with an exception.",XD-2607,David Turanski,Windows build fails
1156,Gary Russell,Sabby Anandan,"As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc. added as part of the message header.",XD-2606,Sabby Anandan,Add support to 'track history' in message headers
1157,,Glenn Renfro,"We're getting a CNF on org.apache.http.impl.client.HttpClients
{noformat}
20:07:03,556 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1, type=CHILD_ADDED
20:07:03,557 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'file' for stream 'ec2Test3'
20:07:03,828 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@8d11c70 moduleName = 'file', moduleLabel = 'file', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map['binary' -> 'true', 'mode' -> 'REPLACE'], children = list[[empty]]]
20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1, type=CHILD_ADDED
20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'twitterstream' for stream 'ec2Test3'
20:07:05,040 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['consumerKey' -> '5ynZLmXyvxXzAlYHRlrb28U8n', 'accessToken' -> '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5', 'accessTokenSecret' -> '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe', 'consumerSecret' -> 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'], children = list[[empty]]]
20:07:05,871 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
	... 39 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 48 more
Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)
	at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 50 more
Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 63 more
20:07:05,874 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
	... 39 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 48 more
Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)
	at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 50 more
Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 63 more
20:07:05,877 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
	... 39 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 48 more
Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)
	at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 50 more
Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 63 more
20:07:05,890 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1, type=CHILD_REMOVED
20:07:05,890 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Undeploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['consumerKey' -> '5ynZLmXyvxXzAlYHRlrb28U8n', 'accessToken' -> '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5', 'accessTokenSecret' -> '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe', 'consumerSecret' -> 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'], children = list[[empty]]]
20:07:19,164 1.1.0.SNAP  INFO main-EventThread server.DeploymentListener - Undeploying module [ModuleDescriptor@8d11c70 moduleName = 'file', moduleLabel = 'file', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map['binary' -> 'true', 'mode' -> 'REPLACE'], children = list[[empty]]]
20:07:19,457 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1, type=CHILD_REMOVED

{noformat}",XD-2605,Glenn Renfro,TwitterStream/TwitterSearch sources fail when deploying on Yarn
1158,Gunnar Hillert,Gunnar Hillert,"In order to decrease CI build issues, we should checkin bower dependencies. 

See: http://addyosmani.com/blog/checking-in-front-end-dependencies/",XD-2604,Gunnar Hillert,Change Grunt Build - Checkin Bower Artifacts
1159,Mark Pollack,Mark Pollack,"As an developer, I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava.  A plugin should allow a reactor processor module to specify the bare minimum to work, e.g. the processor class.    Explore how additional configuration can be achieved with well known module option commands.

",XD-2603,Mark Pollack,Create plugin module for RxJava based processors
1160,,Neeraj Kumar,"deploying stream:

stream create foo2 --definition ""jdbc --fixedDelay=600 --split=1 --url='jdbc:sqlserver://ip:port;database=XXXXX' --driverClassName=com.microsoft.sqlserver.jdbc.SQLServerDriver --username=XXXX --password=XXX--query='select * from abc' | hdfs --fsUri=hdfs://hadopIP:port --directory=xddir"" --deploy

It is throwing error:

19:17:10,087 1.0.2.RELEASE ERROR inbound.foo1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'
org.springframework.messaging.MessageHandlingException: failed to write Message payload to HDFS
	at org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:129)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy100.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor88.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy63.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:284)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:280)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:280)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.messaging.MessageHandlingException: message not a String
	at org.springframework.xd.integration.hadoop.outbound.HdfsDataStoreMessageHandler.doWrite(HdfsDataStoreMessageHandler.java:75)
	at org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:126)
	... 60 more

",XD-2602,Neeraj Kumar,trying to import data from MS SQL tables to hadoop using jdbc source and HDFS Sink . HDFS sink is not working
1161,,Paul McMinn,"The *org.springframework.xd.module.options.mixins.ScriptMixin* options class shipped with XD 1.0.3 refers to *script* rather than *location* however the XML configuration still references *$\{location\}* in the service activator:

{noformat}
	<service-activator output-channel=""output"" input-channel=""input"">
		<int-groovy:script location=""${location}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/>
	</service-activator>
{noformat}

Creating a stream using the old *location* argument no longer works obviously:

{noformat}
xd:>stream create myJobArchiveTrigger --definition ""tap:job:myJob.job > script --location=job-status.groovy --variables='tgtStatus=COMPLETED' > queue:job:archiveJob"" --deploy
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor
    location: option named 'location' is not supported
{noformat}

Creating the same stream using *--script* reports success at the shell prompt but results in an error in the container/admin logs:

{noformat}
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}""
{noformat}

Working around this by overriding the XML setting in our deployment:

{noformat}
	<service-activator output-channel=""output"" input-channel=""input"">
		<int-groovy:script location=""${script}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/>
	</service-activator>
{noformat}",XD-2601,Paul McMinn,Mismatch between configuration class and script XML for location/script
1162,Eric Bottard,Mark Pollack,This fix for RichGauge should go into the 1.0.x line.,XD-2600,Mark Pollack,Backport XD-2411 to 1.0.x branch
1163,Mark Pollack,Mark Pollack,"This is a parallel implementation to the RxJava 

https://github.com/spring-projects/spring-xd/blob/master/spring-xd-rxjava/src/main/java/org/springframework/xd/rxjava/SubjectMessageHandler.java

That will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.",XD-2599,Mark Pollack,Create a BroadcasterMessageHandler that uses a 'Serialized' Broadcaster
1164,Thomas Risberg,David Geary,"Update the supplied PostgreSQL JDBC Driver to the latest version (9.3-1102 - 2014-07-10), the current supplied version is from 2012. 

In our particular use case the latest driver allows use of the JDBC connection.unwrap feature which gives access to the underlying connection from a pooled connection which in turn enables use of the postgres copyManager.copyIn functionality which can speed up batch inserts in a batch process. 

See http://jdbc.postgresql.org/documentation/changelog.html
 ",XD-2598,David Geary,Update PostgreSQL JDBC Driver Version
1165,Thomas Risberg,Thomas Risberg,"As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment.

Best way, for now, would be to add an info command to the xd-yarn script.

With the latest changes the admin server runs on a random port when we deploy to YARN. In order for the user to connect they would have to query Zookeeper. This is inconvenient.",XD-2597,Thomas Risberg,"Add an ""xd-yarn info"" command to list admin servers and ports"
1166,,David Turanski,Intermittent. Reported on ubuntu and OS/x,XD-2596,David Turanski,KafkaMessageBusTests#testCompression failing
1167,Thomas Risberg,Thomas Risberg,"Test basic functionality (hdfs sink, jdbchdfs job) on hadoop26, hdp22, cdh5, phd21

Test XD on YARN on hadoop26, hdp22, cdh5 and phd21
",XD-2595,Thomas Risberg,Test recent Hadoop distro changes
1168,Thomas Risberg,Thomas Risberg,"Update spring-data-hadoop version to 2.1.0.RC1. This also includes updating the following:

- adding hadoop26 (Apache Hadoop 2.6.0) as distro
- adding hdp22 (Hortonworks HDP 2.2) as distro
- set default distro to hadoop26
- update cdh5 to version 5.3.0
- remove older distros - hadoop24, hdp21
",XD-2594,Thomas Risberg,Update spring-data-hadoop version to 2.1.0.RC1
1169,,gaojie,"Web UI management interface does not display the stream  list data or deploy status

js ERROR：
definitions.js:28 Uncaught TypeError: undefined is not a function

eg：http://120.27.44.69:9393/admin-ui/#/streams/definitions",XD-2593,gaojie,Web UI is not displayed
1170,,Glenn Renfro,"When deploying XD using Java 7 the user must be able to set the permsize to a value larger than the default.  
The reason this is required is that if we deploy a gemfire component more than 2 times or a kafka source & sink more than 2 times, stream deployment begins to fail.  

The only exception that was captured was the following:
{noformat}
Exception in thread ""ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor""
Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread ""ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor
{noformat}

Logs are not available at this time.

",XD-2592,Glenn Renfro,XD Yarn deployment requires the ability to set permsize
1171,Gary Russell,Gary Russell,,XD-2591,Gary Russell,Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2
1172,Gary Russell,Sabby Anandan,"As a user, I'd like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via _servers.yml_ to control the default message size.

*Notes:*
The adapter currently has that hard-coded (1MB limit) in the HttpChunkAggregator. We will have to expose this property for overrides. [Related PR|https://github.com/spring-projects/spring-xd/pull/1367].",XD-2590,Sabby Anandan,Create MessageConverter interface to allow user extensions
1173,Mark Pollack,Mark Pollack,Create port of https://github.com/spring-projects/spring-xd-samples/tree/master/reactor-moving-average based on RxJava,XD-2589,Mark Pollack,Create sample application for RxJava
1174,Gunnar Hillert,Mark Pollack,Run a clean gradle build to identify all warnings.,XD-2588,Mark Pollack,Remove all deprecated compile warnings
1175,Mark Pollack,Mark Pollack,,XD-2586,Mark Pollack,Update to Reactor 2.0 build snapshots
1176,,Glenn Renfro,"Attempted to set the rmAddress port to a value other than 8032 by using the resourceManagerPort however the value was not recognized.
I've attached the servers.yml.  
{noformat}
2015-01-12 20:21:48,935 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2015-01-12 20:21:48,940 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore, a default SyncTaskExecutor will be created.
2015-01-12 20:21:50,461 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn
2015-01-12 20:21:50,475 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration
2015-01-12 20:21:50,475 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration'
2015-01-12 20:21:50,498 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null
2015-01-12 20:21:50,649 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[file:///] with fsUri=[hdfs://10.111.172.160:9000]
2015-01-12 20:21:50,649 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[10.111.172.160:8032]
2015-01-12 20:21:55,965 INFO [ConfigurationFactoryBean] - Executing with tokens:
2015-01-12 20:21:55,975 INFO [SpringYarnConfigBuilder] - Setting configuration for SpringYarnConfigs:  fs.defaultFS=hdfs://10.111.172.160:9000 yarn.resourcemanager.address=10.111.172.160:8032 Configuration: core-default.xml, core-site.xml, yarn-default.xml, yarn-site.xml, mapred-default.xml, mapred-site.xml
{noformat}",XD-2585,Glenn Renfro,resourceManagerPort value not recognized when deploying container
1177,Gunnar Hillert,Mark Pollack,"Upgrade in 1.0.x branch what was done in this commit on master.

https://github.com/spring-projects/spring-xd/commit/16062d771e23187a1d9e8d549abc646ff44e435b
",XD-2584,Mark Pollack,Upgrade grunt/node plugins
1178,,Alvaro Vega,"From Spring XD Shell, running this command ""stream list"", we counted 30 streams, however Spring XD Admin UI shows only 20.
When destroying some streams from Admin UI, the others that was not in the list start appearing.
We have not reviewed if there is a configuration parameter that tells how many streams to show in the Admin UI.",XD-2583,Alvaro Vega,Spring XD Admin UI does not show all the streams
1179,,Karol Dowbecki,"Spring XD should package *spring-integration-xml* JAR within distribution so we can invoke *#xpath()* SpEL from processors, e.g. using transformer:

{code}... | transform --expression='#xpath(payload, ""/*[name()=''Datasource'']/*[name()=''row'']/text()"" | ... {code}
",XD-2582,Karol Dowbecki,Provide missing JARs to enable #xpath() SpEL
1180,,Karol Dowbecki,"*Expected* 

1. Create MYTABLE table with DATE or TIMESTAMP column MYTIME
2. Create a stream ending with {code}... | object-to-json | jdbc --tableName=MYTABLE ...{code}
3. Send a message with payload being a Java object that has a property myTime of type java.util.Date
4. Message payload is inserted into MYTABLE table, date is correctly stored in MYTIME column.

*Actual*

4. Exception is thrown from JDBC sink which attempts to bind a long into MYTIME column.

*Root cause*

JDBC sink uses *org.springframework.xd.jdbc.JdbcMessagePayloadTransformer* class to deserialize JSON payload into Map which will later be used to bind parameters into java.sql.PreparedStatement.

Unfortunately JdbcMessagePayloadTransformer, and MessageTransformingHandler which is calling it, doesn't respect *json\_\_TypeId\_\_* message header so information about Java types is lost. Other Spring XD components serialize java.util.Date as Unix timestamp e.g. object-to-json transformer. JDBC sink will deserialize the date as java.lang.Long and later attempt to bind incorrect type to query parameter.

In case of GemFire XD following exception will be thrown during query parameter binding phase:
{code}
com.pivotal.gemfirexd.internal.shared.common.sanity.AssertFailure: ASSERT FAILED Number of parameters expected for message id 22005 (3) does not match number of arguments received (2)
	at com.pivotal.gemfirexd.internal.shared.common.sanity.SanityManager.ASSERT(SanityManager.java:239)
	at com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.formatMessage(MessageUtil.java:245)
	at com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:151)
	at com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:191)
	at com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:107)
	at com.pivotal.gemfirexd.internal.client.am.SqlException.<init>(SqlException.java:184)
	at com.pivotal.gemfirexd.internal.client.am.PreparedStatement$PossibleTypes.throw22005Exception(PreparedStatement.java:4007)
	at com.pivotal.gemfirexd.internal.client.am.PreparedStatement.setLong(PreparedStatement.java:843)
	at com.pivotal.gemfirexd.internal.client.am.PreparedStatement.setObject(PreparedStatement.java:1688)
	at org.springframework.jdbc.core.StatementCreatorUtils.setValue(StatementCreatorUtils.java:402)
	at org.springframework.jdbc.core.StatementCreatorUtils.setParameterValueInternal(StatementCreatorUtils.java:235)
	at org.springframework.jdbc.core.StatementCreatorUtils.setParameterValue(StatementCreatorUtils.java:150)
	at org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.setValues(PreparedStatementCreatorFactory.java:300)
	at org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.createPreparedStatement(PreparedStatementCreatorFactory.java:252)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:909)
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:933)
	at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.update(NamedParameterJdbcTemplate.java:313)
	at org.springframework.integration.jdbc.JdbcMessageHandler.executeUpdateQuery(JdbcMessageHandler.java:130)
	at org.springframework.integration.jdbc.JdbcMessageHandler.handleMessageInternal(JdbcMessageHandler.java:112)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 372 more
{code}",XD-2581,Karol Dowbecki,JDBC sink doesn't deserialize JSON types correctly
1181,,Karol Dowbecki,"I attempted to create a stream with a Script processor using Spring XD shell:
{code}xd:>stream create --name test1 --definition ""tcp --port=17654 | script --location=print-stacktrace.groovy | null""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor:
    location: option named 'location' is not supported
{code}

I've corrected the syntax as described in docs by replacing --location with --script:
{code}xd:>stream create --name test1 --definition ""tcp --port=17654 | script --script=print-stacktrace.groovy | null""
Created new stream 'test1'{code}

My stream was created but the deployment failed with exception:
{code}
20:04:45,105 1.0.3.RELEASE  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'test1': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'org.springframework.integration.config.ServiceActivatorFactoryBean#0' defined in null: Could not resolve placeholder 'location' in string value ""${location}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}""
	at org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:211)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.processProperties(PropertySourcesPlaceholderConfigurer.java:180)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.postProcessBeanFactory(PropertySourcesPlaceholderConfigurer.java:155)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:162)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:201)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}""
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:174)
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126)
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:194)
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:158)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer$2.resolveStringValue(PropertySourcesPlaceholderConfigurer.java:175)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveStringValue(BeanDefinitionVisitor.java:282)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:209)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitIndexedArgumentValues(BeanDefinitionVisitor.java:150)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:84)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:169)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitIndexedArgumentValues(BeanDefinitionVisitor.java:150)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:84)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:169)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitPropertyValues(BeanDefinitionVisitor.java:141)
	at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:82)
	at org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:208)
	... 31 more
{code}

# [script.xml in 1.0.3 tag|https://github.com/spring-projects/spring-xd/blob/v1.0.3/modules/processor/script/config/script.xml] uses {code}<int-groovy:script location=""${location}"" ...{code}
# The [Script 1.0.3 processor docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.3.RELEASE/reference/html/#script] have issues with properties naming e.g. example is using --location while later --script is used. Same with --propertiesLocation and --properties-location.",XD-2580,Karol Dowbecki,Failed to create a stream with Script processor
1182,,Karol Dowbecki,"Currently xd-shell script packaged in Spring XD dist creates spring-shell.log file in invocation directory. 

When xd-shell is added to $PATH user will usually invoke the script from many directories leaving log files all over the file system.

Would it be possible to keep the log files in one predefined location (e.g. $HOME/.spring-shell.log or $DIST/shell/logs/spring-shell.log)?",XD-2579,Karol Dowbecki,Spring XD shell should maintain single log file (per user?)
1183,Marius Bogoevici,Vicky Kak,"The module/lib contains the necessary jars but it is not taken, I am attaching the simple custom module which contains just few beans. Here is how I am creating the job from the xd-shell
job create --name job1 --definition ""job-custom"" --deploy

The server logs contains this error
***************************************************************************************
10:43:20,193 1.1.0.M2  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@2963e1e2 moduleName = 'job-custom', moduleLabel = 'job-custom', group = 'job1', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]]
10:43:20,697 1.1.0.M2 ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed
java.lang.NoClassDefFoundError: org/springframework/oxm/Unmarshaller
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2531)
	at java.lang.Class.getDeclaredMethods(Class.java:1855)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:571)
***************************************************************************************

I already had been discussing this over the forums but could not get much help.
stackoverflow.com/questions/27878047/noclassdefinitionerror-with-simple-bean-configuration

If I place the spring-oxm jar in the spring-xd lib I get this error
***************************************************************************************
java.lang.IllegalStateException: Cannot convert value of type [org.springframework.oxm.jaxb.Jaxb2Marshaller] to required type [org.springframework.oxm.Unmarshaller] for property 'unmarshaller': no matching editors or conversion strategy found 
***************************************************************************************
",XD-2578,Vicky Kak,Custom Module not loading class from the module/lib.
1184,,Glenn Renfro,"When deploying XD (admin & container) using Yarn we only get the first 495 characters of the log which is the Ascii Art and Documentation links.
{noformat}
 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
1.1.0.BUILD-SNAPSHOT             eXtreme Data


Started : ContainerServerApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki
{noformat}",XD-2577,Glenn Renfro,XD is not logging when deployed using yarn
1185,,Sabby Anandan,"As a user, I'd like to use RxJava based _processor_ module so that I can leverage RxJava APIs for data computations. ",XD-2576,Sabby Anandan,Add RxJava based Stream processor module
1186,Thomas Risberg,Lukasz Nowanski,"When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file.

Proposed option:
rolloverTimeout
timeout after file will be automatically closed

Link: #XD-2413",XD-2575,Lukasz Nowanski,HDFS sink should provide rolloverTime option not only idleTiemout
1187,David Turanski,Lukasz Nowanski,"Gemfire sink module accepts useLocator, host and port properties but this only allows to use one locator at a time.

We have a need to use the Gemfire sink SpringXD Module in our Seamless access project that we want to go live in Q1.
The Version of SpringXD we planned on using is 1.1

However we need HA and we need to connect to a cluster with multiple locators. Problem is this isn’t supported yet in SpringXD.

We have used multiple locators in many projects in EMC and we don’t want to revert back to a situation where we have to put virtual IPs in front of locators just for SpringXD.

Ref to the SpringXD docs found in 1.0.3 and 1.1.0GA versions:

“The locator option is mostly intended for integration with an existing GemFire installation in which the cache servers are configured to use locators in accordance with best practice. While GemFire supports configuration of multiple locators for failover, this is currently not supported in XD. However, using a single virtual IP backed by hardware routers for failover has proven to be an effective and simpler alternative.”

",XD-2574,Lukasz Nowanski,Gemfire sink SpringXD module does not support multiple locators
1188,Gunnar Hillert,Thomas Risberg,"On Ubuntu 14.04 LTS using OpenJDK version  ""1.7.0_65""

OpenJDK Runtime Environment (IcedTea 2.5.3) (7u71-2.5.3-0ubuntu0.14.04.1)
OpenJDK 64-Bit Server VM (build 24.65-b04, mixed mode)

I see the following failures:

:spring-xd-dirt:test

org.springframework.xd.dirt.security.SingleNodeApplicationWithUserBasedSecurityTest > classMethod FAILED
    org.springframework.beans.factory.BeanCreationException
        Caused by: java.lang.IllegalStateException
            Caused by: java.net.BindException

org.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSimpleBindTest > classMethod FAILED
    org.springframework.beans.factory.BeanCreationException
        Caused by: java.lang.IllegalStateException
            Caused by: java.net.BindException

org.springframework.xd.dirt.security.SingleNodeApplicationWithDefaultSecurityTest > classMethod FAILED
    org.springframework.beans.factory.BeanCreationException
        Caused by: java.lang.IllegalStateException
            Caused by: java.net.BindException

org.springframework.xd.dirt.security.SingleNodeApplicationWithSslTest > classMethod FAILED
    org.springframework.beans.factory.BeanCreationException
        Caused by: java.lang.IllegalStateException
            Caused by: java.net.BindException

org.springframework.xd.dirt.security.SingleNodeApplicationWithUsersFileTest > classMethod FAILED
    org.springframework.beans.factory.BeanCreationException
        Caused by: java.lang.IllegalStateException
            Caused by: java.net.BindException

org.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSearchAndBindTest > classMethod FAILED
    org.springframework.beans.factory.BeanCreationException
        Caused by: java.lang.IllegalStateException
            Caused by: java.net.BindException

595 tests completed, 6 failed, 2 skipped
:spring-xd-dirt:test FAILED

The test reports has this:

Caused by: java.lang.IllegalStateException: HSQLDB could not be started on 0.0.0.0:7714, state: SHUTDOWN
	at org.springframework.xd.batch.hsqldb.server.HSQLServerBean.startServer(HSQLServerBean.java:162)
	at org.springframework.xd.batch.hsqldb.server.HSQLServerBean.afterPropertiesSet(HSQLServerBean.java:82)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)
	... 42 more
Caused by: java.net.BindException: Address already in use
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)
	at java.net.ServerSocket.bind(ServerSocket.java:376)
	at java.net.ServerSocket.<init>(ServerSocket.java:237)
	at java.net.ServerSocket.<init>(ServerSocket.java:128)
	at org.hsqldb.server.HsqlSocketFactory.createServerSocket(Unknown Source)
	at org.hsqldb.server.Server.openServerSocket(Unknown Source)
	at org.hsqldb.server.Server.run(Unknown Source)
	at org.hsqldb.server.Server.access$000(Unknown Source)
	at org.hsqldb.server.Server$ServerThread.run(Unknown Source)

So I assume I see this due HSQL running from another test.",XD-2573,Thomas Risberg,Full build with tests fail on Ubuntu
1189,Gunnar Hillert,Gunnar Hillert,Ensure build works in Windows environments,XD-2572,Gunnar Hillert,Set fixed NPM version for Grunt Gradle Plugin
1190,,Sabby Anandan,"As a developer, I'd like to upgrade _reactor-ip_ and _syslog_ modules to Reactor 2.0 so that we can sync up with the latest release.",XD-2571,Sabby Anandan,Update reactor-ip and syslog modules to Reactor 2.0 RC1
1191,Mark Pollack,Mark Pollack,The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation.  The current handler shares a single broadcast stream.  Change to create a new one per thread usage.,XD-2570,Mark Pollack,Create a new Broadcast stream per thread
1192,Mark Pollack,Mark Pollack,,XD-2569,Mark Pollack,Update to Spring Boot 1.2.1.RELEASE
1193,Glenn Renfro,Glenn Renfro,Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.,XD-2568,Glenn Renfro,Yarn Environment for XD Acceptance Tests
1194,Gary Russell,Gary Russell,"Since the messagebus refactoring, we now see 

{noformat}
15:43:06,379 1.1.0.M2  WARN xdbus.foo.0-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]
{noformat}

When using a rabbit transport and a rabbit sink (the sink Spring AMQP is in its own classloader).",XD-2567,Gary Russell,Strip MessageBus DeliveryMode Header
1195,Glenn Renfro,Sabby Anandan,"As a developer, I'd like to have acceptance test coverage for XD + YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.",XD-2566,Sabby Anandan,Add support to test XD on YARN in EC2
1196,Eric Bottard,Eric Bottard,"MongoDb driver is present on DIRT's classpath, while it should not (should be present on mongo-related modules though).

This is blocked by the shortcoming described here: https://github.com/spring-projects/spring-xd/pull/1116",XD-2565,Eric Bottard,Remove MongoDB from main DIRT classpath
1197,Thomas Risberg,Janne Valkealahti,"Currently yarn runtime needs two yarn appmaster instances(one for admins, one for containers). SHDP's container grouping added functionality to run different type of containers within a same appmaster.

Beyond this, container grouping will also give more functionality like ramping containers up/down on-demand, creating groups with different settings dynamically and restarting failed containers.",XD-2564,Janne Valkealahti,Enhance XD on YARN to use SHDP container clustering
1198,Thomas Risberg,Janne Valkealahti,"Admin on YARN simply fails because messagebus libs are not copied in place during a build.

Already tried and simple fix is for gradle/build-dist.gradle:

{code}
task copyYarnMessageBusLibs(type: Copy) {
  from ""$rootDir/lib/messagebus""
  into ""$buildDir/dist/spring-xd-yarn/xd-yarn/lib/messagebus""
}
{code}

and execute it together with copyMessageBusLibs task.",XD-2563,Janne Valkealahti,XD on YARN broken due to missing messagebus libs
1199,Thomas Risberg,Sabby Anandan,"As a developer, I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn't have to depend upon, thus eliminating the incorrect CP file generation in eclipse. ",XD-2562,Sabby Anandan,Move the Hadoop test dependencies to a different project
1200,Gunnar Hillert,Victor Chugunov,"The build failed on two classes from spring-xd-extension-process:
ShellCommandProcessor.java and ShellCommandProcessorTests.java
with error:
FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':spring-xd-extension-process:licenseTest'.
> License violations were found: /Users/victor.chugunov/git/repos/spring/spring-xd/extensions/spring-xd-extension-process/src/test/java/org/springframework/xd/extension/process/ShellCommandProcessorTests.java}


In both classes the license is misplaced:
package org.springframework.xd.extension.process;/*
 *
 *  * Copyright 2014 the original author or authors.
 *  *
 *  * Licensed under the Apache License, Version 2.0 (the ""License"");
 *  * you may not use this file except in compliance with the License.
 *  * You may obtain a copy of the License at
 *  *
 *  * http://www.apache.org/licenses/LICENSE-2.0
 *  *
 *  * Unless required by applicable law or agreed to in writing, software
 *  * distributed under the License is distributed on an ""AS IS"" BASIS,
 *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  * See the License for the specific language governing permissions and
 *  * limitations under the License.
 *
 */",XD-2561,Victor Chugunov,Document minimum memory requirement for Gradle builds
1201,,Sabby Anandan,"As a user, I'd like to have a Redis based aggregation over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.

*Scope:*
* Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters].
* Identify gaps
* Update reference documentation",XD-2560,Sabby Anandan,Add in-memory based Aggregate Field Value Counters
1202,,Sabby Anandan,"As a user, I'd like to have a Redis based _aggregation_ over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.

*Scope:*
* Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters].
* Identify gaps
* Update reference documentation ",XD-2559,Sabby Anandan,Add Redis based Aggregate Field Value Counters
1203,,Sabby Anandan,The scope is to use this as a bucket for any local test failures. Let's have them accounted in this story and fix as applicable. ,XD-2558,Sabby Anandan,Fix test failures and hangs on various local builds
1204,Gunnar Hillert,Sabby Anandan,"As a developer, I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.",XD-2557,Sabby Anandan,Upgrade to Reactor 2.0 RC1
1205,Mark Pollack,Sabby Anandan,,XD-2556,Sabby Anandan,Reference documentation on RxJava Stream processor
1206,,Sabby Anandan,"As an developer, I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava.  A plugin should allow a reactor processor module to specify the bare minimum to work, e.g. the processor class.    Explore how additional configuration can be achieved with well known module option commands.

",XD-2555,Sabby Anandan,Create plugin module for reactor based processors
1207,,Sabby Anandan,"As a user, I'd like to have the option to stop an existing Spark job so that I can clean-up resources at the time of completion.
",XD-2554,Sabby Anandan,Add support to stop existing Spark job
1208,,Sabby Anandan,"As a CF user, I'd like to have the ability to override the YARN config location so that I can change where the custom module _uber-jar_ can be stored and retrieved. ",XD-2553,Sabby Anandan,Add support to read/write custom modules in YARN
1209,,Sabby Anandan,"As a CF user, I'd like to have the ability to override the HDFS location so that I can change where the custom module _uber-jar_ can be stored and retrieved. ",XD-2552,Sabby Anandan,Add support to override CF Configs specific to custom module location in HDFS
1210,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. ",XD-2551,Sabby Anandan,Add support to read custom module artifact from HDFS
1211,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. ",XD-2550,Sabby Anandan,Add support to upload custom module artifact to HDFS
1212,Marius Bogoevici,Sabby Anandan,We would want to upgrade SI Kafka extension dependency to inherit the refactoring work with Kafka simple consumer API.,XD-2549,Sabby Anandan,Upgrade to SI-Kafka Extension release
1213,Ilayaperumal Gopinathan,Sabby Anandan,"As a performance tester, I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. 

*Scope:*
* Identify the bottlenecks
* Document reasons
* List pros/cons",XD-2548,Sabby Anandan,Investigate why CPU startup is high for admin and container servers
1214,David Turanski,David Turanski,"Expecting <module-name> in module configuration is brittle, especially in conjunction with module upload command which permits the module to be registered under a different name.  The convention should be dropped in favor of any file name. This requires at most one foo.xml, foo.groovy, and/or foo.properties in the top level config folder. It is an exception if multiples are found. 
Accepting any file name provides the most flexibility without sacrificing backward compatibility (except in rare cases in which a module developer may have violated the multiple xml or properties files condition). An alternate approach requiring a well known file name such as 'spring-module' were rejected over concerns that it would break any existing custom module implementations.",XD-2547,David Turanski,Accept any file name for top level module resources
1215,Glenn Renfro,Glenn Renfro,,XD-2546,Glenn Renfro,Create AMI for Spark Server installed
1216,,Glenn Renfro,Create a Sink that can capture the results of the messages sent and log the number of messages received per a configured interval in seconds.,XD-2545,Glenn Renfro,Create a PerfSink Module
1217,Glenn Renfro,Glenn Renfro,"Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.  

",XD-2544,Glenn Renfro,Create a loadGenerator source module
1218,,Sabby Anandan,"As a user, I'd like to have the option to define access control list (ACLs) so that I can define access controls to the resource by 'each user', and what the privileges are for that 'resource'.

*Spike Scope:*
** Review customer use cases and come up with design specs
** Identify the best approach that fits XD runtime
** Identify scope for DSL and UI 
** Document next steps and phases
",XD-2543,Sabby Anandan,Research approach to define and administer Access Control List (ACL)
1219,Mark Pollack,Sabby Anandan,"As a user, I'd like to have a flexible RxJava module so that it can as a processor. 
",XD-2542,Sabby Anandan,Create MessageHandler for RxJava based processor modules
1220,Mark Pollack,Sabby Anandan,"As a user, I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.",XD-2541,Sabby Anandan,Define developer facing interfaces for RxJava processors
1221,,Sabby Anandan,,XD-2540,Sabby Anandan,Integration with Reactive Extensions for the JVM
1222,Gary Russell,Gary Russell,"See http://stackoverflow.com/questions/27725905/spring-xd-1-1-0-m2-fails-to-start

With {{XD_HOME}} set with back-whacks, it fails on {{\U...}} with {{XD_HOME}} set with whacks, it fails with {{/xd\...}}. The StackOverflow failure is similar.

1.0.3 works fine.

{noformat}
set XD_HOME=C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd

Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 5
.*C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd\lib\messagebus\([^/]*).*

set XD_HOME=C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd


Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 71
.*C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd\lib\messagebus\([^/]*).*
{noformat}",XD-2539,Gary Russell,XD 1.1.0.M2 Won't Run on Windows
1223,,Sabby Anandan,"As a user, I'd like to have an option to disable DB requirement so that I can setup to use DIRT runtime when stream processing is the only requirement.",XD-2538,Sabby Anandan,Make DB an optional peripheral for DIRT
1224,Gary Russell,Gary Russell,"An additional commit (https://github.com/spring-projects/spring-xd/commit/db1f585) for XD-2230 was applied only to master; it needs to be backported to 1.0.x.

{{s/$\{location\}/$\{script\}/}}


https://gopivotal-com.socialcast.com/messages/22909482",XD-2537,Gary Russell,BackPort script.xml Bug Fix
1225,,Vicky Kak,"We wanted to bind the spring-xd to the public IP but am not able to do so. 
I scanned at the code here and could make there is not way to bind the IP address 
https://github.com/spring-projects/spring-xd/blob/master/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/AdminServerApplication.java 

This one looks a simple change, I can fix it and push the pull request.",XD-2536,Vicky Kak,Provide IP binding to the spring-xd instance.
1226,,Sabby Anandan,"As a performance tester, I'd like to re-run baseline benchmarks with compression enabled on Rabbit so that I can compare the results with previous performance snapshots. ",XD-2535,Sabby Anandan,Re-run baseline benchmarks with payload compression enabled
1227,,Sabby Anandan,"As a performance tester, I'd like to rerun baseline benchmarks with batching enabled on Rabbit so that I can compare the results with previous performance snapshots. 

Note:
- batchingEnabled = true
- batchingSize = 100 (default)

We could also vary default size to compute and record at granular level. ",XD-2534,Sabby Anandan,Re-run baseline benchmarks with payload batching enabled
1228,Mark Pollack,Mark Pollack,,XD-2533,Mark Pollack,Upgrade to Reactor 2.0 M2
1229,Glenn Renfro,Glenn Renfro,When executing a Spark Application Job on XD against a remote Spark Master we receive a CNF exception for FSDataInputStream.  Running against a local[1] Spark Master works normally.  ,XD-2532,Glenn Renfro,Spark Application Job fails when using remote Spark Master
1230,Thomas Risberg,Sabby Anandan,"As a user, I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options. ",XD-2531,Sabby Anandan,Document Sqoop job
1231,,Sabby Anandan,"As a user, I'd like to have the option to extend compression support so that I can override the defaults and customize as needed.

Follow-up from this PR: https://github.com/spring-projects/spring-xd/pull/1346",XD-2527,Sabby Anandan,Add support to extend message compression 
1232,Glenn Renfro,Glenn Renfro,"As a QA, I'd like to include acceptance test coverage for hdfs-dataset module so that I can validate the functionality as part of every CI build.",XD-2526,Glenn Renfro,Create Acceptance Test for hdfs-dataset
1233,,Glenn Renfro,"When using the XD shell a user can enter the first character of a command and it will be accepted as the full command.  for example

e <return/>  will exit the shell
The following commands below show how a user can target a new cluster and then get a job execution list by using the first character of the command.

server-unknown:>a c s http://ec2-54-90-166-140.compute-1.amazonaws.com:9393
Successfully targeted http://ec2-54-90-166-140.compute-1.amazonaws.com:9393
xd:>j e l
  Id  Job Name                                   Start Time               Step Execution Count  Execution Status  Deployment Status  Definition Status
  --  -----------------------------------------  -----------------------  --------------------  ----------------  -----------------  -----------------
  28  tsle2145f21d-5b0b-49df-b9cc-a3fe65c49ecc   2014-12-18 11:08:47,000  2                     COMPLETED         Undeployed         Destroyed
  27  ec2Job3                                    2014-12-18 11:07:13,000  2                     COMPLETED         Undeployed         Destroyed
  26  ec2Job3",XD-2525,Glenn Renfro,In XD shell an incomplete command will be executed as the full command
1234,David Turanski,David Turanski,"warning: [options] bootstrap class path not set in conjunction with -source 1.6
/home/dturanski/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleToJsonStringConverter.java:53: warning: [deprecation] put(String,JsonNode) in ObjectNode has been deprecated
					root.put(name, toObjectNode((Tuple) value));
					    ^
/home/dturanski/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleToJsonStringConverter.java:57: warning: [deprecation] put(String,JsonNode) in ObjectNode has been deprecated
					root.put(name, root.pojoNode(value));",XD-2524,David Turanski,Update deprecated jackson methods in TupleToJsonStringConverter
1235,David Turanski,Sabby Anandan,"As a user, I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for 'MODULE' layout and other boilerplate build configuration.

This is dependent on Boot's module layout scoping issue: https://github.com/spring-projects/spring-boot/issues/2187",XD-2523,Sabby Anandan,Add gradle build support for custom module projects
1236,,Eric Bottard,"Commit https://github.com/spring-projects/spring-xd/commit/8d28b2786acbdea1617d7e903b805e5af5369b90 removed MessageBus implementations from the main dirt classpath, but used a trick to have tests working (basically, MB classes *are* on the CP when in test scope).

This story is about adding more gradle projects that support classpath isolation when running tests (and also when authoring a MB implementation).

This would avoid false positives such as https://github.com/spring-projects/spring-xd/pull/1340 were lacking jars go unnoticed",XD-2522,Eric Bottard,Further decouple message bus deps (test scope)
1237,Gary Russell,Mark Pollack,"https://jira.spring.io/browse/AMQP-453 Added support for compression with RabbitMQ.  XD should expose configuration options to enable and configure compression on the message bus.  Note, some options may be specific for brokers or require additional functionality in XD.  

This issue should not address adding additional functionality to make the feature set as common as possible across msg bus implementations, but expose what makes sense with the current code base for rabbitmq   As an example, Kafka supports compressed.topics which lets you pick a subset of topics to be compressed.  ",XD-2521,Mark Pollack,Add options for supporting compression on the message bus with RabbitMQ
1238,,Thomas Risberg,We need to add some integration tests for the Sqoop job introduced in XD-2430,XD-2520,Thomas Risberg,Add integration tests for Sqoop job
1239,,Thomas Risberg,"The Sqoop tasklet introduced an AbstractProcessBuilderTasklet implementation in XD-2430. We are now adding similar support to Batch SystemCommandTasklet in BATCH-2329, BATCH-2330 and BATCH-2331. We should refactor Sqoop and Spark tasklets to use the SystemCommandTasklet as base.",XD-2519,Thomas Risberg,Refactor Spark and Sqoop tasklets to use SystemCommandTasklet
1240,Gunnar Hillert,Gunnar Hillert,,XD-2518,Gunnar Hillert,Upgrade to Gradle 2.2
1241,,Thomas Risberg,We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project,XD-2517,Thomas Risberg,Clean up spring-xd-batch sub-project
1242,Marius Bogoevici,Glenn Renfro,"When trying to configure XD to use a RabbitMQ instance other than the default localhost:5672, a user is supposedto updated the ""spring_rabbitmq_addresses"" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file.  In this case XD is ignoring this environment variable.  

h3. Steps to reproduce 

# set the transport by using ""export XD_TRANSPORT=rabbit""
# set the spring_rabbitmq_addresses by ""export spring_rabbitmq_addresses=foo:5672""
# Startup a admin container on your local machine
# deploy ticktock
#* this should fail
#* start up a local rabbitmq
#* deploy a new ticktock and stream will deploy.

",XD-2516,Glenn Renfro,spring_rabbitmq_addresses environment variable is ignored
1243,,Sabby Anandan,"As a user, I'd like to have the option of _batching_ for the Rabbit _sink_ so that I can write data in batches as opposed to one-at-a-time. ",XD-2515,Sabby Anandan,Add batching support for Rabbit sink
1244,,Sabby Anandan,"As a user, I'd like to have the option of _compression_ for both Rabbit _source_ and _sink_ modules so that can further enhance the performance characteristics.",XD-2514,Sabby Anandan,Add compression support for Rabbit source/sink
1245,,Sabby Anandan,"As a user, I'd like to have the option to _compress_ messages so that I can influence the performance throughput. It'd be beneficial to have support for gzip, zip compression, and decompression.",XD-2513,Sabby Anandan,Add support for message compression
1246,,David Turanski,"See http://stackoverflow.com/questions/27491237/spring-xd-tcp-source-outputs-byte-array-instead-of-string-how-to-output-regu. 

Same behavior as --outputType text/plain but more intuitive to use application/json if the stream author expects the source to emit json. No content validation will be done. 

",XD-2512,David Turanski,Byte[] to String conversion should support application/json 
1247,,Sabby Anandan,"As a user, I'd like to have a separate _YML_ file to list the deployment manifest properties so that I don't have to include as part of the stream definition. ",XD-2511,Sabby Anandan,New YML file as deployment manifest
1248,Marius Bogoevici,Marius Bogoevici,"RabbitMQ Sink is throwing:
{quote}
09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed
org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)
    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)
    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
    at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
    at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
    at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
    at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
    at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
    at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
    at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
    at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
    at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
    at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
    at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
    at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
    at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:745)
Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)
    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)
    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
    at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
    at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)
    at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)
    at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)
    ... 30 more
09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)
    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)
    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
    at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
    at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
    at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
    at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
    at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
    at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
    at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
    at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
    at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
    at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
    at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
    at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
    at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:745)
Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)
    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)
    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)
    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
    at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
    at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)
    at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)
    at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)
    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)
{quote}",XD-2510,Marius Bogoevici,Fix classpath issues for RabbitMQ source/sink
1249,Marius Bogoevici,Marius Bogoevici,"Rabbit Message Bus is throwing:

{quote}
10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader
    at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)
    at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)
    at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)
    at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)
    at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)
    at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)
    at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)
    at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)
    at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)
    at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)
    at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)
    at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
    at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
    at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
    at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
    at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
    at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
    at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
    at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
    at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
    at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader
    at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)
    at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)
    at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)
    at java.lang.reflect.WeakCache.get(WeakCache.java:141)
    at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)
    at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)
    at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)
    at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)
    at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)
    at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)
    at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)
    at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)
    ... 28 more
{quote}",XD-2509,Marius Bogoevici,Solve CP issues for the Rabbit MessageBus
1250,Gary Russell,Gary Russell,"HA Configuration, async sends.

http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt",XD-2508,Gary Russell,MQTT: Support the New Spring Integration 4.1 Features
1251,,Ilayaperumal Gopinathan,"When XML response is requested from the REST clients, the server has XML serialization errors.

For example: the endpoint  /jobs/configurations from the web browser
has:
nested exception is javax.xml.bind.MarshalException - with linked exception: [com.sun.istack.SAXException2: unable to marshal type ""org.springframework.xd.rest.domain.DetailedJobInfoResource"" as an element because it is not known to this context.]",XD-2507,Ilayaperumal Gopinathan,REST endpoints XML response is broken
1252,,Michael Campbell,"The EXAMPLE in the documentation (and the paragraph preceding the example) for the ""script"" processor uses both ""location"" and ""properties-location"" options, but these are in actuality ""script"" and ""locationProperties"" according to ""module info processor:script"" and the text of the documentation.

See: http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script


{quote}To use the module, pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script, you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.

{code}xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log"" --deploy{code}
{quote}",XD-2506,Michael Campbell,"""script"" processor options incorrect on docs"
1253,Thomas Risberg,Jason Hubbard,"When using the hadoop namespace to create a hadoop configuration and filesystem, the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module, the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed",XD-2505,Jason Hubbard,Undeploying HDFS module closes filesystem
1254,Glenn Renfro,Glenn Renfro,"Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI
Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future.
",XD-2504,Glenn Renfro,Upgrade CI Acceptance AMI to HVM
1255,Marius Bogoevici,Glenn Renfro,"I believe it is being cause by the following PR:
XD-2381: Split MessageBus and Analytics dependencies from DIRT
PR:  1307
SHA: 8d28b2786acbdea1617d7e903b805e5af5369b90

*RabbitMQ Sink is throwing:*
{noformat}
09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed
org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
	at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)
	at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)
	... 30 more
09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
	at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)
	at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)
	at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)
{noformat}
*Rabbit Message Bus is throwing:*
{noformat}
10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader
	at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)
	at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)
	at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)
	at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)
	at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)
	at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader
	at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)
	at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)
	at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)
	at java.lang.reflect.WeakCache.get(WeakCache.java:141)
	at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)
	at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)
	at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)
	at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)
	at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)
	... 28 more
{noformat}",XD-2503,Glenn Renfro,"RabbitMQ Message bus, RabbitMQ Source/Sinks are throwing exceptions"
1256,Marius Bogoevici,Mark Pollack,Test is failing since Kafka isn't installed on the CI server.  Using an embedded server will make the testing more robust vs. needing an external server.,XD-2502,Mark Pollack,KafkaSourceSinkTests to use embedded Kafka server
1257,David Turanski,Sabby Anandan,"As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug-fixes and enhancements. 

*Following XD dependencies needs upgraded to sync-up with Boot 1.2.0 RELEASE:*

<activemq.version>5.10.0</activemq.version>
<aspectj.version>1.8.4</aspectj.version>
<commons-dbcp2.version>2.0.1</commons-dbcp2.version>
<h2.version>1.4.182</h2.version>
<hibernate.version>dd4.3.7.Final</hibernate.version>
<hibernate-validator.version>5.1.3.Final</hibernate-validator.version>
<hikaricp.version>2.2.5</hikaricp.version>
<hornetq.version>2.4.5.Final</hornetq.version>
<httpasyncclient.version>4.0.2</httpasyncclient.version>
<httpclient.version>4.3.6</httpclient.version>
<jackson.version>2.4.4</jackson.version>
<janino.version>2.6.1</janino.version>
<jetty.version>9.2.4.v20141103</jetty.version>
<jetty-jsp.version>2.2.0.v201112011158</jetty-jsp.version>
<joda-time.version>2.5</joda-time.version>
<jolokia.version>1.2.3</jolokia.version>
<junit.version>4.12</junit.version>
<liquibase.version>3.3.0</liquibase.version>
<log4j.version>1.2.17</log4j.version>
<log4j2.version>2.1</log4j2.version>
<mockito.version>1.10.8</mockito.version>
<mongodb.version>2.12.4</mongodb.version>
<mysql.version>5.1.34</mysql.version>
<reactor.version>1.1.5.RELEASE</reactor.version>
<reactor-spring.version>1.1.3.RELEASE</reactor-spring.version>
<servlet-api.version>3.1.0</servlet-api.version>
<spring.version>4.1.3.RELEASE</spring.version>
<spring-batch.version>3.0.2.RELEASE</spring-batch.version>
<spring-data-releasetrain.version>Evans-SR1</spring-data-releasetrain.version>
<spring-hateoas.version>0.16.0.RELEASE</spring-hateoas.version>
<spring-mobile.version>1.1.3.RELEASE</spring-mobile.version>
<spring-security.version>3.2.5.RELEASE</spring-security.version>
<tomcat.version>8.0.15</tomcat.version>
<undertow.version>1.1.1.Final</undertow.version>",XD-2501,Sabby Anandan,Upgrade to Boot 1.2.0 RELEASE and the dependencies
1258,,Sabby Anandan,,XD-2500,Sabby Anandan,Sync-up with boot dependencies
1259,Eric Bottard,Sabby Anandan,"As a user, I'd like to use _partitionResultsTimeout_ attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki. 

*Note:*
The property should be available for all the jobs that import; 3 OOTB jobs have it imported (ref. attachment)",XD-2499,Sabby Anandan,Document 'partitionResultsTimeout' metadata attribute
1260,,Sabby Anandan,"As a user, I'd like to use the _Mail_ sink to connect to secured IMAP and/or SMTP mail servers. Currently, the sink doesn't support TLS.

_Mail_ sink config file requires a <util:properties/> bean (with ssl/tls properties), provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].

{code:xml}
<util:properties id=""javaMailProperties"">
  <prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</prop>
  <prop key=""mail.imap.socketFactory.fallback"">false</prop>
  <prop key=""mail.store.protocol"">imaps</prop>
  <prop key=""mail.debug"">false</prop>
</util:properties>
{code}

[List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]",XD-2498,Sabby Anandan,Add imap/smtp properties to Mail sink
1261,,Mark Pollack,"When building on a branch, the docs should be defaulting to build from origin/master, but that doesn't seem to be happening.  Instead an explicit -Pwikibranch=origin/master is required to be specified on the command line.

",XD-2497,Mark Pollack,Investigate lack of falling back to origin/master when building docs on a branch
1262,Mark Pollack,Mark Pollack,Some cleanup to make the tests a bit easer to read.,XD-2496,Mark Pollack,Refactor use of getContainerHostForSource in integration tests
1263,,Glenn Renfro,"* Environment:
** Can be reproduced on local machine with Admin and a single container.
* create the following job
** job create ogg --definition ""filejdbc --resources=file:filejdbctest//filejdbctestpartition* --names=data --tableName=filejdbctest --initializeDatabase=true "" --deploy
* note: this works on Rabbit and Redis as a message bus
* The following exception is thrown on the admin:
6:54:22,856 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.JobDeploymentListener - Deployment status for job 'ogg': DeploymentStatus{state=failed,error(s)=java.lang.UnsupportedOperationException: Auto-generated method stub
	at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)
	at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)
	at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)
	at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
}

* The following exception is thrown on the container
21:08:14,721 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 config.ReleaseStrategyFactoryBean - No annotated method found; falling back to SequenceSizeReleaseStrategy, target:org.springframework.batch.integration.partition.MessageChannelPartitionHandler@692ee39f, methodName:null
21:08:15,946 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
java.lang.UnsupportedOperationException: Auto-generated method stub
	at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)
	at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)
	at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)
	at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)",XD-2495,Glenn Renfro,Add Request/Reply support to Kafka message bus
1264,,Eric Bottard,"see problem reported at http://stackoverflow.com/questions/27368351/spring-xd-module-sourcetrigger-does-not-work-as-expected

",XD-2494,Eric Bottard,Make trigger options explicitly exclusive
1265,,abhineet kumar,There is no support for Amazon s3 source module in spring xd. Spring Integration for s3 as custom source module is also not working gracefully. ,XD-2493,abhineet kumar,No support for Amazon s3 source module in xpring xd
1266,Gunnar Hillert,Buelent Zeyben,"The Step Execution Process (http://localhost:9393/admin-ui/#/jobs/executions/38/52) page should list more lines of text for 'Exit Description' field to make sense of error messages.

*Scope:*
Investigate how much information can be collected directly from the ExecutionContext. It may be dependent on the error types. Let's have the observation documented to decide next steps. 
",XD-2492,Buelent Zeyben,Increase Exit Description Text field on Job Execution Process step page
1267,,Buelent Zeyben,"The JDBCHDFS Master process fails with a timeout error while the child process is still processing data.

The error message on the error message on the master process is:

org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned
	at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)
	at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy47.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)
	at sun.reflect.NativeMethodAccessorImpl",XD-2491,Buelent Zeyben,JDBCHDFS Master Process Timeout error
1268,Mark Pollack,Mark Pollack,"The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed.  Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.",XD-2490,Mark Pollack,Update Reactor Stream processor to use latest snapshots
1269,Mark Pollack,Mark Pollack,,XD-2489,Mark Pollack,Reference documentation on creating Reactive Stream processor/sink
1270,Mark Pollack,Mark Pollack,"A sample, perhaps taken from Pivotal Labs use-case in Denver, that would calculate some time window averages for a many individual senor values .",XD-2488,Mark Pollack,Create sample module in spring-xd-modules for a Reactor Stream processor
1271,Mark Pollack,Mark Pollack,The module should be flexible to act as a sink as well as a processor.  ErrorHandling will be considered as part of another JIRA,XD-2487,Mark Pollack,Create ReactorMessageHandler for Reactor based XD processor/sink modules
1272,Michael Minella,Jason Hubbard,"If a class is added to a batch execution context that is located in an isolated context, an exception will be thrown when that object is deserialized.  It appears the serialize doesn't use the ParentFirstClassloader during deserialization.",XD-2486,Jason Hubbard,Context Deserialize Doesn't Use Parent First Classloader
1273,Thomas Risberg,Thomas Risberg,,XD-2485,Thomas Risberg,Update spring-data-hadoop version to 2.0.4 for XD 1.0.3
1274,Thomas Risberg,Thomas Risberg,,XD-2484,Thomas Risberg,Update spring-data-hadoop version to 2.1.0.M3
1275,Thomas Risberg,Thomas Risberg,"As a user, I would like to be able disable snappy compression when using hdfs-dataset sink with Avro files. I'd also like to be able to provide a different codec.",XD-2483,Thomas Risberg,Add codec option to hdfs-dataset sink
1276,Gary Russell,Enrique Medina,"Currently, the {{source:trigger}} module is based on 3 profiles: {{date}}, {{cron}} or {{fixedDelay}}, where the latter has precedence over the former in {{TriggerSourceOptionsMetadata}}:

{code:java}
@Override
public String[] profilesToActivate() {
    if (cron != null) {
        return new String[] { ""use-cron"" };
    }
    else if (fixedDelay != null) {
        return new String[] { ""use-delay"" };
    }
    else {
        return new String[] { ""use-date"" };
    }
}
{code}

Therefore it is not possible to combine {{date}} and {{fixedDelay}} to start off at a specific point in time, and then repeat every X seconds.

This is a request to provide another parameter to {{source:trigger}} such as *{{initialDelay}}* to be able to achieve the desired behaviour.",XD-2482,Enrique Medina,"Add ""initialDelay"" to ""source:trigger"""
1277,Mark Pollack,Mark Pollack,What is the core interface contract users will be exposed to when creating a processor module that uses Reactor's Stream API.   Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.,XD-2481,Mark Pollack,Define developer facing interfaces for Reactor Stream processors
1278,Thomas Risberg,Sabby Anandan,"As a QA, I'd like to benchmark _Sqoop_ vs. _jdbchdfs_ batch job so that I can compare and contrast performance stats. ",XD-2480,Sabby Anandan,Benchmark: Sqoop vs. jdbchdfs
1279,,Sabby Anandan,"As a user, I'd like to incremental-data-load so that I can retrieve only rows newer than some previously-imported.",XD-2479,Sabby Anandan,Add METADATA store for incremental-load
1280,,Sabby Anandan,"As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively. 

We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.",XD-2478,Sabby Anandan,Add support to access Sqoop logs
1281,Thomas Risberg,Sabby Anandan,"As a user, I'd like to have the option to _stop_ an existing Sqoop job so that I can clean-up resources at the time of completion.",XD-2477,Sabby Anandan,Add support to stop existing Sqoop jobs
1282,,Sabby Anandan,,XD-2476,Sabby Anandan,Sqoop integration stories/tasks
1283,Gary Russell,Sabby Anandan,"As a user, I'd like to have the option to setup _batching_ so that I can ingest data in batches as opposed to payload-at-a-time.",XD-2475,Sabby Anandan,Add batching support to Spring AMQP/Rabbit
1284,,Sabby Anandan,"As a user, I'd like to have the option to implement _bindRequestor_ and _bindReplier_ so that I can ""bind a producer that expects async replies"" and ""bind a consumer that handles requests from a requestor and asynchronously sends replies"" respectively. 

",XD-2474,Sabby Anandan,Add support for bindRequestor and bindReplier
1285,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the option to _ACK_ messages so that I can guarantee that the message/request sent is successful. ",XD-2473,Sabby Anandan,Kafka Bus: Add support for ACK mode
1286,Gary Russell,Sabby Anandan,"As a user, I'd like to have the option to choose between async vs. sync Kafka producer so that I can decide what algorithm better suits for sending messages. ",XD-2472,Sabby Anandan,Kafka Bus: Add suppor for async vs. sync producer
1287,Eric Bottard,Sabby Anandan,"As a user, I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and/or increase responsiveness

*Things to consider:*
* make global configuration options be ""defaults"" and allow per-deployment overrides
* add options for 
** concurrency
** compression support",XD-2471,Sabby Anandan,Kafka Bus: Concurrency and compression support
1288,Glenn Renfro,Glenn Renfro,"During an integration test over the weekend the cluster based tests failed.
They showed that a job was left in an inconsistent state (incomplete) 
and other jdbc job tests failed because they could not connect to the database.  
",XD-2470,Glenn Renfro,Identify scenario where XD JDBC based jobs fail to connect to DB
1289,,David Turanski,"Thinking about the UBS(?) scenario that MP described. They want all their Cassandra modules to share a connection, leading to the need for a parent context for those modules. We could introduce a parent module for this purpose. The module declares a parent in its properties which likely ends up as a parent module definition in the module definition. When the child module is deployed, its parent must be deployed first if it is not already (i.e., parent is a singleton per container). The module sets that as it's parent context.  We would have to make sure things happen in the correct order so the global context is the parent of the parent (ad infinitum). The alternative is to add a module parent context to the XD hierarchy which is extensible, but this is more elegant IMHO.

Also, in cases that don't require singleton bean definitions, the parent could package and provide common jars to children, e.g., we set the parent module's classloader as the parent classloader, eliminating the
need to install common jars in an HDFS path (basically the approach I described https://jira.spring.io/browse/XD-2420) 

MP :
>> Also, in cases that don't require singleton bean definitions, the parent could package and provide common jars to children, e.g., we set the parent module's classloader as the parent classloader
This approach does not offer some of the advantages offered by a central yaml config noted in the JIRA . But it is simpler in many ways. The developer just installs a parent module containing dependent jars and sets that as a parent in the child modules. This requires no additional infrastructure. To address the hadoop scenario we discussed, we would need another level of indirection so the parent of the hdfs modules is bound to the configured hadoop distro.   e.g. something like

parent = ${xd.hadoop.distro} in module properties

MF:
Possibly the parent modules could go in the ""common"" directory? They should be considered ""abstract"" also - in the same sense as abstract bean definitions in a Spring context (and they should only be started on demand when needed by at least one concrete child module - then destroyed when the last child module is destroyed).

Maybe this would also allow us to wrap up those xml files that currently live in ""common"" so that they are treated as parent modules?

MF: Yea, that sounds good wrt to common.

Also it might be a good idea to enable spring to throw an error if it finds more than one bean of the same name in the application context - i think that applies to searching in parent contexts as well.  this would avoid the 'last one wins' rule and give more deterministic behavior.
",XD-2469,David Turanski,Parent Modules
1290,Glenn Renfro,Glenn Renfro,,XD-2468,Glenn Renfro,Kafka Profiling for Base & Distributed base benchmarks
1291,Mark Fisher,Mark Fisher,"This should include lifecycle management, so that when the module's stream is undeployed, the Spark Streaming application should be stopped, etc.

Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata.
",XD-2467,Mark Fisher,Implement a Spark Streaming Driver application that can be controlled as an XD module instance
1292,Ilayaperumal Gopinathan,Mark Fisher,,XD-2466,Mark Fisher,Implement a dirt plugin for Spark Streaming support
1293,,Mark Fisher,,XD-2465,Mark Fisher,"Implement an XD module type that integrates with Spark Streaming, reactor etc.,"
1294,,Mark Fisher,,XD-2464,Mark Fisher,Provide simple developer interfaces and an XD module type that acts as a Spark Streaming driver application.
1295,,Sabby Anandan,,XD-2463,Sabby Anandan,Test with Java8 runtime
1296,Glenn Renfro,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _Kafka_ as a message bus so that I can validate the functionality as part of every CI build.",XD-2462,Sabby Anandan,Acceptance test for Kafka as a message bus
1297,,Sabby Anandan,,XD-2461,Sabby Anandan,Make XD-EC2 Bootiful
1298,,Sabby Anandan,,XD-2460,Sabby Anandan,Update to use Compute optimized and standard machine types
1299,,Sabby Anandan,,XD-2459,Sabby Anandan,Update XD-EC2 to use placement groups
1300,Glenn Renfro,Sabby Anandan,,XD-2458,Sabby Anandan,Update Base AMI to be a HVM
1301,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _timestampfile_ batch job so that I can validate the functionality as part of every CI build. ",XD-2457,Sabby Anandan,"Acceptance test for ""timestampfie"" batch job"
1302,Glenn Renfro,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _spark-app_ batch job so that I can validate the functionality as part of every CI build. ",XD-2456,Sabby Anandan,"Acceptance test for ""spark-app"" batch job"
1303,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _throughput-sampler_ sink module so that I can validate the functionality as part of every CI build. ",XD-2455,Sabby Anandan,"Acceptance test for ""throughput-sampler"""
1304,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _splunk_ sink module so that I can validate the functionality as part of every CI build. ",XD-2454,Sabby Anandan,"Acceptance test for ""splunk"""
1305,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _shell_ sink module so that I can validate the functionality as part of every CI build. ",XD-2453,Sabby Anandan,"Acceptance test for ""shell"""
1306,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _router_ sink module so that I can validate the functionality as part of every CI build. ",XD-2452,Sabby Anandan,"Acceptance test for ""router"""
1307,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _rich_gauge_ sink module so that I can validate the functionality as part of every CI build. ",XD-2451,Sabby Anandan,"Acceptance test for ""rich-gauge"""
1308,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _null_ sink module so that I can validate the functionality as part of every CI build. ",XD-2450,Sabby Anandan,"Acceptance test for ""null"" sink"
1309,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _mail_ sink module so that I can validate the functionality as part of every CI build. ",XD-2449,Sabby Anandan,"Acceptance test for ""mail"" sink"
1310,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _hdfs-dataset_ sink module so that I can validate the functionality as part of every CI build. ",XD-2448,Sabby Anandan,Acceptance test for hdfs-dataset
1311,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _field-value-counter_ sink module so that I can validate the functionality as part of every CI build. ",XD-2447,Sabby Anandan,Acceptance test for field-value-counter
1312,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _aggregate-counter_ sink module so that I can validate the functionality as part of every CI build. ",XD-2446,Sabby Anandan,"Acceptance test for ""aggregate-counter"""
1313,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _gauge_ sink module so that I can validate the functionality as part of every CI build. ",XD-2445,Sabby Anandan,"Acceptance test for ""gauge"""
1314,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _splitter_ processor module so that I can validate the functionality as part of every CI build. ",XD-2444,Sabby Anandan,Acceptance test for Splitter
1315,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for both _script_ and _scripts_ processor modules so that I can validate the functionality as part of every CI build. ",XD-2443,Sabby Anandan,Acceptance test for script(s)
1316,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _json-tuple_ processor module so that I can validate the functionality as part of every CI build. ",XD-2442,Sabby Anandan,Acceptance test for json-tuple
1317,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _http-client_ processor module so that I can validate the functionality as part of every CI build. ",XD-2441,Sabby Anandan,Acceptance test for http-client
1318,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _bridge_ processor module so that I can validate the functionality as part of every CI build. ",XD-2440,Sabby Anandan,"Acceptance test for ""bridge"""
1319,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _analytic-pmml_ processor module so that I can validate the functionality as part of every CI build. ",XD-2439,Sabby Anandan,Acceptance test for analytic-pmml
1320,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _aggregator_ processor module so that I can validate the functionality as part of every CI build. ",XD-2438,Sabby Anandan,"Acceptance test for ""aggregator"""
1321,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _SFTP_ source module so that I can validate the functionality as part of every CI build. ",XD-2437,Sabby Anandan,Acceptance test for SFTP
1322,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _reactor-syslog_ source module so that I can validate the functionality as part of every CI build. ",XD-2436,Sabby Anandan,Acceptance test for reactor-syslog
1323,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _reactor-ip_ source module so that I can validate the functionality as part of every CI build. ",XD-2435,Sabby Anandan,Acceptance test for reactor-ip
1324,,Sabby Anandan,"As a QA, I'd like to include acceptance test coverage for _Mail_ source module so that I can validate the functionality as part of every CI build. ",XD-2434,Sabby Anandan,Acceptance test for Mail source
1325,Ilayaperumal Gopinathan,Sabby Anandan,,XD-2433,Sabby Anandan,Implement a Spark Streaming Receiver that binds to the MessageBus
1326,Mark Fisher,Sabby Anandan,,XD-2432,Sabby Anandan,Define developer-facing interfaces for Spark Streaming modules
1327,,Sabby Anandan,"* The workaround explicitly updates spring-core (latest boot needs it)
* merges all application.yml documents that are not profile-specific under on spring: key (the latest boot requires it, at least for now. Boot may go back, see spring-projects/spring-boot#2022",XD-2431,Sabby Anandan,Workaround latest boot snapshot issue
1328,Thomas Risberg,Thomas Risberg,"Based on the POC from XD-2124 we should create the actual implementation.

Things to consider to store in step context:
- capture Log output/MapReduce job counters
- capture last-value from incremental imports
",XD-2430,Thomas Risberg,Create a Sqoop job and required batch tasklet integration code
1329,Gary Russell,Gary Russell,"{quote}
		Here is the full exception:
		org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'ResourceConfiguredModule [name=filter, type=processor, group=request-rate, index=0 @58b0f318]:use-expression,default,admin,singlenode,hsqldbServer:9393.output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
		and here is that stream:
		topic:httpstartstop > filter --expression=payload.getHttpStartStop().getPeerType().name().equals('Client') | requestRateAggregator | appMetricsSplitter | router --expression='topic:app-request-rate-'+#jsonPath(payload,'$.appId')
[2:59 PM] Gary Russell: @MarkFisher  @IlayaperumalGopinathan @PatrickPeralta  This looks like another (not fixed by the previous fix) timing problem with taps when using singlenode. The tap is started before the tap stream is deployed. But it's not clear to me how the filter module could be deployed/bound as a consumer before the requestRateAggregator
[3:08 PM] Gary Russell: I see the problem: AbstractMessageBusBinderPlugin.bindConsumerAndProducers() binds the consumer before the producer - this is the wrong order for a passive component such as the filter. /cc @DavidTuranski
{quote}",XD-2429,Gary Russell,Bind Producer Before Consumer
1330,,Peter Rietzler,"The reference states the following:

""The JDBC driver jars for the HSQLDB, MySql, and Postgres are already on the XD classpath""

It looks like this is true for Postgres and HSQLDB, but I can't see a driver for MySQL shipped with the distribution.",XD-2428,Peter Rietzler,Mysql Libraries not shipped with XD by default
1331,Gunnar Hillert,Gunnar Hillert,"In order to improve the build reliability, we should be using the NPM repo provided by *repo.spring.io* 

See *spring-xd-ui/README.md* for further details.",XD-2427,Gunnar Hillert,Use repo.spring.io as NPM repository
1332,Eric Bottard,Eric Bottard,"Travis CI recently introduced docker based builds.
This prevents root access (which we don't need), but allows caching (which we could not use before) and seems to come with beefier machine specs",XD-2426,Eric Bottard,Travis CI improvements
1333,Gary Russell,Derek OKeeffe,"SpringXD's syslog source cannot parse rfc5424 messages into a Map.
For the messages we get in RFC 3164, springXD converts these to a Map.

Since the rfc5424 data cannot be interpreted then the map contains just one key called 'UNDECODED'.
The result of this is that we get a string that looks like this (when we convert the message to a String)
{code}
 {UNDECODED=<182>Dec 02 2014 07:56:35: %ASA-6-113008: AAA transaction status ACCEPT : user = jbloggs}
{code}

Should be something like this (note the values below are for illustrative purposes only and should not be used as test data)

{code}
 {FACILITY=22, SEVERITY=6, TIMESTAMP=Tue Dec 02 07:56:35, HOST=the-hostname-that-sent-the-data, TAG=%ASA-6-113008, MESSAGE=........}
{code}

h3. Root Cause
Spring integration does not parse these messages. There is a JIRA for SI here:
https://jira.spring.io/browse/INT-3450
",XD-2425,Derek OKeeffe,SpringXD's syslog source does not fully support syslog RFC5424
1334,David Turanski,Eric Bottard,"See discussion at https://github.com/spring-projects/spring-xd/pull/1311

1) there seems to be unused SimpleDateFormat in TupleBuilder which hurst perf
2) More generally, should take some time to profile / micro-benchmark TupleBuilder",XD-2424,Eric Bottard,Profile / Improve performance of TupleBuilder
1335,Gary Russell,Gary Russell,"When establishing the tap, we create the tap channel and add the WireTap before the tap channel has been bound to the bus.

{quote}
17:00:23,918 ERROR task-scheduler-8 handler.LoggingHandler - org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'tap:stream:foo.time.0.tap.bridge'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:129)
{quote}",XD-2423,Gary Russell,WireTap is Applied to OutputChannel Before the Tap Channel has been Bound To The Bus
1336,Gunnar Hillert,Gunnar Hillert,,XD-2422,Gunnar Hillert,UI Provide fixed version numbers for NPM and Bower dependencies
1337,Gunnar Hillert,Gunnar Hillert,"See Screenshot.

The error is caused when loading all stream definitions in method *loadStreamDefinitions*. 

Only 1 or two streams exist in the system. 
",XD-2421,Gunnar Hillert,"UI: List of Streams causes ""undefined is not an option"""
1338,,Sabby Anandan,"As a user, I'd like to have a common shared location so that I can place the dependent jar's that are required by 2 or more custom modules. 

*Current Recommendation:*
* Place the dependent jar under xd/lib folder
* if it necessary to support different versions of jar's then bundle it in custom module to get around the _classloader_ problem, if a older/newer version exist in xd/lib",XD-2420,Sabby Anandan,Add support for common dependent jars for modules
1339,,David Turanski,See my comment on https://github.com/spring-projects/spring-xd/pull/1295 for details,XD-2419,David Turanski,'module delete' tab completion includes undeletable modules
1340,,Gary Russell,"The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).

Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element

{{async=""$\{async\}""}}",XD-2418,Gary Russell,Kafka Sink: Support async Producer
1341,,Glenn Renfro,"When using the --close=true flag for the tcp-client the following exception is triggered.
Caused by: java.lang.IllegalArgumentException: For client-mode, connection factory must have single-use='false'
	at org.springframework.util.Assert.isTrue(Assert.java:65)
	at org.springframework.integration.ip.tcp.TcpReceivingChannelAdapter.onInit(TcpReceivingChannelAdapter.java:96)
	at org.springframework.integration.context.IntegrationObjectSupport.afterPropertiesSet(IntegrationObjectSupport.java:135)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1627)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1564)",XD-2417,Glenn Renfro,tcp-client reports error when using --close=true flag
1342,Eric Bottard,Dennis Hunziker,"I can only reproduce this when using single quotes around the expression:

{code}
stream create test --definition ""http | transform --expression='payload.replace(\""abc\"", \""\"")' | log"" --deploy true
{code}

The following two alternatives work fine though:
{code}
# Using trim on a single space
stream create test --definition ""http | transform --expression='payload.replace(\""abc\"", \"" \"".trim())' | log"" --deploy true

# Not using single quotes or spaces in the expression
stream create test --definition ""http | transform --expression=payload.replace(\""abc\"",\""\"") | log"" --deploy true
{code}",XD-2416,Dennis Hunziker,"SpelParseException is thrown when using empty string ("""") inside of an expression"
1343,,Karol Dowbecki,"Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory.

Following exception is thrown:
{code}6:26:03,064 1.0.2.RELEASE ERROR http-nio-9393-exec-4 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.IllegalStateException: Can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.BindingStrategy
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:137)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:193)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:154)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:173)
	at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:745){code}

Please see attached patch file, this seems to be enough to resolve the problem.
",XD-2415,Karol Dowbecki,Using custom classes for module properties leads to ClassNotFoundException
1344,Eric Bottard,Karol Dowbecki,"Please see [hdfs-dataset 1.0.2.RELEASE docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.2.RELEASE/reference/html/#hdfs-dataset-avroparquet].

According to docs there should be ""directory"" option in this sink but in code ""basePath"" is used.",XD-2414,Karol Dowbecki,"Incorrect ""directory"" option described in hdfs-dataset docs"
1345,,Karol Dowbecki,"hdfs-datasink should support rollover option, just like hdfs sink.

This might be mutually exclusive with batchSize option which also performs rollover.",XD-2413,Karol Dowbecki,Rollover support in hdfs-datasink
1346,Eric Bottard,Eric Bottard,"That method is actually currently never called, but :
- The case where a mapping already exists is not covered (outstanding TODO comment)
- the semantics of the method should just be to ""save and override""

",XD-2412,Eric Bottard,Fix Redis FieldValueCounter repo save() method
1347,Eric Bottard,Eric Bottard,"The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other.  Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.",XD-2411,Eric Bottard,"Make Redis RichGauge repository ""cluster safe"""
1348,Eric Bottard,Eric Bottard,,XD-2410,Eric Bottard,"Rename metrics repositories setValue(x, y, z) to something less ""javabean"""
1349,Thomas Risberg,Janne Valkealahti,"Having a pojo:
{code}
public class User{
	private String name;
	public String getName() {
		return user;
	}
	public void setName(String name) {
		this.name = name;
	}
}
{code}

with:
{code}
hdfs-dataset --inputType='application/x-java-object;type=test.User'
{code}

throws exception:
{code}
12:43:27,698 1.1.0.SNAP ERROR task-scheduler-1 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: Expression evaluation failed: payload.getClass().getName(); nested exception is org.springframework.expression.AccessException: Problem invoking method: public java.lang.String test.User.getName()
{code}

Which I believe is caused by `correlation-strategy-expression` spel in aggregator:
{code}
	<int:aggregator
			input-channel=""input""
			correlation-strategy-expression=""payload.getClass().getName()""
			release-strategy-expression=""size() == ${batchSize}""
			expire-groups-upon-completion=""true""
			send-partial-result-on-expiry=""true""
			message-store=""messageStore""
			output-channel=""objects""/>
{code}

Changing `getName()` method in pojo to something else works.",XD-2409,Janne Valkealahti,hdfs-dataset sink with getName() method in Pojo
1350,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When a tap on a stream is undeployed and re-deployed, it stops working.
To make it work, the main stream associated with the tap needs to be undeployed and re-deployed.
",XD-2408,Ilayaperumal Gopinathan,"When a tap is re-deployed after undeploy, it doesn't work"
1351,Eric Bottard,Eric Bottard,"Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle (if one decided to use upload) is quicker and edits can be done in place.",XD-2407,Eric Bottard,"Enhance ""module upload"" to support exploded dirs (on the shell side)"
1352,David Turanski,David Turanski,"Create one or more Sample module projects in the Spring XD Examples repo to serve as templates for Spring XD module projects. Similar to https://github.com/dturanski/siDslModule, these should include unit and single node integration tests, and demonstrate the use of Spring XD build and packaging tools, and other module development support. This may be split out into separate tasks, but should include a sample for source, processor, sink, and job, using @Configuration or XML configuration (either as separate samples or using build profiles). ",XD-2406,David Turanski,Create Sample Module projects
1353,David Turanski,David Turanski,Provide maven and gradle plugins to execute module upload via REST to upload and install a module to Spring XD.  e.g. mvn xd:upload-module ...  ,XD-2405,David Turanski,Provide XD module build plugins to upload a module 
1354,David Turanski,David Turanski,"Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for 'MODULE' layout and other boilerplate build configuration. This should include a similar feature for gradle.",XD-2404,David Turanski,Provide an XD Starter POM for module projects
1355,David Turanski,Sabby Anandan,"As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds. 

*Scope:*
* Use the environment where Bamboo is running
* Gain access to powershell 
* Setup services (redis, rabbit, etc.)
* Kick-off CI task",XD-2403,Sabby Anandan,Spike: Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure
1356,,Sabby Anandan,"As a developer, I'd like to investigate the increase in WARN logs so that I can troubleshoot and fix PMD/Sonar violations.

Consider notifying the violations through SONAR configurations. The committer should be notified.",XD-2402,Sabby Anandan,Investigate why builds have more WARN logs
1357,Mark Pollack,Sabby Anandan,"As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities.

*Scope:*
* Enable 'distributed jvm test'
* Change from using artifactory gradle task to a command task (that calls ./gradlew)
* Test w/ embedded hadoop off
* Turn on maxParallelForks
",XD-2401,Sabby Anandan,EC2 CI build improvements
1358,Gunnar Hillert,Sabby Anandan,"As a build master, I'd like to research CI options so that I can improve CI build stability and reliability.

*Potential Option:*
[npm-cache|https://github.com/swarajban/npm-cache]

Caching previously installed dependencies, _npm-cache_ doesn't require downloading the internet each time we build.",XD-2400,Sabby Anandan,Research options to improve CI reliability
1359,,Sabby Anandan,,XD-2399,Sabby Anandan,Epic to track CI related issues and improvements
1360,,Sabby Anandan,"As a user, I should be able to leverage native _WebSocket_ sink so that I can take the advantage of full-duplex communications channels over a single TCP connection.",XD-2398,Sabby Anandan,Add Websocket sink
1361,Eric Bottard,Sabby Anandan,"*Version:*
XD: 1.1 M1

*Problem:*
Trying to use tcp-client source module and observing an exception while deploying the stream.

*Stream Definition:*
{code:xml}
 curl --data name=dummy-firehose --data definition='tcp-client --decoder=LF --port=8080 | log' --data deploy=true http://localhost:9393/streams/definitions
{""name"":""dummy-firehose"",""status"":null,""definition"":""tcp-client --decoder=LF --port=8080 | log"",""_links"":{""self"":{""href"":""http://localhost:9393/streams/dummy-firehose""}}}
{code}

The same curl command works fine against XD 1.0.1 release.
",XD-2397,Sabby Anandan,TCP-Client source module throws ClassNotFoundException
1362,,Glenn Renfro,"In order to identify potential problems that may occur if XD is running for multiple hours we need to create a long duration test regime.
Create an environment from which we can run both Singlenode and a simple cluster (1 Admin 2 container) for 24+ hours.

* Create 2 simple streams 
 * http|file
 * file|log 
* Send data to http source 2 times a second for 24 hours
* This test should execute checkprocs every 5 minutes to capture and record the status of the XD>
* Record memory usage and system load.",XD-2396,Glenn Renfro,XD requires long duration tests
1363,,Dusty Pressley,"A scenario where I have multiple jobs deployed to one singlenode or distributed instance of SpringXD that need to use different namenodes can easily exist.   The ability to specify a namenode, much the same way I can specify a directory would solve this problem.  The desired behavior would be to specify a namenode that wasn't set using 'hadoop config fs <namenode>' in the job description and have that value used instead of the value set at the SpringXD global level.",XD-2395,Dusty Pressley,Need a way to specify a specific namenode for a given hdfs based job
1364,,Buelent Zeyben,"Users should have the ability to load data from a jdbc source to a file sink pointing to a file location (NFS mount to an Isilon cluster) in a particular directory structure.

Isilon support multiple protocols, including NFS and HDFS. by storing data directly into an NFS mount we would eliminate the HDFS overhead.

This functionality should be similar to the jdbchdfs job that is currently available in SpringXD. See Jira issue 'XD-2309' for more details.",XD-2394,Buelent Zeyben,incremental jdbcfile process for loading data into Isilon cluster
1365,,Sabby Anandan,Scope is to have integration test coverage for source and sink modules. ,XD-2392,Sabby Anandan,Add integration tests
1366,Glenn Renfro,Sabby Anandan,"Verify that network interruptions will not negatively affect the XD cluster.  
Verify that a container that looses connectivity will be able to rejoin the cluster cleanly.
Modules will redploy when the network is back up.
",XD-2390,Sabby Anandan,Add regression test
1367,Gary Russell,Mark Fisher,"Currently I believe we only mention labels in this section of the doc:
https://github.com/spring-projects/spring-xd/wiki/DSL-Reference#labels

And it is not even clear there that they are *required* when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition.

We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module, we should add one to illustrate this point.
",XD-2389,Mark Fisher,Streams section of doc should explicitly mention that labels are required for ambiguous modules
1368,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the custom module (built as uber-jar) hosted in HDFS so that I can deploy the module to newly arriving containers. ",XD-2388,Sabby Anandan,Add support to host custom module in HDFS
1369,Glenn Renfro,Glenn Renfro,,XD-2387,Glenn Renfro,Acceptance test for Kafka source and sink
1370,Glenn Renfro,Glenn Renfro,,XD-2386,Glenn Renfro,Need TCP-Client Source Acceptance test
1371,,Thomas Risberg,The hdfs-dataset sink currently requires a POJO as input. We should also support JSON and a Map as input plus the ability to specify an Avro schema to be used.,XD-2385,Thomas Risberg,hdfs-dataset sink should support JSON and a Map as input formats
1372,David Turanski,Sabby Anandan,"As a user, I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.",XD-2384,Sabby Anandan,Document custom module install procedures
1373,Eric Bottard,Sabby Anandan,"As a user, I'd like to have a Shell command so that I can point to the custom-built _module_ archive and push it to the runtime for immediate usage. ",XD-2383,Sabby Anandan,Add a Shell command to push custom module
1374,Marius Bogoevici,Sabby Anandan,"As a developer, I'd like to setup a performance testing infrastructure (rackspace), so I can start benching Kafka baselines and continue with XD use-cases.",XD-2382,Sabby Anandan,Re-run Kafka baseline tests in new infrastructure
1375,Eric Bottard,Sabby Anandan,"*Refactoring scope:* (_spring-xd-dirt_)
* Message bus dependencies


The goal is to decouple them from startup phase to further enhance initialization time. ",XD-2381,Sabby Anandan,Decouple messagebus dependencies
1376,,Derek OKeeffe,"A new sink that would POST the message payload to a REST service over http.

Could be created with code something like this, except without hardcoded user and password for basic auth...

rest-store.xml
{code}
<?xml version=""1.0"" encoding=""UTF-8""?>
<beans xmlns=""http://www.springframework.org/schema/beans""
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:int=""http://www.springframework.org/schema/integration""
       xmlns:http=""http://www.springframework.org/schema/integration/http""
       xsi:schemaLocation=""http://www.springframework.org/schema/beans
		http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/integration
		http://www.springframework.org/schema/integration/spring-integration.xsd
		http://www.springframework.org/schema/integration/http
		http://www.springframework.org/schema/integration/http/spring-integration-http.xsd"">

	<int:channel id=""input"" />
	<int:channel id=""restout"" />
	<int:header-enricher input-channel=""input"" output-channel=""restout"">
		<int:header name=""Content-Type"" value=""${contenttype:application/json}""/>
	</int:header-enricher>

	<http:outbound-channel-adapter url=""${url}""
                                       request-factory=""clientHttpRequestFactory""
                                                                          channel=""restout""
                                                                                                             http-method=""${method:POST}""
                                                                                                                         header-mapper=""""/>

	<bean id=""httpComponentsMessageSender"" class=""org.springframework.ws.transport.http.HttpComponentsMessageSender"">
		<property name=""credentials"">
			<bean class=""org.apache.http.auth.UsernamePasswordCredentials"">
				<constructor-arg value=""myuser""/>
				<constructor-arg value=""mypassword""/>
			</bean>
		</property>
	</bean>

	<bean id=""clientHttpRequestFactory"" class=""org.springframework.http.client.HttpComponentsClientHttpRequestFactory"">
		<property name=""httpClient"" value=""#{httpComponentsMessageSender.httpClient}""/>
	</bean>
</beans>			
{code}

rest-store.properties
{code}
options.url.description = The URL to send data to
options.url.type = String

options.method.description = HTTP method. Default POST
options.method.type = String

options.contenttype.description = Content-Type header to set. Default application/json
options.contenttype.type = String
{code}",XD-2380,Derek OKeeffe,New sink for REST resources
1377,,Gary Russell,"The {{syslog-tcp}} source uses the default tcp connection factory which has an unbounded thread pool; this can cause OOM if the bus blocks (e.g. rabbit is out of resources).
",XD-2379,Gary Russell,syslog-tcp Configure a FIxed Thread Pool
1378,Gunnar Hillert,Gunnar Hillert,"While there is a server endpoint to logout, we don't have that ability yet from the UI. As indicated by XD-2122 we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled, whether the user is logged etc. So we can fulfill the requirements: 

* Show a logout button only if a) security is enabled and b) user is logged in
* Show the username and/or full name of the user being logged in
 ",XD-2378,Gunnar Hillert,Add ability to logout using the Admin UI
1379,Gunnar Hillert,Sabby Anandan,"As a user, I'd like to have API and Documentation links in the [""About""|https://github.com/spring-projects/spring-xd/blob/master/spring-xd-ui/app/scripts/shared/views/about.html] section within _admin-ui_. 

It would be ideal to have the version # dynamically replaced for every release.
",XD-2377,Sabby Anandan,"Update ""About"" section in UI with relevant release links"
1380,,Sabby Anandan,"As a user, I'd like to have _microbatching_ capability so that I can ingest based on batch intervals for enhanced performance throughput. 

*Example:*
""http --batchInterval=10 | log""",XD-2376,Sabby Anandan,Add batching support for Rabbit Message Bus
1381,Mark Pollack,Sabby Anandan,"As a user, I'd like to have a _reactor-stream_ processor module so that I can ingest data using XD source modules and process them as time-window operations. 

*Example 1:*
http | reactor-stream --timeWindow=10s --field=payload.sensorData --expressions=min,avg

This would give you 10 second time window of the min and avg values.

*Example 2:*
Reactor as a module

*Example 3:*
Integration with Spark streaming and reactor",XD-2375,Sabby Anandan,Research reactor-stream integration options
1382,,Sabby Anandan,,XD-2374,Sabby Anandan,Support for modules that use Reactor’s Stream API
1383,Patrick Peralta,Patrick Peralta,"After each test execution, the containers are shut down via:

{code}
@After
public void after() {
	distributedTestSupport.shutdownContainers();
	distributedTestSupport.ensureTemplate().streamOperations().destroyAll();
}
...
public void shutdownContainers() {
	for (Iterator<Map.Entry<Long, JavaApplication<SimpleJavaApplication>>> iterator =
				mapPidContainers.entrySet().iterator(); iterator.hasNext();) {
		iterator.next().getValue().close();
		iterator.remove();
	}
}
{code}

The problem is that {{close()}} guarantees that the process is shut down, but it does not guarantee that the container is no longer registered in ZooKeeper. The cleanup procedure should verify that no containers appear in the output of  the {{runtime containers}} shell command. This will prevent the next test from deploying to a non-existent container.",XD-2373,Patrick Peralta,Distributed test should verify container shutdown
1384,,Eric Bottard,"See http://stackoverflow.com/questions/26880903/using-mappedrequestheaders-in-spring-xd

",XD-2372,Eric Bottard,Allow arbitrary headers to be set in http-client processor
1385,,Thomas Darimont,"Often one has to perform some basic conversion / parsings in Stream definitions. It would be helpful if one could provide some helper functions to simplify SpEL expressions.

E.g. instead of:
{code}
transform --expression=T(java.lang.Long).parseLong(payload.value.toString())
{code}
it would be nice to be able to write:
{code}
transform --expression=parseLong(payload.value)
{code}

I'm thinking of support for:
* parseByte
* parseInt
* parseShort
* parseLong
* parseFloat
* parseDouble
* parseBoolean
* parseTuple

(I don't think we'd need support for parseCharacter)

This issue is about:
1) providing the centralised infrastructure for defining the SpEL expressions
2) Add support for the above listed predefined SpEL expressions

Those functions should be able to work with String based as well as {{JsonToStringFriendlyNode}} as input.",XD-2371,Thomas Darimont,Allow registering default SpEL functions to simplify expressions
1386,Glenn Renfro,Glenn Renfro,The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build.,XD-2370,Glenn Renfro,Remove Test Scripts From XD
1387,,Gunnar Hillert,"""the meaning of the backtick has changed. The backtick now only does monospaced formatting, it does not escape the content. The migration guide walks you through the options: 

http://asciidoctor.org/docs/migration/#migration-scenarios

""

For more details see: https://github.com/asciidoctor/asciidoctor-gradle-plugin/issues/134",XD-2369,Gunnar Hillert,Make Asciidoc documentation compatible with Asciidoctor 1.5.x
1388,Mark Fisher,Sabby Anandan,"As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.",XD-2368,Sabby Anandan,Research Spark integration options (phase #2)
1389,,Sabby Anandan,TypeConvertingStreamTests.testBasicTypeConversionWithTap() is failing intermittently. Why?,XD-2367,Sabby Anandan,Investigate TypeConvertingStreamTests.testBasicTypeConversionWithTap test failure in CI builds
1390,Gunnar Hillert,Gunnar Hillert,"When generating docs, the build tries to access

http://docbook.sourceforge.net/release/images/draft.png

You will observe output like:

{code}
Error with opening URL 'http://docbook.sourceforge.net/release/images/draft.png': docbook.sourceforge.net
Background image not available: http://docbook.sourceforge.net/release/images/draft.png
Background image not available: http://docbook.sourceforge.net/release/images/draft.png
Background image not available: http://docbook.sourceforge.net/release/images/draft.png
Background image not available: http://docbook.sourceforge.net/release/images/draft.png
Background image not available: http://docbook.sourceforge.net/release/images/draft.png
Background image not available: http://docbook.sourceforge.net/release/images/draft.png
{code}",XD-2366,Gunnar Hillert,Doc generation accesses http://docbook.sourceforge.net
1391,,Janne Valkealahti,"xd:>stream create --name foo --definition ""time|log""
xd:>stream deploy --name foo --properties ""module.*.count=0""

{code}
16:42:35,121 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module
java.lang.IllegalArgumentException: LocalMessageBus does not support consumer property: directBindingAllowed for foo.0.
{code}

Ok, that's cool. Let's destroy and create again:

xd:>stream destroy --name foo 
xd:>stream create --name foo --definition ""time|log"" --deploy

{code}
org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#9363c963-41db-4cd6-b273-b52b02aba80d'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=time.0,component=MessageChannel,name=output
{code}


{code}
xd:>runtime modules 
  Module Id       Container Id                          Options                                     Deployment Properties  Unit status
  --------------  ------------------------------------  ------------------------------------------  ---------------------  -----------
  foo.sink.log.1  ce5cf83f-3e62-4960-8d46-e5cb06203992  {name=foo, expression=payload, level=INFO}  {count=1, sequence=1}  failed
{code}",XD-2365,Janne Valkealahti,Direct binding with singlenode leaves stream broken
1392,,Mark Pollack,This doesn't follow the conventions we have with other modules and it also means it isn't easy to override via environment variables etc.  This is in HDFS and some others.,XD-2364,Mark Pollack,Remove usage of <context:property-placeholder location=.../> in module defitions
1393,,Stanley Stewart,"The word ""that"" is written in duplicate.
See the attached PNG file.

==========================================================
Caveats
Note that that inputType and outputType parameters only apply to payloads that require type conversion. For example, if a module produces an XML string with outputType=application/json, the payload will not be converted from XML to JSON. This is because the payload at the module’s output channel is already a String so no conversion will be applied at runtime.
==========================================================

http://docs.spring.io/spring-xd/docs/1.0.1.RELEASE/reference/html/
",XD-2363,Stanley Stewart,"The word ""that"" is written in duplicate"
1394,Glenn Renfro,Glenn Renfro,"* Create the infrastructure (Mongo, Hadoop, ActiveMQ, Gemfire, Mysql, etc) in EC2 for the 1.0.2 acceptance tests
* Retrofit the 1.0.2 to use the new infrastructure
* Create a 1.0.2 branch for XD-EC2",XD-2362,Glenn Renfro,Created Acceptance CI test environment for 1.0.x
1395,Marius Bogoevici,Sabby Anandan,"As a user, I want Spring XD’s message bus to be able to pre-allocate partitions between nodes when a stream is deployed, so that rebalancing doesn’t happen when a container crashes and/or it’s redeployed.",XD-2361,Sabby Anandan,Pre-allocate partitions for Kafka message bus
1396,Marius Bogoevici,Sabby Anandan,"As a user, I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed, so that deployment is simpler, and rebalancing doesn’t take place. ",XD-2360,Sabby Anandan,Pre-allocate partitions for Kafka source
1397,Marius Bogoevici,Sabby Anandan,"As a user, I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed, so that I can colocate with other data sources.",XD-2359,Sabby Anandan,Add partition allocation support for Kafka source
1398,Marius Bogoevici,Sabby Anandan,"As a user, I want to be able to control the starting offset of the Kafka source when a stream is deployed, so that I can replay a topic if necessary.

Note:
- starting offset is only considered when the stream is deployed
- progress made by modules must survive their crash for a running stream
- undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start 

TBD: what happens when streams are undeployed/redeployed - where do they resume from?",XD-2358,Sabby Anandan,Add starting offset support for Kafka source
1399,,Sabby Anandan,,XD-2356,Sabby Anandan,Kafka support
1400,Ilayaperumal Gopinathan,Thomas Darimont,"If you start xd-singlenode with the --verbose flag the configuration information is printed twice.

Steps to reproduce 
1) run {{xd-singlenode --verbose}}

Example output:
{code}

 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
1.1.0.BUILD-SNAPSHOT             eXtreme Data


Started : SingleNodeApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki

20:40:43,098 1.1.0.SNAP  INFO main server.SingleNodeApplication - Starting SingleNodeApplication v1.1.0.BUILD-SNAPSHOT on gauss with PID 79926 (/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar started by tom in /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd)
20:40:43,512 1.1.0.SNAP  INFO main server.SingleNodeApplication - Started SingleNodeApplication in 0.993 seconds (JVM running for 1.374)
20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local
20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/
20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://gauss:9393/admin-ui
20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:38225
20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory
20:40:56,226 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - 
	Apple_PubSub_Socket_Render=/tmp/launch-k1iYmY/Render
	BROWSER=open
	CRASH_HOME=/Users/tom/.gvm/crash/current
	DISPLAY=/tmp/launch-16fQxe/org.macosforge.xquartz:0
	EDITOR=vim
	GAIDEN_HOME=/Users/tom/.gvm/gaiden/current
	GEM_HOME=/Users/tom/.rvm/gems/ruby-1.9.3-p484
	GEM_PATH=/Users/tom/.rvm/gems/ruby-1.9.3-p484:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global
	GLIDE_HOME=/Users/tom/.gvm/glide/current
	GRADLE_HOME=/Users/tom/.gvm/gradle/current
	GRAILS_HOME=/Users/tom/.gvm/grails/current
	GREP_COLOR=1;33
	GREP_OPTIONS=--color=auto
	GRIFFON_HOME=/Users/tom/.gvm/griffon/current
	GROOVYSERV_HOME=/Users/tom/.gvm/groovyserv/current
	GROOVY_HOME=/Users/tom/.gvm/groovy/current
	GVM_BROADCAST_SERVICE=http://cast.gvm.io
	GVM_BROKER_SERVICE=http://release.gvm.io
	GVM_DIR=/Users/tom/.gvm
	GVM_INIT=true
	GVM_PLATFORM=Darwin
	GVM_SERVICE=http://api.gvmtool.net
	GVM_VERSION=2.2.0
	HADOOP_DISTRO=hadoop25
	HOME=/Users/tom
	IRBRC=/Users/tom/.rvm/rubies/ruby-1.9.3-p484/.irbrc
	JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home
	JAVA_MAIN_CLASS_79926=org.springframework.xd.dirt.server.SingleNodeApplication
	JBAKE_HOME=/Users/tom/.gvm/jbake/current
	LANG=en_US.UTF-8
	LAZYBONES_HOME=/Users/tom/.gvm/lazybones/current
	LC_ALL=en_US.UTF-8
	LC_CTYPE=UTF-8
	LESS=-F -g -i -M -R -S -w -X -z-4
	LESS_TERMCAP_mb=[01;31m
	LESS_TERMCAP_md=[01;31m
	LESS_TERMCAP_me=[0m
	LESS_TERMCAP_se=[0m
	LESS_TERMCAP_so=[00;47;30m
	LESS_TERMCAP_ue=[0m
	LESS_TERMCAP_us=[01;32m
	LOGNAME=tom
	LSCOLORS=exfxcxdxbxGxDxabagacad
	LS_COLORS=di=34:ln=35:so=32:pi=33:ex=31:bd=36;01:cd=33;01:su=31;40;07:sg=36;40;07:tw=32;40;07:ow=33;40;07:
	MAVEN_HOME=/Applications/dev/tools/apache-maven-3.2.1
	MY_RUBY_HOME=/Users/tom/.rvm/rubies/ruby-1.9.3-p484
	OLDPWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
	PAGER=less
	PATH=/Users/tom/.gvm/vertx/current/bin:/Users/tom/.gvm/springboot/current/bin:/Users/tom/.gvm/lazybones/current/bin:/Users/tom/.gvm/jbake/current/bin:/Users/tom/.gvm/groovyserv/current/bin:/Users/tom/.gvm/groovy/current/bin:/Users/tom/.gvm/griffon/current/bin:/Users/tom/.gvm/grails/current/bin:/Users/tom/.gvm/gradle/current/bin:/Users/tom/.gvm/glide/current/bin:/Users/tom/.gvm/gaiden/current/bin:/Users/tom/.gvm/crash/current/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global/bin:/Users/tom/.rvm/rubies/ruby-1.9.3-p484/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/go/bin:/usr/texbin:/Users/tom/.rvm/bin:/Users/tom/.yadr/bin:/Users/tom/.yadr/bin/yadr:/Applications/dev/tools/apache-maven-3.2.1/bin:/Applications/dev/tools/apache-ant-1.9.2/bin:/Users/tom/.rvm/bin
	PID=79926
	PS4=+ %* %F{red}%x:%I %F{green}%N:%i%F{white} %_
	PWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd
	SCREEN_NO=
	SECURITYSESSIONID=186a4
	SHELL=/bin/zsh
	SHLVL=1
	SPRINGBOOT_HOME=/Users/tom/.gvm/springboot/current
	SSH_AUTH_SOCK=/tmp/launch-KXqpmP/Listeners
	TERM=xterm-256color
	TERM_PROGRAM=Apple_Terminal
	TERM_PROGRAM_VERSION=326
	TERM_SESSION_CLASS_ID=D65D4C24-B8F2-4B53-9179-EC38F2DCD1AE
	TERM_SESSION_ID=3FA5B432-B6C3-4F62-A7FB-00EB6B0F18C7
	TMPDIR=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/
	USER=tom
	VERTX_HOME=/Users/tom/.gvm/vertx/current
	VISUAL=vim
	XD_ANALYTICS=memory
	XD_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
	XD_CONFIG_NAME=servers,application
	XD_HOME=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
	XD_JMX_ENABLED=true
	XD_MODULE_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/
	XD_MODULE_CONFIG_NAME=modules
	XD_TRANSPORT=local
	__CF_USER_TEXT_ENCODING=0x1F5:0:0
	__CHECKFIX1436934=1
	_system_arch=x86_64
	_system_name=OSX
	_system_type=Darwin
	_system_version=10.9
	analytics=memory
	awt.toolkit=sun.lwawt.macosx.LWCToolkit
	catalina.base=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393
	catalina.home=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393
	catalina.useNaming=false
	document=--
	embeddedHsql=true
	endpoints.jmx.enabled=true
	endpoints.jmx.uniqueNames=true
	endpoints.jolokia.enabled=true
	file.encoding=UTF-8
	file.encoding.pkg=sun.io
	file.separator=/
	ftp.nonProxyHosts=local|*.local|169.254/16|*.169.254/16
	gopherProxySet=false
	http.nonProxyHosts=local|*.local|169.254/16|*.169.254/16
	java.awt.graphicsenv=sun.awt.CGraphicsEnvironment
	java.awt.headless=true
	java.awt.printerjob=sun.lwawt.macosx.CPrinterJob
	java.class.path=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules/processor/scripts:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/activation-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/amqp-client-3.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aopalliance-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/args4j-2.0.16.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/asm-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjrt-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjweaver-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-compiler-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/cglib-2.2.1-v20090111.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/classmate-1.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/com.ibm.jbatch-tck-spi-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-beanutils-1.9.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-cli-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-codec-1.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-collections-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-compress-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-configuration-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-daemon-1.0.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-dbcp-1.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-digester-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-el-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-fileupload-1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-httpclient-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-io-2.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-jexl-2.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-lang-2.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-math-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-net-3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool2-2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-client-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-framework-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-recipes-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/disruptor-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/groovy-all-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-api-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guava-16.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-servlet-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hibernate-validator-5.0.3.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hsqldb-2.3.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-annotations-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-databind-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-mapper-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javassist-3.18.1-GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.batch-api-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.inject-1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.mail-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jboss-logging-3.1.1.GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jcl-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jedis-2.5.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jersey-guice-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jettison-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jline-2.11.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/joda-time-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jolokia-core-1.2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jopt-simple-4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-path-0.9.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-simple-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-smart-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jsr305-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jul-to-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kafka_2.10-0.8.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-data-core-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-hadoop-compatibility-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kryo-2.22.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-1.2.17.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-annotation-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-core-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/mongo-java-driver-2.12.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/netty-3.7.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/objenesis-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/ognl-3.0.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/opencsv-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/paranamer-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-avro-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-column-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-common-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-encoding-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-format-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-generator-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-hadoop-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-jackson-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/postgresql-9.2-1002-jdbc4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/reactor-core-1.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/scala-library-2.10.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-api-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-log4j12-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snakeyaml-1.14.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snappy-java-1.1.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-amqp-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-aop-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-manager-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-resources-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-core-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-infrastructure-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-integration-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-beans-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-actuator-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-autoconfigure-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-loader-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-logging-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-security-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-thymeleaf-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-tomcat-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-web-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-cloudfoundry-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-core-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-spring-service-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-support-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-core-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-commons-1.9.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-mongodb-1.5.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-redis-1.4.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-expression-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-hateoas-0.14.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-amqp-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-core-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-event-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-file-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-http-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-jmx-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-kafka-1.0.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-redis-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-jdbc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-ldap-core-2.0.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-messaging-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-plugin-core-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-rabbit-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-retry-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-config-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-core-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-ldap-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-web-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-tx-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-web-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-webmvc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-analytics-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-batch-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-hadoop-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-spi-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-rest-domain-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-tuple-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-ui-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-layout-dialect-1.2.5.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-spring4-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-core-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-el-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-logging-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-websocket-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-jdbc-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/unbescape-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/validation-api-1.1.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlenc-0.52.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlpull-1.1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xpp3_min-1.1.4c.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xstream-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xz-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zkclient-0.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zookeeper-3.4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-annotations-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-auth-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-distcp-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-hdfs-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-core-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-jobclient-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-shuffle-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-streaming-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-api-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-client-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-nodemanager-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-core-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-server-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jetty-util-6.1.26.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/protobuf-java-2.5.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-batch-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-core-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hbase-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hive-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-pig-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-store-2.1.0.M2.jar
	java.class.version=52.0
	java.endorsed.dirs=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/endorsed
	java.ext.dirs=/Users/tom/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java
	java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre
	java.io.tmpdir=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/
	java.library.path=/Users/tom/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
	java.runtime.name=Java(TM) SE Runtime Environment
	java.runtime.version=1.8.0_25-b17
	java.specification.name=Java Platform API Specification
	java.specification.vendor=Oracle Corporation
	java.specification.version=1.8
	java.vendor=Oracle Corporation
	java.vendor.url=http://java.oracle.com/
	java.vendor.url.bug=http://bugreport.sun.com/bugreport/
	java.version=1.8.0_25
	java.vm.info=mixed mode
	java.vm.name=Java HotSpot(TM) 64-Bit Server VM
	java.vm.specification.name=Java Virtual Machine Specification
	java.vm.specification.vendor=Oracle Corporation
	java.vm.specification.version=1.8
	java.vm.vendor=Oracle Corporation
	java.vm.version=25.25-b02
	line.separator=

	logging.config=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config///xd-singlenode-logger.properties
	management.contextPath=/management
	management.port=9393
	management.security.enabled=false
	os.arch=x86_64
	os.name=Mac OS X
	os.version=10.9.5
	path.separator=:
	rvm_alias_expanded=
	rvm_bin_path=/Users/tom/.rvm/bin
	rvm_docs_type=
	rvm_gemstone_package_file=
	rvm_gemstone_url=
	rvm_niceness=
	rvm_nightly_flag=
	rvm_path=/Users/tom/.rvm
	rvm_prefix=/Users/tom
	rvm_proxy=
	rvm_quiet_flag=
	rvm_ruby_file=
	rvm_ruby_make=
	rvm_ruby_make_install=
	rvm_ruby_mode=
	rvm_script_name=
	rvm_sdk=
	rvm_silent_flag=
	rvm_version=1.25.18 (master)
	rvm_wrapper_name=
	security.basic.enabled=false
	security.basic.realm=SpringXD
	server.port=9393
	socksNonProxyHosts=local|*.local|169.254/16|*.169.254/16
	spring.application.name=admin
	spring.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
	spring.config.name=servers,application
	spring.datasource.abandonWhenPercentageFull=0
	spring.datasource.alternateUsernameAllowed=false
	spring.datasource.driverClassName=org.hsqldb.jdbc.JDBCDriver
	spring.datasource.fairQueue=true
	spring.datasource.initialSize=0
	spring.datasource.jmxEnabled=true
	spring.datasource.logAbandoned=false
	spring.datasource.maxActive=100
	spring.datasource.maxAge=0
	spring.datasource.maxIdle=100
	spring.datasource.maxWait=30000
	spring.datasource.minEvictableIdleTimeMillis=60000
	spring.datasource.minIdle=10
	spring.datasource.password=
	spring.datasource.removeAbandoned=false
	spring.datasource.removeAbandonedTimeout=60
	spring.datasource.suspectTimeout=0
	spring.datasource.testOnBorrow=true
	spring.datasource.testOnReturn=false
	spring.datasource.testWhileIdle=false
	spring.datasource.timeBetweenEvictionRunsMillis=5000
	spring.datasource.url=jdbc:hsqldb:hsql://localhost:9101/xdjob
	spring.datasource.useEquals=true
	spring.datasource.username=sa
	spring.datasource.validationInterval=30000
	spring.datasource.validationQuery=select 1 from INFORMATION_SCHEMA.SYSTEM_USERS
	spring.freemarker.checkTemplateLocation=false
	spring.hadoop.fsUri=hdfs://localhost:8020
	spring.main.show_banner=false
	spring.profiles=singlenode
	spring.profiles.active=default
	spring.rabbitmq.addresses=localhost:5672
	spring.rabbitmq.password=guest
	spring.rabbitmq.sslProperties=
	spring.rabbitmq.useSSL=false
	spring.rabbitmq.username=guest
	spring.rabbitmq.virtual_host=/
	spring.redis.host=localhost
	spring.redis.pool.maxActive=8
	spring.redis.pool.maxIdle=8
	spring.redis.pool.maxWait=-1
	spring.redis.pool.minIdle=0
	spring.redis.port=6379
	sun.arch.data.model=64
	sun.boot.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/classes
	sun.boot.library.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib
	sun.cpu.endian=little
	sun.cpu.isalist=
	sun.io.unicode.encoding=UnicodeBig
	sun.java.command=org.springframework.xd.dirt.server.SingleNodeApplication --verbose
	sun.java.launcher=SUN_STANDARD
	sun.jnu.encoding=UTF-8
	sun.management.compiler=HotSpot 64-Bit Tiered Compilers
	sun.os.patch.level=unknown
	transport=local
	user.country=US
	user.country.format=DE
	user.dir=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd
	user.home=/Users/tom
	user.language=en
	user.name=tom
	user.timezone=Europe/Berlin
	vcs_info_msg_0_=(%F{81}master%f%F{166}●%f)
	vcs_info_msg_1_=
	verbose=true
	xd.config.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
	xd.container.groups=
	xd.container.host=
	xd.container.ip=
	xd.data.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/data
	xd.extensions.basepackages=
	xd.extensions.locations=META-INF/spring-xd/ext
	xd.home=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
	xd.messageRateMonitoring.enabled=false
	xd.messagebus.kafka.brokers=localhost:9092
	xd.messagebus.kafka.numOfKafkaPartitionsForCountEqualsZero=10
	xd.messagebus.kafka.replicationFactor=1
	xd.messagebus.kafka.zkAddress=localhost:2181
	xd.messagebus.rabbit.default.ackMode=AUTO
	xd.messagebus.rabbit.default.autoBindDLQ=false
	xd.messagebus.rabbit.default.backOffInitialInterval=1000
	xd.messagebus.rabbit.default.backOffMaxInterval=10000
	xd.messagebus.rabbit.default.backOffMultiplier=2.0
	xd.messagebus.rabbit.default.concurrency=1
	xd.messagebus.rabbit.default.deliveryMode=PERSISTENT
	xd.messagebus.rabbit.default.maxAttempts=3
	xd.messagebus.rabbit.default.maxConcurrency=1
	xd.messagebus.rabbit.default.prefetch=1
	xd.messagebus.rabbit.default.prefix=xdbus.
	xd.messagebus.rabbit.default.replyHeaderPatterns=STANDARD_REPLY_HEADERS,*
	xd.messagebus.rabbit.default.requestHeaderPatterns=STANDARD_REQUEST_HEADERS,*
	xd.messagebus.rabbit.default.requeue=true
	xd.messagebus.rabbit.default.transacted=false
	xd.messagebus.rabbit.default.txSize=1
	xd.messagebus.redis.default.backOffInitialInterval=1000
	xd.messagebus.redis.default.backOffMaxInterval=10000
	xd.messagebus.redis.default.backOffMultiplier=2.0
	xd.messagebus.redis.default.concurrency=1
	xd.messagebus.redis.default.maxAttempts=3
	xd.messagebus.redis.headers=
	xd.module.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/
	xd.module.config.name=modules
	xd.module.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules
	xd.transport=local
	xd.ui.allow_origin=http://localhost:9889
	xd.ui.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/spring-xd-ui/dist/
	zk.client.connect=
	zk.embedded.client.connect=localhost:38225
	zk.namespace=xd

20:40:56,280 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin admin:default,admin,singlenode,hsqldbServer:9393 is watching for stream/job deployment requests.
20:40:56,322 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 5.545 seconds (JVM running for 14.185)
20:40:56,341 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED
20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local
20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/
20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 172.16.200.1
20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   gauss
20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop25
20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.5.1
20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:38225
20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory
20:40:58,162 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - 
	Apple_PubSub_Socket_Render=/tmp/launch-k1iYmY/Render
	BROWSER=open
	CRASH_HOME=/Users/tom/.gvm/crash/current
	DISPLAY=/tmp/launch-16fQxe/org.macosforge.xquartz:0
	EDITOR=vim
	GAIDEN_HOME=/Users/tom/.gvm/gaiden/current
	GEM_HOME=/Users/tom/.rvm/gems/ruby-1.9.3-p484
	GEM_PATH=/Users/tom/.rvm/gems/ruby-1.9.3-p484:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global
	GLIDE_HOME=/Users/tom/.gvm/glide/current
	GRADLE_HOME=/Users/tom/.gvm/gradle/current
	GRAILS_HOME=/Users/tom/.gvm/grails/current
	GREP_COLOR=1;33
	GREP_OPTIONS=--color=auto
	GRIFFON_HOME=/Users/tom/.gvm/griffon/current
	GROOVYSERV_HOME=/Users/tom/.gvm/groovyserv/current
	GROOVY_HOME=/Users/tom/.gvm/groovy/current
	GVM_BROADCAST_SERVICE=http://cast.gvm.io
	GVM_BROKER_SERVICE=http://release.gvm.io
	GVM_DIR=/Users/tom/.gvm
	GVM_INIT=true
	GVM_PLATFORM=Darwin
	GVM_SERVICE=http://api.gvmtool.net
	GVM_VERSION=2.2.0
	HADOOP_DISTRO=hadoop25
	HOME=/Users/tom
	IRBRC=/Users/tom/.rvm/rubies/ruby-1.9.3-p484/.irbrc
	JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home
	JAVA_MAIN_CLASS_79926=org.springframework.xd.dirt.server.SingleNodeApplication
	JBAKE_HOME=/Users/tom/.gvm/jbake/current
	LANG=en_US.UTF-8
	LAZYBONES_HOME=/Users/tom/.gvm/lazybones/current
	LC_ALL=en_US.UTF-8
	LC_CTYPE=UTF-8
	LESS=-F -g -i -M -R -S -w -X -z-4
	LESS_TERMCAP_mb=[01;31m
	LESS_TERMCAP_md=[01;31m
	LESS_TERMCAP_me=[0m
	LESS_TERMCAP_se=[0m
	LESS_TERMCAP_so=[00;47;30m
	LESS_TERMCAP_ue=[0m
	LESS_TERMCAP_us=[01;32m
	LOGNAME=tom
	LSCOLORS=exfxcxdxbxGxDxabagacad
	LS_COLORS=di=34:ln=35:so=32:pi=33:ex=31:bd=36;01:cd=33;01:su=31;40;07:sg=36;40;07:tw=32;40;07:ow=33;40;07:
	MAVEN_HOME=/Applications/dev/tools/apache-maven-3.2.1
	MY_RUBY_HOME=/Users/tom/.rvm/rubies/ruby-1.9.3-p484
	OLDPWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
	PAGER=less
	PATH=/Users/tom/.gvm/vertx/current/bin:/Users/tom/.gvm/springboot/current/bin:/Users/tom/.gvm/lazybones/current/bin:/Users/tom/.gvm/jbake/current/bin:/Users/tom/.gvm/groovyserv/current/bin:/Users/tom/.gvm/groovy/current/bin:/Users/tom/.gvm/griffon/current/bin:/Users/tom/.gvm/grails/current/bin:/Users/tom/.gvm/gradle/current/bin:/Users/tom/.gvm/glide/current/bin:/Users/tom/.gvm/gaiden/current/bin:/Users/tom/.gvm/crash/current/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global/bin:/Users/tom/.rvm/rubies/ruby-1.9.3-p484/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/go/bin:/usr/texbin:/Users/tom/.rvm/bin:/Users/tom/.yadr/bin:/Users/tom/.yadr/bin/yadr:/Applications/dev/tools/apache-maven-3.2.1/bin:/Applications/dev/tools/apache-ant-1.9.2/bin:/Users/tom/.rvm/bin
	PID=79926
	PS4=+ %* %F{red}%x:%I %F{green}%N:%i%F{white} %_
	PWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd
	SCREEN_NO=
	SECURITYSESSIONID=186a4
	SHELL=/bin/zsh
	SHLVL=1
	SPRINGBOOT_HOME=/Users/tom/.gvm/springboot/current
	SSH_AUTH_SOCK=/tmp/launch-KXqpmP/Listeners
	TERM=xterm-256color
	TERM_PROGRAM=Apple_Terminal
	TERM_PROGRAM_VERSION=326
	TERM_SESSION_CLASS_ID=D65D4C24-B8F2-4B53-9179-EC38F2DCD1AE
	TERM_SESSION_ID=3FA5B432-B6C3-4F62-A7FB-00EB6B0F18C7
	TMPDIR=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/
	USER=tom
	VERTX_HOME=/Users/tom/.gvm/vertx/current
	VISUAL=vim
	XD_ANALYTICS=memory
	XD_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
	XD_CONFIG_NAME=servers,application
	XD_HOME=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
	XD_JMX_ENABLED=true
	XD_MODULE_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/
	XD_MODULE_CONFIG_NAME=modules
	XD_TRANSPORT=local
	__CF_USER_TEXT_ENCODING=0x1F5:0:0
	__CHECKFIX1436934=1
	_system_arch=x86_64
	_system_name=OSX
	_system_type=Darwin
	_system_version=10.9
	analytics=memory
	awt.toolkit=sun.lwawt.macosx.LWCToolkit
	catalina.base=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393
	catalina.home=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393
	catalina.useNaming=false
	document=--
	embeddedHsql=true
	endpoints.jmx.enabled=true
	endpoints.jmx.uniqueNames=true
	endpoints.jolokia.enabled=true
	endpoints.shutdown.enabled=true
	file.encoding=UTF-8
	file.encoding.pkg=sun.io
	file.separator=/
	ftp.nonProxyHosts=local|*.local|169.254/16|*.169.254/16
	gopherProxySet=false
	http.nonProxyHosts=local|*.local|169.254/16|*.169.254/16
	java.awt.graphicsenv=sun.awt.CGraphicsEnvironment
	java.awt.headless=true
	java.awt.printerjob=sun.lwawt.macosx.CPrinterJob
	java.class.path=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules/processor/scripts:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/activation-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/amqp-client-3.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aopalliance-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/args4j-2.0.16.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/asm-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjrt-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjweaver-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-compiler-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/cglib-2.2.1-v20090111.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/classmate-1.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/com.ibm.jbatch-tck-spi-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-beanutils-1.9.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-cli-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-codec-1.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-collections-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-compress-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-configuration-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-daemon-1.0.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-dbcp-1.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-digester-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-el-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-fileupload-1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-httpclient-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-io-2.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-jexl-2.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-lang-2.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-math-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-net-3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool2-2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-client-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-framework-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-recipes-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/disruptor-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/groovy-all-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-api-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guava-16.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-servlet-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hibernate-validator-5.0.3.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hsqldb-2.3.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-annotations-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-databind-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-mapper-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javassist-3.18.1-GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.batch-api-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.inject-1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.mail-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jboss-logging-3.1.1.GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jcl-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jedis-2.5.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jersey-guice-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jettison-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jline-2.11.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/joda-time-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jolokia-core-1.2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jopt-simple-4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-path-0.9.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-simple-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-smart-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jsr305-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jul-to-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kafka_2.10-0.8.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-data-core-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-hadoop-compatibility-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kryo-2.22.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-1.2.17.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-annotation-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-core-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/mongo-java-driver-2.12.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/netty-3.7.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/objenesis-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/ognl-3.0.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/opencsv-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/paranamer-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-avro-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-column-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-common-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-encoding-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-format-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-generator-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-hadoop-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-jackson-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/postgresql-9.2-1002-jdbc4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/reactor-core-1.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/scala-library-2.10.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-api-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-log4j12-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snakeyaml-1.14.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snappy-java-1.1.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-amqp-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-aop-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-manager-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-resources-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-core-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-infrastructure-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-integration-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-beans-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-actuator-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-autoconfigure-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-loader-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-logging-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-security-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-thymeleaf-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-tomcat-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-web-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-cloudfoundry-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-core-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-spring-service-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-support-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-core-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-commons-1.9.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-mongodb-1.5.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-redis-1.4.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-expression-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-hateoas-0.14.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-amqp-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-core-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-event-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-file-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-http-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-jmx-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-kafka-1.0.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-redis-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-jdbc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-ldap-core-2.0.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-messaging-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-plugin-core-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-rabbit-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-retry-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-config-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-core-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-ldap-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-web-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-tx-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-web-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-webmvc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-analytics-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-batch-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-hadoop-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-spi-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-rest-domain-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-tuple-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-ui-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-layout-dialect-1.2.5.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-spring4-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-core-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-el-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-logging-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-websocket-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-jdbc-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/unbescape-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/validation-api-1.1.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlenc-0.52.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlpull-1.1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xpp3_min-1.1.4c.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xstream-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xz-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zkclient-0.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zookeeper-3.4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-annotations-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-auth-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-distcp-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-hdfs-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-core-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-jobclient-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-shuffle-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-streaming-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-api-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-client-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-nodemanager-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-core-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-server-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jetty-util-6.1.26.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/protobuf-java-2.5.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-batch-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-core-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hbase-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hive-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-pig-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-store-2.1.0.M2.jar
	java.class.version=52.0
	java.endorsed.dirs=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/endorsed
	java.ext.dirs=/Users/tom/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java
	java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre
	java.io.tmpdir=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/
	java.library.path=/Users/tom/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
	java.runtime.name=Java(TM) SE Runtime Environment
	java.runtime.version=1.8.0_25-b17
	java.specification.name=Java Platform API Specification
	java.specification.vendor=Oracle Corporation
	java.specification.version=1.8
	java.vendor=Oracle Corporation
	java.vendor.url=http://java.oracle.com/
	java.vendor.url.bug=http://bugreport.sun.com/bugreport/
	java.version=1.8.0_25
	java.vm.info=mixed mode
	java.vm.name=Java HotSpot(TM) 64-Bit Server VM
	java.vm.specification.name=Java Virtual Machine Specification
	java.vm.specification.vendor=Oracle Corporation
	java.vm.specification.version=1.8
	java.vm.vendor=Oracle Corporation
	java.vm.version=25.25-b02
	line.separator=

	logging.config=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config///xd-singlenode-logger.properties
	management.contextPath=/management
	management.port=
	management.security.enabled=false
	os.arch=x86_64
	os.name=Mac OS X
	os.version=10.9.5
	path.separator=:
	rvm_alias_expanded=
	rvm_bin_path=/Users/tom/.rvm/bin
	rvm_docs_type=
	rvm_gemstone_package_file=
	rvm_gemstone_url=
	rvm_niceness=
	rvm_nightly_flag=
	rvm_path=/Users/tom/.rvm
	rvm_prefix=/Users/tom
	rvm_proxy=
	rvm_quiet_flag=
	rvm_ruby_file=
	rvm_ruby_make=
	rvm_ruby_make_install=
	rvm_ruby_mode=
	rvm_script_name=
	rvm_sdk=
	rvm_silent_flag=
	rvm_version=1.25.18 (master)
	rvm_wrapper_name=
	security.basic.enabled=false
	security.basic.realm=SpringXD
	server.port=0
	socksNonProxyHosts=local|*.local|169.254/16|*.169.254/16
	spring.application.name=admin
	spring.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
	spring.config.name=servers,application
	spring.datasource.abandonWhenPercentageFull=0
	spring.datasource.alternateUsernameAllowed=false
	spring.datasource.driverClassName=org.hsqldb.jdbc.JDBCDriver
	spring.datasource.fairQueue=true
	spring.datasource.initialSize=0
	spring.datasource.jmxEnabled=true
	spring.datasource.logAbandoned=false
	spring.datasource.maxActive=100
	spring.datasource.maxAge=0
	spring.datasource.maxIdle=100
	spring.datasource.maxWait=30000
	spring.datasource.minEvictableIdleTimeMillis=60000
	spring.datasource.minIdle=10
	spring.datasource.password=
	spring.datasource.removeAbandoned=false
	spring.datasource.removeAbandonedTimeout=60
	spring.datasource.suspectTimeout=0
	spring.datasource.testOnBorrow=true
	spring.datasource.testOnReturn=false
	spring.datasource.testWhileIdle=false
	spring.datasource.timeBetweenEvictionRunsMillis=5000
	spring.datasource.url=jdbc:hsqldb:hsql://localhost:9101/xdjob
	spring.datasource.useEquals=true
	spring.datasource.username=sa
	spring.datasource.validationInterval=30000
	spring.datasource.validationQuery=select 1 from INFORMATION_SCHEMA.SYSTEM_USERS
	spring.freemarker.checkTemplateLocation=false
	spring.hadoop.fsUri=hdfs://localhost:8020
	spring.main.show_banner=false
	spring.profiles=container
	spring.profiles.active=default
	spring.rabbitmq.addresses=localhost:5672
	spring.rabbitmq.password=guest
	spring.rabbitmq.sslProperties=
	spring.rabbitmq.useSSL=false
	spring.rabbitmq.username=guest
	spring.rabbitmq.virtual_host=/
	spring.redis.host=localhost
	spring.redis.pool.maxActive=8
	spring.redis.pool.maxIdle=8
	spring.redis.pool.maxWait=-1
	spring.redis.pool.minIdle=0
	spring.redis.port=6379
	sun.arch.data.model=64
	sun.boot.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/classes
	sun.boot.library.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib
	sun.cpu.endian=little
	sun.cpu.isalist=
	sun.io.unicode.encoding=UnicodeBig
	sun.java.command=org.springframework.xd.dirt.server.SingleNodeApplication --verbose
	sun.java.launcher=SUN_STANDARD
	sun.jnu.encoding=UTF-8
	sun.management.compiler=HotSpot 64-Bit Tiered Compilers
	sun.os.patch.level=unknown
	transport=local
	user.country=US
	user.country.format=DE
	user.dir=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd
	user.home=/Users/tom
	user.language=en
	user.name=tom
	user.timezone=Europe/Berlin
	vcs_info_msg_0_=(%F{81}master%f%F{166}●%f)
	vcs_info_msg_1_=
	verbose=true
	xd.config.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//
	xd.container.groups=
	xd.container.host=
	xd.container.ip=
	xd.data.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/data
	xd.extensions.basepackages=
	xd.extensions.locations=META-INF/spring-xd/ext
	xd.home=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd
	xd.messageRateMonitoring.enabled=false
	xd.messagebus.kafka.brokers=localhost:9092
	xd.messagebus.kafka.numOfKafkaPartitionsForCountEqualsZero=10
	xd.messagebus.kafka.replicationFactor=1
	xd.messagebus.kafka.zkAddress=localhost:2181
	xd.messagebus.rabbit.default.ackMode=AUTO
	xd.messagebus.rabbit.default.autoBindDLQ=false
	xd.messagebus.rabbit.default.backOffInitialInterval=1000
	xd.messagebus.rabbit.default.backOffMaxInterval=10000
	xd.messagebus.rabbit.default.backOffMultiplier=2.0
	xd.messagebus.rabbit.default.concurrency=1
	xd.messagebus.rabbit.default.deliveryMode=PERSISTENT
	xd.messagebus.rabbit.default.maxAttempts=3
	xd.messagebus.rabbit.default.maxConcurrency=1
	xd.messagebus.rabbit.default.prefetch=1
	xd.messagebus.rabbit.default.prefix=xdbus.
	xd.messagebus.rabbit.default.replyHeaderPatterns=STANDARD_REPLY_HEADERS,*
	xd.messagebus.rabbit.default.requestHeaderPatterns=STANDARD_REQUEST_HEADERS,*
	xd.messagebus.rabbit.default.requeue=true
	xd.messagebus.rabbit.default.transacted=false
	xd.messagebus.rabbit.default.txSize=1
	xd.messagebus.redis.default.backOffInitialInterval=1000
	xd.messagebus.redis.default.backOffMaxInterval=10000
	xd.messagebus.redis.default.backOffMultiplier=2.0
	xd.messagebus.redis.default.concurrency=1
	xd.messagebus.redis.default.maxAttempts=3
	xd.messagebus.redis.headers=
	xd.module.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/
	xd.module.config.name=modules
	xd.module.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules
	xd.transport=local
	xd.ui.allow_origin=http://localhost:9889
	xd.ui.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/spring-xd-ui/dist/
	zk.client.connect=
	zk.embedded.client.connect=localhost:38225
	zk.namespace=xd

20:40:58,171 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=172.16.200.1, host=gauss, groups=, pid=79926, id=f75f4b79-a82c-442f-954b-3df1687ce25c} joined cluster
20:40:58,174 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.863 seconds (JVM running for 16.037)
20:40:58,177 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED
20:40:58,178 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/f75f4b79-a82c-442f-954b-3df1687ce25c, type=CHILD_ADDED
20:40:58,193 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='f75f4b79-a82c-442f-954b-3df1687ce25c', attributes={ip=172.16.200.1, host=gauss, groups=, pid=79926, id=f75f4b79-a82c-442f-954b-3df1687ce25c}}
20:40:58,194 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms 
20:41:04,880 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leadership canceled due to thread interrupt
{code}",XD-2355,Thomas Darimont,xd-singlenode --verbose prints configuration information twice
1401,Glenn Renfro,Thomas Risberg,"Many of the tests fail with:

{code}
java.lang.IllegalStateException: Cannot find template location: class path resource [templates/] (please add some templates, check your Groovy configuration, or set spring.groovy.template.check-template-location=false)
{code}

Somehow we need to disable this check, using the property suggested.",XD-2354,Thomas Risberg,EC2 Integration Tests fail after Boot 1.2 upgrade
1402,Glenn Renfro,Glenn Renfro,"spring.groovy.template.check-template-location=false must now be set in the properties file.
",XD-2353,Glenn Renfro,Boot upgrade caused test failures
1403,Eric Bottard,Mark Pollack,"After updating to Boot 1.2 RC1 the following replacement doesn't work.  

{code:xml}
	<bean id=""messageConverter"" class=""${converterClass}"" />
{code}

which appears in the rabbit source and sink.  Feels like a core spring thing, but that was updated earlier.

Current workaround that was commited already so the build can pass is

{code:xml}
	<bean id=""clazz"" class=""java.lang.Class"" factory-method=""forName"">
	  <constructor-arg value=""${converterClass}""/>
	</bean>

	<bean id=""messageConverter"" factory-bean=""clazz"" factory-method=""newInstance""/>
{code}

",XD-2352,Mark Pollack,Property replacement does not happen in XML class attribute
1404,David Turanski,Mark Pollack,We are referencing Spring.IO deps when we shouldn't (since we moved to a different version of boot than in in the platform).,XD-2351,Mark Pollack,POM generation creates the correct dependency list
1405,,David Turanski,"Install a boot uberjar containing custom modules plus stream and job definitions, and possibly specific configuration. This potentially includes the ability to export and import all deployable resources defined in an XD environment.  ",XD-2350,David Turanski,User wants to package and deploy an XD application
1406,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a source or a sink as recommended. ",XD-2349,Sabby Anandan,Document Kafka source/sink
1407,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to refer to documentation in wiki so that I can setup and configure Spark as a Batch job as recommended. ",XD-2348,Sabby Anandan,Document Spark job
1408,,Sabby Anandan,"As a user, I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended. ",XD-2347,Sabby Anandan,Document Kafka message bus
1409,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to refer to documentation in wiki so that I can configure the new sources, sinks and processor modules and as well as any new features. ",XD-2346,Sabby Anandan,Document 1.1 major features
1410,Gunnar Hillert,Thomas Risberg,Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI.,XD-2345,Thomas Risberg,XD UI not usable with IE 11
1411,Gunnar Hillert,Thomas Risberg,"Trying to deploy the `timestampfile` job using the UI.

Seems the UI doesn't quote string parameters that contains a space so the job creation fails.

Keeping all the defaults I get the following ""Resulting Definition"" in the UI:

timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true

(note: the --format parameter has a space)

which causes:

XD100E:(pos 128): Found unexpected data after stream definition: 'HH' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true *^
",XD-2344,Thomas Risberg,UI should quote parameters containing a space
1412,,Eric Bottard,"Currently, module composition always guesses the correct type because we don't have a module with a given name N that is both a source and a processor, or a processor and a sink (we only have the case source and sink, as in jdbc/jdbc or file/file).

If it were the case, then the heuristics for guessing the resulting type of a composition would break.

This issue is about adding the option for the user to explicitly specify the expected type of the composition, /if needed/.",XD-2343,Eric Bottard,"Allow ""module compose"" to specify an explicit type"
1413,Gunnar Hillert,Buelent Zeyben,"Password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (See attached image).

The password has an '_' char but it shouldn't matter. The entire password should be masked with '*' instead.",XD-2342,Buelent Zeyben,JDBCHDFS Job Password issue
1414,Ilayaperumal Gopinathan,Allan Baril,"Using single-node deployment of Spring XD 1.0 GA, we needed to redefine several batch jobs. We deleted the jobs (""job destroy all""). When attempting to re-add, we received an error that a job with the name already exists. Performing ""job list"" confirms the jobs were gone.
To workaround, I needed to terminate the instance (server) of Spring XD and restart it. Since this was the single-node deployment without a live stream of data coming in this was okay, but would have been a major problem if bouncing the Spring XD server was not acceptable (i.e., live data being actively received).",XD-2341,Allan Baril,Deleting a job and then re-adding a new definition with the same name fails
1415,Gunnar Hillert,Gunnar Hillert,,XD-2340,Gunnar Hillert,Ensure that branch-specific documentation is pulled and generated
1416,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"There are some modules that use external config properties (kafka producer/consumer, hadoop properties etc.,). We need to avoid using such properties and have them configured inside module so that module and its properties are self contained.

",XD-2339,Ilayaperumal Gopinathan,Remove external config properties for modules
1417,Sabby Anandan,Gunnar Hillert,"Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see: 

{code}
FAILURE: Build failed with an exception.

* Where:
Build file '/Users/hillert/dev/git/spring-xd/build.gradle' line: 219

* What went wrong:
A problem occurred evaluating root project 'spring-xd'.
> Could not find method forceDependencyVersions() for arguments [project ':documentation-toolchain'] on root project 'spring-xd'.
{code}",XD-2338,Gunnar Hillert,Upgrade to Gradle 2.2
1418,,Michael Campbell,Requesting a ZeroMQ based source.  ,XD-2337,Michael Campbell,"Feature Request: ZeroMQ (ZMQ, 0MQ) source"
1419,,Sabby Anandan,,XD-2336,Sabby Anandan,Bucket for Kafka as a message bus for performance testing
1420,Glenn Renfro,Glenn Renfro,Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.,XD-2335,Glenn Renfro,Update Performance AMI to include Kafka
1421,Glenn Renfro,Glenn Renfro,"Since Kafka and Rabbit have different strategies on how a message system is implemented, we will need to update the tests used on rabbit to work with Kafka.  While they will not be exactly the same as before, they should exercise the same principles.
This story covers: 
* Create the consumer and producer execution configurations for
kafka-producer-perf-test.sh and kafka-consumer-perf-test.sh. 
* Record the tests a spreadsheet much like the Rabbit Base test spreadsheet

",XD-2334,Glenn Renfro,Create base perf test criteria
1422,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ",XD-2333,Ilayaperumal Gopinathan,Add test coverage for Kafka source and sink modules
1423,Gunnar Hillert,Gunnar Hillert,"It is easy to get a cron expression wrong. 

Provide validation of the cron expression on the Schedule Job page using async validation. 

* Submit the cron expression to the server-side - and validate that the expression is valid.
* Send a success message back (we may even send back some meta data … e.g. when is the next execution going to take place)
",XD-2332,Gunnar Hillert,AdminUI - Provide Server-Side Cron Expression Validation
1424,Patrick Peralta,Gunnar Hillert,"*Version:*
XD 1.0.1
Mac OSX 10.9.5

*Problem:*
- Deployed a simple batch job in 'singlenode'
- Laptop put to sleep mode
- After login: notice that ZK is establishing connection 
- Continues to clean-up prior to redeployment, but never goes through successfully
- Listing job both in UI and Shell states it is ""undeployed""

*Gunnar's experiment:*
- System is running in Single Node
- Laptop goes to sleep
- After waking up your laptop from sleep, you cannot retrieve the list of deployed jobs anymore (in AdminUI)

*Error:*
Only getting back a *404* - ""NoSuchBatchJobException"", ""Batch Job with the name abcd doesn't exist""",XD-2331,Gunnar Hillert,Job deployment list returns 404 after Laptop wakes up
1425,Thomas Risberg,Glenn Renfro,"XD, gemfire, directories in the zip file are missing.",XD-2330,Glenn Renfro,Zip created by Publish 1.1 only contains the shell.
1426,,Sabby Anandan,"Placeholder to update to Apache 2.5.1 on CI machines.

*Next steps:*
* It looks like the dependencies.properties still file has 2.2.0; update it to 2.5.1
* I guess we just bumped the spring-data-hadoop dependency; check for relevant other dependencies ",XD-2329,Sabby Anandan,Update Hadoop in CI machines
1427,Mark Pollack,Sabby Anandan,Placeholder for Doc generation and supporting multiple doc branches.,XD-2328,Sabby Anandan,Create a 1.0.x 'Docs' branch 
1428,Mark Pollack,Sabby Anandan,Placeholder to update [Wiki|https://github.com/spring-projects/spring-xd/wiki] with release version number.,XD-2327,Sabby Anandan,Update wiki page with release version
1429,David Turanski,Thomas Risberg,"Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition ""time | log'

{code}
09:34:20,789 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..
09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local
09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//
09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
09:34:20,793 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo
dules/
09:34:20,794 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
09:34:20,795 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Seattle:9393/admin-ui
09:34:20,797 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424
09:34:20,798 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
09:34:20,799 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory
09:34:20,913 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin singlenode:default,admin,singlenode,hsqldbServer:9393 is watching for
stream/job deployment requests.
09:34:21,013 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED
09:34:21,070 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 6.364 seconds (JVM running for 18.031)
09:34:22,593 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849
099f} joined cluster
09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..
09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local
09:34:22,595 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo
dules/
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 192.168.0.120
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   Seattle
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop22
09:34:22,597 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/08c72e88-66d4-4b47-bd4a-8f5e5849099f, type=CH
ILD_ADDED
09:34:22,600 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED
09:34:22,607 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='08c72e88-66d4-4b47-bd4a-8f5e5849099f', attrib
utes={ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849099f}}
09:34:22,609 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms
09:34:22,611 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.2.0
09:34:22,612 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424
09:34:22,613 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
09:34:22,615 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory
09:34:22,616 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.61 seconds (JVM running for 19.576)
09:36:15,837 1.1.0.SNAP ERROR http-nio-9393-exec-3 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.StringIndexOutOfBoundsException: String index out of range: -1
        at java.lang.String.substring(String.java:1954)
        at org.springframework.xd.dirt.module.ArchiveModuleRegistry.fromResource(ArchiveModuleRegistry.java:140)
        at org.springframework.xd.dirt.module.ArchiveModuleRegistry.findDefinition(ArchiveModuleRegistry.java:68)
        at org.springframework.xd.dirt.module.DelegatingModuleRegistry.findDefinition(DelegatingModuleRegistry.java:48)
        at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:78)
        at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:317)
        at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:212)
        at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:168)
        at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)
        at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at org.springframework.web.method.support.InvocableHandalerMethod.invoke(InvocableHandlerMethod.java:215)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)
        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)
        at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf
iguration.java:280)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)
        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.lang.Thread.run(Thread.java:745)
{code}",XD-2326,Thomas Risberg,Can't create stream running on Windows
1430,Marius Bogoevici,Marius Bogoevici,"We have to explicitly set it to false, in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.",XD-2325,Marius Bogoevici,Set 'auto-startup' to false in Kafka source
1431,,Gary Russell,"{{JobCommandTests}} in xd-shell only uses a {{LocalMessageBus}} so the problem in XD-2323 was not discovered until a manual integration test was executed.

At a minimum, {{JobCommandTests.testLaunchPartitionedJob()}} should be run with all bus implementations.",XD-2324,Gary Russell,Add Partitioned Job Integration Tests Using Other Bus Implementations
1432,Gary Russell,Glenn Renfro,"SHA: 67473dc71332c0727516b6f3fd11a55561b2472e
Deployment: 1 Admin, 2 Containers
JobStore: HSQLDB
OS: Mac OSX & Ubuntu
Reproducible: Yes
Job: job create foo \-\-definition ""filejdbc \-\-resources=file:filejdbctest/filejdbctest.out \-\-names=data --tableName=filejdbctest \-\-initializeDatabase=true ""\-\-deploy

When using Rabbit as a transport with more than one container and launching the job above.  The Job execution stays as ""STARTED"" status, even though the job is actually finished.   We expect it to reach a state of ""COMPLETED"".  Using Redis as a transport the job execution status does reach ""COMPLETED"".   

The execution step list shows: 
Id  Step Name                Job Exec ID  Start Time               End Time                 Status
  --  -----------------------  -----------  -----------------------  -----------------------  ---------
  8   step1-master             4            2014-11-06 15:28:29,820                           STARTED
  9   step1-master:partition0  4            2014-11-06 15:28:29,854  2014-11-06 15:28:29,890  COMPLETED",XD-2323,Glenn Renfro,"Filejdbc jobs status shows ""STARTED"" even when job is complete"
1433,Marius Bogoevici,Marius Bogoevici,"The field exists and it is referred to in application.yml, but it does not have a setter and the bus will always use the configured default, which is 1.",XD-2322,Marius Bogoevici,Enable configuration of replication factor on the Kafka message bus
1434,Gunnar Hillert,Gunnar Hillert,"Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.

Similar to XD-2320",XD-2321,Gunnar Hillert,UI: Create a dedicated scheduling page for Jobs
1435,Gunnar Hillert,Gunnar Hillert,Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.,XD-2320,Gunnar Hillert,UI: Create a dedicated Launch Page for Jobs
1436,David Turanski,David Turanski,,XD-2319,David Turanski,Add spring-xd-python to the distribution
1437,David Turanski,David Turanski,"Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas.  ",XD-2318,David Turanski,Create Boot Starters for Modules
1438,,Buelent Zeyben,"User should have the option of Greenplum DB sink so they can write data directly to Greenplum DB via the pgfdist/gploader (Greenplum bulk loader).

The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.",XD-2317,Buelent Zeyben,Add Greenplum Sink
1439,Ilayaperumal Gopinathan,Gunnar Hillert,"There is a bug in the deployments rest end-point. 

*How to reproduce:* 

* Deploy a Batch job (success) that for example does not all necessary libraries in the class-patch and thus causes a “java.lang.ClassNotFoundException”

*Result:*

You cannot retrieve the list of deployments list anymore using:

* http://localhost:9393/jobs/configurations

The rest endpoint will now report:

[{""links"":[],""logref"":""NoSuchBatchJobException"",""message"":""Batch Job with the name myJob doesn't exist""}]

This message is not entirely wrong…but extremely misleading. I think we should still return the entire list and rather mark the job as having an error.

Also returning an “404 Not Found” is misleading as well.
",XD-2316,Gunnar Hillert,"REST: ""jobs/configurations"" returns 404 if one job has error"
1440,Gunnar Hillert,Gunnar Hillert,"* Update Angular Growl to v2
* Allowing for stoppable notifications (in case you want to see it for longer than 5 secs)
",XD-2315,Gunnar Hillert,UI: Add support for stoppable notifications
1441,,Sabby Anandan,"Send 1M messages of 1000 bytes via the generator, vary the number of producer threads.

Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of threads*
* 2
* 4
* 8",XD-2314,Sabby Anandan,Vary producer threads (XD-B-2)
1442,,Sabby Anandan,"As a user, I'd like to create a stream such as _generator | perf-meter_ so that I can ingest 1M messages of 1000 bytes and one thread using XD's 'singlenode' container and measure performance characteristics.",XD-2313,Sabby Anandan,Baseline (XD-B-1)
1443,Sabby Anandan,Sabby Anandan,"As a user, I'd like to have a _perf-meter_ sink that will collect and push metrics to the standard container log file.  

Example: perf-meter --numMsgs 1000

Will write to the container log a timestamp, message count, and message rate every 1000 messages.  The message rate is the value since the last log event.  Default values are those specified above.
",XD-2312,Sabby Anandan,"Add ""perf_meter"" sink (perf. testing)"
1444,Sabby Anandan,Sabby Anandan,"As a user, I'd like to have a _generator_ source module so that I can create a number of messages of a specified size (similar to Rabbit's PerfTest utility).

Example: generator --numMsgs 10000 --msgSize 1024 --numThreads 1
",XD-2311,Sabby Anandan,"Add ""generator"" source (perf. testing)"
1445,Marius Bogoevici,Marius Bogoevici,"Using Kafka as a transport option yields:

[2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed
org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml]
Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml]; nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".
	at org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)
	at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)
	at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)
	at org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)
	... 31 more
Caused by: org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)
	at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)
	at com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)
	at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)
	... 36 more",XD-2310,Marius Bogoevici,Parsing issues with kafka-bus.xml
1446,Michael Minella,Derek OKeeffe,"Enhance the current jdbchdfs job in spring-xd to have an incremental load / delta load feature similar to sqoop. See sqoop documentation [here|http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports]. The job will need to maintain some state between executions in order to decide the start point for the next data load. 

The jdbchdfs job definition could take the following 2 new options. 

h5. checkColumn 
optional
Specifies the column to be examined when determining which rows to import. (the column should not be of type CHAR/NCHAR/VARCHAR/VARNCHAR/ LONGVARCHAR/LONGNVARCHAR). Column should be numeric or timestamp.
h5. lastValue 
optional
If specified this will override any data saved from previous job runs. If not specified will take the saved max-value from the last job run. If no last job run data is available then it will not be an incremental load and all the data which satisfies the query will be used.

Sqoop provides 2 modes of operation for incremental load, 'append' and 'lastModified'. For jdbchdfs the job will always append as it is writing to a hdfs file.

Example: To import data from the database table some_table which has a last update column called lastUpdated, you could use.
{code}
xd:> job create myjob --definition ""jdbchdfs --sql='select col1,col2,col3 from some_table' --checkColumn=lastUpdated"" --deploy
{code}

The batch job should also be capable of being partitioned to run in parallel across multiple containers",XD-2309,Derek OKeeffe,Incremental data import with jdbchdfs job
1447,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have a sample app (GitHub project) so that I can use it as a reference while provisioning Spring XD cluster with Kafka.

Consider:
* Kafka as message bus
* Kafka as source

",XD-2308,Sabby Anandan,Create sample app to demonstrate Kafka integration
1448,Thomas Risberg,Sabby Anandan,"*XD 1.1 M1 Release + PHD 2.1 Upgrade - Action Items:*

* Update to SHDP 2.1.M2, 
* Add Hadoop 2.5 (hadoop25)
* Remove hadoop22
* Remove PHD 1.0 (phd1) 
* Change PHD 2.x from phd20 to phd21
* Test PHD 2.0 with phd21",XD-2307,Sabby Anandan,Add support for PHD 2.1 (XD 1.1 M1 Release)
1449,Eric Bottard,Sabby Anandan,"As a user, I'd like to push the custom module (built as uber-jar) via a REST API so that I can install the custom module in cluster. ",XD-2306,Sabby Anandan,Add support to install custom module archive
1450,Mark Fisher,Sabby Anandan,"*Spike Scope:*

* Experiment with identified options
* POC with the logical integration choice",XD-2305,Sabby Anandan,POC for Spark Integration
1451,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically.

*Spike scope*:
- Study simple consumer API functionality
- Document findings, approach and next steps",XD-2304,Sabby Anandan,Research refactoring effort for Kafka source to use simple consumer instead of high-level API
1452,David Turanski,David Turanski,"Need to update the Modules page and any other that describes top level xml files. Also describe alternate module implementations: XD-713, XD-1805, XD-2100",XD-2303,David Turanski,Update https://github.com/spring-projects/spring-xd/wiki/Modules
1453,Gunnar Hillert,Gunnar Hillert,"
* https://docs.angularjs.org/guide/migration#migrating-from-1-2-to-1-3
* http://angularjs.blogspot.com/2014/10/ng-europe-angular-13-and-beyond.html
* http://angularjs.blogspot.com/2014/10/angularjs-130-superluminal-nudge.html

",XD-2302,Gunnar Hillert,UI: Update AngularJS to v1.3
1454,Mark Fisher,Sabby Anandan,"*Spike scope:*

* Brainstorm
* Identify options
* Document
",XD-2301,Sabby Anandan,Research Spark integration options
1455,Gary Russell,Sabby Anandan,The scope is to document the automatic creation and binding of DLQ for each 'pipe' (consumer queue).,XD-2300,Sabby Anandan,Document automatic declaration of DQL for each consumer queue
1456,Sabby Anandan,Sabby Anandan,,XD-2299,Sabby Anandan,Placeholder for 1.0.2 and 1.1M1 release testing effort
1457,Thomas Risberg,Sabby Anandan,"As a user, I'd like to mass ingest data from databases (and others) into HDFS/HAWQ/GPDB so that I don't have to write custom code and as well as be able to ingest in an efficient way.",XD-2298,Sabby Anandan,Review POC and identify scope for gpload as OOTB Batch Job
1458,,Sabby Anandan,,XD-2297,Sabby Anandan,Add support for mass data ingest
1459,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to have a config parameter preferably in _servers.yml_ file so that I can enable/disable message rates in the cluster view. ",XD-2296,Sabby Anandan,Add config parameter to enable/disable message rates in cluster view
1460,,Sabby Anandan,"As a user, I'd like to stream ingest audio and video data so that I can apply predictive analytics algorithms for facial detection.

*Spike scope:*
* Research the feasibility of implementing [Motion-JPEG|http://en.wikipedia.org/wiki/Motion_JPEG]
* Design specs on Motion-JPEG format

*Note:* [opencv|http://docs.opencv.org/trunk/doc/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html], although having OOTB support, it is not platform compatible. ",XD-2295,Sabby Anandan,Add support for audio/video source
1461,,Vladimir Safin,,XD-2294,Vladimir Safin,Make processor:header-enricher available
1462,Eric Bottard,Sabby Anandan,"As a follow-up to Kafka message bus support, we would like to rerun the failing tests after upgrading to new [consumer|https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design] rewrite. 

[Response from Kafka support|http://mail-archives.apache.org/mod_mbox/kafka-users/201410.mbox/%3CCAHwHRrWZmLr94eHX1z5i36BYz%2B%3DCisx7GcbW1_Nn7ooNJcShMw%40mail.gmail.com%3E].",XD-2293,Sabby Anandan,Upgrade to Kafka 0.9 and rerun failing tests
1463,,Sabby Anandan,,XD-2292,Sabby Anandan,Add-ons for Rabbit as a Message Bus
1464,,Gunnar Hillert,"This may be broken down into 2 issues. First of all we need to define the proper UI interaction for the CLI to deal with pagination and then of course the actual implementation.

",XD-2291,Gunnar Hillert,Shell - Handle Pagination
1465,,Mark Pollack,"Query parameters for resolution, from, and to should be documented along with how to specify the time string (yyyy-MM-dd HH:mm:ss).",XD-2290,Mark Pollack,Documentation for aggregate counter REST API should include query parameters
1466,,Mark Pollack,"An aggregate counter query should return results inclusive of start and end time, [start,end] for time resolutions, minute, hour, day, month.

",XD-2289,Mark Pollack,"Redis backed aggregate counters should return results inclusive of start,end time interval"
1467,,Sabby Anandan,"As a user, I'd like to have the ability to access the random port (generated by tomcat) of the admin server (via _xd-shell_) so that I can point to the server and continue my interactions. 

*Spike Details:*
* Research whether connecting _xd-shell_ directly to ZK is a good approach or have a LB in-charge for the interaction.
* How about something other than a pointer to a ZK directory in the shell for folks to experiment a bit before getting a LB involved?

*Note:*
On some hadoop/hdfs setups access to zk is mandatory from hdfs client libs. There are some HA and federation setups which would anyway require xd shell to get access to zk if fs shell commands are used. ",XD-2288,Sabby Anandan,Research how to use 'admin' server ports from ZK
1468,Eric Bottard,Eric Bottard,"ArchiveModuleRegistry and the use of Boot Archives inherently relies on java.io.File
Have ResourceModuleRegistry extend/compose ArchiveMR to transparently download and cache (remote) jars that may be located in a (non-file:) location.

The staging area should be customizable, but some subdir of java.io.tmpdir sounds like a sensible default",XD-2287,Eric Bottard,Have ResourceModuleRegistry transparently proxy a remote root thru filesystem
1469,Patrick Peralta,Patrick Peralta,"Similar to {{time | log}}, we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.",XD-2286,Patrick Peralta,Simple OOTB job for testing
1470,,Eric Bottard,"Composed Module currently behave as ""white boxes"". As soon as a module is composed (say ""http | filter"") then all options of the children modules are available (as e.g. http.port and filter.expression in the example above).

Change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name). Hardcoding of values would be retained (and possibly overridable).

Possible syntaxes :
1)
{code}
module compose foo --definition ""http --port=${myport:1234} | filter""
{code}

2)
{code}
module compose foo --definition ""http | filter"" --expose port
{code}

2.1) in case of ambiguity (simulated in this particular example):
{code}
module compose foo --definition ""http | filter"" --expose http.port
{code}

2.2) for specifying a default:
{code}
module compose foo --definition ""http | filter"" --expose port=1234
{code}

3) allow both 1) and 2), using 1) mainly for cases where we don't map 1 to 1 with the underlying option, e.g.:
{code}
filter --expression=${expr}+'foo'
{code}

",XD-2285,Eric Bottard,"Change composed module behavior to ""black box"" "
1471,,Eric Bottard,"CMD should contain not only name and type of the child module, but also capture the options that were used in the composition.
An intermediate between ModuleDefinition and ModuleDescriptor should be created for that purpose (and maybe be part of ModuleDescriptor then)",XD-2284,Eric Bottard,CompositeModuleDefinition should contain more than List<ModuleDefinition>
1472,Glenn Renfro,Mark Pollack,Rerun test XD-2278 on a EC2 32 core machine and see when we max out.,XD-2283,Mark Pollack,Vary queue number on 32 core machine (ECB-8)
1473,Chris Schaefer,Mark Pollack,"Based on the the results from B-6, select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate, prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ‘top’ for the broker and PerfTest processes.

Test 1 (2 queues)
* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500

Test 2 (3 queues)
* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500

Test 3 (4 queues)
* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500

Test 4 (5 queues)
* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500

etc...

",XD-2282,Mark Pollack,Vary queue number (B-7)
1474,Chris Schaefer,Mark Pollack,"The results from EC2 testing show that once prefetch and message size are set, varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies. 

Using 500 prefetch, 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.

Test 1 (one producer / one consumer):
* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500

Test 2 (one producer / two consumers):
* -a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500

Test 3 (two producers / one consumer):
* -a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500
* -a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500

Test 4 (two producers / two consumers):
* -a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500
* -a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500
",XD-2281,Mark Pollack,Vary Producer and Consumer in combination using 2 Queues (B-6) 
1475,Glenn Renfro,Sabby Anandan,"Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers), message size 100 bytes, Prefetch 100.   Send 1M messages

Vary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of producers:*
* 2
* 4
* 6
* 10
* 50

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2280,Sabby Anandan,Vary producer size (EC-DB-5)
1476,Glenn Renfro,Sabby Anandan,"Using a single producer, message size of 1000 bytes, Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of consumers:*
* 1
* 2
* 4
* 6
* 10
* 50

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2279,Sabby Anandan,Vary consumer size (EC-DB-4)
1477,Glenn Renfro,Mark Pollack,"Based on the the results from B-6, select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate, prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ‘top’ for the broker and PerfTest processes.


Test 1 (2 queues)
-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500

Test 2 (3 queues)
-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500
Test 3 (4 queues)
-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500
Test 4 (5 queues)
-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500
etc.
",XD-2278,Mark Pollack,Vary queue number (ECB-7)
1478,Glenn Renfro,Sabby Anandan,"Use a single producer, single consumer, message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Prefetch Sizes:*
* 1
* 10
* 50
* 100
* 10000

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2277,Sabby Anandan,Vary prefecth size (EC-DB-3)
1479,Glenn Renfro,Sabby Anandan,"Use a single producer, single consumer, prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.

*Message Sizes:*
100 bytes
1000
10,000
100,000 

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2276,Sabby Anandan,Vary message size (EC-DB-2)
1480,Glenn Renfro,Mark Pollack,"The results from EC2 testing show that once prefetch and message size are set, varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies. 

Using 500 prefetch, 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.

Test 1 (one producer / one consumer):
-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500
-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500
Test 2 (one producer / two consumers):
-a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500
-a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500
Test 3 (two producers / one consumer):
-a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500
-a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500
Test 4 (two producers / two consumers):
-a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500
-a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500
",XD-2275,Mark Pollack,Vary Producer and Consumer in combination using 2 Queues (ECB-6)
1481,Patrick Peralta,Patrick Peralta,"{noformat}
org.junit.ComparisonFailure: org.junit.ComparisonFailure: expected:<[Hi there!
]> but was:<[]>
org.junit.ComparisonFailure: expected:<[Hi there!
]> but was:<[]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.springframework.xd.shell.command.TcpModulesTests.testTcpSink(TcpModulesTests.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
(60 more lines...)
{noformat}

https://build.spring.io/browse/XD-JDK8-JOB1-1162/test",XD-2274,Patrick Peralta,Intermittent TcpModulesTests.testTcpSink test failure
1482,,Mark Pollack,"Getting Caused by: 
{quote}
org.springframework.transaction.CannotCreateTransactionException: Could not open JDBC Connection for transaction; nested exception is java.sql.SQLException: S
QLSTATE=XJ045,SEVERITY=-1: (Server=localhost[1529],Thread[DRDAConnThread_24,5,gemfirexd.daemons]) Invalid or (currently) unsupported isolation level, '8', passed to Conn
ection.setTransactionIsolation(). The currently supported values are java.sql.Connection.TRANSACTION_NONE, java.sql.Connection.TRANSACTION_READ_UNCOMMITTED, java.sql.Con
nection.TRANSACTION_READ_COMMITTED and java.sql.Connection.TRANSACTION_REPEATABLE_READ.
	at org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:242)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:373)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:420)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:257)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:95)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy95.getLastJobExecution(Unknown Source)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:98)
{quote}

when launching a simple batch job with GemXD configured as the database

{quote}
job create --name myjob --definition ""filejdbc --resources=file:///home/mpollack/csv/*.csv --driverClassName=com.pivotal.gemfirexd.jdbc.ClientDriver --names=id,name,test --tableName=APP.mytable""
job deploy --name myjob 
job launch --name myjob 
{quote}

{quote}
spring:
  datasource:
    url: jdbc:gemfirexd://localhost:1527/
    username: admin
    password: admin
    driverClassName: com.pivotal.gemfirexd.jdbc.ClientDriver
{quote}",XD-2273,Mark Pollack,Support for GemXD as a target database in a batch job
1483,,Mark Pollack,"XD-2172 added a custom BatchConfigurer to allow the configuration of various properties when creating the JobRepository, isolationLevel, tablePrefix etc.  This should be documented in either the Application Configuration second of the docs or in the Batch Job section.",XD-2272,Mark Pollack,Document the configuration of the JobRepository 
1484,Gary Russell,Sabby Anandan,"As to prepare for 1.1 release, we would like to upgrade to Spring Integration 4.1.0 (RC) so that we can leverage the new features, enhancement and bug fixes. 

",XD-2271,Sabby Anandan,Upgrade to Spring Integration 4.1.0
1485,Thomas Risberg,Sabby Anandan,"As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 (RC1) (depends on Spring 4.1.2) so that we can leverage the new features, enhancement and bug fixes. 

[Spring Boot Milestones|https://github.com/spring-projects/spring-boot/milestones]",XD-2270,Sabby Anandan,Upgrade to Spring Boot 1.2.0
1486,Eric Bottard,Sabby Anandan,"As a follow-up action from module registry refactoring we would have to clean-up deprecated functions _(ex: download of module definitions)_ within our codebase. 

It may also be necessary to clean-up Shell and Admin-UI modules. ",XD-2269,Sabby Anandan,Remove deprecated functions 
1487,Mark Fisher,Sabby Anandan,"As a developer, I'd like to have a maintenance branch so that I can commit MINOR release _(ex: 1.0.2)_ code changes instead of committing to MASTER.",XD-2268,Sabby Anandan,Create a maintenance branch
1488,,Sabby Anandan,,XD-2267,Sabby Anandan,Action items to account for a release
1489,Glenn Renfro,Sabby Anandan,"Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers), message size 100 bytes, Prefetch 100.   Send 1M messages

Vary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of producers:*
* 2
* 4
* 6
* 10
* 50

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2266,Sabby Anandan,Vary producers size (ECB-5)
1490,Glenn Renfro,Sabby Anandan,"Using a single producer, message size of 1000 bytes, Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of consumers:*
* 1
* 2
* 4
* 6
* 10
* 50

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2265,Sabby Anandan,Vary consumers size (ECB-4)
1491,Glenn Renfro,Sabby Anandan,"Pre-requisite for Rabbit MQ Benchmarks:

* Infrastructure setup
* Configuration changes
* Tool-chain setup

* IPerf",XD-2264,Sabby Anandan,Infrastructure for RabbitMQ Cluster (ECB)
1492,,Sabby Anandan,,XD-2263,Sabby Anandan,Measure baseline performance of RabbitMQ in EC2
1493,Thomas Risberg,Sabby Anandan,Document --idleTimeout setting to not exceed the HDFS timeout value.,XD-2262,Sabby Anandan,Document 'idleTimeout' setting 
1494,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the option to configure permissions so that I'll have the flexibility to bind permissions (REST endpoint) to a specific role. 

Default Roles:
* Admin (CRUD)
* Viewer (R)",XD-2261,Sabby Anandan,Document user-defined permission to role mapping
1495,,Sabby Anandan,"As a user, I'd like to have the option to configure _Admin_ and _Viewer_ roles so that I'll have the flexibility to decide role configurations.",XD-2260,Sabby Anandan,Document Admin and Viewer roles
1496,Chris Schaefer,Sabby Anandan,"Pre-requisite for Rabbit MQ Benchmarks:

* Infrastructure setup
* Configuration changes
* Tool-chain setup",XD-2259,Sabby Anandan,Infrastructure for RabbitMQ Cluster (DB)
1497,Marius Bogoevici,Sabby Anandan,Please refer to the GH Issue reported here: https://github.com/spring-projects/spring-xd/issues/1218,XD-2258,Sabby Anandan,Research adding support for 'spring-cloud-config' to configure Modules
1498,Chris Schaefer,Sabby Anandan,"Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers), message size 100 bytes, Prefetch 100.   Send 1M messages

Vary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of producers:*
* 2
* 4
* 6
* 10
* 50

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2257,Sabby Anandan,Vary producers size (DB-5)
1499,Chris Schaefer,Sabby Anandan,"Using a single producer, message size of 1000 bytes, Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Number of consumers:*
* 1
* 2
* 4
* 6
* 10
* 50

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2256,Sabby Anandan,Vary consumers size (DB-4)
1500,Chris Schaefer,Sabby Anandan,"Use a single producer, single consumer, message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.

*Prefetch Sizes:*
* 1
* 10
* 50
* 100
* 10000

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2255,Sabby Anandan,Vary prefetch size (DB-3)
1501,Chris Schaefer,Sabby Anandan,"Use a single producer, single consumer, prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.

Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.

*Message Sizes:*
100 bytes
1000
10,000
100,000 

During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",XD-2254,Sabby Anandan,Vary message size (DB-2)
1502,Sabby Anandan,Sabby Anandan,"Using the [iperf tool|https://iperf.fr/], find out the transfer rate in MB/sec between three machines in a four machine configuration.",XD-2253,Sabby Anandan,Baseline tcp measurements (DB-1)
1503,Chris Schaefer,Sabby Anandan,,XD-2252,Sabby Anandan,Measure baseline performance of RabbitMQ using PerfTest (In-house)
1504,Marius Bogoevici,Marius Bogoevici,"The ChannelPipelineFactory used by the HTTP source should cache expensive objects used by the ChannelPipeline between requests, because creating them every time is inefficient (and in the case of HTTPS it can become even more expensive). ",XD-2251,Marius Bogoevici,The HTTP Source creates the ChannelPipeline inefficiently
1505,,Thomas Risberg,"The jdbc sink is currently limited to handling the entire payload as a string and converting a single json object to row data. We should improve that and support the following input types:

 - LinkedCaseInsensitiveMap (single row)
 - List<LinkedCaseInsensitiveMap> (multiple rows as a batch insert)
 - JSON string {""ID"":74488,""NAME"":""Foo"",""YEAR"":""2014""} (single row)
 - JSON array [{""ID"":74488,""NAME"":""Foo"",""YEAR"":""2014""},{""ID"":74489,""NAME"":""Bar"",""YEAR"":""2014""}] (multiple rows as a batch insert)
 - none of the above use payload.toString()

The above matches what the new jdbc source puts out (depending on outputType used)",XD-2250,Thomas Risberg,Improve type handling for jdbc sink
1506,David Turanski,David Turanski,"Provide a BPP to do this in the StreamPlugin.  (Possibly JobPlugin as well). Remove auto-startup=""false"" in existing module configs.",XD-2249,David Turanski,Automatically disable autostartup in module SmartLifeCycle components
1507,Glenn Renfro,Glenn Renfro,"If you create more than 4 gemfire modules, the container will throw a OOME Permgen on Java 7.  

The solution is to put a technote into the wiki for the gemfire modules stating that for Java 7 they will need to add the following to environment.  
export JAVA_OPTS=""-XX:PermSize=256m""",XD-2248,Glenn Renfro,Gemfire Source and Sink deployments cause OOME PermGen
1508,Patrick Peralta,Patrick Peralta,"When answering support questions, the first step is to determine what version of the software the customer is using. This question can be easily answered if we log the version as one of the fields in the log file. For example:

{noformat}
10:44:21,212 1.0.2.BUILD-SNAPSHOT  INFO DeploymentSupervisorCacheListener-0 server.ContainerListener - Container arrived: Container{name='431baa56-b23b-48fc-b37d-18b52231e799', attributes={ip=192.168.25.177, host=Patrick-Peralta-MacBook-Pro.local, groups=, pid=38004, id=431baa56-b23b-48fc-b37d-18b52231e799}}
{noformat}

This way when we receive log snippets (initial support inquires rarely include the entire log file) we can immediately determine if the issue has already been fixed in a later release.
",XD-2247,Patrick Peralta,Log version number in log files
1509,Gunnar Hillert,Sabby Anandan,"As a user, I'd like to have the flexibility to specify config options for IP and Hostname so that I can list the correct configuration for XD Admin and XD Container servers in the Admin-UI and Shell. ",XD-2246,Sabby Anandan,Document default behavior if config option is not present
1510,David Turanski,Glenn Renfro,"* Steps to reproduce.
** Start admin & container.
** Follow the instructions from https://github.com/spring-projects/spring-xd/wiki/Sources#gemfire-source
*** When you post the message is when the stacktrace shows up in the container.

Copying the gemfire-7.0.2.jar to the lib directory will resolve the error.  
The stacktrace is attached.
",XD-2245,Glenn Renfro,Gemfire Source throws classnotfound 
1511,,Venkatesh Sivasubramanian,"Look at the below Stream definition. This gets to ""deployed"" state even without the corresponding job. And then from there the same Job or any other Job can't be deployed and it goes to a hung state. 

Here is an example of the Stream definition:

stream create --name jobName --definition ""file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv > queue:job:filetsjob-sample002"" --deploy
",XD-2244,Venkatesh Sivasubramanian,Streams sending to Job Queue issue
1512,,Venkatesh Sivasubramanian,"We are using the SpringXD REST endpoints for creating and managing streams. With Version 1.0.0 and 1.0.1, the Stream Definition API Call Times-out at times. Here is the log from the admin node.  Look at the 30000 ms in the logs. I have also left a few other lines around for context. 

API Call: http://<hostname>:9393/jobs/definitions

We need to come up with a fix for this. 

14 Oct 2014 17:40:28,062   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/sample, type: CHILD_ADDED
14 Oct 2014 17:40:28,198   INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='sample'}
14 Oct 2014 17:40:38,847   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-sample002': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-sample002', type=job, label='filepollsomething'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms}
14 Oct 2014 17:41:28,225   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'sample': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='sample', type=sink, label='something'}' to container 'f877a8e8-08b3-44f9-8f73-bf163acb0cef' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='sample', type=source, label='http'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms}
14 Oct 2014 17:41:28,227   INFO Deployer server.StreamDeploymentListener - Stream Stream{name='sample'} deployment attempt complete
",XD-2243,Venkatesh Sivasubramanian,Stream Definition Calls Times-out often
1513,,Leo Chu,"In SpringXD ver 1.0.1, runtime/containers fetches additional runtime modules information for each container.  When a user queries the runtime containers while a stream is being deploy it throws a NullPointerException.

See below:

15:56:02,829  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: path=/deployments/streams/testCreateHTTPStream_postData1413327352991, type=CHILD_ADDED
15:56:02,935  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='testCreateHTTPStream_postData1413327352991'}
15:56:05,069 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.NullPointerException
	at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)
	at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)
	at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)
	at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)
	at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:724)
",XD-2242,Leo Chu,NullPointerException while fetching runtime containers
1514,,Venkatesh Sivasubramanian,"Sorry to set it ""Blocker""; but the problem makes SpringXD unusable. We are getting this weird, NoNode exception on the status ZNode. Example and Log given below. Once this happens, both streams and jobs cannot be deployed. For whatever reason the ""status"" znode goes missing.  

The only way for us to get the cluster back to working state, is to clear the zk znode /xd tree and restart spring-xd. At which point, we have to recreate all our streams and jobs back again.. 

/xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status

NoNode Exception:

13 Oct 2014 14:16:16,044   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testDestroyStream1413234903170, type: CHILD_REMOVED
13 Oct 2014 14:16:16,705   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170, type: CHILD_ADDED
13 Oct 2014 14:16:22,818   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170, type: CHILD_REMOVED
13 Oct 2014 14:16:23,585   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170, type: CHILD_ADDED
13 Oct 2014 14:16:37,694   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_ADDED
13 Oct 2014 14:16:49,950   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170, type: CHILD_REMOVED
13 Oct 2014 14:16:54,490   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'testCreateStream_SrcHttp_SinkFile1413234903170': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170', type=sink, label='file'}' to container 'd03bccd6-524b-4ff8-84d2-88f3f6daac42' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170', type=source, label='http'}' to container '52abf1c8-ba45-4994-8324-6079b03c670c' timed out after 30000 ms}
13 Oct 2014 14:16:54,493  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event
org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status
        at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)
        at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)
        at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:185)
        at org.springframework.xd.dirt.server.StreamDeploymentListener.onChildAdded(StreamDeploymentListener.java:100)
        at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)
        at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
        at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
        at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
        at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)
        at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
        at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
        at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:179)
        ... 7 more
13 Oct 2014 14:16:56,251   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_REMOVED
13 Oct 2014 14:17:08,179   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-newjob001': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-newjob001', type=job, label='filepolltimeseries'}' to container '244d5076-f69d-42a4-8110-3b046cea2667' timed out after 30000 ms}
13 Oct 2014 14:17:08,181  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event
org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status
        at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)
        at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)
        at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:175)
        at org.springframework.xd.dirt.server.JobDeploymentListener.onChildAdded(JobDeploymentListener.java:99)
        at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)
        at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
        at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
        at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
        at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)
        at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
        at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
        at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:165)
        ... 7 more
13 Oct 2014 14:17:10,553   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_ADDED

",XD-2241,Venkatesh Sivasubramanian,NoNode Exception in SpringXD Admin
1515,,Ilayaperumal Gopinathan,"Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/1188#discussion_r18788216",XD-2240,Ilayaperumal Gopinathan,Redis sink: better handling of module options/profile activation
1516,Gunnar Hillert,Sabby Anandan,"The XD Container IP address displayed on both 'singlenode' and Distributed modes are incorrect both on _Shell_ as well as _Admin-UI_. 

*Example:*
Noticed IP address as 10.10.10.*

Following function in [RuntimeUtils|http://docs.spring.io/autorepo/docs/spring-xd/1.0.1.RELEASE/api/org/springframework/xd/dirt/util/RuntimeUtils.html] could be flawed:
{code}
public static String getIpAddress() {
	try {
		for(Enumeration<NetworkInterface> enumNic = NetworkInterface.getNetworkInterfaces();
				enumNic.hasMoreElements();) {
			NetworkInterface ifc = enumNic.nextElement();
			if (ifc.isUp()) {
				for (Enumeration<InetAddress> enumAddr = ifc.getInetAddresses();
						enumAddr.hasMoreElements(); ) {
					InetAddress address = enumAddr.nextElement();
					if (address instanceof Inet4Address && !address.isLoopbackAddress()) {
						return address.getHostAddress();
					}
				}
			}
		}
	}
	catch (IOException e) {
		// ignore
	}

	return ""unknown"";
}
{code}
",XD-2239,Sabby Anandan,Fix incorrect IP Address associated with containers
1517,Patrick Peralta,Patrick Peralta,"When a container joins the XD cluster (via ZooKeeper) it triggers stream/job module deployments for modules that need to be deployed. If multiple containers are being started at around the same time, this can result in the first few containers taking all of the deployments while leaving the rest without any deployments.

To solve this, we will introduce a ""quiet period"" where no deployments will be triggered within _n_ seconds of a container joining, where _n_ will have a default value (perhaps 5 to 10 seconds). This value will be configurable.",XD-2238,Patrick Peralta,Improve module deployment distribution
1518,David Turanski,David Turanski,,XD-2237,David Turanski,Provide Python module to handle I/O for implementing a Python shell processor 
1519,,Peter Rietzler,"Cannot use a JSON null value as job paramter value, e.g. 

{code}
job launch --params {""name"":null}
{code}

The problem seems to be the usage of a HashTable, which does not allow null values.

{code}
Caused by: java.lang.NullPointerException
	at java.util.Hashtable.put(Hashtable.java:459)
	at java.util.Hashtable.putAll(Hashtable.java:523)
	at org.springframework.xd.dirt.plugins.job.ExpandedJobParametersConverter.getJobParametersForMap(ExpandedJobParametersConverter.java:191)
	at org.springframework.xd.dirt.plugins.job.ExpandedJobParametersConverter.getJobParametersForJsonString(ExpandedJobParametersConverter.java:177)
	at org.springframework.xd.dirt.plugins.job.JobLaunchRequestTransformer.toJobLaunchRequest(JobLaunchRequestTransformer.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	... 62 more 
{code}",XD-2236,Peter Rietzler,Cannot send null values as job parameters
1520,Marius Bogoevici,Marius Bogoevici,"Besides the Basic authentication realm being always {{null}}, {{security.basic.realm}} is always ignored.",XD-2235,Marius Bogoevici,Basic authentication realm is always 'null'
1521,,Peter Bulman,"the resource manager address overwrite is setting the port to 8032; the value cannot be set in servers.yml.  this occurs when pushing the config to hdfs and also when attempting to start the admin server on yarn.


 [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]

[root spring-xd-1.0.1.RELEASE-yarn]# ./bin/xd-yarn start admin

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.1.7.RELEASE)

2014-10-13 16:50:28,710 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2014-10-13 16:50:28,724 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore, a default SyncTaskExecutor will be created.
2014-10-13 16:50:30,311 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn
2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration
2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration'
2014-10-13 16:50:30,383 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null
2014-10-13 16:50:30,658 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[hdfs://host:8020] with fsUri=[hdfs://host:8020]
2014-10-13 16:50:30,659 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]




",XD-2234,Peter Bulman,Incorrect port in resource manager address overwrite
1522,,Thomas Darimont,"The current representation of REST resources of time-series data (e.g. aggregate counter) can lead to problems in consuming applications.

Despite the time series data provided by the ""counts"" data structure is logically ordered by key (timestamps) it doesn't guarantee an ordering, since many consuming applications interpret JSON data as an unordered map like data structure.

Because of this consuming applications have to apply special ordering / transformation logic to get the data in an chronologically ordered fashion. It would be helpful if one could configure the rendering of the time series data, e.g. as a list of json object like:
{code:json}
{
 ""ts"":""Sun Oct 12 23:10:23 CEST 2014""
 ,""value"": 42
} 
{code}
Where {{ts}} denotes the timestamp and {{value}} denotes the value. It would also be helpful if one could adjust the date format either with a pattern or a well known date format like, c.f.  {{ISO 8601}}.

I attached a python example for this that demonstrates the problem.

Steps to reproduce:
Create stream
{code}
xd:>stream create test --definition ""http | filter --expression=payload.contains('pivotal') | log""
{code}

Create tap on stream with aggregate-counter
{code}
xd:>stream create test_tap --definition ""tap:stream:test.filter > aggregate-counter""
{code}

Post some http data
{code}
xd:>http post --data ""Hello pivotal data labs""
#...some more data...
{code}

Display aggregate counter
{code}
xd:>aggregate-counter display test_tap --resolution minute
  AggregateCounter=test_tap
  -----------------------------  -  -----
  TIME                           -  COUNT
  Sun Oct 12 23:10:23 CEST 2014  |  0
  Sun Oct 12 23:11:23 CEST 2014  |  0
  Sun Oct 12 23:12:23 CEST 2014  |  0
  Sun Oct 12 23:13:23 CEST 2014  |  0
  ...
  Mon Oct 13 00:02:23 CEST 2014  |  0
  Mon Oct 13 00:03:23 CEST 2014  |  0
  Mon Oct 13 00:04:23 CEST 2014  |  0
  Mon Oct 13 00:05:23 CEST 2014  |  0
  Mon Oct 13 00:06:23 CEST 2014  |  0
  Mon Oct 13 00:07:23 CEST 2014  |  0
  Mon Oct 13 00:08:23 CEST 2014  |  3
  Mon Oct 13 00:09:23 CEST 2014  |  1
{code}

Install python Requests library (REST support)
{code}
pip install Requests
{code}

Start a python console (or IPythonNotebook) and run the following program:
{code:python}
import requests
import json

res = requests.get(""http://localhost:9393/metrics/aggregate-counters/test_tap?resolution=minute"")
status_object = json.loads(res.content)
print(json.dumps(status_object, indent=4))
{code}

The above program should result in a similar output, but as one can see, due to pythons interpretation of the JSON object as a dict, the order of the keys in the output got mixed up. 

Instead of showing the counts ....3 and then 1 ... as in the example above. This is just one example of how the current representation of the rest resource could lead to problems in consuming applications.  
{code:json}
{
    ""counts"": {
        ""2014-10-12T21:26:28.553Z"": 0,
        ""2014-10-12T22:15:28.553Z"": 0,
        ""2014-10-12T22:22:28.553Z"": 0,
        ""2014-10-12T21:49:28.553Z"": 0,
        ""2014-10-12T21:35:28.553Z"": 0,
        ""2014-10-12T21:47:28.553Z"": 0,
        ""2014-10-12T22:18:28.553Z"": 0,
        ""2014-10-12T22:12:28.553Z"": 0,
        ""2014-10-12T22:16:28.553Z"": 0,
        ""2014-10-12T21:57:28.553Z"": 0,
        ""2014-10-12T21:28:28.553Z"": 0,
        ""2014-10-12T22:08:28.553Z"": 3,
        ""2014-10-12T21:40:28.553Z"": 0,
        ""2014-10-12T22:06:28.553Z"": 0,
        ""2014-10-12T21:27:28.553Z"": 0,
        ""2014-10-12T21:52:28.553Z"": 0,
        ""2014-10-12T22:11:28.553Z"": 0,
        ""2014-10-12T22:05:28.553Z"": 0,
        ""2014-10-12T21:29:28.553Z"": 0,
        ""2014-10-12T21:24:28.553Z"": 0,
        ""2014-10-12T21:56:28.553Z"": 0,
        ""2014-10-12T21:43:28.553Z"": 0,
        ""2014-10-12T22:00:28.553Z"": 0,
        ""2014-10-12T22:10:28.553Z"": 0,
        ""2014-10-12T21:58:28.553Z"": 0,
        ""2014-10-12T22:21:28.553Z"": 0,
        ""2014-10-12T21:32:28.553Z"": 0,
        ""2014-10-12T21:46:28.553Z"": 0,
        ""2014-10-12T22:04:28.553Z"": 0,
        ""2014-10-12T22:02:28.553Z"": 0,
        ""2014-10-12T21:51:28.553Z"": 0,
        ""2014-10-12T21:38:28.553Z"": 0,
        ""2014-10-12T21:31:28.553Z"": 0,
        ""2014-10-12T22:20:28.553Z"": 0,
        ""2014-10-12T21:54:28.553Z"": 0,
        ""2014-10-12T22:07:28.553Z"": 0,
        ""2014-10-12T22:03:28.553Z"": 0,
        ""2014-10-12T21:34:28.553Z"": 0,
        ""2014-10-12T22:09:28.553Z"": 1,
        ""2014-10-12T21:44:28.553Z"": 0,
        ""2014-10-12T22:17:28.553Z"": 0,
        ""2014-10-12T21:53:28.553Z"": 0,
        ""2014-10-12T22:19:28.553Z"": 0,
        ""2014-10-12T21:30:28.553Z"": 0,
        ""2014-10-12T22:23:28.553Z"": 0,
        ""2014-10-12T21:36:28.553Z"": 0,
        ""2014-10-12T21:41:28.553Z"": 0,
        ""2014-10-12T22:13:28.553Z"": 0,
        ""2014-10-12T21:59:28.553Z"": 0,
        ""2014-10-12T22:01:28.553Z"": 0,
        ""2014-10-12T21:33:28.553Z"": 0,
        ""2014-10-12T21:45:28.553Z"": 0,
        ""2014-10-12T21:39:28.553Z"": 0,
        ""2014-10-12T21:50:28.553Z"": 0,
        ""2014-10-12T21:37:28.553Z"": 0,
        ""2014-10-12T22:14:28.553Z"": 0,
        ""2014-10-12T21:25:28.553Z"": 0,
        ""2014-10-12T21:55:28.553Z"": 0,
        ""2014-10-12T21:42:28.553Z"": 0,
        ""2014-10-12T21:48:28.553Z"": 0
    },
    ""name"": ""test_tap"",
    ""links"": [
        {
            ""href"": ""http://localhost:9393/metrics/aggregate-counters/test_tap"",
            ""rel"": ""self""
        }
    ]
}
{code}",XD-2233,Thomas Darimont,REST representation of an aggregate-counter can lead to mixed up output
1523,,Thomas Darimont,"Often it is useful to have access to the median value for fields of a data stream since they are more robust with respect to outliers.

The median is defined as the value of a dataset such that, when sorted, 50% of the data is smaller than the value and 50% of the data is larger then the value. Ordinarily this is difficult to calculate on a stream because it requires the collection and sorting of all data.

The median of a data stream can be approximated with a technique called stochastic averaging. To approximate the median value of a data stream one could use the following approach:
Given the current estimate of the median {{M}}. If the next observed value in the stream is larger than {{M}}, increase the current estimate by {{r}} (= the learning rate). If it is smaller, decrease the estimate by {{r}}. When {{M}} is close to the median, it increases as often as it decreases, and therefore it stabilizes.


The following example shows a primitive implementation of the above mentioned algorithm in groovy (to be placed under ${XD_HOME}/modules/processor/scripts).
{code:groovy}
import org.springframework.xd.tuple.TupleBuilder;
import org.springframework.xd.tuple.Tuple;

/**
 * Stochastic averaging to compute the median of a data stream.
 * To approximate this value using stochastic optimization, the value
 * of interest is the current estimate of the median M. If the next observed 
 * value of the stream is larger than M, increase by r. If it is smaller decrease the
 * estimate by r. When M is close to the median, it increases as often as it decreases,
 * and therefore stablilizes.
 * r denotes the learningRate.
 */
enum MedianEstimator{
  
  INSTANCE

  //TODO Add support for estimating multiple medians
  /*
   * The current median value.
   */
  double current = Double.POSITIVE_INFINITY
  
  public double update(double value, double learningRate){
    
    //Initialize current with given value
    if(current == Double.POSITIVE_INFINITY){
       current = value
    }
    
    if(current == value){
      return current
    }

    //Move current value towards the median
    current = current + (current < value ? learningRate : -learningRate)

    return current
  }
}

//TODO Make learning rate configurable
def learningRate = 0.7
//TODO Add support for dynamic field selection.
double median = MedianEstimator.INSTANCE.update(payload.getDouble('value'), learningRate)

def fieldNames = new ArrayList<String>(payload.getFieldNames())
def fieldValues = new ArrayList<Object>(payload.getValues())

//TODO Add make median output field configurable
fieldNames.add(""value_median"")
fieldValues.add(median)

//Return the original tuple values extended with the computed median.
TupleBuilder.tuple().ofNamesAndValues(fieldNames, fieldValues)
{code}

Stream definition:
{code}
xd:>stream create median --definition ""http --outputType=application/x-xd-tuple | script --location=median-est.groovy | log"" --deploy
Created and deployed new stream 'median'
{code}

Post some JSON data...
{code}
xd:>http post --contentType application/json --data '{""value"":2}'
> POST (application/json;charset=UTF-8) http://localhost:9000 {""value"":2}
> 200 OK
{code}

Output:
{code}
20:44:37,829  INFO pool-35-thread-4 sink.median - {""id"":""cd9719b3-eeff-59c9-fdf1-fdb628c7fbb8"",""timestamp"":1413139477829,""value"":""2"",""value_median"":2.0}
{code}

... After ~15 the median value should stabilize.

This approach was taken from the book ""Real-time Analytics - Techniques to Analyze and Visualize Streaming Data"" P. 296 / Byron Ellis / Wiley

Open points:
- Support for resetting the median value
- Better state management (Redis?)
- Support median estimation for multiple fields
- Make learning rate configurable from outside
- Maybe add this as aggregate-counter aggregation strategy?",XD-2232,Thomas Darimont,Add support for estimating the median value of a data stream.
1524,Michael Minella,Sabby Anandan,"As a user, I'd like to have the flexibility to configure DB creds so that I can use a DB of choice for batch job repository (metadata persistence). 

The scope of this task is to have the configuration specifics documented in the wiki.",XD-2231,Sabby Anandan,Document job repo schema overrides
1525,David Turanski,Sabby Anandan,"As a user, I'd like to leverage _propertieis-location_ parameter while using *Filter* or *Transform* modules so that I can load the user-defined properties included in the external properties file. 

Attempting to include the _propertieis-location_ attribute errors out - refer to the attachment.

It could also be beneficial to load user-defined properties through stream definition similar to deployment properties.

Example:
--script=myscript.groovy --variables=foo=bar,goo=gaz
",XD-2230,Sabby Anandan,Fix the configuration problem with Filter and Transform modules
1526,,Glenn Renfro,"In this scenario I copied 2 files (fakeFile.csv, anotherFile.csv) into the bar directory.  
* Created thew following job:
job create myjob2 --definition ""filejdbc --resources=file:bar/*.csv --names=name --tableName=people2 --initializeDatabase=true --commitInterval=1 --deleteFiles=true"" --deploy
* Then launched the job:
job launch myjob2

* The result was that the first file was processed, but then the module deleted all *.csv files in the directory before processing the 2nd file.  
* The net result was that the job failed and the 2nd file was not processed.
",XD-2229,Glenn Renfro,When using --deletefile option for filejdbc all files are deleted before processing complete
1527,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to type the _username_ and _password_ to gain access to Admin server so that I don't have to add it in some file; hence I don't have to worry about having the password getting logged somewhere.",XD-2228,Sabby Anandan,Remove logging of password in Shell
1528,Glenn Renfro,Glenn Renfro,"XD-2180 introduced a default commit level for jobs to be 1000, vs the original 100.  Now tests sporadically fail.  Need to set the --commitInterval for the tests to a small value.",XD-2227,Glenn Renfro,Need to set small commit level for Acceptance tests.  
1529,Mark Fisher,Sabby Anandan,"As a user, I'd like to have the flexibility to change the namespace so that I can isolate ZK _metadata_ based on each _tenant_ profile. ",XD-2226,Sabby Anandan,Add support for configurable ZK namespace
1530,Gunnar Hillert,Gunnar Hillert,"Implement pagination for:

http://localhost:9393/jobs/executions",XD-2225,Gunnar Hillert,REST: Make the Job Execution REST endpoint pagination-aware
1531,Ilayaperumal Gopinathan,Gunnar Hillert,"Add pagination for:

http://localhost:9393/jobs/configurations

Related to XD-1864",XD-2224,Gunnar Hillert,REST: Make the Configurations REST endpoint pagination-aware
1532,Gunnar Hillert,Gunnar Hillert,"With the implementation of XD-1864, we need to make sure that the (paginated) data returned from the REST endpoints has proper default ordering.

Up to now we have done client-side ordering in the Admin UI, but with server-side pagination, the server-side should support proper pagination as well.

Eventually, we may even decide to provide more flexible ordering options (ASC vs DESC, sort on different properties etc.), which may be a separate Jira.",XD-2223,Gunnar Hillert,Provide proper ordering for all REST endpoints
1533,David Turanski,David Turanski,"see ModuleDeployer.setApplicationContext(). It appears the shared server context (child of global) is incorrectly set as the module context's parent. However, the first attempt caused some test failures, so this needs further investigation. Things still function correctly, but is not according to design. ",XD-2222,David Turanski,global context reference is incorrect in ModuleDeployer
1534,,Sabby Anandan,"As a user, I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via Admin UI.

*Examples:*
* Who can create streams?
* Who can destroy the streams?
* Who can view the streams? ??(defaults to all)??",XD-2220,Sabby Anandan,Add support to configure security definitions via Admin UI (ACL)
1535,,Sabby Anandan,"As a user, I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via DSL Shell.

*Examples:*
* Who can create streams?
* Who can destroy the streams?
* Who can view the streams? ??(defaults to all)??",XD-2219,Sabby Anandan,Add support to configure security definitions via Shell (ACL)
1536,,Sabby Anandan,"As a user, I'd like to define security definitions so that I can configure entity (REST API) specific group/role access policies.",XD-2218,Sabby Anandan,Add support to define granular security definitions by entity (ACL)
1537,,Mark Pollack,The change in XD 1.0.1 to use Spring Boot 1.1.7 meant that we can't pickup the boot dependency by importing the platform-bom.  Andy W's suggestion is to change the generated pom to refer to the platform-bom as a parent (not import) and then declare the explicit dependency on Boot 1.1.7,XD-2217,Mark Pollack,Generated pom does not include spring boot 1.1. dependency
1538,Gary Russell,Sabby Anandan,"As a user, I'd like to have Spring 'Core' upgraded to 4.1.1 (_milestone_ ) so that I can benefit from performance improvements associated with 'compiled' SpEL and other enhancements. 
",XD-2216,Sabby Anandan,"Upgrade to Spring 4.1.2, SI 4.1.0, SA 1.4.0"
1539,Patrick Peralta,Patrick Peralta,"Running the distributed tests ({{-Drun_distributed_tests=true}}) against d109a3a and got the following:

{noformat}
   java.lang.NullPointerException
   	at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)
   	at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)
   	at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)
   	at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)
   	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
   	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
   	at java.lang.reflect.Method.invoke(Method.java:483)
   	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
   	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
   	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
   	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
   	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
   	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
   	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
   	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
   	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
   	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)
   	at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)
   	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
   	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
   	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:
{noformat}",XD-2215,Patrick Peralta,NPE in ContainerRedeploymentTests
1540,Marius Bogoevici,Marius Bogoevici,"1. The sample {{httpSSLproperties}} file that is included in the distribution contains the line:

{quote}
keystore.passPhrase=secret
{quote}

The correct key value is {{keyStore.passPhrase}}. This issue causes HTTPS sources to deploy, but not bind to the port.

2. The password is always defaulting to ""secret""",XD-2214,Marius Bogoevici,HTTPS Source Configuration issues
1541,,Sabby Anandan,"To enrich acceptance test coverage, I'd like to have stress test scenario that includes ingesting data from _HTTP_ and then writing it to _Log_ sink.",XD-2213,Sabby Anandan,Add stress test
1542,,Sabby Anandan,"To enrich acceptance tests, I'd like to have test coverage to evaluate _FieldValueCounts_ and _AggregateCounts_ for a given scenario.",XD-2212,Sabby Anandan,Add acceptance tests for FieldValueCounts and AggregateCounts
1543,Glenn Renfro,Sabby Anandan,"To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",XD-2211,Sabby Anandan,Exclude DB initialization for JDBC sink test
1544,,Sabby Anandan,"To enrich acceptance test, I'd like to add coverage to JDBC sink by including *-- driverclass* and *-- url* options.",XD-2210,Sabby Anandan,Enhance JDBC sink test to include more options
1545,,Sabby Anandan,"To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. 

An example would be to ingest data from HTTP source and write it to Gemfire server.",XD-2209,Sabby Anandan,Add acceptance test to include Gemfire use case
1546,,Sabby Anandan,"To enrich the acceptance test, I'd like to evaluate JSON object to extract ""Good"" and ""Bad"" instead of just relying on a basic filter test to assert the payload content. ",XD-2208,Sabby Anandan,Add acceptance test to extract and assert payload from JSON object
1547,,Sabby Anandan,"As a user, I would like to have an option to write data into _Hive_ sink so that I can query and manage large datasets in distributed storage.",XD-2207,Sabby Anandan,Add Hive sink
1548,,Sabby Anandan,"As a user, I'd like to have a _R_ processor, so I can efficiently perform data computations and statistical analysis in the context of streaming pipeline. 

Investigate the right approach that fits Spring XD model.

*R Java Libraries*
[rJava|http://rforge.net/rJava/]
[Renjin|http://www.renjin.org/]",XD-2206,Sabby Anandan,Add R processor
1549,David Turanski,Sabby Anandan,"As a user, I'd like to have a _Python_ processor so that I can efficiently perform data computations and statistical analysis. 

Investigate the right approach (native or via stdin/stdout) that fits Spring XD model.

[Integrate Java and Python|https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#Java]",XD-2205,Sabby Anandan,Add Python processor
1550,,Sabby Anandan,,XD-2204,Sabby Anandan,Add new processor modules
1551,Gunnar Hillert,Thomas Risberg,"The scope is to make sure that a new PDF is generated (both for 1.0.2 and 1.1 M1 releases) and/or revision references are correctly rendered.

",XD-2203,Thomas Risberg,Make sure Spring XD's PDF reference doc has right release revision references
1552,Mark Pollack,Mark Pollack,,XD-2202,Mark Pollack,Release 1.0.1
1553,Gary Russell,Derek OKeeffe,"Exception in a tap will stop the tapped stream from sinking data.

h2. Background
Running xd-singlenode.
We experienced this when streaming data from a rabbit queue to hdfs. The stream was tapped and we had a groovy processor on the tap stream. Any exceptions in the processor stopped the main stream from writing data to the hdfs sink.

h2. Steps to reproduce.
1: Create a groovy script that throws an exception in  modules/processor/scripts/exceptionthrower.groovy. Code below
{code}
/**
 * Custom processor to be wired into a tap to throw an exception.
 */
 throw new RuntimeException(""Error from processor"")
{code}
2: Create a sample main stream
{code}
xd:>stream create --name ticktock --definition ""time | log"" --deploy
{code}
3: Tail the log to confirm the data is going to the sink. We see  'sink.ticktock' appearing in the log as expected.
4: Add a tap to the stream that will throw an exception.
{code}
xd:>stream create --name exTap --definition ""tap:stream:ticktock > script --location=exceptionthrower.groovy | log"" --deploy
{code}
5: Tail the log and we see that there are no more 'sink.ticktock' strings being logged. Looks like the main stream is no longer sending messages to the sink.
",XD-2201,Derek OKeeffe,Exception in a tap will stop the tapped stream from sinking data
1554,Eric Bottard,Eric Bottard,Build on top of https://github.com/spring-projects/spring-integration-extensions/pull/116/files wrt the partition header to use (see https://github.com/spring-projects/spring-xd/pull/1200#issuecomment-57622400),XD-2200,Eric Bottard,Add option to set PARTITION_HEADER
1555,Eric Bottard,David Turanski,"MR is responsible for looking up existing module definitions by name and type.  ModuleDefinition should contain name, type, and resource; where resource is a springframework.core.io.Resource containing the root path of the module definition. This could be file, classpath, http, hdfs or something else but the contents under this path will not be inspected or processed by MR. The exception is for composite modules which should contain a list of corresponding Resources.

Simplify ModuleDefinition - remove classpath. Provide support for CompositeModuleDefinition - requires a list of resources (possibly a subclass)

Also retire RedisModuleRegistry
",XD-2199,David Turanski,Simplify ModuleRegistry
1556,Eric Bottard,David Turanski,Currently there is no ModuleRegistry contract for composite modules. The composed module definition is maintained in ZooKeeperModuleDefinitionRepository which delegates to the ModuleRegistry to define and validate component modules. The repository should be converted to a ModuleRegistry.,XD-2198,David Turanski,Create CompositeModuleRegistry
1557,David Turanski,David Turanski,"ModuleFactory is responsible for determining how the Module application context is created from available sources at the resource location exposed via the ModuleDefinition. The factory creates the application context and creates a SimpleModule or CompositeModule as appropropriate. For example, if an XML file is present, it is assumed to be the bean definition file used to create a CXMLAC. If no XML file is present, inspect the properties file for the existence of well-known properties such as base-package-name for component scanning for an @Configuration, or a module-class-name for an Annotated POJO based module (see XD-2100).  The MF is also responsible for creating composite modules.   Also includes Module refactoring, add getApplicationContext() and probably setApplicationContext().  Also refactor CompositeModule code to use boot SpringApplicationBuilder  
",XD-2197,David Turanski,Create ModuleFactory
1558,David Turanski,David Turanski,Decouple from DeploymentListener. Make DL a public class to handle deployment related events.  Remove createSimpleModule() and createComposedModule() from DL.  This will be delegated to ModuleDeployer which will eventually be further refactored to use the proposed ModuleFactory.,XD-2196,David Turanski,Refactor ContainerRegistrar
1559,,Eric Bottard,"Now that we have --incrementExpression, we often want to increment by some domain specific value that may not be integral (e.g. Watts in smartgrid demo)",XD-2195,Eric Bottard,Have counters use Double arithmetic instead of Long
1560,,Glenn Renfro,"When running the gradlew build the JsonStringToObjectTransformerTests unit test failed.  The cause is enumerated below:
Caused by: com.gemstone.gemfire.internal.tcp.ConnectionException: While creating ServerSocket and Stub on port 0 with address glenns-mbp/192.168.1.254

If I added 127.0.0.1 glenns-mbp to my /etc/hosts the tests succeeded.

",XD-2194,Glenn Renfro,JsonStringToObjectTransformerTests fail on mac if local machine name is not in /etc/hosts
1561,,Eric Bottard,,XD-2193,Eric Bottard,Add authentication support to the mongo sink
1562,Thomas Risberg,Mark Pollack,See https://build.spring.io/browse/XD-SCRIPTS-723,XD-2192,Mark Pollack,Fix failing script integration test
1563,,Eric Bottard,"Amongst (maybe) other things, the doc says we don't ship ZK:

http://docs.spring.io/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#_setting_up_zookeeper",XD-2191,Eric Bottard,Fix doc related to ZK install
1564,Ilayaperumal Gopinathan,Kashyap Parikh,"Targeting xd-shell from 1.0.1 to 1.0.0 GA admin server fails

server-unknown:>admin config info
  -------------  -------------------------------------------------------------
  Result         Unable to contact XD Admin Server at 'http://localhost:9393'.
  Target         http://localhost:9393
  Timezone used  Pacific Standard Time (UTC -8:00)
  -------------  -------------------------------------------------------------
-------------------------------------------------------------------------------
An exception ocurred during targeting:
java.lang.NullPointerException
    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:110)
    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:137)
    at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:106)
    at org.springframework.xd.shell.command.ConfigCommands.afterPropertiesSet(ConfigCommands.java:191)
",XD-2190,Kashyap Parikh,xd-shell from 1.0.1 doesn't work with 1.0.0 GA admin
1565,,Ilayaperumal Gopinathan,"If the security is enabled for the container, then admin server won't be able to fetch the message rates for the deployed modules in that container.

The REST endpoint 'cluster/containers' needs to be fixed.",XD-2189,Ilayaperumal Gopinathan,Fix 'cluster/containers' REST endpoint if security is enabled
1566,Glenn Renfro,Glenn Renfro,"Need to add a retry to the mkdir command, in the case that it fails.",XD-2188,Glenn Renfro,FilePollHdfs sporadically fails 
1567,Glenn Renfro,Glenn Renfro,"The hdfs sink needs to have a unique stream name.  Because the twitterSearch test uses the ""defaultName"" and it may broadcast more than one message to the sink for the search.  So when the stream is destroyed the message is abandoned until hdfsTest starts up using the same 
""defaultName"" and the message is delivered to hdfs sink and thus the twitter data is written to the file.  ",XD-2187,Glenn Renfro,testHdfsSink  sporadically fails because twitter data is written to file.
1568,,Ilayaperumal Gopinathan,"Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.",XD-2186,Ilayaperumal Gopinathan,Fix 'cluster/containers' REST endpoint with security enabled
1569,,Ilayaperumal Gopinathan,"Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.",XD-2185,Ilayaperumal Gopinathan,Fix 'cluster/containers' REST endpoint with security enabled
1570,,Ilayaperumal Gopinathan,"Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.",XD-2184,Ilayaperumal Gopinathan,Fix 'cluster/containers' REST endpoint with security enabled
1571,,Ilayaperumal Gopinathan,"Once the container's management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.",XD-2183,Ilayaperumal Gopinathan,Fix 'cluster/containers' REST endpoint with security enabled
1572,Marius Bogoevici,Marius Bogoevici,"As a user, I want to know how to enable and configure LDAP as an authentication provider for the administration server, so that I can set up my security configuration accordingly.",XD-2182,Marius Bogoevici,Document how to enable LDAP security for admin endpoints
1573,Marius Bogoevici,Marius Bogoevici,"As a user, I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints, so that I can secure my application.",XD-2181,Marius Bogoevici,Document how to enable SSL and Basic authentication 
1574,Thomas Risberg,Sabby Anandan,"As a user, I'd like to override the default ""commit-interval"" so that I can configure commit interval depending on data volume.

*Note:*
This would apply for all OOTB jobs that has partition support. The property could be part of _servers.yml_ file.",XD-2180,Sabby Anandan,"Expose property to change ""commit-interval"""
1575,,Sabby Anandan,"As a user, I'd like to have the option of _HDFS_ source module so that I can ingest data directly from HDFS file system.",XD-2179,Sabby Anandan,Add HDFS source
1576,Thomas Risberg,Sabby Anandan,"As a user, I'd like to have the option to supply data partitioning strategy so that I can parallelize ingest of data from RDBMS to HDFS.",XD-2178,Sabby Anandan,Add remote partitioning on 'jdbchdfs' job
1577,Thomas Risberg,Thomas Risberg,"*XD 1.0.2 Release + PHD 2.1 Upgrade - Action Items:*

* Update to SHDP 2.0.3
* Add Hadoop 2.5 (hadoop25)
* Change PHD 2.x from phd20 to phd21
* Test PHD 2.0 with phd21 
* Document that both PHD 2.1 and PHD 2.0 is supported with phd21

",XD-2177,Thomas Risberg,Add support for Pivotal HD 2.1 (XD 1.0.2 Release)
1578,,Glenn Renfro,"When simulating a slow network by deploying a Zookeeper with 3 nodes.
* Zookeeper 1 (follower)was located at US-East-1
* Zookeeper 2 (follower) was in Sydney 
* Zookeeper 3 (Leader) was in Sydney
XD Admin and containers were running in US-East-1 Zone

In this case we simulated a loss of quorum by killing the zookeeper 2 (follower in Sydney).  All modules were undeployed.  When I restarted the zookeeper 2 all containers and admin recognized the ensemble was up and tried to redeploy the modules, but the stream was left in a ""Failed"" state.

Steps to reproduce: 
* Deploy Stream ""http|file""
* Start Data Flow to stream from JMeter
* Terminate ZK Follower in AU
* Restart ZK Follower in AU

The workaround is to undeploy and deploy the stream.",XD-2176,Glenn Renfro,Module (re) deployment failed after ZK Cluster Ensemble lost quorum
1579,,Kashyap Parikh,"One of the goal for a micro benchmark is to compare throughput difference  between two types of streams:
1. source | sink
2. source | processor | sink

For this test I used reactor-tcp source, throughput-sampler as sink and created a NoOp processor. Tests were performed on a single node container with direct binding turned on for all streams.

1. Throughput for ""source|sink""

{noformat}
stream create reactortcp --definition ""reactor-ip --transport=tcp --port=4000 | throughput-sampler""
stream deploy reactortcp --properties module.*.count=0
{noformat}

On my system I get following numbers:
Throughput sampled for 5000000 items: 345423/s in 14475ms elapsed time

2. Throughput for ""source|processor|sink""

Code for NoOpProcessor is available here:
https://github.com/parikhkc/xd-noop-processor

{noformat}
stream create reactornoop --definition ""reactor-ip --transport=tcp --port=5000 | noopprocessor | throughput-sampler""
stream deploy reactornoop --properties module.*.count=0
{noformat}

On the same system the throughput reduces to less then 70K/sec.
Throughput sampled for 5000000 items: 67250/s in 74349ms elapsed time

Yourkit shows 50% of CPU time on following thread:

{noformat}
* ringBuffer-17 [RUNNABLE] [DAEMON]
java.lang.reflect.Method.getParameterAnnotations() Method.java:770
org.springframework.xd.integration.reactor.net.NetServerInboundChannelAdapter$1.accept(Object) NetServerInboundChannelAdapter.java:53
reactor.net.AbstractNetChannel$3.accept(Event) AbstractNetChannel.java:131
reactor.net.AbstractNetChannel$3.accept(Object) AbstractNetChannel.java:128
reactor.event.routing.ArgumentConvertingConsumerInvoker.invoke(Consumer, Class, Object) ArgumentConvertingConsumerInvoker.java:73
reactor.event.routing.ConsumerFilteringEventRouter.route(Object, Event, List, Consumer, Consumer) ConsumerFilteringEventRouter.java:78
reactor.event.dispatch.AbstractLifecycleDispatcher.route(AbstractLifecycleDispatcher$Task) AbstractLifecycleDispatcher.java:64
reactor.event.dispatch.AbstractSingleThreadDispatcher$SingleThreadTask.run() AbstractSingleThreadDispatcher.java:50
reactor.event.dispatch.RingBufferDispatcher$3.onEvent(RingBufferDispatcher$RingBufferTask, long, boolean) RingBufferDispatcher.java:115
reactor.event.dispatch.RingBufferDispatcher$3.onEvent(Object, long, boolean) RingBufferDispatcher.java:112
com.lmax.disruptor.BatchEventProcessor.run() BatchEventProcessor.java:128
java.lang.Thread.run() Thread.java:745

{noformat}
",XD-2175,Kashyap Parikh,Throughput in a stream with any processor
1580,,Glenn Renfro,"In cases where the zookeeper ensemble is down or does not have quorum, the xd cluster effectively stops all work.  However the health status of the containers is ""Up"".  The container health status should be ""Awaiting Zookeeper Session""  until it can get a successful zookeeper session.",XD-2174,Glenn Renfro,Health Actuator Endpoint (JMX)  Needs to portray an accurate status for Admin or Containers
1581,,Glenn Renfro,"During the slow network tests the user undeployed a stream and then immediately redeployed the same stream to get the modules on different containers.  The deployment failed as reflected in the stacktrace below from the admin server, however the the shell did not report an error and the user could not deploy the stream.  
* The stream in question is ""http|log"" 
* The Shell did not report any error.  
* Stream list does show the state of the stream as failed. 
* executing a stream deploy fails with the following error:
    ** Command failed org.springframework.xd.rest.client.impl.SpringXDException: The stream named 'foo' is already deployed
 * Undeploy and deploy of the stream worked.
 
17:54:39,487  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/73f0a93d-e213-414d-8337-6c04409ec210/foo.source.http.1/status
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:205)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:163)
	at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:166)
	at org.springframework.xd.dirt.server.StreamDeploymentListener.onChildAdded(StreamDeploymentListener.java:100)
	at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)
	at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
}
17:54:39,496  INFO Deployer server.StreamDeploymentListener - Stream Stream{name='foo'} deployment attempt complete",XD-2173,Glenn Renfro,Shell does not report failed deploy attempt 
1582,Michael Minella,Sergey Shcherbakov,"The Gemfire XD database cannot be used to store the Spring XD metadata because the former doesn't support the default Spring Batch transaction isolation level ISOLATION_SERIALIZABLE.

There looks to be no way to configure the Spring XD's internal Spring Batch JobRepository with another isolation level.

The JobRepository instance is getting created with default settings by the Spring Batch'es {{SimpleBatchConfiguration}} and there are no custom {{BatchConfigurer}}s available to change the default settings of the JobRepository.",XD-2172,Sergey Shcherbakov,Provide a way to customize the isolation level of the JobRepository
1583,Eric Bottard,Eric Bottard,,XD-2171,Eric Bottard,Document Kafka source
1584,Patrick Peralta,Patrick Peralta,"The following exception was encountered by a few parties: for example https://gopivotal-com.socialcast.com/messages/21678398

{noformat}
ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/NNNN/modules
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1586)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)
	at org.springframework.xd.dirt.server.JobDeploymentListener.recalculateJobStates(JobDeploymentListener.java:197)
	at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:389)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{noformat}

No specific details on reproducing yet; although the Socialcast thread indicates:

{quote}
I only hit this when I have tried to deploy a job that fails deployment the first time
{quote}",XD-2170,Patrick Peralta,NoNodeException for job creation
1585,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to evaluate Spring Boot dependency upgrades so that I can make sure there aren't any side effects or impacts to existing functionalities. ",XD-2169,Sabby Anandan,Evaluate Spring Boot dependency upgrade
1586,,Sabby Anandan,,XD-2167,Sabby Anandan,Provide support for XD Runtime on Vagrant
1587,Chris Schaefer,Sabby Anandan,"As a user, I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework.
",XD-2166,Sabby Anandan,Research the approach for XD Runtime on Mesos 
1588,,Sabby Anandan,"As a user, I need to have the ability to create docker images via CI build so that I can build all the components/configurations I need into a Docker image, test it, and deploy the image to various environments. ",XD-2165,Sabby Anandan,Provide CI build support for Docker images
1589,,Sabby Anandan,"As a user, I want to configure Docker XD Containers using Service Discovery so that I can have tools to manage how processes and services in a cluster can find and talk to one another.",XD-2164,Sabby Anandan,Provide support for Docker Service Discovery
1590,,Sabby Anandan,"As a user, I need the ability to configure Docker XD Containers so that I can link to external services such as _Rabbit, Redis, Zookeeper, Hadoop, Mongo, etc_.

Includes pointers to:
* Linking/binding attributes
* Environment variables
",XD-2163,Sabby Anandan,Provide ability to configure Docker containers
1591,,Sabby Anandan,"As a user, I need a ""production-ready' Docker Image so that I can use that as a baseline to deploy XD with the following setup.

* Ubuntu OS
* Full XD Jar
* Java 7.x",XD-2159,Sabby Anandan,Provide Docker image for production deployment
1592,Eric Bottard,Sabby Anandan,"As a user, I need a 'sandbox' Docker Image so that I can get started to experiment XD deployment with the following setup:

* Ubuntu OS
* Full XD Jar
* Java 7.x
* Redis
* RabbitMQ",XD-2158,Sabby Anandan,Provide Docker image for developers
1593,Chris Schaefer,Sabby Anandan,,XD-2157,Sabby Anandan,Support for Mesos based s-c-d deployment 
1594,,Sabby Anandan,,XD-2156,Sabby Anandan,Support XD Runtime on Docker
1595,Gunnar Hillert,Gunnar Hillert,Small follow up story to XD-2094 to improve tooltip handling.,XD-2155,Gunnar Hillert,UI: Add Tooltip Directive
1596,Eric Bottard,Sabby Anandan,"As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don't have to manually move and set it up.

*Scope of this spike:*
* Assess customer requirement, brainstorm, and document options
* Socialize with the team to collect feedback
* Identify phases
* Create new stories",XD-2154,Sabby Anandan,Research REST endpoint approach to push custom module
1597,,Glenn Renfro,"Update the wiki to reflect the change from:
runtime containers to cluster containers and runtime modules to cluster modules.  ",XD-2153,Glenn Renfro,Update Wiki to reflect the change from runtime x to cluster x
1598,,Sabby Anandan,,XD-2152,Sabby Anandan,Support XD as a service on PCF
1599,Thomas Risberg,Thomas Risberg,"Looks like the --fileExtension isn't used when compressing files with bzip2, some use cases requirer bz2 instead of bzip2 as the extension. Also, '.bz2' should be the default extension. At the same time we should change the default gzip extension to '.gz'.",XD-2151,Thomas Risberg,HDFS sink should honor --fileExtension parameter for bzip2 compressed files
1600,Glenn Renfro,Glenn Renfro,"From time to time FilePollHdfsTest fails in the CI Acceptance Tests. The exception that is fired is as follows: 
java.lang.AssertionError: java.lang.AssertionError: The data returned from hadoop was different than was sent.   expected:<942b9f47-8169-4dc3-a2ba-3d8fab04a4dc
> but was:<null>

Need to investigate if this is a timing issue with the test (more than likely) or with the actual module.",XD-2150,Glenn Renfro,FilePollHdfsTest fails intermittently 
1601,Kashyap Parikh,Kashyap Parikh,"Shell currently adds all jars from xd/lib to its classpath. 
Remove jars that are not needed to run shell.",XD-2149,Kashyap Parikh,Remove un-necessary libs from shell
1602,Kashyap Parikh,Kashyap Parikh,Create zip distribution for shell,XD-2148,Kashyap Parikh,Create separate distribution for shell
1603,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features.",XD-2147,Sabby Anandan,Upgrade to spring boot 1.1.7.RELEASE
1604,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features.",XD-2146,Sabby Anandan,Upgrade to spring boot 1.1.7.SNAPSHOT
1605,Marius Bogoevici,Sabby Anandan,"As a user, I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth

Technical implementation:

Add ---password and --username to the admin config command.


",XD-2145,Sabby Anandan,XD Shell needs to be be able to authenticate using basic auth to admin server
1606,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have the option to provide single-user security configurations so that I can override them as needed.

*Reference:*
[Spring Boot - Security|http://docs.spring.io/spring-boot/docs/1.1.x-SNAPSHOT/reference/html/boot-features-security.html]

*Scope:*
Configurations can be provided through _servers.yml_ file.",XD-2144,Sabby Anandan,Support Spring Boot's single-user security configurations
1607,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have the option of _Basic Auth_ so that I'm challenged to provide _user name_ and _password_ when making a request.

Technical Implementation:

This functionality is provided in Spring Boot 1.1.x, it should be a matter of adding the spring boot security starter dependency to the spring-xd-dirt project.  

It will be controlled using the spring boot property server.basic.enabled = true/false.  Our default in application.yml for this property should be false.

",XD-2143,Sabby Anandan,Add Basic Auth support
1608,,Ilayaperumal Gopinathan,"Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/1183#issuecomment-55917701
",XD-2142,Ilayaperumal Gopinathan,XD Cluster view: create container details page
1609,,Ilayaperumal Gopinathan,"Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/1183#issuecomment-55917701",XD-2141,Ilayaperumal Gopinathan,XD Cluster view: improve hover over capabilities 
1610,Mark Fisher,Eric Bottard,"stream create foo --definition ""label: bar | xxxx""
stream deploy foo --properties ""module.label.yyy=zzz"" seems to work but it does not. The pre-validation is correct, but downstream, deployment logic still looks for module.bar (instead of module.label)",XD-2140,Eric Bottard,Deployment properties should use label instead of name
1611,Gunnar Hillert,Franck MARCHAND,"It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore, the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module.",XD-2139,Franck MARCHAND,Add ftp sink to default sink modules
1612,,Sabby Anandan,"As a user, I'd like to have the data partition strategy state preserved so that when I add/delete modules, they are able to dynamically adapt to the strategy.

This is already included as part of the GA release. This story is to account for the testing effort.",XD-2138,Sabby Anandan,Test partitions by dynamic additions/deletions of modules
1613,,Sabby Anandan,"As a user, I'd like to retain the data partitioning state so that when I restart the containers, I continue to write based on the original partitioning strategy. 

Currently, the state is not preserved; hence, on restarts the definition of partitioning strategy is lost due to different _hashCode()_.

*Design consideration:*
Mine through the container info to derive the ""partition index"" instead of relying on _hashCode()_.",XD-2137,Sabby Anandan,Preserve partition state on container restarts
1614,,Sabby Anandan,"As a user, I should not be allowed to create a custom module with a _reserved_ keywords so that I it will avoid confusions from seeing duplicate strings in deployment manifest.

*Example:*
We would like to avoid a _custom_ module name of *producer* to eliminate the confusion below:
{code}

xd:>stream deploy --name test1 --properties ""module.producer.producer.deliveryMode= PERSISTENT,module.log.criteria=groups.contains('group1')""

{code}

[List of available reserved keywords|https://github.com/spring-projects/spring-xd/wiki/Deployment#deployment-properties]",XD-2136,Sabby Anandan,Restrict the use of reserved keywords
1615,,Sabby Anandan,"As a user, I'd like to have the option to explicitly define/configure ""error channel"" so that I can stage and route the errors/exceptions through the dedicated channel and continue ingestion.

*Scenario:*
* 'http' source ingest 
* failure at either source, processor, or sink module
* regardless of whether it is a custom module or not, traverse through the exception to propagate the actual _Caused by:..._, stage the error as payload, and route it to the error channel

*Example Configuration:*
* error channel definition similar to ""topic.errors.stream.module""
* configure custom exception similar to ""catch=**Exception""
* exception hierarchy
** GlobalException
** DefaultException
** ModuleSpecificException
",XD-2135,Sabby Anandan,"Add explicit ""error channel"" support"
1616,,Sabby Anandan,,XD-2134,Sabby Anandan,Improve stream processing capabilities
1617,,Sabby Anandan,"As a user, I'd like to have the option of _SOLR_ sink so that I can perform full-text indexing and search through SOLR backend server. ",XD-2133,Sabby Anandan,Add SOLR sink
1618,,Sabby Anandan,"As a user, I'd like to have the option of _HAWQ_ sink so that I can write data directly into HAWQ via PXF extensions through Avro/Parquet format.",XD-2132,Sabby Anandan,Add HAWQ sink
1619,,Sabby Anandan,"As a user, I'd like to have the option of _AWS_ sink so that I can write data into S3 directly. 

*Reference:*
[Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws]",XD-2131,Sabby Anandan,Add S3 sink
1620,Artem Bilan,Sabby Anandan,"As a user, I'd like to have the option of _Cassandra_ sink, so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.",XD-2130,Sabby Anandan,Add Cassandra sink
1621,,Sabby Anandan,"As a user, I'd like to have an option of _AWS_ source module so that I can ingest data from Amazon S3 or use the Simple Email Service (SES).

*Reference:*
[Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws]",XD-2129,Sabby Anandan,Add S3 source
1622,,Sabby Anandan,"As a user, I'd like to have the option of _WebSocket_ source module so that I can create a interactive communication channel between user's browser session and the runtime to ingest browser based events and activities.

*Reference:*
[Spring Integration WebSocket Support|https://github.com/spring-projects/spring-integration/tree/master/spring-integration-websocket/src]",XD-2128,Sabby Anandan,Add WebSocket source
1623,,Sabby Anandan,"As a user, I'd like to have the option of _JMX_ source module so that I can publish/subscribe to JMX notifications.

*Reference:*
[Sprint Integration JMX Support|http://docs.spring.io/spring-integration/reference/html/system-management-chapter.html#jmx]",XD-2127,Sabby Anandan,Add JMX source
1624,,Sabby Anandan,"As a user, I'd like to have the option to write into _File Roll_ sink so that I can store events on the local file system.",XD-2126,Sabby Anandan,Add File Roll sink
1625,,Sabby Anandan,"As a user, I would like to have an option to write data into HBase sink so that I can perform random, realtime read/write access on Big Data.",XD-2125,Sabby Anandan,Add HBase sink
1626,Thomas Risberg,Sabby Anandan,"As a user, I'd like to have the ability to mass-ingest data from various database systems so that I'm not restricted with the current approach (_jdbchdfs_) that is dependent on JDBC drivers. 

*Spike Scope:*
* Identify integration options
* Collaborate to determine the design
* Document outcome (design specs)
",XD-2124,Sabby Anandan,Research integration options for Sqoop 'tasklet'
1627,Janne Valkealahti,Sabby Anandan,"As a user, I'd like to have the option of _kerberized_ HDFS sink so that I can leverage Kerberos (open source distributed authentication system) for secured data writes into Hadoop.",XD-2123,Sabby Anandan,Provide kerberos support for HDFS sink
1628,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the option to configure default access control for endpoints so that I can grant access by _Admin_ or _Viewer_ roles.",XD-2122,Sabby Anandan,Secure endpoints using either ROLE_VIEWER and ROLE_ADMIN
1629,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner.

Ideally, all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within LDAP based security layer.

Reference:
[Authentication using LDAP|https://spring.io/guides/gs/authenticating-ldap/]",XD-2121,Sabby Anandan,Secure all endpoints using LDAP based security configurations
1630,Eric Bottard,Sabby Anandan,"As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner.

Ideally, all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within file based security layer.

Reference:
[Securing Web App|https://spring.io/guides/gs/securing-web/]",XD-2120,Sabby Anandan,"Provide file based storage for users, groups (and roles)"
1631,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have the option to enable HTTPS so that I can access XD's Admin server [endpoints|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] over secured communication.

Technical Implementation:

This functionality is available in Spring Boot 1.2.0 M1 and has been backported into the 1.1.x branch to be released under Spring 1.1.7.  We can test against 1.1.7 SNAPSHOT.

Working through the way to update the build file to pick up a new version of boot is a bit tricky :(",XD-2119,Sabby Anandan,Support accessing admin server endpoints over HTTPS
1632,David Turanski,David Turanski,Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.,XD-2118,David Turanski,Create a shell command processor and sink
1633,Patrick Peralta,Bruno Domingues,"When using redis as transport bus there is a problem when using many streams and taps. Basically the maxTotal parameter of org.apache.commons.pool2.GenericObjectPool default is 8. After some streams are deployed it starts to occur concurrency problems hence the number of inbound redis channel adapters is larger than that number.

A more detailed explanation is in stackoverflow:

http://stackoverflow.com/questions/25851660/spring-xd-very-poor-performance-when-using-redis-as-transport",XD-2117,Bruno Domingues,Spring XD very poor performance when using redis as transport
1634,,Derek OKeeffe,"Would be nice to have a sink for REST resources. 
Might be configurable with an endpoint URI. Basic auth details would be a nice to have too. 
Would perform a POST to the endpoint passing the payload.",XD-2116,Derek OKeeffe,Add REST resource sink
1635,Gary Russell,Sameer Vohra,"Setup: DIRT Spring XD, 2 Admins, 3 Containers

Step 1. Deploy the following streams (which would get deployed to all 3 containers)

stream create --name httpFoo --definition ""http | file""
stream deploy httpFoo --properties ""module.*.count=0""

stream create --name httpFooTap --definition ""tap:stream:httpFoo > file""
stream deploy httpFooTap --properties ""module.*.count=0""

stream create --name httpFooCounter --definition ""tap:stream:httpFoo > counter --name=httpFooCounter""
stream deploy httpFooCounter --properties ""module.*.count=0""
Step 2. Run runtime modules to ensure each module was deployed to every container

Step 3. Do a test curl call

http post --target http://container-1:9000 --data ""{\""xlmagic\"":\""dorothy\""}""
Step 4. The httpFooTap and httpFooCounter will receive duplicate messages. The number of messages = # of containers. In our case, httpFoo.out exists only one 1 container. However, httpFooTap.out exists on all 3 containers and contains the same message. Similarly, httpFooCounter has a value of 3.

Looking at how the taps are represented in rabbit, this behaviour makes sense as XD is using fanout exchanges and each instance for a given tap is a consumer.",XD-2115,Sameer Vohra,Using taps with deployment property module.*.count=0 causes duplication of messages
1636,Patrick Peralta,Leo Chu,"A job gets stuck in ""deploying"" state when a job is deployed when there are no containers available.  When a container is started after this event, the job doesn't automatically start because of the job is stuck in the ""deploying"" state instead of the ""failed"" state.  

Refer to https://github.com/spring-projects/spring-xd/blob/193088dc164c73e07d7b4509de22241b28bf42b3/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/JobDeploymentListener.java

Update of the status in Zookeeper is inside the NoContainerException catch block.

This works correctly for streams.",XD-2114,Leo Chu,"Job stuck in ""deploying"" state when no containers are available"
1637,Eric Bottard,Eric Bottard,"curl http://localhost:9393/metrics/aggregate-counters/smartgrid_h_28_load_predicted\?resolution\=minute\&from\=2013-09-01T12:55:00.000Z\&to\=2013-09-01T13:00:00.000Z 

would return 0 as the last bucket, while

curl http://localhost:9393/metrics/aggregate-counters/smartgrid_h_28_load_predicted\?resolution\=minute\&from\=2013-09-01T12:55:00.000Z\&to\=2013-09-01T13:05:00.000Z

would correctly return the value for 13:00:00",XD-2113,Eric Bottard,Redis aggregate-counter fails when end of interval is on the hour
1638,Glenn Renfro,Glenn Renfro,Currently the application allows AWS select which zone in the region to create an instance.,XD-2112,Glenn Renfro,User wants to select the ec2 zone when deploying XD
1639,,Thomas Risberg,"There is a class-loader issue when defining JDBC driver/pool dataSource for a custom job module. If I use the Tomcat DataSource it pulls the driver classes from /xd/lib, but if I use a DataSource class that's not loaded by the XD runtime like SimpleDriverDataSource then it pulls the jdbc driver jars from my job module's lib directory which I was expecting since the JDBC drivers I'm using are not delivered as part of XD. 

The whole class-loading scheme for custom modules needs either better documentation or improvement. Currently it's difficult to tell where classes will be loaded from and what classes are available on the server classpath and which classes have already been loaded. ",XD-2111,Thomas Risberg,JDBC driver classpath issues for custom job modules
1640,Glenn Renfro,Glenn Renfro,"[Current Behavior]
Currently XD-EC2 downloads an XD zip file from the location specified by the xd-dist-url after verifying that the file is accessible..  
",XD-2110,Glenn Renfro,XD-EC2 needs to provide ability to use a preinstalled zip vs downloading from s3
1641,Gunnar Hillert,Thomas Risberg,The resulting definition starts with --makeUnique=true even if the MakeUnique checkbox is unchecked. I can check and uncheck the box and the --make unique parameter isn't included. Since the default for this parameter is true the end result is the same. There doesn't seem to be a way to set --makeUnique=false.,XD-2109,Thomas Risberg,No way to set 'makeUnique' false when creating job in UI
1642,,Thomas Darimont,"It would be nice if the admin ui would sort the streams in such a way that the taps that are created for a particular stream are somehow placed UNDER the tapped stream...
{code}
Stream A ...
 +-Tap A.foo ...
 +-Tap A.bar ...
{code}

Same goes for the list command in the XD-Shell",XD-2108,Thomas Darimont,Show Stream / Tap relationship in Admin UI
1643,Eric Bottard,Eric Bottard,"Currently, the aggregate counter only adds +1 to the individual values, even though support is there to add any increment.

This ticket is about surfacing a SpEL expression on the message to choose the increment",XD-2107,Eric Bottard,Allow aggregate-counter to increment by some value of the message
1644,Ilayaperumal Gopinathan,Sabby Anandan,"As a user, I'd like to have the ability to visually explore XD's cluster view so that I'm aware where the components are deployed and how they are connected within the topology. ",XD-2106,Sabby Anandan,Provide the ability to visualize XD cluster view
1645,Eric Bottard,Eric Bottard,"Currently, custom SI property accessors are registered by a plugin (org.springframework.xd.dirt.plugins.SpelPropertyAccessorPlugin) and are not visible by the bus.

I believe they should be.

This may just be a matter of moving them around.",XD-2105,Eric Bottard,MessageBus should see custom SpEL property accessors
1646,,Gunnar Hillert,"As a result of fixing XD-2015 we still cannot execute:

{code}
grunt test:e2e
{code}

Basically running the tests AND the server together in one process fails. We see the following error: *Fatal error: socket hang up*.

If we separate the protractor execution into 2 separate steps, the tests pass:

{code}
grunt serve (one console window)
grunt protractor:run (second console window)
{code}

In the *grunt serve* window, you can still observe *Fatal error: socket hang up* being printed out but the tests execute successfully.


",XD-2104,Gunnar Hillert,"Investigate and Fix E2E test execution for grunt task ""test:e2e"""
1647,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a user, I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker.",XD-2103,Ilayaperumal Gopinathan,Add Kafka sink
1648,,Girish Lingappa," We noticed that  when there is a problem with one of the deployed streams the container logs have too many stack trace messages and quickly fill up the disk.

 For instance, there are several streams deployed writing to hdfs and if hdfs is restarted for some reason the containers fail to write to hdfs and start filling up the disk. 

Couple of thoughts that come to mind :
1. stack trace logging can happen in debug mode esp for message level logging on containers
2. if a stream is failing on all containers can we undeploy the stream? this would require some sort of alerting to notify admins or owners of these streams. Or we can just alert that streams are failing.


",XD-2102,Girish Lingappa,container logs filling up disk
1649,,Eric Bottard,,XD-2101,Eric Bottard,Provide tab completion for deployment manifest properties
1650,David Turanski,David Turanski,"XD Module configured for component scanning classes (or methods?) annotated with @Source, (consider @Processor, and @Sink as well) and simply provide the POJOs and dependent jars in the module /lib directory. Custom processor is fairly straightforward currently, but still requires an XML module definition to wire up the POJO as a service activator or transformer to the input and output channel. A service activator works for a POJO backed sink. Writing a source that is not backed by an existing inbound channel adapter is a bit more involved and requires more than basic familiarity with SI. It should be possible for XD to automatically create a polling source by wiring a Java method to an inbound adapter configured with a poller. Ideally, we would require no XML, even to enable component scanning- this will require some changes to the module registry/module initializer.",XD-2100,David Turanski,Create XD source from POJO annotated @Source 
1651,,Sandro Lehmann,"If a job is deployed an the singlenode job is canceled, the job name cannot neither be reused nor destroyed.
See screenshots.
",XD-2099,Sandro Lehmann,Remove unavailable jobs
1652,Eric Bottard,Eric Bottard,"Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning.

Implement KafkaMessageBus and supporting classes and UT/IT.",XD-2098,Eric Bottard,Implement KafkaMessageBus
1653,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the container starts up, it has a random http port for management configurations. If the container has management port enabled, then we can store it as container attribute. If the admin can reach out to the container on that port, then we can provide an option to shutdown container from the admin server.",XD-2097,Ilayaperumal Gopinathan,Enable shutdown containers from admin server
1654,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"For a given stream/job, we need a visual representation of the stream/job with any deployed modules.",XD-2096,Ilayaperumal Gopinathan,UI: Visual representation of Stream/Job with deployed modules
1655,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Admin UI currently allows job to be deployed with deployment properties, we need similar way to deploy stream with the deployment properties (module count, container matching criteria).",XD-2095,Ilayaperumal Gopinathan,UI: Ability to deploy stream with deployment properties
1656,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,We need a visual representation of the XD cluster with runtime container and deployed modules.,XD-2094,Ilayaperumal Gopinathan,UI: Cluster view of a container
1657,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, there is a ""stream list""/""job list"" which shows the status of a given stream/job along with the DSL. and, there is ""runtime modules"" which shows all the deployed modules with their container info.

We need a better REST endpoint that gives all the deployed modules for a given stream/job along with the status.",XD-2093,Ilayaperumal Gopinathan,List Streams/Jobs based with deployed modules
1658,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, org.springframework.xd.dirt.cluster.Container has name and attributes (container attributes). This can be enhanced to include all the deployed modules, number of deployed modules and any more useful info. and can subsequently be used to get a detailed runtime container info.",XD-2092,Ilayaperumal Gopinathan,Enhance Container domain object
1659,David Turanski,Sabby Anandan,Design Spike: Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?,XD-2091,Sabby Anandan,Research approach to bootstrap custom modules
1660,David Turanski,Sabby Anandan,"As a user, I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach. 

11/20: Update: Scope of this task is to create an example to demonstrate and document the capability.",XD-2090,Sabby Anandan,Custom module packaging strategy
1661,,Sabby Anandan,,XD-2089,Sabby Anandan,Process for creating and deploying custom XD modules
1662,,Sabby Anandan,"As a developer, I'd like to have the option of extending the Trigger abstraction so that I can implement my own trigger. 


",XD-2088,Sabby Anandan,Research how to extend 'Trigger' interface to implement custom triggers
1663,,Sabby Anandan,"As an Ops, I'd like to setup security for the ZK nodes, so I could restrict access to zNodes to the right users/apps.
",XD-2087,Sabby Anandan,Spike: Research how to leverage ZK's ACLs
1664,,Sabby Anandan,Design Spike: Investigate best approach to encrypt data pipeline. Consider all moving parts within the topology including the scenarios where data is at rest and as well as in transit. ,XD-2086,Sabby Anandan,Research how to handle data encryption within pipeline
1665,Glenn Renfro,Glenn Renfro,"h1. Run Acceptance tests on the following  deployments.  

h2. Slow Network
Simulate slow network by deploying a XD cluster where the ZK Ensemble is only available via WAN.  

h2. Network packet loss
Simulate cases where a network packets can be lost.  
",XD-2085,Glenn Renfro,Test Recommended XD Cluster Strategy on slow/bad network
1666,Glenn Renfro,Glenn Renfro,"h1. Summary 
User wants the ability to deploy an ec2 cluster where the admin & containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. 

h2. Current functionality
Currently spring-xd-ec2 sets up its containers & admin server to use a ZK, rabbit and redis that are provisioned and collocated with the admin server.  

h2. Detail
The following properties will be added to the spring-xd-ec2.properties
# *spring_zk_client_connect* - contains a comma delimited list of zk hosts:ports for a ensemble.  The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail.  Default is adminServer_host:2181.
# *spring_rabbitmq_addresses* - contains a comma delimited list of hosts:ports for a rabbit cluster.  The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail.  Default is adminServer_host:5672.
# *spring_redis* - contains a host:port for a redis instance. The application will check to see if the port is open , if not deployment will fail.  Default is adminServer_host:5672.
# *ec2_zone* - user can specify the zone to which the containers and admin will be deployed.  If not present AWS will decide which zone to deploy the cluster.",XD-2084,Glenn Renfro,Spring XD EC2 needs to setup cluster that uses static resources.
1667,,Michael Minella,"h3.  Narrative
As a developer, I need to be able to configure a partitioned job's grid size so that the correct number of partitions are created (the current code is hard coded to 1 for the grid size).

h3.  Acceptance Criteria
# Expose the gridSize attribute of the {{MessageChannelPartitionHandler}} as an option.

h3.  Assumptions
# Existing OOTB jobs should not be impacted by this given they don't use the grid size.
",XD-2083,Michael Minella,singlestep-partition-support needs to allow grid size to be configurable
1668,,Mark Pollack,In some cases it maybe useful to share a specific bean instance contributed by a user across multiple module instances.  This story is a placeholder to collect requirements and discuss.,XD-2082,Mark Pollack,Investigate how to provide a means to share bean defintions across module instances
1669,,Glenn Renfro,"* SHA baddfc24b08286a78392d5f565742c9bab5adfea
* EC2 Environment
** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology

h2. The test scenario 
# Can be duplicated with single server ZK ensemble
# Start Container on a EC2 instance.  Wait till it joins cluster
# Start 2nd container on same EC2 instance.

h2. Observed Behavior. 
# Container 1 starts normally
# Container 2 reports that failed to bind to address.  (shown in attached stack trace)
## But does not terminate 
## Shown as valid container when executing ""runtime containers"" command.
xd:>runtime containers
  Container Id                          Host              IP Address     PID   Groups  Custom Attributes

  0c88a300-9469-4f21-a256-7733259b13c7  ip-10-70-11-185   10.70.11.185   2061
  256c35b7-c9f4-43ba-81dd-e1bfff0fb7c1  ip-10-70-9-57     10.70.9.57     3604
  31fedc48-2762-4c45-8075-1dce64af5391  ip-10-110-186-48  *10.110.186.48*  2396  GROUPA
  524bb933-a8b5-4014-a0b5-06d4fa8b30c2  ip-10-2-209-174   10.2.209.174   2123
  e993026e-e2ac-4d16-9890-0786149d7b75  ip-10-110-186-48  *10.110.186.48*  2524  GROUPA
  f9437b15-1ee2-4827-99d4-e7957f9abdf2  ip-10-70-9-153    10.70.9.153    2366  GROUP0
 
",XD-2081,Glenn Renfro,Container does not fail if sharing same ports on same machine with another container.
1670,,Glenn Renfro,"* SHA baddfc24b08286a78392d5f565742c9bab5adfea
* EC2 Environment
** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology

h2. The test scenario 
# Bring up a up a 5 container 2 admin XD Cluster up using 3 ZK Server ensemble.
# Create ticktock  stream ""time|log""
# Deploy with --properties ""module.log.count=5""
# Kill one of the ZK Servers in the ensemble

h2. Observed Behavior. 
# In this particular scenario 3 containers were affected by killing (sudo kill <pid>) Zookeeper 2
# 2 Containers did not come back online even though they did show up in the runtime containers
 
h2. Timeline
# 14:08:21 deployed stream
# 14:09:10 kill server in ZK Ensemble
# After waiting a few seconds ran runtime Modules (*Note:* log2 is undeployed and log5 is then deployed)  :

xd:>runtime modules
  Module             Container Id                          Options                                     Deployment Properties
  -----------------  ------------------------------------  ------------------------------------------  ---------------------
  foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}
  foo.sink.log.2     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo, expression=payload, level=INFO}  {count=5, sequence=2}
  foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}

xd:>runtime modules
  Module             Container Id                          Options                                     Deployment Properties
  -----------------  ------------------------------------  ------------------------------------------  ---------------------
  foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}
  foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}
  foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}

xd:>runtime modules
  Module             Container Id                          Options                                     Deployment Properties
  -----------------  ------------------------------------  ------------------------------------------  ---------------------
  foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}
  foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}
  foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}

xd:>runtime containers
  Container Id                          Host              IP Address     PID   Groups  Custom Attributes
  ------------------------------------  ----------------  -------------  ----  ------  -----------------
  0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045
  5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099
  707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055
  98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA
  9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0


h2.  Undeploy and redeploy stream 

# 14:16:42 Undeploy and redploy with module.log.count=5
xd:>runtime modules
  Module             Container Id                          Options                                     Deployment Properties
  -----------------  ------------------------------------  ------------------------------------------  ---------------------
  foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}
  foo.sink.log.2     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=2}
  foo.sink.log.5     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}
  foo.source.time.1  98a32c62-302a-484b-af9c-d670f2a3cfc2  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}

xd:>runtime containers
  Container Id                          Host              IP Address     PID   Groups  Custom Attributes
  ------------------------------------  ----------------  -------------  ----  ------  -----------------
  0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045
  5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099
  707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055
  98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA
  9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0
  
# 14:21:06 undeploy foo

",XD-2080,Glenn Renfro,Modules do not redeploy properly when Zookeeper node is lost.
1671,Gary Russell,Gary Russell,Provide for retry and/or dead-lettering for the rabbit source (similar to the rabbit message bus).,XD-2079,Gary Russell,Add a Retry/Dead Letter Interceptor to the RabbitMQ Source
1672,Thomas Risberg,Sina Sojoodi,"Environment:
- Hadoop Installation: PHD Service for PCF  (PHD1.1 based on Apache Hadoop 2.0.5:  2.0.5-alpha-gphd-2.1.0.0 ) running on vCHS
- Spring XD running in singlenode mode (version 1.0.0.RC1) on a vCHS VM

Steps to reproduce:
1- Setup a stream in Spring XD shell: ""http --port=9000 | hdfs --rollover=10M --idleTimeout=60000"" --deploy
2- Hit port 9000 every second with 1-10KB of JSON data
3- Observe the temp file being created in HDFS under /xd/<stream name>
4- Run `hadoop fs tail <file> --follow` to see that data is being written to HDFS

Expected result:
- HDFS sink continues to operate and eventually roll-over at 10MB

Actual:
- After about 2 minutes of successful HDFS writes, the HDFS sink crashes and starts throwing exceptions (see full log attached): 
""'java.io.IOException: All datanodes 192.168.109.61:50010 are bad. Aborting...""
- The temp file is never closed even after the stream is undeployed or destroyed.  

Here are some details of our investigation that may be useful:
- I start both the shell and the singlenode runner with --hadoopDistro phd1;  I also configured the hadoop fs namenode correctly in the XD shell.
- ""http <options> | file <options>"" work as expected; so does ""http <options> | log""
- ""time | hdfs"" does not show the same crash problem. Up until now only the http source combined with hdfs sink presents this problem
- Putting a 4-10MB file in HDFS via the `Hadoop fs put` commands in Spring XD worked fine; so it's not a disk limitation.
- This could be related to PHD service running on vCHS since supporting this configuration is fairly new. But it's only reproducable (consistently) with Spring XD's ""http | hdfs"" stream. ",XD-2078,Sina Sojoodi,"""http | hdfs"" stream starts throwing exceptions after a few minutes "
1673,,Thomas Risberg,"Problem using twittersearch when the system where the XD container is running has two network interfaces.

With the following config:

eth0      local network, resolves `hostname` 
eth1      internet network

I get an error deploying the stream:

{code}
12:08:22,965  WARN twitterSource-1-1 client.RestTemplate - GET request for ""https://stream.twitter.com/1.1/statuses/sample.json"" resulted in 401 (Authorization Required); invoking error handler
12:08:22,972 ERROR twitterSource-1-1 twitter.TwitterStreamChannelAdapter - Twitter authentication failed: 401 Authorization Required
{code}

If I flip the network interfaces to be:

eth0      internet network, resolves `hostname`
eth1      local network  

then it seems to work.
",XD-2077,Thomas Risberg,Problem using twittersearch when system where container is running has two network interfaces.
1674,,Sandro Lehmann,"I'd be very pratical if the mail sink has the ability to send files as attachment.
I.e. add the attribute ""attachment-filename"" to header-enricher.",XD-2076,Sandro Lehmann,Ability to send files as attachment (mail sink)
1675,Gary Russell,Gary Russell,See http://stackoverflow.com/questions/25226527/mqtt-source-spring-xd/25227531#25227531,XD-2075,Gary Russell,Add --binary Option to MQTT Source
1676,Thomas Risberg,Thomas Risberg,"Trying to run a twitterstream on YARN on HDP 2.1 and get the following:

{code}
14/08/08 12:12:50 ERROR server.ContainerRegistrar: Exception deploying module
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in URL [file:./spring-xd-yarn-1.0.0.RELEASE.zip/modules/source/twitterstream/config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in URL [file:./spring-xd-yarn-1.0.0.RELEASE.zip/modules/source/twitterstream/config/twitterstream.xml]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:336)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:646)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:703)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:203)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:98)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:88)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:78)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:231)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:577)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:447)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$800(ContainerRegistrar.java:95)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:826)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in URL [file:./spring-xd-yarn-1.0.0.RELEASE.zip/modules/source/twitterstream/config/twitterstream.xml]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:278)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1114)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1017)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:328)
	... 41 more
Caused by: org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:164)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:125)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:270)
	... 50 more
Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:74)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)
	at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:148)
	... 52 more
{code}",XD-2074,Thomas Risberg,Modules that depend on HttpClient fail when running on YARN on Hadoop 2.4.x and later
1677,,Glenn Renfro,,XD-2073,Glenn Renfro,Create a Sink and Source for Riak
1678,,Rodrigo Meneses,"xd-shell by default will try to connect to the admin node in the same host. You need to run ""admin config server"" to specify the URI where the admin node is - every time you run xd-shell. 

xd-shell should have a command line argument ""--adminUri"" so that the user can invoke the xd-shell passing the Admin Node Uri as an argument when running the shell and then be able to use xd-shell in interactive mode without having to run ""admin config server"" every time. 



",XD-2072,Rodrigo Meneses,"xd-shell should provide a command line argument ""--adminUri"" to specify the location of the admin node"
1679,David Turanski,David Turanski,split out build.gradle into multiple files.,XD-2071,David Turanski,Modularize gradle build
1680,Eric Bottard,Eric Bottard,"Remove 
{noformat}
		filter { line ->
			// TODO: refine regex to only match local documents
			def match = (line =~ /link:(.*?)#(.*?)\[(.*?)\]/)
			if (match) match.replaceAll('xref:$2[$3]') else line
		}

{noformat}

and replace link:Foo#bar by xref:Foo#bar

",XD-2070,Eric Bottard,Get rid of custom asciidoctor link: transformations
1681,Marius Bogoevici,Mark Pollack,"The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned.

I updated the log4j config for org.jboss.netty but it had no effect.  I suspect this is due to the need to configure the netty logging system via InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory()).

",XD-2069,Mark Pollack,Provide a way to debug the http source
1682,,Thomas Darimont,"In some scenarios like when performing exploratory data-analysis on streaming data one often create a stream, keep it running for some time (or until some condition is met) and then stop the stream and start to investigate the collected data.

It would be cool to be able to specify some undeploy condition, like e.g. a timeout after x minutes, no. of events collected, a specific counter past a given threshold, file-size greater then x etc.",XD-2068,Thomas Darimont,Add support for specifying an undeploy-condition for stream definitions
1683,Eric Bottard,Eric Bottard,This will in turn allow us to get rid of the custom logic for handling crossref links between documents,XD-2067,Eric Bottard,Upgrade asciidoctor toolchain
1684,Glenn Renfro,Glenn Renfro,"Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail.  This is because, sometimes it takes 2 or more sends to get the data transmitted between modules.  With the current test structure this is considered a failure.  Is this the correct behavior?",XD-2066,Glenn Renfro,Tests sporadically fail when checking send counts with rabbit as transport
1685,Glenn Renfro,Glenn Renfro,Update  to replace deprecated code.,XD-2065,Glenn Renfro,Update JClouds to 1.8 For XD-EC2
1686,Glenn Renfro,Glenn Renfro,Have to update the code because of deprecation and to get ready for 2.0.,XD-2064,Glenn Renfro,Update JClouds to 1.8
1687,Thomas Risberg,Sabby Anandan,"Use a baseline DIRT infrastructure to measure throughput, HA and scalability for various payload sizes.

Depends on testing infrastructure setup, configuration and availability.",XD-2063,Sabby Anandan,Investigate setting up performance test environment on cloud providers
1688,,Sabby Anandan,"Non-functional requirements such as reliability, availability, scalability, and performance needs measured and validated. 

Acceptance criteria:
- Throughput: Measure the messaging infrastructure (broker/bus) capabilities in terms of messages consumed/sec. Compute the data ingestion rate/sec.

- HA/Scalability: Measure of DIRT architecture capabilities through linear increase/decrease/destroy xd-containers and xd-admins along with payload variations.

- Durability: Measure linear variations on payload with baseline DIRT infrastructure to compute end-to-end durability.
",XD-2062,Sabby Anandan,"Investigate, measure, validate and verify quality attributes"
1689,Ilayaperumal Gopinathan,Sabby Anandan,"As an user, I'd like to have the ability to ingest data into _Redis_ sink.",XD-2061,Sabby Anandan,Add Redis sink
1690,Eric Bottard,Sabby Anandan,"As an user, I'd like to have a native _JDBC_ source module to ingest data directly from various databases. ",XD-2060,Sabby Anandan,Add JDBC source
1691,Glenn Renfro,Glenn Renfro,"Need to add a retry to the createDataFileOnRemote machine, because the creation of the test file on the remote machine fails from time to time.
Usually related to network issues.
",XD-2059,Glenn Renfro,FilePollHdfs sporadically fails to create files on remote machines
1692,David Turanski,Sabby Anandan,The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ,XD-2058,Sabby Anandan,Investigate long running tests
1693,,Sabby Anandan,"We are currently facing issues with Travis. Determine the root cause, isolate the bottleneck, and resolve the issues.",XD-2057,Sabby Anandan,Investigate Travis issues
1694,Marius Bogoevici,Sabby Anandan,"As a user, I should be able to leverage native _ElasticSearch_ sink so that I can aggregate, search and analyze data insights in real-time.",XD-2055,Sabby Anandan,Add ElasticSearch sink
1695,,Sabby Anandan,"As an user, I'd like to have the ability to setup infrastructure to develop/enhance UI functionality.

This is including but not limited to:
- UI designs (mockup's)
- Unit testing
- CI
- JS 'minification'

",XD-2054,Sabby Anandan,Add infrastructure support for Admin UI
1696,,Sabby Anandan,"As an user, I'd like to have OOTB sink modules to integrate with various data sources to egest data using Spring XD. 

Note:
The OOTB support, however, is limited to currently available Spring Integration adapters.

Acceptance Criteria:
- User should be able to list the 'new sink' through DSL commands 
- User should be able to optionally choose the ""new sink"" adapters for stream creation using XD shell
- User should see appropriate error messages if the required attributes are missing while creating a stream with the 'new sink' module
- After successful stream creation with the 'new sink' module, the definition should be included in stream listing
- REST endpoints should include 'new sink' definitions
- Data ingested into 'new sink' should be validated for accurateness
- Appropriate error/exception message needs logged if there's any problem ingesting data into 'new sink' module",XD-2053,Sabby Anandan,Add new sink modules
1697,,Sabby Anandan,"As an user, I'd like to have OOTB source modules to integrate with various data sources to ingest data using Spring XD. 

Note:
The OOTB support, however, is limited to currently available Spring Integration adapters. 

Acceptance Criteria:
- User should be able to list the 'new source' through DSL commands 
- User should be able to optionally choose the ""new source"" adapters for stream creation using XD shell
- User should see appropriate error messages if the required attributes are missing while creating a stream with the 'new source' module
- After successful stream creation with the 'new source' module, the definition should be included in stream listing
- REST endpoints should include 'new source' definitions
- Data ingested using the 'new source' should be validated for accurateness
- Appropriate error/exception message needs logged if there's any problem ingesting data using 'new source' module 



",XD-2052,Sabby Anandan,Add new source modules
1698,Glenn Renfro,Glenn Renfro,"Download zipped Job Modules from a HTTP Site and deploy them to modules on the admin & containers, before container is started.",XD-2051,Glenn Renfro,Add ability to copy job from http site to containers
1699,Janne Valkealahti,Girish Lingappa,"I have not tested this on M7 but I believe it is the case with latest release as well.

Stream definition 1:
stream create logIngestion --definition ""rabbit --queues=demo --host=<rabbitmq-broker> | script --location=linemerge.groovy | hdfs --rollover=10M --idleTimeout=10000 --fileUuid=true --directory=/data/loganalysis --partitionPath=path(payload.split('\u0001')[1],dateFormat('yyyy/MM/dd/HH',payload.split('\u0001')[0],'yyyyMMddHHmmss'))""

we noticed this was causing writes to be slower

Stream definition 2:
stream create logIngestion --definition ""rabbit --queues=demo --host=<rabbitmq-broker> | script --location=linemerge.groovy | hdfs --rollover=10M --idleTimeout=10000 --fileUuid=true --directory=/data/loganalysis ""

but this definition caused the writes to be much faster.

Please note this was just a one time test I did and not reproduced multiple times. 

Janne also seems to have reproduced this in another use case.

Thanks
Girish",XD-2050,Girish Lingappa,HDFS sink Partition Path causing writes to be slower in certain cases
1700,,David Turanski,"Singlenode fails to start using spring-xd-dirt-1.0.0.RELEASE.jar see https://github.com/dturanski/xd-test

The root cause of the error:

java.lang.NoSuchMethodError: javax.servlet.ServletContext.addServlet(Ljava/lang/String;Ljavax/servlet/Servlet;)Ljavax/servlet/ServletRegistration$Dynamic;

Indicating an incompatible servlet version is being pulled in by default.",XD-2049,David Turanski,Singlenode fails to start from external module
1701,,zouweixing,"Do you have plans to support Spark?
In version 1.0 GA, Spring XD has supported Hadoop, But it has not supported the brand new big data calculation platform Spark. do you have plans to support Spark in the future?",XD-2048,zouweixing,Do you have plan to support Spark?
1702,Gary Russell,Gary Russell,"http://stackoverflow.com/questions/25072967/spring-xd-redis-message-bus-removing-headers-from-the-message/25081538#25081538

Currently, you have to modify {{redis-bus.xml}} in the dirt jar.",XD-2047,Gary Russell,Easier Customization of Headers Passed by RedisMessageBus
1703,,Tu Pham ,"I have a stream that watch output of multi file in a directory, process data and put it to HDFS. Here is my stream creat command:

stream create --name fileHdfs --definition ""file --dir=/var/log/supervisor/ --pattern=tracker.out-*.log --outputType=text/plain | logHdfsTransformer | hdfs --fsUri=hdfs://192.168.1.115:8020 --directory=/data/log/appsync --fileName=log --partitionPath=path(dateFormat('yyyy/MM/dd'))"" --deploy

Problem is source:file module send all data read from file to log processing module instead of one line each turn, becase of that, payload string have millions of char, i can't process it. Ex:

--- PAYLOAD LENGTH---- 9511284

Please tell me how to read line by line when use source:file module, thanks !!!",XD-2046,Tu Pham ,Source:file module read file line by line
1704,,Glenn Renfro,"SHA: 33de93797106c8dd413dfb08f2fdbbb4931b528c
Deployment: 1 Admin, 1 Container
DataStore: MySQL

A SpringXDException is thrown when running the  testJobDeployUndeployFlow test in Acceptance tests back to back.

# Ran the test once.  Success
# Ran the test a second time.
## The following exception is thrown: SpringXDException: Batch Job with the name deployundeployjob already exists 
## The XD_JOB_REGISTRY_STEP_NAMES & XD_JOB_REGISTRY still have job_name deployunderployjob still stored.
## The following Exception is seen on the admin server
### 20:45:59,214  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob, type: CHILD_ADDED
20:46:04,741  INFO Deployer server.JobDeploymentListener - Deployment status for job 'deployundeployjob': DeploymentStatus{state=deployed}
20:46:05,436  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob, type: CHILD_REMOVED
20:46:12,471  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob, type: CHILD_ADDED
20:46:16,330  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob, type: CHILD_REMOVED
20:46:17,819  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob, type: CHILD_ADDED
20:46:17,832  INFO Deployer server.JobDeploymentListener - Deployment status for job 'deployundeployjob': DeploymentStatus{state=deployed}
20:46:17,834 ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event
org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/jobs/deployundeployjob/status
	at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)
	at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)
	at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:175)
	at org.springframework.xd.dirt.server.JobDeploymentListener.onChildAdded(JobDeploymentListener.java:99)
	at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)
	at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/deployundeployjob/status
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:165)
	... 7 more

# Clear  XD_JOB_REGISTRY_STEP_NAMES & XD_JOB_REGISTRY tables and run the test a third time 
# Ran the test a third time.
## The following exception is thrown: SpringXDException: The job named 'deployundeployjob' is already deployed
## The following Exception was reported by the admin server.
### 21:18:29,355  WARN http-nio-9393-exec-4 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'deployundeployjob' state to undeploying
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/deployundeployjob/status
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:174)
	at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:196)
	at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:54)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:77)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:103)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:111)
	at org.springframework.xd.dirt.rest.XDController.deleteAll(XDController.java:114)
	at sun.reflect.GeneratedMethodAccessor161.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:885)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:652)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:257)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:683)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1040)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:607)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1720)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1679)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:745)
# Ran the test a fourth time.  Success
",XD-2045,Glenn Renfro,"Deploy,Undeploy,Deploy Acceptance tests run back to back causes exception."
1705,Ilayaperumal Gopinathan,Mark Pollack,"As a user, I'd like to have the option to use the _SFTP_ source module so that I can access, transfer, and mange files over any reliable data streams.

*Reference:*
[Spring Integration SFTP Adapter|http://docs.spring.io/spring-integration/reference/html/sftp.html]

Need to consider the infrastructure for testing.",XD-2044,Mark Pollack,Add SFTP source
1706,,Girish Lingappa,"rabbit source was modified to accept addresses instead of host and existing stream definitions fail. we cannot even destroy the strream

Although this is still not GA wanted to file this to keep track of the issue.

Ex 

xd:>stream list
  Stream Name   Stream Definition                                                                                                                                                                                                                                                                Status
  ------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ----------
  logIngestion  rabbit --queues=demo --host=rhel64-5 | script --location=linemerge.groovy | hdfs --rollover=10M --idleTimeout=1000 --fileUuid=true --directory=/data/loganalysis --partitionPath=path(payload.split('')[1],dateFormat('yyyy/MM/dd/HH',payload.split('')[0],'yyyyMMddHHmmss'))  undeployed

xd:>stream destroy logIngestion
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module rabbit of type source:
    host: option named 'host' is not supported

xd:>stream deploy logIngestion
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module rabbit of type source:
    host: option named 'host' is not supported

In general, destroying a stream should not validate the stream definition",XD-2043,Girish Lingappa,allow deletion of invalid streams
1707,Glenn Renfro,Glenn Renfro,"* Update XD-EC2 configs to Pull from 1.0.1 Repo
* Update XD-EC2 Configs to use spring-xd-1.0.1.BUILD-SNAPSHOT dir 
* Update test configs XD_HOME to spring-xd-1.0.1.BUILD-SNAPSHOT instead of spring-xd-1.0.0.BUILD-SNAPSHOT",XD-2042,Glenn Renfro,Update XD-EC2 & Acceptance Test Configs to use 1.0.1 repo
1708,Eric Bottard,David Turanski,Part of the issue is likely with the build script https://github.com/spring-projects/spring-xd/blob/master/build.gradle#L1859  We should also add a link checker to the CI build.,XD-2041,David Turanski,Fix anchor links so that they work in both the wiki and generated docs
1709,Mark Pollack,Mark Pollack,,XD-2040,Mark Pollack,Release 1.0 GA
1710,,Glenn Renfro,"https://github.com/spring-projects/gradle-plugins/tree/master/spring-io-plugin
Allows us to create a springIoCheck that will verify the status of XD's dependencies as it stands with SpringIO.  

We would need to add the dependencies as show in the document.  But we would need to add the: 
if (project.hasProperty('platformVersion')) {
     ...
    }
code segment to the configure(javaProjects).",XD-2039,Glenn Renfro,Add Spring IO Plugin to XD Gradle.
1711,Mark Fisher,Mark Fisher,,XD-2038,Mark Fisher,Restore JDK6 compatibility
1712,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"It would be good to log the server, module config locations and names when the admin, container, singlenode servers startup.",XD-2037,Ilayaperumal Gopinathan,Log the servers/modules config locations and names
1713,,Mark Pollack,Maybe only have it run after the publish build instead of triggering builds directly from jdk6->7->8.,XD-2036,Mark Pollack,Create JDK6 CI build
1714,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"With HealthIndicatorAutoConfiguration, the health endpoint shows up:

{""status"":""DOWN"",""healthIndicator"":{""status"":""UP""},""rabbit"":{""status"":""DOWN"",""error"":""org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused""},""redis"":{""status"":""UP"",""version"":""2.8.9""},""mongo"":{""status"":""DOWN"",""error"":""org.springframework.dao.InvalidDataAccessResourceUsageException: Timed out while waiting to connect after 3894 ms; nested exception is com.mongodb.MongoTimeoutException: Timed out while waiting to connect after 3894 ms""},""db"":{""status"":""UP"",""database"":""HSQL Database Engine"",""hello"":1}}

We can only use vanilla health indicator, since other status may not be relevant.",XD-2035,Ilayaperumal Gopinathan,Exclude HealthIndicatorAutoConfiguration
1715,Ilayaperumal Gopinathan,Thomas Risberg,"tried local xd-admin/xd-container after setting

{code}
export XD_MODULE_CONFIG_LOCATION=file:./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/config/
{code}

have my twitter stuff in modules.yml in that directory but not picked up by the twitterstream module

Also not working for me deploying on YARN, this used to work at some point, not sure how long ago I actually tested this part - M6/M7?

The setting used for YARN deployment:

{code}
-Dxd.module.config.location: ""file:./""
{code}",XD-2034,Thomas Risberg,Custom location for modules.yml not working
1716,Thomas Risberg,Thomas Risberg,"The 
#ConnectionPoolSettings

define this in the beginning - 

{code}
#spring:
#  datasource:
{code}

uncommenting this will override/invalidate any changes made earlier in the section since it defines spring:datasource again

should either be removed or in separate section",XD-2033,Thomas Risberg,Connection pool settings need to be in their own section in server.yml
1717,Gunnar Hillert,Mark Pollack,"Noticed a few issues while reviewing the documentation

* The sidebar for TOC is no longer there :(  That was really nice.
* Somehow the 'Using-MQTT-on-XD' section is giving an error.

{quote}
asciidoctor: WARNING: index.adoc: line 167: invalid style for paragraph: appendix
asciidoctor: WARNING: index.adoc: line 169: include file not found: /data/projects/spring-xd/build/asciidoc/guide/Using-MQTT-on-XD.asciidoc
:distZip
{quote}

but I don't notice anything different between that appendix and the others in index.adoc.


",XD-2032,Mark Pollack,Fix misc doc formatting issues
1718,Mark Pollack,Mark Pollack,"Removed  various TODO comments in code and put here for proper triage.

DefaultTuple
  * Error handling.  When delegating to the conversion service, the ConversionFailedException does not have the context of which key caused the failure.  Need to wrap ConversionFailedException with IllegalArgumentException and add that context back in.  (see method convert)
 * Ctor visibility.  Consider making ctor final and package protect the ctor so as to always use TupleBuilder
 * check for no duplicate values when initializing names/values list

tuple.
* top level methods to add.  
  String getComponentName... somethign that would indicate which stream or job this tuple is being processed in....

* TupleFieldSetMapper

Only one date format?

* JsonStringtoTupleConverter/JsonNodetoTupleConverter
 * do we want to not map id and timestamp (believe the answer is don't map, preserve original)

",XD-2031,Mark Pollack,Improvements to Tuple project
1719,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"As a temporary work around to fix XD-1935, make producible media type to 'application/json' for Job executions GET request endpoints.",XD-2030,Ilayaperumal Gopinathan,Make producible media type to `application/json` for Job executions GET request endpoints 
1720,Mark Pollack,Mark Pollack,Spring 4.0 provides a UUID generator (used by default in SI) that should be used instead of the com.eaoi.uuid library in the xd-tuple library,XD-2029,Mark Pollack,Use AlternativeJdkIdGenerator  instead of 3rd party library
1721,Mark Pollack,Mark Pollack,"There are a few places in the doc we can reference regarding overall lifecycle of jobs but this should provide a basic recipe for a single step job.

The focus should be on creating a job item processor.

In particular how List<Message<Tuple>> as the payload.

this should link back to a new section in the aggregator that also mentions List<Message<Tuple>>

Change title from  Creating a Job Item Processor to Creating a Job Module",XD-2028,Mark Pollack,Add docs for creating a Job Module
1722,,Mark Pollack,"https://github.com/spring-projects/spring-xd/wiki/Creating-a-Job-Item-Processor

should be very brief introduction to this topic, before linking to relevant spring batch documentation.",XD-2027,Mark Pollack,"Add docs for ""Creating a job Item Processor"""
1723,Janne Valkealahti,Ilayaperumal Gopinathan,"If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to '0', the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port.

We also need to persist the admin servers' ports into ZK so that this repo can be accessed by the client.",XD-2026,Ilayaperumal Gopinathan,Handle random available http port for admin server
1724,Thomas Risberg,Thomas Risberg,Need a re-write of the configuration files for YARN deployments,XD-2025,Thomas Risberg,Update spring-xd-yarn configuration options
1725,,Mark Pollack,"issue seems to be

error	25-Jul-2014 18:36:18	cat: gemfire.pid: No such file or directory
error	25-Jul-2014 18:36:18	Usage:
error	25-Jul-2014 18:36:18	  kill pid ...              Send SIGTERM to every process listed.
error	25-Jul-2014 18:36:18	  kill signal pid ...       Send a signal to every process listed.
error	25-Jul-2014 18:36:18	  kill -s signal pid ...    Send a signal to every process listed.
error	25-Jul-2014 18:36:18	  kill -l                   List all signal names.
error	25-Jul-2014 18:36:18	  kill -L                   List all signal names in a nice table.
error	25-Jul-2014 18:36:18	  kill -l signal            Convert between signal numbers and names.
error	25-Jul-2014 18:36:18	rm: cannot remove `gemfire.pid': No such file or directory",XD-2024,Mark Pollack,Fix failing script integration tests
1726,Thomas Risberg,Mark Pollack,A bug in the HDFS Store was discovered that should be fixed. ,XD-2023,Mark Pollack,Update to Spring Hadoop 2.0.2
1727,Mark Pollack,Mark Pollack,0xData is a rich JVM based machine learning and scoring engine.,XD-2022,Mark Pollack,0xData - investigate embedding
1728,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Please refer to: https://github.com/spring-projects/spring-xd/issues/1119,XD-2021,Ilayaperumal Gopinathan,Admin UI: Deployment Status tooltip should close when the controller scope is lost
1729,Glenn Renfro,Glenn Renfro,"Replace the execution of JPS to retrieve PID for the containers in the acceptance tests with runtimeOperations().listRuntimeContainers().

",XD-2020,Glenn Renfro,Replace jps calls to get the PIDs for the container log with listRuntimeContainers
1730,,Glenn Renfro,"1)StreamUtils should be removed (in that static util classes are frowned upon) and its functionality should be placed in the appropriate classes. 

2) XdEnvironment - Many classes use this to obtain Environment variables.  The environment variables should be obtained via @Value in the classes that they are required. Only those values that require special setup ssh private key, Connection factories should remain in XdEnvironment.
",XD-2019,Glenn Renfro,Refactor StreamUtils in Acceptance Tests
1731,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The reference pdf doc has some of the images not aligned well within the document.

For the latest doc from snapshot build, please refer here:

http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/",XD-2018,Ilayaperumal Gopinathan,Fix images alignment in reference pdf doc
1732,Ilayaperumal Gopinathan,Florent Biville,"When I start xd-singlenode for instance, I would expect to see http://localhost:9393/admin-ui listed in the logs.",XD-2017,Florent Biville,Spring XD should log the address of the admin UI
1733,David Turanski,Mark Pollack,"Here is a strawman
{noformat}
Getting Started  (rather meaty compared to other top level sections, maybe have a section - running in SingleNode)
* Running in Distributed Mode
* Running on YARN
*Application Configuration
Message Bus Configuration
Monitoring and Management

Technical Documentation  

Architecture
Distributed Runtime  (remove 'XD' prefix)
Interactive Shell
Batch Jobs
Streams
Modules
Tuples
Sources
Processors
Analytics
Sinks
Taps
Type Conversion
Deployment  (better name?)
Best Practices (new section)

Admin UI
DSL Reference
REST API

Samples

{noformat}",XD-2016,Mark Pollack,Reorganize TOC for manual
1734,Gunnar Hillert,Florent Biville,"Currently, end-to-end tests of Spring XD UI will not run, as protractor relies on a non-existing chromedriver.exe file.

Either the configuration has to be removed from the Gruntfile or the necessary dependencies should be there.",XD-2015,Florent Biville,Spring XD UI: end-to-end tests do not work
1735,,Mark Pollack,"The condition that leads to this exception does not seem like it would ever occur, namely the BPP processing a job deployment for a job that was already deployed to the same container.",XD-2014,Mark Pollack,Investigate throwing of exception in BatchJobRegistryBeanPostProcessor
1736,,Ilayaperumal Gopinathan,"Based on this change, https://github.com/spring-projects/spring-xd/commit/87b97a0b4651f862e8a639697745ad232bb42e6a
The gradle build scripts now refer to two different places to check for the list of hadoop distro sub projects. We can simplify this to make it available in one place so that maintenance will be easier.",XD-2013,Ilayaperumal Gopinathan,Build scripts can refer hadoop distro sub projects in a unique place
1737,Mark Pollack,Mark Pollack,,XD-2012,Mark Pollack,Upgrade to Spring Shell 1.1 GA
1738,Glenn Renfro,Glenn Renfro,"When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available, so Mark wrote one for XD.  The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.",XD-2011,Glenn Renfro,Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter
1739,Eric Bottard,Eric Bottard,,XD-2010,Eric Bottard,Fix package-info.java warnings
1740,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Container's module deployer (org.springframework.xd.dirt.module.ModuleDeployer) has some unused code and container-server.xml has listeners.xml which is no longer used. Also, all the extension code is moved to SharedContextConfiguration.",XD-2009,Ilayaperumal Gopinathan,Cleanup Module Deployer
1741,Ilayaperumal Gopinathan,Mark Pollack,"https://docs.sonatype.org/display/Repository/Central+Sync+Requirements

has a list of requirements.  This also means that https://jira.spring.io/browse/XD-1509 is critical to fix.",XD-2008,Mark Pollack,Verify we meet all requirements to publish to maven central
1742,Glenn Renfro,Glenn Renfro,"Introduced by XD-2006, admin and container logs will have a pid suffix appended to their filename.
The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the xd_container_log_dir.",XD-2007,Glenn Renfro,Acceptance test must be able to handle log names with PID suffix
1743,Patrick Peralta,Patrick Peralta,"Propose the following changes to our logging:
* Create unique file names by including the pid in the file name - this allows each process (in particular containers) to maintain its own log file
* Use DailyRollingFileAppender to roll files over on a daily basis ",XD-2006,Patrick Peralta,Logging improvements
1744,Patrick Peralta,Patrick Peralta,"{noformat}
13:23:57,643  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@1c736092 moduleName = 'log', moduleLabel = 'log', group = 'paymenttap', sourceChannelName = 'tap:job:payment', sinkChannelName = [null], sinkChannelName = [null], index = 0, type = sink, parameters = map[[empty]], children = list[[empty]]]
13:23:57,643 ERROR main-EventThread imps.CuratorFrameworkImpl - Watcher exception
java.lang.IllegalStateException: instance must be started before calling this method
at com.google.common.base.Preconditions.checkState(Preconditions.java:176)
at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:344)
at org.springframework.xd.dirt.server.ContainerRegistrar.unregisterTap(ContainerRegistrar.java:292)
at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:257)
at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:711)
at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)
at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
{noformat}

Sequence of events:
* Stream module ZK path is removed
* Event is raised
* ZK connection is closed
* Event handler causes module undeployment which includes unregistration of tap
* Since connection is closed, exception is thrown
",XD-2005,Patrick Peralta,IllegalStateException when shutting down container
1745,Patrick Peralta,Glenn Renfro,"SHA = a205d43f0b59e1984bf55c3368b031a373a03712
Environment: Rabbit Transport Test 1 admin 2 containers.

[Initial Event]
During the run of FileJdbcTest.testPartitionedFileJdbcJob the containers quit responding to the admin server.   After the initial failure at 12:26:46 no other streams can be deployed.  

[Secondary Event]
When shutting down one of the container 1 the following exception occurs on the admin server:
12:51:12,004  INFO DeploymentSupervisorCacheListener-0 server.DepartingContainerModuleRedeployer - Container departed: Container{name='5353dc4b-6068-49a0-8981-fa175869edf0', attributes={id=5353dc4b-6068-49a0-8981-fa175869edf0, host=domU-12-31-39-07-81-02, pid=1270, groups=, ip=10.209.130.240}}
12:51:12,004 ERROR DeploymentSupervisorCacheListener-0 cache.PathChildrenCache - 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/5353dc4b-6068-49a0-8981-fa175869edf0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)
	at org.springframework.xd.dirt.server.DepartingContainerModuleRedeployer.deployModules(DepartingContainerModuleRedeployer.java:101)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:104)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

The attached container logs are only partial, because they have rolled over.  The attached admin log is fairly complete.
",XD-2004,Glenn Renfro,Containers stopped responding to Admin
1746,Glenn Renfro,Glenn Renfro,"In cases where the deployment requires jars that can not be included with the distribution, the user should be able to pull a jar from a http site and place it in lib/xd.  

The use case is that when we removed the mysql jar from the distribution, the CI tests could not start the XD instances on EC2 without it.  It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests.",XD-2003,Glenn Renfro,"In EC2 deployment, Allow users to set download jars into the lib/xd directory "
1747,,Ilayaperumal Gopinathan,"Determine a better package name for the following packages once we have a common model that applies to both stream/job:

`org.springframework.xd.dirt.stream`  
`org.springframework.xd.dirt.stream.zookeeper` 
",XD-2002,Ilayaperumal Gopinathan,Rename packages that is applicable for both stream/job
1748,,Eric Bottard,"The REST API for DSL completion currently returns a List<String>.

This prevents future backwards compatible extension.
Should change to List<Completion> where Completion has e.g. a ""text"" property.",XD-2001,Eric Bottard,REST API for DSL completion should allow extension
1749,,Eric Bottard,see https://github.com/FasterXML/jackson-module-afterburner,XD-2000,Eric Bottard,Consider usage of jackson afterburner
1750,Ilayaperumal Gopinathan,Mark Pollack,,XD-1999,Ilayaperumal Gopinathan,Remove unused post module references
1751,Eric Bottard,Mark Pollack,"The jars

 jersey-test-framework-core-1.9.jar
 jersey-test-framework-grizzly2-1.9.jar

are incorrectly classified as compile time deps in hadoop vs. testCompile.

",XD-1998,Mark Pollack,Remove jersey test framework for xd/lib distribution
1752,,Mark Fisher,"The AggregateCounterTests were created to satisfy XD-1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added (including the testing of the Redis-based implementation in addition to in-memory).

For more info, see the comment here:
https://github.com/spring-projects/spring-xd/pull/1087#issuecomment-49638189",XD-1997,Mark Fisher,Add comprehensive tests for AggregateCounterRepository
1753,Gunnar Hillert,Ilayaperumal Gopinathan,"After clicking 'deploy' on the definitions page, the 'deploy' button is deactivated and message says:

""An error occurred. We were unable to retrieve the module name from the provided definition ....""
and web console says:

TypeError: Cannot read property '0' of null
    at Object.getModuleNameFromJobDefinition (http://localhost:9393/admin-ui/scripts/shared/services.js:43:26)
    at http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:35:36
    at wrappedCallback (http://localhost:9393/admin-ui/lib/angular/angular.js:11319:81)
    at http://localhost:9393/admin-ui/lib/angular/angular.js:11405:26
    at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)
    at Scope.$digest (http://localhost:9393/admin-ui/lib/angular/angular.js:12224:31)
    at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12516:24)
    at done (http://localhost:9393/admin-ui/lib/angular/angular.js:8204:45)
    at completeRequest (http://localhost:9393/admin-ui/lib/angular/angular.js:8412:7)
    at XMLHttpRequest.xhr.onreadystatechange (http://localhost:9393/admin-ui/lib/angular/angular.js:8351:11) ",XD-1996,Ilayaperumal Gopinathan,Inconsistent failure while deploying job from admin UI
1754,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"For the Job execution list, the step execution count for each job execution is always set to zero.

For a single job execution display command, the step execution count is set correctly.",XD-1995,Ilayaperumal Gopinathan,Step execution count is zero for the job execution list result
1755,Gunnar Hillert,Gunnar Hillert,"I am converting a Spring XD Sample (Batch notifications) from copying jars to (old way)

{code}
$XD_HOME/lib
{code}

To rather copy the module jar to (new preferred way)

{code}
$XD_HOME/modules/job/payment-import/lib
{code}

By doing so, I hit a classloader issue. Custom classes and resources are loaded in Spring XD using *org.springframework.xd.module.support.ParentLastURLClassLoader*.

However, the sample is initializing custom bean definitions and one of those creates a new *DataSource* using the *EmbeddedDatabaseBuilder*. This class however, under the hood, uses the *Default* class loader to load SQL scripts:

{code}
	public DefaultResourceLoader() {
		this.classLoader = ClassUtils.getDefaultClassLoader();
	}
{code}

Therefore, the SQL scripts are NOT FOUND.

*Possible Solution*

A possible solution seems to be for *ParentLastURLClassLoader* to set itself as the context ClassLoader for the current thread:

{code}
	public ParentLastURLClassLoader(URL[] classpath, ClassLoader parent) {
		...
		Thread.currentThread().setContextClassLoader(this);
		...
	}
{code}",XD-1994,Gunnar Hillert,ParentLastURLClassLoader should set itself as context ClassLoader
1756,Kashyap Parikh,Mark Pollack,,XD-1993,Mark Pollack,Update rpm and brew recipes
1757,,Mark Pollack,,XD-1992,Mark Pollack,Release 1.0 RC1
1758,Ilayaperumal Gopinathan,David Turanski,"e.g., 

^C09:42:00,882 ERROR localhost-startStop-2 loader.WebappClassLoader - The web application [] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak.

The thread name may be different...",XD-1991,David Turanski,Error message about memory leak when ctrl-c xd-container and xd-admin
1759,Eric Bottard,Gary Russell,"http://stackoverflow.com/questions/24819401/how-to-get-spring-xd-to-deploy-a-predefined-set-of-streams-and-taps-on-startup

It is documented here https://github.com/spring-projects/spring-xd/wiki/Shell#executing-a-script

But maybe it should also be at the top of the appendix?

https://github.com/spring-projects/spring-xd/wiki/ShellReference",XD-1990,Gary Russell,Add Docs (or Reference) For Standard Shell Commands (e.g. script)
1760,Ilayaperumal Gopinathan,Thomas Risberg,"Some hadoop commands generate warnings/deprecation messages. We should try to get rid of most of them.

{code}
xd:>hadoop fs ls /xd --recursive 
Hadoop configuration changed, re-initializing shell...
lsr: DEPRECATED: Please use 'ls -R' instead.
13:01:07,120  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
drwxr-xr-x   - trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount
drwxr-xr-x   - trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount/output
-rw-r--r--   3 trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount/output/_SUCCESS
-rw-r--r--   3 trisberg supergroup        833 2014-07-17 11:19 /xd/hashtagcount/output/part-r-00000
drwxr-xr-x   - trisberg supergroup          0 2014-07-16 18:28 /xd/tweets
-rw-r--r--   3 trisberg supergroup     982993 2014-07-16 18:28 /xd/tweets/tweets-0.txt
{code}",XD-1989,Thomas Risberg,Remove warnings from Shell hadoop commands
1761,,Glenn Renfro,"To remain consistent across all (processor, sink, job) tests, http should be used as the source.   ",XD-1988,Glenn Renfro,Remove Trigger as a source for Acceptance Tests
1762,,Glenn Renfro,Create a test specific to for the trigger source instead of it being tested with other Acceptance tests.,XD-1987,Glenn Renfro,Create Acceptance Test for source Trigger
1763,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Fix package tangle issue reported here:

https://build.spring.io/browse/XD-SONAR-490",XD-1986,Ilayaperumal Gopinathan,Fix package tangle
1764,Thomas Risberg,Thomas Risberg,"Trying to deploy the hashtagcount batch sample [1] to Hadoop 2.4.1 or Hortonworks HDP 2.1 fails with an IllegalAccessError exception.

Looks like a Guava versioning issue - Swapping out guava-17.0.jar for guava-11.0.2.jar in the xd/lib directory solves it.

Mark P suggested we try 16.0.1 which is what Curator uses and that seems to work as well. 

Looking into changing the build to not force 17.0 which is the IO platform version.

http://upstream-tracker.org/java/compat_reports/guava/16.0.1_to_17.0/src_compat_report.html 


I get the following exception:

{code}
16:42:22,214  INFO Deployer server.JobDeploymentListener - Deployment status for job 'hashtagCountJob': DeploymentStatus{state=deployed}
16:42:27,315  WARN task-scheduler-2 mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16:42:27,325 ERROR task-scheduler-2 step.AbstractStep - Encountered an error executing step hashtagcount in job hashtagCountJob
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:369)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:493)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:510)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:394)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1282)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1303)
	at org.apache.hadoop.mapreduce.Job$$FastClassBySpringCGLIB$$a048cbfe.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:708)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:133)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:121)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:644)
	at org.apache.hadoop.mapreduce.Job$$EnhancerBySpringCGLIB$$875ec891.waitForCompletion(<generated>)
	at org.springframework.data.hadoop.mapreduce.JobExecutor$2.run(JobExecutor.java:199)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.data.hadoop.mapreduce.JobExecutor.startJobs(JobExecutor.java:170)
	at org.springframework.data.hadoop.batch.mapreduce.JobTasklet.execute(JobTasklet.java:90)
	at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:406)
	at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:330)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133)
	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271)
	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77)
	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:368)
	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)
	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144)
	at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy44.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.GeneratedMethodAccessor98.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy125.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy123.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.GeneratedMethodAccessor98.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy125.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy123.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{code}

[1] https://github.com/spring-projects/spring-xd-samples",XD-1985,Thomas Risberg,Packaging of Guava 17 results in failure to deploy mapreduce job to Hadoop 2.4 based distros
1765,Patrick Peralta,David Turanski,"A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ",XD-1984,David Turanski,Avoid all modules deploying to the first container instance upon system restart
1766,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the container which has modules deployed disconnects/reconnects to the cluster while the admin leader isn't available, following exception is thrown:
This is more likely to happen in single-node scenario as there is no admin leader re-election there. In distributed mode, we can always setup HA on admins so that the leadership re-election happens.

20:03:16,307 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache - 
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/allocated/53f41042-8abd-443b-abfb-ba42a24fb9fb/foo.sink.log.1/metadata
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at org.springframework.xd.dirt.server.ContainerRegistrar.writeModuleMetadata(ContainerRegistrar.java:486)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:461)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:426)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:807)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)",XD-1983,Ilayaperumal Gopinathan,NodeExists Exception upon container disconnect/reconnect without admin leader
1767,Gary Russell,Gary Russell,,XD-1982,Gary Russell,Add Https Support to the HTTP Source
1768,,Eric Bottard,"https://github.com/spring-projects/spring-xd/commit/db66aa2a329a6fc7ef89a340dd4d562fa70d14a4 introduces org.apache.tomcat.embed:tomcat-embed-logging-log4j which is not covered by platform. Yet, we should lookup the version to use from other tomcat artifacts, using some gradle magic",XD-1981,Eric Bottard,Automatically align version for tomcat components from platform
1769,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the admin, container and singlenode servers start, the ""Started ..Application"" log message is displayed everytime the spring application is created.
We should only log when the server is started eventually.",XD-1980,Ilayaperumal Gopinathan,Remove duplicate logger info on application started
1770,Eric Bottard,Glenn Renfro,"The log sink is not writing information to the log.
Not the solution but, when log4j.rootLogger is set to INFO, the log sink information is written to the log.  ",XD-1979,Glenn Renfro,Change xd.sink logging level to INFO
1771,Gary Russell,Gary Russell,,XD-1978,Gary Russell,SSL Support For RabbitMQ (Bus and Modules)
1772,,Glenn Renfro,"Many attributes in Mixins use hard coded values instead of using property placeholders.  

JdbcConnectionMixin, JdbcConnectionPoolMixin, MqttConnectionMixin...",XD-1977,Glenn Renfro,Mixins need to use Property PlaceHolders instead of hard coded values where possible
1773,Gunnar Hillert,Thomas Risberg,"This only happens when creating jobs via the CLI and deploying using the UI

On the job page:
http://localhost:9393/admin-ui/#/jobs/definitions

I click [Deploy] for a Job and get a screen asking for Container Match Criteria and Job Module Count - clicking on the [Deploy] button on that screen does nothing - I see this error reported:

Deploying Job Definition undefined angular.js:9778
TypeError: Cannot read property 'jobDefinition' of undefined
    at Scope.$scope.deployDefinition (http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:52:78)
    at http://localhost:9393/admin-ui/lib/angular/angular.js:10567:21
    at http://localhost:9393/admin-ui/lib/angular/angular.js:18627:17
    at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)
    at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12510:23)
    at HTMLButtonElement.<anonymous> (http://localhost:9393/admin-ui/lib/angular/angular.js:18626:21)
    at HTMLButtonElement.jQuery.event.dispatch (http://localhost:9393/admin-ui/lib/jquery/jquery.js:5095:9)
    at HTMLButtonElement.elemData.handle (http://localhost:9393/admin-ui/lib/jquery/jquery.js:4766:46) angular.js:9778",XD-1976,Thomas Risberg,Unable to deploy job in UI
1774,Gary Russell,Thomas Risberg,"To reproduce - 

Download recent snapshot - http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/spring-xd-1.0.0.BUILD-20140715.101224-1-dist.zip

Start XD and shell -
xd:>stream create --name tweets --definition ""twitterstream | file"" --deploy 
xd:>stream undeploy --name tweets 

(Note: the IllegalStateException has been fixed for RC1, still need to fix the MessageDeliveryException)

There is an error logged in the logs:

{code}
08:37:57,022  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=twitterstream, type=source, group=tweets, index=0 @581a12b9]
08:38:02,685  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@4807f3e2 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'tweets', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map[[empty]], children = list[[empty]]]
08:38:02,687  INFO main-EventThread module.ModuleDeployer - removed SimpleModule [name=twitterstream, type=source, group=tweets, index=0 @581a12b9]
08:38:02,705  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar - Path cache event: /deployments/modules/allocated/fa40cb45-3c16-4b19-81e9-eb6d357d186d/tweets.source.twitterstream.1, type: CHILD_REMOVED
08:38:02,779  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream.
org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=twitterstream, type=source, group=tweets, index=0 @581a12b9]:default,container:0.to.discardDeletes'.
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy81.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.x.twitter.TwitterStreamChannelAdapter.doSendLine(TwitterStreamChannelAdapter.java:154)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:553)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:521)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 33 more
08:38:02,780  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream, waiting for 250 ms before restarting
08:38:02,781 ERROR task-scheduler-4 handler.LoggingHandler - java.lang.IllegalStateException: java.lang.InterruptedException: sleep interrupted
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:258)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.waitLinearBackoff(AbstractTwitterInboundChannelAdapter.java:232)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.access$600(AbstractTwitterInboundChannelAdapter.java:54)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:174)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:254)
	... 11 more
{code}
",XD-1975,Thomas Risberg,Undeploying twitterstream logs warning - MessageDeliveryException
1775,Ilayaperumal Gopinathan,Thomas Risberg,The [Back] button is at lower left of the page which requires scrolling all the way to the bottom - could we move it to top right? Would make clicking back and forth for job executions much easier.,XD-1974,Thomas Risberg,Move [Back] button to top right
1776,,Mark Pollack,"In dev mode I created a twitter stream, rebuilt the server, and then wanted to destroy it.

My new install didn't have any twitter keys as I was also not using XD_CONFIG_LOCATION.

xd:>stream destroy --name tweets 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module twitterstream of type source:
    consumerKey: You must provide a 'consumerKey' token to use this module.
    consumerSecret: You must provide a 'consumerSecret' token to use this module.


I should be able to destroy a stream w/o having to supply values for PPCs.",XD-1973,Mark Pollack,stream destroy does not need to validate metadata
1777,liujiong,Michael Minella,"h3.  Narrative
As a developer, I need to be able to create a Spring XD job module that consists of a job orchestrating the execution of other Spring Batch jobs using the Spring Batch Job Step (see section 5.3.6 here: http://docs.spring.io/spring-batch/reference/html/configureStep.html) within the same module definition.

h3.  Acceptance Criteria
# Define the ""contract"" for a job module
## Currently the contract consists of a single job definition within the assembled {{ApplicationContext}} ({{context.getBean(Job.class)}}).
## The new version will need to document what job definition within the assembled {{ApplicationContext}} should be run as the entry point.  I'm assuming it would be by id ({{context.getBean(""job"")}} for example) of the job but am open to other options.
# A custom job module that orchestrates multiple Spring Batch jobs via Job steps should be able to be deployed and executed as a single Spring XD module.
## Spring XD launches the job that conforms to the previously defined ""contract"".
## Spring Batch manages the execution of the child jobs.
# The existing OOTB jobs should work under the new ""contract"".

h3.  Assumptions
# The UI should ""just work"" in that child jobs update the job repository independently so no updates should be needed for an MVP of this functionality.
# *This will be a breaking change for users that have developed custom job modules.*

h3.  Out of Scope
# Execution of child jobs that are remote (deployed on another node / {{ApplicationContext}}).
# Dynamically assembling jobs via the shell's DSL or the UI.
",XD-1972,Michael Minella,Add ability to define nested jobs
1778,,Michael Minella,"When a validation error occurs in the UI, it is displayed as a small box then fades away.  If it is a larger form or a less specific error, the user may not catch everything before it fades away.  We should display the error in a way that they can refer to as they are fixing it.",XD-1971,Michael Minella,Display errors in a persistent way
1779,Gary Russell,Gary Russell,"The Rabbit {{SMLC}} uses a {{SimpleAsyncTaskExecutor}} by default.

This makes it difficult to debug when multiple modules are in the same container because all threads are named {{SimpleAsyncTaskExecutor-1}}.",XD-1970,Gary Russell,Name the TaskExecutors in the RabbitMessageBus
1780,,Glenn Renfro,"Acceptance tests check the number of ""sends"" for each module after a single event is triggered.  This should entail that each module in the stream should have a send count of ""1"".  
Sporadically this test will fail on a sink, where the send count will be 2.  

The stacktrace below occurred on a singleAdmin/2 container deployment with rabbit as its transport and this stream was used: ""tcp --port=1234 |file --binary=true --mode=REPLACE""

java.lang.AssertionError: java.lang.AssertionError: Module file.1 for channel input did not have expected count  expected:<1> but was:<2>
java.lang.AssertionError: Module file.1 for channel input did not have expected count  expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.springframework.xd.integration.util.XdEc2Validation.verifySendCounts(XdEc2Validation.java:349)
	at org.springframework.xd.integration.util.XdEc2Validation.verifySendCounts(XdEc2Validation.java:323)
	at org.springframework.xd.integration.util.XdEc2Validation.assertReceived(XdEc2Validation.java:140)
	at org.springframework.xd.integration.test.AbstractIntegrationTest.assertReceived(AbstractIntegrationTest.java:490)
	at org.springframework.xd.integration.test.TcpTest.testTCPSourceCRLF(TcpTest.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:233)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:87)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:176)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)",XD-1969,Glenn Renfro,Send count check occasionally fails on Acceptance tests.
1781,,Glenn Renfro,"HdfsTest uses the following stream to test the hdfs sink.  trigger --payload='foobar' | hdfs.  In the test failure, the test reported that no file was created on the hdfs.  

I'm wondering if the trigger fired before the hdfs was fully deployed. 

I would say that we set the phase to the maximum, but the problem is that by default it is MAX_INT.  Thoughts?",XD-1968,Glenn Renfro,HdfsTest in Acceptance test fails sporadically (uses trigger as a source)
1782,David Turanski,Thomas Risberg,"We used to have distro specific jars i the lib/[distro] directory. That is no longer working and all distros seem to contain mostly the same version (hadoop 2.2.0 dependencies)

This is the list for phd1 now:

avro-1.7.5.jar
hadoop-annotations-2.2.0.jar
hadoop-auth-2.2.0.jar
hadoop-client-2.0.5-alpha-gphd-2.1.0.0.jar
hadoop-common-2.2.0.jar
hadoop-distcp-2.2.0.jar
hadoop-hdfs-2.2.0.jar
hadoop-mapreduce-client-app-2.2.0.jar
hadoop-mapreduce-client-common-2.2.0.jar
hadoop-mapreduce-client-core-2.2.0.jar
hadoop-mapreduce-client-jobclient-2.2.0.jar
hadoop-mapreduce-client-shuffle-2.2.0.jar
hadoop-streaming-2.2.0.jar
hadoop-yarn-api-2.2.0.jar
hadoop-yarn-client-2.2.0.jar
hadoop-yarn-common-2.2.0.jar
hadoop-yarn-server-common-2.2.0.jar
hadoop-yarn-server-nodemanager-2.2.0.jar
jersey-core-1.9.jar
jersey-server-1.9.jar
jetty-util-6.1.26.jar
protobuf-java-2.5.0.jar
spring-data-hadoop-2.0.1.RELEASE.jar
spring-data-hadoop-batch-2.0.1.RELEASE.jar
spring-data-hadoop-core-2.0.1.RELEASE.jar
spring-data-hadoop-store-2.0.1.RELEASE.jar
",XD-1967,Thomas Risberg,Dependendcies for Hadoop distros are broken 
1783,Thomas Risberg,Ilayaperumal Gopinathan,"When constructing StepExecutionInfo, the TaskletType class could not be loaded as the spring-data-hadoop-batch jar is missing from admin classpath in distributed mode.

Following exception is thrown:

SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/data/hadoop/batch/hive/HiveTasklet] with root cause
java.lang.ClassNotFoundException: org.springframework.data.hadoop.batch.hive.HiveTasklet
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at org.springframework.xd.dirt.job.TaskletType.<clinit>(TaskletType.java:57)
	at org.springframework.xd.dirt.job.StepExecutionInfo.<init>(StepExecutionInfo.java:94)
	at org.springframework.xd.dirt.rest.BatchStepExecutionsController.details(BatchStepExecutionsController.java:98)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)",XD-1965,Ilayaperumal Gopinathan,StepExecutionInfo can not be retrieved in distributed mode
1784,Ilayaperumal Gopinathan,Mark Pollack,"12:30:43,930  WARN main logging.LoggingApplicationListener - Logging environment value 'file:/data/projects/spring-xd/build/dist/spring-xd/xd/config///xd-container-logger.properties' cannot be opened and will be ignored

There are extra slashes in there.... probably due to some recent changes related to xd/config location in the scripts.",XD-1964,Mark Pollack,Servers not finding logging file
1785,Mark Fisher,Mark Fisher,"Curator 2.6.0 was released on July 11:
https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12314425&version=12327098",XD-1963,Mark Fisher,Upgrade Curator to 2.6.0
1786,Glenn Renfro,Glenn Renfro,"The acceptance tests interrogate the XD-Admin for the containers that are available.  When on EC2 the admin only returns the internal EC2 addresses without the associated suffix of .ec2.internal or .compute-1.internal.   

[Defect]
The acceptance tests only handled the most common suffix of .ec2.internal.  Thus some CI Acceptance tests will fail because, because the container's IPs were not properly mapped.  Thus the acceptance tests should map internal to external IP without regard to the suffixes EC2 issues.

FYI
EC2 issues addresses in 2 different formats: ip-XXX-XXX-XXX-XXX.ec2.internal or domU-XX-XX-XX-XX-XX-XX.compute-1.internal.  The code only able to handle ip-XXX-XXX-XXX-XXX.ec2.internal.  ",XD-1962,Glenn Renfro,Acceptance Tests fail to map some EC2 internal IPs to External IPs
1787,Eric Bottard,Thomas Risberg,The 'module info' command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does 'fairQueue' have to do with filejdbc jobs?,XD-1961,Thomas Risberg,Module info for jdbc sink and jobs are unreadable
1788,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the leadership election happens, the new deployment supervisor's container listener tries to deploy unallocated modules (via ArrivingContainerModuleRedeployer) into existing container that has the modules of the same type on a given stream/job already deployed.

Currently, on a given stream/job we don't allow more than one deployment of the same module type and there by avoiding any conflicting properties for the given module type.
",XD-1960,Ilayaperumal Gopinathan,Prevent deploying modules of same type on a given stream/job when new leadership election happens
1789,Patrick Peralta,Patrick Peralta,"Steps to reproduce:

h6. 1. Clear out ZK
{code}
[zk: localhost:2181(CONNECTED) 0] rmr /xd
{code}

h6. 2. Start admin

h6. 3. Deploy stream
{code}
xd:>stream create --name tt --definition ""time|log"" --deploy 
{code}

Admin log:
{code}
16:38:10,537  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='tt'}
16:38:10,545  WARN Deployer server.StreamDeploymentListener - No containers available for deployment of module 'log' for stream 'tt'
16:38:10,547  WARN Deployer server.StreamDeploymentListener - No containers available for deployment of module 'time' for stream 'tt'
16:38:10,547  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'tt': DeploymentStatus{state=failed}
16:38:10,550  INFO Deployer server.StreamDeploymentListener - Stream Stream{name='tt'} deployment attempt complete
{code}

h6. 4. Shut down and restart admin. The following is logged:
{code}
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/tt/modules
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)
	at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)
	at org.springframework.xd.dirt.server.StreamDeploymentListener.recalculateStreamStates(StreamDeploymentListener.java:207)
	at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:352)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)

{code}
",XD-1959,Patrick Peralta,NoNodeException after bouncing admin server
1790,Gary Russell,Thomas Risberg,"The filejdbc job is broken in distributed mode (redis and rabbit)

To reproduce:

export XD_TRANSPORT=rabbit

start xd-admin
start xd-container

start shell and create this job:

{code}
>job create mydata --definition ""filejdbc --names=col1,col2,col3 --resources=file:///home/trisberg/Test/input/*.csv --initializeDatabase=true"" --deploy
>job launch mydata
{code}

results in JOB starting but never completing:

{code}
>job execution list
  Id  Job Name  Start Time                            Step Execution Count  Execution Status  Deployment Status  Definition Status
  --  --------  ------------------------------------  --------------------  ----------------  -----------------  -----------------
    0  mydata      2014-07-11 15:44:33 America/New_York  0                     STARTED           Deployed           Exists
{code}

Steps:

{code}
Step Id	Step Name	Reads	Writes	Commits	Rollbacks	Duration	Status	Details
0	step1-master	0	0	0	0	-1405349644032 ms	EXECUTING	
1	step1-master:partition0	292	292	3	0	302 ms	COMPLETED	
2	step1-master:partition1	292	292	3	0	203 ms	COMPLETED	
3	step1-master:partition2	292	292	3	0	193 ms	COMPLETED	
{code}

When using Redis, I also get this stacktrace in container:

{code}
15:40:51,220  INFO DeploymentsPathChildrenCache-0 boot.SpringApplication - Started application in 1.965 seconds (JVM running for 66.949)
15:40:51,220  INFO DeploymentsPathChildrenCache-0 core.SimpleModule - initialized module: SimpleModule [name=filejdbc, type=job, group=job1, index=0 @64a28a58]
15:40:51,233  INFO DeploymentsPathChildrenCache-0 redis.RedisMessageBus - binding requestor: job1.0
15:40:51,236  INFO DeploymentsPathChildrenCache-0 redis.RedisMessageBus - binding replier: job1.0
15:40:51,243  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=filejdbc, type=job, group=job1, index=0 @64a28a58]
15:40:57,110 ERROR inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'
org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.aggregator.AggregatingMessageHandler#0]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy84.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy78.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:251)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:247)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:247)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.IllegalStateException: Null correlation not allowed.  Maybe the CorrelationStrategy is failing?
	at org.springframework.util.Assert.state(Assert.java:385)
	at org.springframework.integration.aggregator.AbstractCorrelatingMessageHandler.handleMessageInternal(AbstractCorrelatingMessageHandler.java:383)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 60 more
15:41:00,129 ERROR inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'
org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.aggregator.AggregatingMessageHandler#0]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy84.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy78.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:251)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:247)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:247)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.IllegalStateException: Null correlation not allowed.  Maybe the CorrelationStrategy is failing?
	at org.springframework.util.Assert.state(Assert.java:385)
	at org.springframework.integration.aggregator.AbstractCorrelatingMessageHandler.handleMessageInternal(AbstractCorrelatingMessageHandler.java:383)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 60 more
{code}
",XD-1958,Thomas Risberg,filejdbc job broken in distributed mode
1791,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/1052#issuecomment-48761686",XD-1957,Ilayaperumal Gopinathan,Remove footer from admin UI
1792,Michael Minella,Thomas Risberg,"Setting --deleteFiles=true has no effect any longer. This also causes the Script Integration Tests to fail.

Suspect this is related to the change here https://github.com/spring-projects/spring-xd/commit/6dbac167758ce23b9a4dbf07169b2d26d1eddef1
",XD-1956,Thomas Risberg,"filepollhdfs --deleteFiles=true has no effect, files are not deleted"
1793,,Mark Pollack,,XD-1955,Mark Pollack,Remove copyright/licence info in UI screens
1794,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Upon the container shutdown, the deployed modules' contexts get closed before the corresponding `Stream/JobModuleWatcher` does the undeployment of the stream/job modules.",XD-1954,Ilayaperumal Gopinathan,Investigate deployed module context close upon container shutdown
1795,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the container that has deployed module is shutdown, following stacktrace is thrown:

10:10:27,560  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@3a615460 moduleName = 'job', moduleLabel = 'job', group = 'j4', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]]
10:10:27,560  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=job, type=job, group=j4, index=0 @7df1aff2]
10:10:27,561 ERROR main-EventThread imps.CuratorFrameworkImpl:555 - Watcher exception
java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@422fd7b7 has been closed already
	at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)
	at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:164)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:219)
	at org.springframework.xd.dirt.plugins.job.JobPlugin.removeModule(JobPlugin.java:70)
	at org.springframework.xd.dirt.module.ModuleDeployer.removeModule(ModuleDeployer.java:204)
	at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:162)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:140)
	at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:112)
	at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:256)
	at org.springframework.xd.dirt.server.ContainerRegistrar$JobModuleWatcher.process(ContainerRegistrar.java:753)
	at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
10:10:27,561  INFO main-EventThread zookeeper.ClientCnxn:512 - EventThread shut down
10:10:27,564  INFO Thread-2 jmx.EndpointMBeanExporter:433 - Unregistering JMX-exposed beans on shutdown",XD-1953,Ilayaperumal Gopinathan,Stacktrace on container with deployed modules is shutdown
1796,,Eric Bottard,"Should be part of the daily build.
One ""easy"" way to do it would be to use the ""hardcoded"" authentication scheme as described here (bamboo should mask a property whose name contains password)
We may want to create a dedicated github user though",XD-1952,Eric Bottard,Automate execution of gradle pushGeneratedDocs
1797,Eric Bottard,Eric Bottard,,XD-1951,Eric Bottard,Anchor the footer at the bottom of page
1798,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The filejdbc module's single step partition support configures to use jdbc module's datasource rather than XD's batch datasource.

```
org.springframework.messaging.MessageHandlingException: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy115.send(Unknown Source)
	at org.springframework.xd.dirt.integration.bus.LocalMessageBus$3.handleMessage(LocalMessageBus.java:188)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.access$000(UnicastingDispatcher.java:48)
	at org.springframework.integration.dispatcher.UnicastingDispatcher$1.run(UnicastingDispatcher.java:92)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:660)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:695)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:727)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:737)
	at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:811)
	at org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.getJobExecution(JdbcJobExecutionDao.java:267)
	at org.springframework.batch.core.explore.support.SimpleJobExplorer.getStepExecution(SimpleJobExplorer.java:142)
	at org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:52)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	... 41 more
Caused by: java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)
	at org.sqlite.DB.newSQLException(DB.java:383)
	at org.sqlite.DB.newSQLException(DB.java:387)
	at org.sqlite.DB.throwex(DB.java:374)
	at org.sqlite.NestedDB.prepare(NestedDB.java:134)
	at org.sqlite.DB.prepare(DB.java:123)
	at org.sqlite.PrepStmt.<init>(PrepStmt.java:42)
	at org.sqlite.Conn.prepareStatement(Conn.java:404)
	at org.sqlite.Conn.prepareStatement(Conn.java:399)
	at org.sqlite.Conn.prepareStatement(Conn.java:383)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126)
	at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:109)
	at org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:80)
	at com.sun.proxy.$Proxy109.prepareStatement(Unknown Source)
	at org.springframework.jdbc.core.JdbcTemplate$SimplePreparedStatementCreator.createPreparedStatement(JdbcTemplate.java:1557)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)
	... 63 more
12:23:37,941  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@d192973 moduleName = 'filejdbc', moduleLabel = 'filejdbc', group = 'csvjdbcjob0', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map['resources' -> 'file:///tmp/xdtest/jdbc/delete_after_use.csv', 'initializeDatabase' -> 'true', 'names' -> 'col1,col2,col3', 'deleteFiles' -> 'true', 'driverClassName' -> 'org.sqlite.JDBC', 'url' -> 'jdbc:sqlite:/tmp/xdtest/jdbc/jdbc.db'], children = list[[empty]]]
12:23:37,941  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=filejdbc, type=job, group=csvjdbcjob0, index=0 @73cc35b5]
12:23:37,944 ERROR task-scheduler-1 step.AbstractStep:225 - Encountered an error executing step step1-master in job csvjdbcjob0
org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned
	at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)
	at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy44.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy115.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy115.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
```",XD-1950,Ilayaperumal Gopinathan,Single step partition support on filejdbc module uses module's datasource
1799,Mark Pollack,Mark Pollack,,XD-1949,Mark Pollack,Ensure DSM matrix is diagonal
1800,Thomas Risberg,Thomas Risberg,The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that.,XD-1948,Thomas Risberg,Build should use Spring Boot plugin version 1.1.4 
1801,Eric Bottard,Mark Pollack,See PR https://github.com/spring-projects/spring-xd/pull/1043/,XD-1947,Eric Bottard,Fix support for @CliAvailabilityIndicator
1802,,Mark Pollack,Test to verify stream state is correct after starting/stopping containers.,XD-1946,Mark Pollack,Add stream state tests
1803,Glenn Renfro,Thomas Risberg,"Starting xd-singlenode and then ctrl-c to shut down produces WARN message that should be suppressed according to log4j config

Setting XD_CONFIG_LOCATION explicitly works for suppressing the message.

The message I see:

[2014-07-10 09:39:59.786] boot - 58034  WARN [Thread-2] --- MBeanRegistry: Failed to unregister MBean InMemoryDataTree
[2014-07-10 09:39:59.786] boot - 58034  WARN [Thread-2] --- MBeanRegistry: Error during unregister
javax.management.InstanceNotFoundException: org.apache.ZooKeeperService:name0=StandaloneServer_port-1,name1=InMemoryDataTree
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.zookeeper.jmx.MBeanRegistry.unregister(MBeanRegistry.java:115)
	at org.apache.zookeeper.jmx.MBeanRegistry.unregister(MBeanRegistry.java:132)
	at org.apache.zookeeper.server.ZooKeeperServer.unregisterJMX(ZooKeeperServer.java:465)
	at org.apache.zookeeper.server.ZooKeeperServer.shutdown(ZooKeeperServer.java:458)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.shutdown(NIOServerCnxnFactory.java:271)
	at org.apache.zookeeper.server.ZooKeeperServerMain.shutdown(ZooKeeperServerMain.java:132)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.xd.dirt.zookeeper.EmbeddedZooKeeper.stop(EmbeddedZooKeeper.java:176)
	at org.springframework.xd.dirt.zookeeper.EmbeddedZooKeeper.stop(EmbeddedZooKeeper.java:204)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStop(DefaultLifecycleProcessor.java:229)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$300(DefaultLifecycleProcessor.java:51)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.stop(DefaultLifecycleProcessor.java:363)
	at org.springframework.context.support.DefaultLifecycleProcessor.stopBeans(DefaultLifecycleProcessor.java:202)
	at org.springframework.context.support.DefaultLifecycleProcessor.onClose(DefaultLifecycleProcessor.java:118)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:888)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:841)
	at org.springframework.boot.builder.ParentContextCloserApplicationListener$ContextCloserListener.onApplicationEvent(ParentContextCloserApplicationListener.java:100)
	at org.springframework.boot.builder.ParentContextCloserApplicationListener$ContextCloserListener.onApplicationEvent(ParentContextCloserApplicationListener.java:84)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:98)
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:333)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:880)
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:809)
",XD-1945,Thomas Risberg,XD_CONFIG_LOCATION doesn't seem to be set for log4j config files 
1804,Patrick Peralta,Thomas Risberg,"Steps to reproduce:

1. start xd-admin

2. start shell and create and deploy stream (""time | hdfs"")

3. start container

I got:

[2014-07-10 09:10:29.019] boot - 19923  INFO [DeploymentSupervisorCacheListener-0] --- InitialDeploymentListener: Path cache event: /deployments/streams/test, type: CHILD_ADDED
[2014-07-10 09:10:29.137] boot - 19923  INFO [Deployer] --- StreamDeploymentListener: Deploying stream Stream{name='test'}
[2014-07-10 09:10:29.146] boot - 19923  WARN [Deployer] --- StreamDeploymentListener: No containers available for deployment of stream test
[2014-07-10 09:10:29.146] boot - 19923  INFO [Deployer] --- StreamDeploymentListener: Stream Stream{name='test'} deployment attempt complete
[2014-07-10 09:11:08.003] boot - 19923  INFO [DeploymentSupervisorCacheListener-0] --- ContainerListener: Path cache event: /containers/007c2bcc-13f4-466e-95d3-bd926bb456ea, type: CHILD_ADDED
[2014-07-10 09:11:08.006] boot - 19923  INFO [DeploymentSupervisorCacheListener-0] --- ArrivingContainerModuleRedeployer: Container arrived: 007c2bcc-13f4-466e-95d3-bd926bb456ea
[2014-07-10 09:11:08.176] boot - 19923 ERROR [DeploymentSupervisorCacheListener-0] --- PathChildrenCache: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/test/modules
  at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
  at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)
  at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)
  at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)
  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)
  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)
  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)
  at org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployUnallocatedStreamModules(ArrivingContainerModuleRedeployer.java:133)
  at org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployModules(ArrivingContainerModuleRedeployer.java:106)
  at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:99)
  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
  at java.util.concurrent.FutureTask.run(FutureTask.java:262)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
  at java.util.concurrent.FutureTask.run(FutureTask.java:262)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
  at java.lang.Thread.run(Thread.java:744)
",XD-1944,Thomas Risberg,Error deploying stream when admin running and container arrives after stream deployment request
1805,Mark Pollack,Mark Pollack,,XD-1943,Mark Pollack,Update to Spring Batch Admin 1.3.0.GA
1806,Mark Pollack,Mark Pollack,jclouds is not compatible with versions of guava higher than 15.,XD-1942,Mark Pollack,Use guava 15.0 for spring-xd-integration-test
1807,Thomas Risberg,Thomas Risberg,"Error deploying to YARN - 

$ ./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/bin/xd-yarn push -p spring-xd-1.0.0.BUILD-SNAPSHOT-yarn
no main manifest attribute, in spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/lib/spring-xd-yarn-client-1.0.0.BUILD-SNAPSHOT.jar

probably related to boot changes",XD-1941,Thomas Risberg,No main manifest attribute in xd-yarn-client jar
1808,Thomas Risberg,Thomas Risberg,Remove unnecessary/duplicated jars from the lib directory in spring-xd-yarn zip distribution,XD-1940,Thomas Risberg,Clean up duplicated dependencies from XD on YARN installation
1809,Mark Pollack,Mark Pollack,,XD-1939,Mark Pollack,Update to Spring Batch Admin 1.3.0.RC1
1810,Eric Bottard,Eric Bottard,"The XD shell completion crashes on:
job launch --name <TAB> gives
{noformat}
xd:>job launch --name Exception in thread ""Spring Shell"" java.lang.IllegalStateException: Could not determine kind: tab-completion-count-1 existing-job disable-string-converter
	at org.springframework.xd.shell.converter.CompletionConverter.determineKind(CompletionConverter.java:109)
	at org.springframework.xd.shell.converter.CompletionConverter.getAllPossibleValues(CompletionConverter.java:69)
	at org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)
	at org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)
	at jline.console.ConsoleReader.complete(ConsoleReader.java:3077)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)
	at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)
	at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)
	at java.lang.Thread.run(Thread.java:744)
{noformat}

Moreover, seems completion generally crashes when the server is not up (which was taken care of previously if I'm not mistaken):

xd:>job destroy --name <TAB>
{noformat}
Exception in thread ""Spring Shell"" org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:9393/jobs/definitions?size=10000&deployments=true"":Connection refused; nested exception is java.net.ConnectException: Connection refused
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:561)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:506)
	at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:243)
	at org.springframework.xd.rest.client.impl.JobTemplate.list(JobTemplate.java:121)
	at org.springframework.xd.rest.client.impl.JobTemplate.list(JobTemplate.java:40)
	at org.springframework.xd.shell.converter.ExistingXDEntityConverter.getAllPossibleValues(ExistingXDEntityConverter.java:72)
	at org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)
	at org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)
	at jline.console.ConsoleReader.complete(ConsoleReader.java:3077)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)
	at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)
	at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:180)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:78)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:52)
{noformat}",XD-1938,Eric Bottard,Shell completion crashes
1811,Mark Pollack,Mark Pollack,postgresql is BSD - http://jdbc.postgresql.org/about/license.html,XD-1937,Mark Pollack,Add licence files in distribution for 3rd party dependencies.
1812,Mark Pollack,Mark Pollack,"The work here is doing the research....

mysql client jar should be removed as it is GPL - http://dev.mysql.com/downloads/connector/j/5.0.html  (GPL)

postgresql is BSD so that is ok (another issue will handle license file inclusion.",XD-1936,Mark Pollack,Remove jars from .zip packaging whose license prevents distribution
1813,Eric Bottard,Eric Bottard,"Whether it's after applying https://github.com/spring-projects/spring-xd/pull/1034/ or not, this causes the following problem:

{noformat}
....
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:644)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:541)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:644)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152)
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100)
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21)
	at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:541)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:644)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:541)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:644)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152)
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100)
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21)
Caused by: java.lang.StackOverflowError
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:800)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:660)
	... 1011 more
{noformat}",XD-1935,Eric Bottard,Batch jobs executions by jobname causes stackoverflow
1814,Gunnar Hillert,Mark Pollack,,XD-1934,Mark Pollack,Update Spring Integration Splunk Extension to 1.1 GA
1815,,Mark Pollack,"Platform version of netty is 4.0.18.Final.  Current http source is using 3.7.

Packages/classes have changed in netty4",XD-1933,Mark Pollack,Update http source to use netty 4
1816,,Mark Pollack,"Should be able to specify which user,group will own the files that are written in HDFS.",XD-1932,Mark Pollack,Support user impersonation in HDFS sink
1817,Glenn Renfro,Ilayaperumal Gopinathan,"We need to make sure there is no conflicting/missing dependency with build.gradle using spring IO platform dependencies.

https://jira.spring.io/browse/XD-1929 is one such scenario where jolokia dependency went missing.",XD-1931,Ilayaperumal Gopinathan,Verify platform compatibility versions with the XD dependencies
1818,Eric Bottard,Patrick Peralta,"The following warning appears when compiling with JDK 8:


{panel}
/Users/pperalta/src/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/SingleNodeApplication.java:67: warning: auxiliary class ContainerConfiguration in /Users/pperalta/src/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/ContainerServerApplication.java should not be accessed from outside its own source file
						.child(ContainerConfiguration.class)}}
{panel}

Can this be turned into a static inner class?",XD-1930,Patrick Peralta,JDK 1.8 compile warning for ContainerConfiguration
1819,Ilayaperumal Gopinathan,Mark Pollack,"http://localhost:9393/management/jolokia/search/xd.*:type=*,*

for singlenode in M7 returned a value..... on master it returns 404 error...

",XD-1929,Mark Pollack,Jolokia endpoints returning 404
1820,liujiong,Mark Pollack,,XD-1928,Mark Pollack,Provide JMS as a supported MessageBus implementation
1821,nebhale,Mark Pollack,"Previously, the scripts all looked for the logging configuration in $XD_HOME/config (or %XD_HOME%/config). This caused issues because it meant that if you moved all of the configuration and overrode $XD_CONFIG_LOCATION (or %XD_CONFIG_LOCATION%), the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in $XD_CONFIG_LOCATION (or %XD_CONFIG_LOCATION%).",XD-1927,Mark Pollack,Find logging configuration relative to environment
1822,,Eric Bottard,"Have a REST endpoint that would run validation of a definition (without actually attempting the creation, let alone deployment) and return a structured representation of validation errors.

This to benefit the web ui",XD-1926,Eric Bottard,Create REST endpoint for validation of a job/stream definition
1823,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"For more info, please see here:

https://github.com/spring-projects/spring-xd/pull/1021/files#r14617723",XD-1925,Ilayaperumal Gopinathan,Rename ModuleDeployer
1824,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"See this for more info:
https://github.com/spring-projects/spring-xd/pull/1021/files#r14611854",XD-1924,Ilayaperumal Gopinathan,Create RuntimeModuleDescriptor that represents runtime module instance
1825,,Gunnar Hillert,"Ideally we could try out best if there was a date that didn't have the TZD format on it: e.g. figure what the local time zone is (AdminUI or Shell) and figure out if we are ahead/behind UTC.

So
* ""YYYY-MM-DDThh:mm""  would say 'try to use local time zone'
* ""YYYY-MM-DDThh:mmZ"" would be UTC
* ""YYYY-MM-DDThh:mm+4:00"" would be '4 hrs ahead of UTC

However, we need to ultimately submit an ISO compliant time to the XD server.

The UI/shell should try to be as accommodating as possible...e.g postel's law: http://en.wikipedia.org/wiki/Robustness_principle

Be conservative in what you do, be liberal in what you accept from others.

",XD-1923,Gunnar Hillert,XD Shell Should be lenient in regards to specified dates/times for triggers 
1826,,Gunnar Hillert,"Currently specified Cron Expressions are executed in the Container's default TimeZone. In *Trigger.xml* we specify:

{code}
	<beans profile=""use-cron"">
		<int:inbound-channel-adapter channel=""output""
			auto-startup=""false"" expression=""'${payload}'"">
			<int:poller cron=""${cron}"" />
		</int:inbound-channel-adapter>
	</beans>
{code}

This translates in *org.springframework.integration.config.xml.PollerParser* to

{code}
BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(CronTrigger.class);
builder.addConstructorArgValue(cronAttribute)
{code}

Which will call *org.springframework.scheduling.support.CronTrigger*:

{code}
	/**
	 * Build a {@link CronTrigger} from the pattern provided in the default time zone.
	 * @param cronExpression a space-separated list of time fields,
	 * following cron expression conventions
	 */
	public CronTrigger(String cronExpression) {
		this.sequenceGenerator = new CronSequenceGenerator(cronExpression);
	}
{code}

""Build a {@link CronTrigger} from the pattern provided in the *default time zone*.""

We need to pass-in a timezone. *Should cron expressions as part of an XD *Definition* have a TimeZone parameter?* When creating the stream via the UI or the Shell the timezone can be inferred (if not specified) but should be mandatory for the REST API, meaning being passed in as a mandatory parameter (OR alternatively, if not passed in we assume the Cron expression is specified for UTC).

That way we could ensure that a (Stream/Job) Definition is globally valid.",XD-1922,Gunnar Hillert,Make Cron-based Triggers TimeZone aware 
1827,Gunnar Hillert,Gunnar Hillert,"To bring in line with the rest of default date-formats, change the date format to yyyy-MM-dd HH:mm:ss in TriggerSourceOptionsMetadata",XD-1921,Gunnar Hillert,TriggerSourceOptionsMetadata - Change DateFormat to be ISO 8601 compliant (with TimeZone)
1828,David Turanski,David Turanski,,XD-1920,David Turanski,Update https://github.com/spring-guides/gs-spring-xd/ for new Release
1829,liujiong,Gary Russell,"XD currently has rabbit source and sink but only a source for JMS.

Add a JMS sink - the provider infrastructure should be configured in a similar manner to the source ({{--provider}}).

Other properties needed: 
{code}
destinationName
destinationExpression
sessionTransacted
deliveryPersistent*
pubSubDomain
priority*
timeToLive*
{code}

* if any of these properties are set we need to coerce the {{explicit-qos-enabled}} to be {{true}}
",XD-1919,Gary Russell,Add a JMS Sink
1830,David Turanski,David Turanski,"Need to update the examples in the TypeConversion doc, re spring social Tweet which is no longer used.",XD-1918,David Turanski,Update TypeConversion Page
1831,Thomas Risberg,Sandro Lehmann,"Hi

If I create a hdfs stream as proposed in the documentation I get some errors.

Example:
stream create --name xxx --definition ""http --port=8000 | hdfs --rollover=10"" 
stream deploy --name xxx

The exception:
Caused by: java.io.FileNotFoundException: ...spring-xd-1.0.0.M7/config/hadoop.properties (No such file or directory)
	at java.io.FileInputStream.open(Native Method)

There is a folder /spring-xd-1.0.0.M7/xd/config but no folder /spring-xd-1.0.0.M7/config
when I copied the file from /xd/config to /config it worked fine.",XD-1917,Sandro Lehmann,Exception for sample hdfs sample
1832,Glenn Renfro,Marius Bogoevici,"Using the MongoDB out-of-the-box capabilities of Spring Batch such as MongoItemReader and MongoItemWriter require that spring-data-mongodb and mongo-driver are added to xd/libs.

The above mentioned classes have dependencies on classes found in mongo-driver and spring-data-mongodb. Due to the fact that Spring Batch classes are loaded in the parent class loader, adding the complementary jars to the module will not make their dependencies visible to the deployment, resulting in a NoClassDefFoundError on spring-data-mongodb classes in this scenario.

There are a few possible solutions: 

- requiring the user to add the missing jars to the shared libs folder - this is the straightforward solution, but has the disadvantage of putting the onus on enhancing the distribution on the user (who must have knowledge of the proper version(s) to include);
- including the missing jars in the distribution (which can potentially increase its size to satisfy an optional scenario);
- increasing the granularity of the packaged Spring Batch distribution and allowing the users to add the classes on demand;

Essentially, this applies to any other dependencies of Spring Batch that are not part of the distribution. ",XD-1916,Marius Bogoevici,Batch jobs using Spring Batch MongoDB support require adding MongoDB dependencies to the shared libs folder
1833,Thomas Risberg,Thomas Risberg,Hadoop 2.4.1 is now a stable release and we should add support for running against it,XD-1915,Thomas Risberg,Add Hadoop 2.4.x as an option
1834,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"In case of the deployment property module count for a specific module in a stream/job is zero, the stream/job deployment status is calculated as ""zero"" even though the modules are deployed to all matching containers.

Currently, the DefaultStateCalculator's 'calculate' method doesn't check if the expected count is zero. 
Also, we would need all the matching containers to determine the same module is deployed to all the matching containers (in case of module count = 0)",XD-1914,Ilayaperumal Gopinathan,"Stream/Job deployment state is always ""incomplete"" in case of module count zero"
1835,,David Turanski,"FtpHdfsTest was added in https://github.com/spring-projects/spring-xd/pull/1005 but excluded since it will require some changes to run on ec2, including setting up an ftpServer on ec2 with appropriate security, etc.",XD-1913,David Turanski,Enable FtpHdfsTest
1836,Thomas Risberg,Ayyappan Arunachalam,"I am using Spring XD to ingest the data into Pivotal HD.My source is log files which is coming from logstash through Rabbitmq. I could able to ingest the log files in HDFS (by using Rabbitmq source and HDFS sink)
However when i try to ingest the data directly into Hawq by using JDBC sink,it's not working. Shall we directly load Rabbitmq source into any databases like Hawq?


stream create --name pivotalqueue --definition ""rabbit --host=<my host name>   | jdbc   --columns='colum list'""      ---Not working

I configured jdbc in jdbc.properties. There was no issue with jdbc configuration(because i tested this with simple tail source it's working and load the data into HAWQ.
stream create --name pivotalqueue --definition ""tail --name=/tmp/xd/output/test.out   | jdbc  --columns='columns list'""  )
",XD-1912,Ayyappan Arunachalam,Rabbitmq source is not ingested the data into jdbc sink
1837,,Mark Pollack,https://github.com/spring-guides/gs-spring-xd/issues/1,XD-1910,Mark Pollack,Improve getting started docs for installation
1838,Mark Pollack,Mark Pollack,,XD-1909,Mark Pollack,Update to Spring Shell 1.0 RC4
1839,Eric Bottard,Gary Russell,Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.,XD-1908,Gary Russell,Remove Retry from TCP Sink
1840,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the job is in ""deploying"" state, until we decide whether the job is actually ""deployed"" or ""failed""/""incomplete"", there is no way to know if it is fine to launch/schedule (though the launching requests are going to go to the job launch request queue). 

We could either disable both ""deploy""/""undeploy"" until the state changes from ""deploying""?",XD-1907,Ilayaperumal Gopinathan,Handle 'deploying' state at the Admin UI
1841,Ilayaperumal Gopinathan,Gunnar Hillert,"As a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (E.g. during deployment of streams/jobs)

Ideally, I would like to have this addressed on the server-side as well. It would be nice if we could propagate events between, containers and admin-server that would inform about any changes in the system. We could then use those to notify connected UI clients.",XD-1906,Gunnar Hillert,Handle Status Changes in Client (Dynamically update UI)
1842,David Turanski,Gunnar Hillert,"When deploying a definition with a container match criteria specified, and no container could be selected - the logging is ambiguous and should mention the affected module:

{code}
11:58:24,089  WARN DeploymentSupervisorCacheListener-0 cluster.DefaultContainerMatcher - No currently available containers match criteria 'somecriteria'
{code}",XD-1905,Gunnar Hillert,DefaultContainerMatcher - Improve Logging and mention affected Module
1843,,Gunnar Hillert,"In order to minimize code duplication - Create an AngularJS directive to render deployment statuses. We could even color code the various statuses.

We should also create a 2nd directive for the status-help-popover. We should consider to possibly use the Angular Bootstrap UI popover support.",XD-1904,Gunnar Hillert,Create AngularJS directive to render deployment statuses
1844,Eric Bottard,Eric Bottard,"see https://github.com/spring-projects/gradle-plugins/blob/master/propdeps-plugin/README.md

This would allow us to reduce the distribution size further maybe",XD-1903,Eric Bottard,Leverage gradle plugin for provided/optional deps
1845,,Ilayaperumal Gopinathan,"There are couple of places where jquery is being used in the admin UI and those are for some DOM manipulations.

I believe these can certainly be replaced with the use of angular directive or custom functions and thereby we can remove jQuery dependency in the app.",XD-1902,Ilayaperumal Gopinathan,Avoid using jQuery inside Admin UI
1846,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Job `undeploy` operation throws the following stacktrace:

```
http-nio-9393-exec-5 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'j' state to undeploying
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/j/status
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1266)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:260)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:256)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:252)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:239)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:39)
	at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:177)
	at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:199)
	at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:1)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:68)
	at org.springframework.xd.dirt.rest.XDController.undeploy(XDController.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
```",XD-1901,Ilayaperumal Gopinathan,Job undeploy operation throws exception
1847,Ilayaperumal Gopinathan,Gunnar Hillert,"I have a deployed Batch Job (Single Node Server, running inside STS). My machine goes to sleep. Once I bring it back up I see the following log: 

{code}
12:57:35,854 ERROR LeaderSelector-5 leader.LeaderSelector - The leader threw an exception
java.lang.IllegalArgumentException: Label is required
	at org.springframework.util.Assert.hasText(Assert.java:162)
	at org.springframework.xd.module.ModuleDescriptor$Key.<init>(ModuleDescriptor.java:616)
	at org.springframework.xd.dirt.server.JobDeploymentListener.recalculateJobStates(JobDeploymentListener.java:218)
	at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:354)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)
	at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)
	at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
{code}

In the UI the job is marked as *undeployed* - however, when I click *deploy* I get an error: *The job named 'bbb' is already deployed*.

",XD-1900,Gunnar Hillert,Batch job is marked as undeployed once computer comes back from hibernation
1848,Patrick Peralta,Patrick Peralta,"Upon shutdown via ^C, an IllegalStateException stack trace appears in the server logs. While harmless, the traces are annoying and should be prevented.",XD-1899,Patrick Peralta,IllegalStateException on single node shutdown
1849,,Sathiya Shunmugasundaram,"The build task ""gradlew dist"" fails with the following error.

00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	... 52 more
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] Caused by: javax.xml.transform.TransformerException: Failure reading /Users/ixr303/spring-xd/build/reference-work/index.xml
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	at com.icl.saxon.om.Builder.build(Builder.java:267)
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	at com.icl.saxon.Controller.transform(Controller.java:936)
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	at com.icl.saxon.Controller$transform.call(Unknown Source)
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	at AbstractDocbookReferenceTask.transform(DocbookReferencePlugin.groovy:146)
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:63)
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	... 59 more
00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] Caused by: java.io.IOException: Server returned HTTP response code: 500 for URL: http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.impl.XMLEntityManager.setupCurrentEntity(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.impl.XMLEntityManager.startEntity(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.impl.XMLEntityManager.startDTDEntity(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.impl.XMLDTDScannerImpl.setInputSource(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.impl.XMLDocumentScannerImpl$DTDDispatcher.dispatch(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
00:20:16.978 [ERROR] [org.gradle.BuildExceptionReporter] 	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
00:20:16.978 [ERROR] [org.gradle.BuildExceptionReporter] 	at com.icl.saxon.om.Builder.build(Builder.java:265)


The URL http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd returns 500 error most of the times. 

Tried to circumvent the error by manually getting the did file locally and running again causes unintended relative path issues.

Help is very much appreciated. ",XD-1898,Sathiya Shunmugasundaram,dist task failure - unable to access http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd
1850,Gary Russell,Sathiya Shunmugasundaram,"If a sink fails for whatever reason, will it be possible to handle it? Say by sending the payload to an error queue for later processing when a JDBC or Mongo sink fails due to a database connectivity loss? Or the modules are designed by certain principles / contracts not to be meant to handle such failures? ",XD-1897,Sathiya Shunmugasundaram,Spring XD - Handling sink failures
1851,Mark Pollack,Mark Pollack,,XD-1896,Mark Pollack,Investigate why netty 3.7 is in xd/lib and not 3.6.6
1852,Dave Syer,Mark Pollack,,XD-1895,Mark Pollack,Use Boot plugin and IO Platform for versions where possible
1853,Mark Fisher,Mark Pollack,"This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency.

It should also discuss the 'bypass' functionality - or reference another section that covers it.

We should probably include how to scale out http sources, e.g. the need to use a load balancer.",XD-1894,Mark Pollack,Create documentation section on best practices
1854,Mark Pollack,Mark Pollack,,XD-1893,Mark Pollack,Update to Spring Batch 3.0.1 snapshots
1855,Mark Pollack,Mark Pollack,,XD-1892,Mark Pollack,Update to Spring Platform 1.0.1
1856,Gary Russell,Mark Pollack,"See https://jira.spring.io/browse/XD-1684

Requires update to gradle 2.1",XD-1891,Mark Pollack,Add configuration files for hornetmq jms provider.
1857,Patrick Peralta,Mark Pollack,Use external JVM launch support provided by the Oracle Tools framework (https://java.net/projects/oracletools).,XD-1890,Mark Pollack,"Create multi-container, single host, testing framework"
1858,Gunnar Hillert,Gunnar Hillert,"Addressed for the REST API by XD-1848

The status of a stream, as returned by the REST API (and thus the shell also), may now contain any of the following states:

* deploying (deployment has been initiated)
* deployed (fully deployed based on each of the stream's modules' count properties)
* incomplete (at least 1 of each module, but 1 or more of them not at requested capacity)
* failed (1 or more of the modules does not have even a single instance deployed)
* undeployed (intentionally undeployed, or created but not yet deployed)
",XD-1889,Gunnar Hillert,UI Needs to handle the finer-grained deployment statuses
1859,Eric Bottard,Eric Bottard,,XD-1888,Eric Bottard,Use 2 tabs for hidden options in shell
1860,Michael Minella,Michael Minella,"h2. Narrative
As a developer, I need to be able to process the importing of files in parallel via the hdfsjdbc batch job.

h2. Acceptance Criteria
# Be able to provide a list of files to the job and have them be read in parallel based on the number of slaves deployed.
# Use {{MultiResourcePartitioner}} to create on partition per incoming file.",XD-1887,Michael Minella,Add remote partitioning to hdfsjdbc job
1861,,Gary Russell,Spring IO Compatibility,XD-1886,Gary Russell,Update Netty to 4
1862,Eric Bottard,Eric Bottard,"Not all module options are born equal. Some are more important/useful than others, and having the more ""expert"" ones show up e.g. in TAB completion is very noisy (esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit)",XD-1885,Eric Bottard,Provide ability to disable tab completion for specific module options
1863,David Turanski,Eric Bottard,"It seems that no option validation (being Spring or jsr 303) is happening anymore at stream creation time.

eg
{noformat}
stream create foo --definition ""http --port=bar | log""
{noformat}",XD-1884,Eric Bottard,Module option validation not happening anymore
1864,,Mark Pollack,"https://github.com/spring-projects/gradle-plugins/tree/master/spring-io-plugin is the starting point to introduce the appropriate plugin to check for the correct dependencies.



",XD-1883,Mark Pollack,Update dependencies to latest Spring IO platform versions
1865,Michael Minella,Michael Minella,"h2. Narrative
As a developer, I need to be able to process the importing of files in parallel via the filejdbc batch job.

h2. Acceptance Criteria
# Be able to provide a list of files to the job and have them be read in parallel based on the number of slaves deployed.
# Use {{MultiResourcePartitioner}} to create on partition per incoming file.",XD-1882,Michael Minella,Add remote partitioning to filejdbc job
1866,Eric Bottard,Eric Bottard,"Also, the approach may not work as expected on windows.",XD-1881,Eric Bottard,"HadoopDistroOptionHandler fails when XD_HOME ends with a ""/"""
1867,Glenn Renfro,Mark Pollack,"https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/tweet_tests  use field-value-counter and aggregate-counter.

Should do a simplified version of this so that we can assert values of the field-value-counter and aggregate-counter.",XD-1880,Mark Pollack,Integration test for field-value-counter and aggregate-counter
1868,Glenn Renfro,Mark Pollack,"See

https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/jdbc_tests#L96

and

https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/jdbc_tests#L64

The second assert has initializeDb=false and so there are double the number of rows running the job a second time.",XD-1879,Mark Pollack,Create test with jdbc sink and initializeDb=false
1869,,Mark Pollack,"The test

https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/httpbash

is very simple, it doesn't even check the results.  A small change to

https://github.com/spring-projects/spring-xd/blob/master/spring-xd-test-fixtures/src/main/java/org/springframework/xd/test/generator/SimpleHttpGenerator.java

so that number of messages to post is specified would be part of this work.",XD-1878,Mark Pollack,Create low volume http stress test
1870,David Turanski,Mark Pollack,"Port https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/gemfire_stream_tests

Need to consider how to start the server, maybe use the jvm fork utilities?  Look into spring-data-gemfire as well.",XD-1877,Mark Pollack,Create gemfire test
1871,Glenn Renfro,Mark Pollack,"The script tests does the following.

{code}
# Filter for good and bad
create_stream 'httpfilter' ""http | good: filter --expression=#jsonPath(payload,'\$.entities.hashtags[*].text').contains('good') \
| aftergood: filter --expression=true \
| bad: filter --expression=#jsonPath(payload,'\$.entities.hashtags[*].text').contains('bad') \
| goodandbad: splitter --expression=#jsonPath(payload,'$.id') \
| file --dir=$TEST_DIR"" 'true'
{code}",XD-1876,Mark Pollack,Create test that uses #jsonPath with the filter module
1872,,Mark Pollack,Would like to consolidate the testing infrastructure so that we have one approach for doing integration tests.  The scripts test were useful in the beginning as a quick way to get some coverage but the current tests in spring-xd-integration-test is broader and also based on standard JUnit.  ,XD-1875,Mark Pollack,Create equivalent tests in spring-xd-integration which are only present in the script based tests.
1873,Eric Bottard,Eric Bottard,"Note that the documentation for the module options (in particular for http-client) should be autogenerated using the following syntax (see others):
{noformat}
//^processor.http-client
//$processor.http-client
{noformat}

",XD-1874,Eric Bottard,"Document json-to-tuple, object-to-json and http-client"
1874,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Investigate ""Job Executions"" list page load timing based on number of job executions to load. 

The investigation can be of the following steps:

1) Return all the size restrictions to retrieve the number of job executions.
2) Setup 5, 10, 100, 500, 1000 number of job executions and measure the page load timings.

Based on this, we can address the paging support mentioned in XD-1864.",XD-1873,Ilayaperumal Gopinathan,Investigate JobExecutions page list performance
1875,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, TapLifecycleConnectionListener (which implements ZooKeeperConnectionListener) clears(but not closes) the taps (PathChildrenCache) upon ZK `onDisconnect` child event.
Since, `onConnect` child event re-creates the tap PathChildrenCache, the previously created PathChildrenCache is still hanging in there.
I would be better to close the cache upon disconnect.",XD-1872,Ilayaperumal Gopinathan,Tap lifecycle connection listener should close the tap path children cache upon ZK disconnect
1876,Mark Pollack,Ilayaperumal Gopinathan,Update documentation related to database migration with the changes from XD-1822,XD-1871,Ilayaperumal Gopinathan,Create documentation for Batch DB migration
1877,Glenn Renfro,Glenn Renfro,"Acceptance Tests failed on the Rabbit Source and Sink Tests.  The test started failing when XD-1824 was introduced (Support RabbitMQ Cluster in source/sink).  This story added addresses to support rabbit cluster failover.  
Currently if a user set --host --port to a remote Rabbit instance, XD will use the default host=localhost and port=5672.  However using --addresses does work.  ",XD-1870,Glenn Renfro,Rabbit Sink & Source --host and --port are not updating module host/port.
1878,Eric Bottard,Artem Bilan,See the discussion: https://gopivotal-com.socialcast.com/messages/20771872,XD-1869,Artem Bilan,Provide option for sources/sinks to configure mapped headers to/from Messages
1879,,Eric Bottard,This is a generalization of XD-1702,XD-1868,Eric Bottard,Split DIRT project into common/admin/container/standalone
1880,,Eric Bottard,"Currently, the tapping infrastructure uses <modulename>.<index> as part of  the internal name of the channel.

Now that module labels are uniques per stream, we may change to just <modulelabel>

The strategy used to derive the channel name should also be extracted, so that a change to a single piece of code is necessary in the future (currently, there is likely duplication in ChannelNode.resolve() and -I assume- the bus)",XD-1867,Eric Bottard,Change internal tapping namings to use labels
1881,Eric Bottard,Eric Bottard,,XD-1866,Eric Bottard,Remove ability to do index-based tapping
1882,liujiong,Ilayaperumal Gopinathan,"In BatchJobExecutionsController's list all job executions, for each given job execution, it needs to be evaluated against all the job executions of a given job instance to see if the job execution is restarted.

The rule is: for a given JobInstance, there could be only one job execution that can be in ""COMPLETED"" state. If the job itself is restartable and if any of the job executions for this job instance are ""FAILED"" or ""STOPPED"" then, that job execution can be restarted (based on the client request).

Hence, if the job execution is complete, then it will set the restartable flag to false for all the job executions on a given job instance.",XD-1865,Ilayaperumal Gopinathan,Increase performance of query to determine Job restartability
1883,Gunnar Hillert,Ilayaperumal Gopinathan,"As a user, I'd like to have _paging_ support so that I can scroll through the list of streams, jobs and containers. 

Currently the following error is thrown when we cross >20 rows:

http://localhost:9393/jobs/definitions.json

JSON Response:
{code:xml}
[
	{
		links: [ ],
		logref: ""IllegalStateException"",
		message: ""Not all instances were looked at""
	}
]
{code}

Stack trace:
{code}
15:51:21,931 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.IllegalStateException: Not all instances were looked at
	at org.springframework.util.Assert.state(Assert.java:385)
{code}",XD-1864,Ilayaperumal Gopinathan,Add paging support for UI list views
1884,Thomas Risberg,Thomas Risberg,"Need a way for end-user to package and add custom modules/scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It's not convenient to un-zip/re-zip this archive to add custom modules/scripts.

See - https://github.com/spring-projects/spring-xd/issues/931",XD-1863,Thomas Risberg,Create way to deploy custom modules for XD on YARN
1885,Eric Bottard,Eric Bottard,"Even if not strictly necessary for all modules, use the one-dir-per-module scheme for all of them.

Care should be taken in case there are <import>",XD-1862,Eric Bottard,Organize modules consistently using a dir per module
1886,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Spring Boot 1.1.1 has the following change:

https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4

where, an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external ""zk-properties"" property source always preceding over the application configuration properties.
",XD-1861,Ilayaperumal Gopinathan,Fix XD config initializer for ZK connection string
1887,,Girish Lingappa,"Spring XD rabbit source supports these options 
http://docs.spring.io/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#rabbit

However, if there are multiple brokers available for a client to connect to then there is no way to configure that when creating a stream. I believe there is support for this already in the rabbitmq client (addresses field if I remember right from the meeting) but it needs to be exposed as one of the options in defining a stream with rabbitmq source. This way if one of the brokers die the client can automatically switch to one of the other configured brokers and provide high availability on the client side.
",XD-1860,Girish Lingappa,Support for configuring more than one broker in rabbit source
1888,,Ilayaperumal Gopinathan,"Currently, /jobs/definitions and /batch/jobs offer similar info related to the job configuration info. The former comes from ZKJobDefinitionRepository while the latter comes from Batch Job Repository.

We need to combine this together so that it is not confusing to the end user.",XD-1859,Ilayaperumal Gopinathan,Combine JobDefinition info and BatchJobInfo endpoints
1889,Eric Bottard,Eric Bottard,See impacted code at https://github.com/spring-projects/spring-xd/pull/951,XD-1858,Eric Bottard,Provide error location when tapping inexistent stream/module
1890,Thomas Risberg,Thomas Risberg,"When using spring.hadoop.fsUri set to webhdfs://localhost/ I'm getting an error:

java.lang.NoClassDefFoundError: javax/ws/rs/core/MediaType

including the following in xd/lib seems to fix this:
- jersey-core-1.9.jar
- jersey-server-1.9.jar
",XD-1857,Thomas Risberg,Can't use webhdfs with hdfs sink
1891,Thomas Risberg,Thomas Risberg,"We should have an --fsUri parameter for hdfs and hdfs-dataset sinks so we can write to different file systems (hdfs, webhdfs)",XD-1856,Thomas Risberg,Add option to specify fsUri to hdfs sinks
1892,Thomas Risberg,Thomas Risberg,,XD-1855,Thomas Risberg,Update to use SHDP 2.0.0.RELEASE
1893,Thomas Risberg,Thomas Risberg,"Going forward it seems that providing Hadoop v1 will be of lesser importance and we might as well drop it now. SHDP 2.1 will also drop any v1 support.

Remove support for:
- hadoop12 - Apache Hadoop 1.2.1
- cdh4 - Cloudera CDH 4.6.0
- hdp13 - Hortonworks Data Platform 1.3

Keep:
- hadoop22 - Apache Hadoop 2.2.0 (default)
- phd1 - Pivotal HD 1.1
- phd20 - Pivotal HD 2.0
- cdh5 - Cloudera CDH 5.0.0
- hdp21 - Hortonworks Data Platform 2.1

This should make configuration and documentation easier too. Not to mention testing.

This affects startup scripts and the shell plus the build script.",XD-1854,Thomas Risberg,Remove Hadoop v1 support
1894,Glenn Renfro,Glenn Renfro,"The Tap fixture does not need to inherit from AbstractModuleFixture
Replace moduleName method with moduleToTap.  
The current tap syntax is: tap:stream:<streamname>.<modulelabel>
and not  tap:stream:<streamname>.<modulelabel>.<modulename> as currently implemented by the label fixture.
",XD-1853,Glenn Renfro,Tap Fixture refactoring
1895,Eric Bottard,Eric Bottard,"Now that Spring HATEOAS has some support for client side consumption, we can consider using its Traverson object to replace code such as 
{noformat}
		resources.put(""streams/definitions"", URI.create(xdRuntime.getLink(""streams"").getHref() + ""/definitions""));
		resources.put(""streams/deployments"", URI.create(xdRuntime.getLink(""streams"").getHref() + ""/deployments""));
		resources.put(""jobs"", URI.create(xdRuntime.getLink(""jobs"").getHref()));

{noformat}

in SpringXDTemplate, etc.",XD-1852,Eric Bottard,Use HATEOAS Traverson for client side consumption
1896,Patrick Peralta,Ilayaperumal Gopinathan,Add Cache implementation for ZooKeeperContainerRepository,XD-1851,Ilayaperumal Gopinathan,Introduce cache to ZooKeeperContainerRepository
1897,Patrick Peralta,Ilayaperumal Gopinathan,"Upon a matching container arrival, if there are orphaned stream modules to be deployed, then following exception is thrown:

java.lang.IllegalStateException: Container missing
    at org.springframework.util.Assert.state(Assert.java:385)
    at org.springframework.xd.dirt.core.StreamDeploymentsPath.hasDeploymentInfo(StreamDeploymentsPath.java:275)
    at org.springframework.xd.dirt.core.StreamDeploymentsPath.build(StreamDeploymentsPath.java:233)
    at org.springframework.xd.dirt.server.ContainerListener.getContainersForStreamModule(ContainerListener.java:337)
    at org.springframework.xd.dirt.server.ContainerListener.redeployStreams(ContainerListener.java:278)
    at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:186)
    at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:155)",XD-1850,Ilayaperumal Gopinathan,IllegalStateException when deploying orphaned stream modules upon a matching container arrival
1898,Eric Bottard,David Turanski,currently we have /batch and /jobs. Everything should move to /jobs. See https://github.com/spring-projects/spring-xd/wiki/REST-API for details.,XD-1849,David Turanski,Consolidate REST endpoints for batch resources under /jobs
1899,Mark Fisher,Patrick Peralta,"See the [design document|https://docs.google.com/a/gopivotal.com/document/d/1kWtoH_xEF1wMklzQ8AZaiuhBZWIlpCDi8G9_hAP8Fgc/edit#heading=h.2rk74f16ow4i] for more details.

The REST controller needs to be modified to obtain stream/job state once it is available in ZooKeeper. This depends on XD-1847.",XD-1848,Patrick Peralta,Modify REST controller to obtain stream/job state
1900,,Patrick Peralta,"See the [design document|https://docs.google.com/a/gopivotal.com/document/d/1kWtoH_xEF1wMklzQ8AZaiuhBZWIlpCDi8G9_hAP8Fgc/edit#heading=h.2rk74f16ow4i] for more details.

This class (or perhaps a method on a repository?) will need to query ZooKeeper to obtain the state of a stream/job in order to pass it along to the REST controller.",XD-1847,Patrick Peralta,Method for obtaining stream/job state
1901,Ilayaperumal Gopinathan,Patrick Peralta,"As part of XD-1591, {{DeploymentVerifier}} was modified to take the node structure into account. As indicated in the review below, the implementation does not take module properties (such as count) into account:

https://github.com/spring-projects/spring-xd/pull/939/files#r13730134

This means the implementation is incorrect. For now this won't affect us since all tests at the moment are single node. However this can be drastically improved (and simplified) once XD-1270 is completed. At that point we'll be able to simply read a single ZK node to determine if/when a deployment succeeded. ",XD-1846,Patrick Peralta,Improve DeploymentVerifier when stream state is complete
1902,Patrick Peralta,Patrick Peralta,"{{DeploymentSupervisor}} will be responsible for maintaining the state data for each stream. When a stream is deployed, a watch should be created so that the supervisor can recalculate the state of a stream as modules are added/removed.",XD-1845,Patrick Peralta,Add watch to stream deployment paths
1903,Patrick Peralta,Patrick Peralta,"When the state of all the individual modules for a stream are collected, these states need to be examined in order to determine what the overall stream state is. These should be fed into an interface that can potentially be pluggable to handle all of the edge cases/scenarios that may arise.

One possibility is:
{noformat}
public interface DeploymentUnitStateCalculator {

	DeploymentUnit.State calculate(DeploymentUnit deploymentUnit,
			ModuleDeploymentPropertiesProvider provider,
			Collection<ModuleState> moduleStates);
}
{noformat}",XD-1844,Patrick Peralta,Interface to capture required data for state calculation
1904,Patrick Peralta,Patrick Peralta,"Currently when a stream is deployed by {{DeploymentSupervisor}} the event thread blocks until all deployment requests have been answered or timed out. If there were any deployment errors we log a stack trace.

Instead (or in addition to) we need to write out the results of the deployment request. My initial thought is that it would go under:
{panel}
{{/xd/deployments/streams/<name>/state}}
{panel}
The data for {{state}} will be a JSON map with fields {{state}} and an optional {{errorDescription}}.",XD-1843,Patrick Peralta,Write out initial stream deployment state
1905,,Gary Russell,"When a {{LocalMessageBus}} bridges producer and consumers, it creates an internal channel and registers it with the application context. This can be a {{DirectChannel}}, a {{QueueChannel}} (for named {{queue:*}} channels) or a {{PublishSubscribeChannel}} (for named {{topic:*}} channels).

These channels remain in the context when both the producer and consumer are undeployed. It's rather benign in that the channels will be reused if the modules are redeployed, but it is a leak and should be addressed at some point. A {{QueueChannel}} should remain in the context if its queue is not empty.",XD-1842,Gary Russell,LocalMessageBus Does Not Destroy Channels
1906,liujiong,Gary Russell,"When producers are created/bound dynamically (e.g. from the router sink), they are not unbound when the module is undeployed.

There is currently no metadata in the binding to provide that functionality.

It is not critical because the producers are just sitting there (and may be reused if the module is redeployed, but it is a leak and should be addressed at some time.",XD-1841,Gary Russell,Remove Dynamically Created Producers
1907,David Turanski,David Turanski,REST API needs to be finalized and documented for the GA release. The API to be reviewed by REST experts ,XD-1840,David Turanski,Document and review REST API
1908,Eric Bottard,Eric Bottard,"This needs closer inspection, but here are some things that currently do not work, either at the parser level, or at actual deployment time:

{noformat}
xd:>module compose foo --definition ""queue:bar > filter""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'filter' and type 'sink'

xd:>module compose foolog --definition ""queue:foo > log"" 
Successfully created module 'foolog' with type sink
==> should fail (not a module, but a full stream)

xd:>module compose foo --definition ""queue:bar > filter | transform""
Successfully created module 'foo' with type processor
==> should be source
{noformat}",XD-1839,Eric Bottard,Do not allow the use of named channels in composed modules
1909,Glenn Renfro,Glenn Renfro,"* Currently Acceptance FileSource Acceptance Tests are failing
** This is because the sink that tests the result for the file source test is a filesink.  Both use the ""file"" token.  Thus causing a failure
* SimpleFileSource and SimpleFileSink needs to support a label method.
* Update testFileSource to use the labels.",XD-1838,Glenn Renfro,FileSourceTest needs to apply label to source and sink
1910,Patrick Peralta,Artem Bilan,"For example:
{noformat}
:spring-xd-dirt:compileTestJava                                                                        
warning: [options] bootstrap class path not set in conjunction with -source 1.7
D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\bus\LocalMessageBusTests.java:95: warning: [overrides] Class Foo overrides equals, but neither it nor any superclass overrides hashCode method
        static class Foo {                      
               ^                                
D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\bus\serializer\kryo\CompositeCodecTests.java:77: warning: [overrides] Class SomeClassWithNoDefaultConstructors overrides equals, but neither it nor any superclass override
s hashCode method
        static class SomeClassWithNoDefaultConstructors {
               ^                                
D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\bus\serializer\kryo\KryoCodecTests.java:77: warning: [overrides] Class SomeClassWithNoDefaultConstructors overrides equals, but neither it nor any superclass overrides has
hCode method
        static class SomeClassWithNoDefaultConstructors {
               ^                                
D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\redis\KryoMessageSerializerTests.java:64: warning: [overrides] Class Foo overrides equals, but neither it nor any superclass overrides hashCode method
        public static class Foo {               
                      ^                         
D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\stream\TypeConvertingStreamTests.java:181: warning: [rawtypes] found raw type: Map
                                Map map = (Map) message.getPayload();
                                ^               
  missing type arguments for generic class Map<K,V>
  where K,V are type-variables:                 
    K extends Object declared in interface Map  
    V extends Object declared in interface Map  
6 warnings 
{noformat}",XD-1837,Artem Bilan,Resolve compile warnings
1911,,Eric Bottard,"Following the merge of https://github.com/spring-projects/spring-xd/commit/03cf962845499610ad021d9e6689bccbf5e13cef , investigate calling sites of module.getIndex() or any similar API and remove it if needed",XD-1836,Eric Bottard,Remove unnecessary usage of module.getIndex()
1912,Gunnar Hillert,Ilayaperumal Gopinathan,"With XD-1311, the job execution list shows the definition/deployment status of the associated job. We need to show the same information for a given job execution.",XD-1835,Ilayaperumal Gopinathan,Job execution display to show job deployment/definition status
1913,Patrick Peralta,Mark Pollack,"This will
eliminate any race conditions between deployments and containers
joining/leaving the cluster.",XD-1834,Mark Pollack,Add single threaded executor service to DeploymentSupervisor
1914,Glenn Renfro,Gary Russell,The JMS Source/Sink has a pluggable provider (default {{activemq}}) but the URL property {{amqUrl}} implies activeMQ - the property name should be generic (found while testing XD-1149).,XD-1833,Gary Russell,Fix JMS Property Names
1915,,Mark Pollack,,XD-1832,Mark Pollack,Issues related to tab completion in the shell
1916,Gunnar Hillert,Michael Minella,"When deploying a batch job, the UI displays the database password found in the server.yml in plain text to the user.  At the very least, this should be displayed in a password field so it's masked out and have it masked out in the resulting definition at the bottom of the page.  Ideally, we wouldn't provide the password on that page at all and only accept overriding options (if the user wants a password other than the configured one, enter it…otherwise, we'll use what we have).

I'm finding that this occurs in other places as well.  A full pass though of the UI should be done to mask out passwords (or eliminate their display all together).",XD-1831,Michael Minella,Mask Database Passwords in REST Controllers and Admin UI
1917,liujiong,Eric Bottard,"Due to the way the heuristics for module type guessing work, we can't currently support completions of the like:
""queue:foo > s<TAB>"" that would yield valid processor names

We need to add non-determinism (list of types instead of single type) to the type guessing heuristic",XD-1830,Eric Bottard,Support completion proposals of processors after a named channel
1918,Glenn Renfro,Glenn Renfro,,XD-1829,Glenn Renfro,Mongo  Sink Acceptance Tests
1919,Glenn Renfro,Glenn Renfro,"TwitterSearchTest is the only test that is dependent on an external system for its success.  As such there are times that the service is running slower than the test expects, thus the test fails un-necessarily.   Once XD-1814 is merged we can utilize the ""waitForFile"" feature to wait for the result file from the stream to be written.  But the wait time for twitter will be extended to 1 min.  
AAAAND make the the search string configurable.  Some tests fail because the #springio is not consistently present.",XD-1828,Glenn Renfro,Update TwitterSearchTest to use #katyperry
1920,Glenn Renfro,Glenn Renfro,"Currently JdbcSink, HdfsJdbc&  FileJdbc offer only driverClassName, url, user name & password.  They need to offer a full range of configurations offered by the Tomcat Jdbc Connection pool.",XD-1827,Glenn Renfro,Modules utilizing Jdbc Data Source need to offer connection pool configurations externally.
1921,Gunnar Hillert,Gunnar Hillert,"Spring XD should support mandatory module properties. In the UI when creating a definition from an existing Module, mandatory definition properties should be visually highlighted and enforced.

I don't think the XD backend supports this though. ",XD-1826,Gunnar Hillert,"UI Suport ""Mandatory"" Module Parameters"
1922,Patrick Peralta,Mark Pollack,,XD-1825,Mark Pollack,Remove all javadoc warnings
1923,Gary Russell,Gary Russell,Support receiving messages from an HA cluster.,XD-1824,Gary Russell,Add Support for addresses Property on RabbitMQ Source
1924,Gunnar Hillert,Gunnar Hillert,"This issue could be more involved. Proper pagination may not be implemented correctly by the REST controller (making the respective service call).

This would also necessitate some form of improved state management for the UI. E.g.

* User is on page 5 of the listing of Job Executions
* User views details
* User presses the back-button (on the screen)
* The the listing of Job Executions *should* be still on page 5

",XD-1823,Gunnar Hillert,Investigate need for UI Pagination
1925,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, there are JOB_REGISTRY_NAMES, JOB_REGISTRY_RESTARTABLES and JOB_REGISTRY_INCREMENTABLES tables and we can possibly combine them into one table and have a better schema for this.",XD-1822,Ilayaperumal Gopinathan,Combine Distributed job locator related schema changes into one table
1926,,Mark Pollack,,XD-1821,Mark Pollack,internal modeling of modules and streams.
1927,,Mark Pollack,"Calculate the state of the stream based on the aggregation module states.
Calculate the state of a job.",XD-1820,Mark Pollack,Have a state diagram that models the health of streams and jobs.
1928,David Turanski,Mark Pollack,,XD-1819,Mark Pollack,Investigate increased size of XD distribution.
1929,,Eric Bottard,,XD-1818,Eric Bottard,"Provide DSL completion after a ""some:channel >"" prefix"
1930,Eric Bottard,Mark Pollack,When redeploying in the case of a container failure the modules are now redeployed in a random order.  The list of modules in the failed container needs to be sorted based on its position in a given stream and then redeployed.,XD-1817,Mark Pollack,ContainerListener to redeploy modules based on stream order.
1931,Eric Bottard,Eric Bottard,"Generate asciidoc fragments for each module's options, this way it is always up to date.",XD-1816,Eric Bottard,Generate asciidoc doc from module options
1932,Gunnar Hillert,Gunnar Hillert,We should have a facility to easily test the E2E Protractor tests against a variety of common browsers including IE. Sauce Labs seems to be the service to use.,XD-1815,Gunnar Hillert,UI - Setup Sauce Labs Integration
1933,Glenn Renfro,Glenn Renfro,,XD-1814,Glenn Renfro,Acceptance Tests for Labels and taps
1934,David Turanski,Mark Pollack,,XD-1813,Mark Pollack,Upgrade to Spring Boot 1.1 SNAPSHOT
1935,Gary Russell,Gary Russell,"Pass module properties from stream plugin to {{MessageBusAwareChannelResolver}}.

Disallow partitioning properties.",XD-1812,Gary Russell,Support Bus Producer Properties for Dynamic Producers
1936,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"If someone wants to have a dedicated location (module registry) for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support.

Currently, we use Delegating ModuleRegistry which uses ResourceModuleRegistry implementations that look for location `xd.module.home` and `classpath:/modules/`. 

Maybe we can add an additional ResourceModuleRegistry with `xd.custom.module.home` and use it for custom modules.",XD-1811,Ilayaperumal Gopinathan,Add ResourceModuleRegistry with custom modules location
1937,Glenn Renfro,Glenn Renfro,"Deployment: Admin/Container Redis as data transport
SHA: 45e1beb

[Description]
In the case that the Redis is not running locally XD cannot connect to the Redis instance even though the environment variable spring_redis_host has been set.  

[Steps to reproduce]
* Shutdown local instance of Redis.
* For both the admin and container execute the command prior to running the instances:
** export spring_redis_host=YourRedisHost
* Start admin and container instances
* deploy a simple stream 
** You will see the following error:  13:56:59,647 ERROR task-scheduler-9 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter@6a1f1d12]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$SendingHandler.handleMessageInternal(RedisMessageBus.java:235)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy57.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:110)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:97)
	at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:143)
	at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:41)
	at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:85)
	at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:55)
	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169)
	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:149)
	at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)
	at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:68)
	at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:60)
	at org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter.handleMessageInternal(RedisQueueOutboundChannelAdapter.java:109)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 43 more
Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
	at redis.clients.util.Pool.getResource(Pool.java:42)
	at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:90)
	... 54 more
Caused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused
	at redis.clients.jedis.Connection.connect(Connection.java:142)
	at redis.clients.jedis.BinaryClient.connect(BinaryClient.java:75)
	at redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1724)
	at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:819)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:429)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:360)
	at redis.clients.util.Pool.getResource(Pool.java:40)
	... 55 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at redis.clients.jedis.Connection.connect(Connection.java:137)
	... 62 more",XD-1810,Glenn Renfro,Assess XD Fails to connect to remote Redis Instance
1938,Gunnar Hillert,Gunnar Hillert,,XD-1809,Gunnar Hillert,Improve E2E Test Coverage
1939,Gunnar Hillert,Gunnar Hillert,"Theoretically I would have liked to centralize logging of Http/Resource calls global more substantially - but see this limitation:

https://github.com/angular/angular.js/issues/4013",XD-1808,Gunnar Hillert,Add global Http Interceptor in order to centralize error logging
1940,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Add paging support for the appropriate accessor methods in ModuleMetadata/Container repositories,XD-1807,Ilayaperumal Gopinathan,Paging support for ModuleMetadata/Container repositories
1941,Glenn Renfro,Glenn Renfro,So that the code format matches that of the XD Project.,XD-1806,Glenn Renfro,Add Eclipse target to EC2 build.gradle.
1942,David Turanski,David Turanski,"XML is currently required for module definitions. XD should also support Java @Config and Groovy bean definitions and potentially, SI DSLs. ",XD-1805,David Turanski,Support the ability to create module definitions in Groovy
1943,Eric Bottard,Eric Bottard,"The XD parser had initial support for substreams, which have been subsumed by composed modules.
That legacy code is unused and not needed",XD-1804,Eric Bottard,"Remove unused parser code related to ""substreams"" & co"
1944,,Ilayaperumal Gopinathan,"The id field in ModuleMetadata is using module id that is derived from module parameters which varies between stream and job modules.

We can come up with ModuleId class that applies for both stream/job modules and can be used in ModuleMetadata.",XD-1803,Ilayaperumal Gopinathan,Investigate and create ModuleId class for ModuleMetadata
1945,Eric Bottard,Eric Bottard,"Some REST resources lack an @XmlRootElement annotation.

This causes a JAXB marshalling error when trying to access the API with an Accept header of xml (which is the default in most browsers)

This is a preliminary to XD-1800 (which is much more involved), only to fix ugly exception",XD-1802,Eric Bottard,Add @XmlRootElement to all REST resources
1946,liujiong,Mark Fisher,"See comment here:
https://github.com/spring-projects/spring-xd/pull/912/files#r13331190
",XD-1801,Mark Fisher,Encapsulate retrieval of module deployment metadata
1947,David Turanski,Ilayaperumal Gopinathan,"{noformat}
0:44:30,715  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException: 255
	at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)
	at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.toJson(JsonOutput.java:204)
	at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
20:44:30,718  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:31,136  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException: 255
	at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)
	at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.toJson(JsonOutput.java:204)
	at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
20:44:31,137  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:31,525  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException: 255
	at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)
	at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.toJson(JsonOutput.java:204)
	at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
20:44:31,526  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:31,948  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException: 255
	at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)
	at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)
	at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)
	at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)
	at groovy.json.JsonOutput.toJson(JsonOutput.java:204)
	at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)
	at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
20:44:31,949  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:32,345  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:32,346  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:32,727  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:32,727  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:33,103  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:33,104  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:33,548  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:33,548  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:33,935  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:33,935  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:34,318  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:34,318  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:34,696  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:34,696  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:35,060  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:35,061  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:35,445  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:35,445  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:35,825  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:35,825  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:36,221  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:36,221  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:36,602  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:36,602  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:37,006  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:37,006  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:37,396  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:37,396  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:37,790  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:37,790  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:38,179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:38,179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:38,559  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:38,559  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:38,967  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:38,967  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:39,365  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:39,365  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:39,747  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:39,747  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:40,179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:40,179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:40,596  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:40,597  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:40,978  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:40,979  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:41,342  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:41,342  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:41,732  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:41,732  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:42,125  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:42,126  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:42,511  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:42,512  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:42,918  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:42,918  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:43,309  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:43,309  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:43,689  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:43,689  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:44,071  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:44,071  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:44,470  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:44,470  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:44,847  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:44,847  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:45,307  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:45,308  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:45,710  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:45,710  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:46,136  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:46,137  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:46,530  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:46,530  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:46,913  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:46,913  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:47,306  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:47,306  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:47,700  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:47,700  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:48,124  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:48,124  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:48,520  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:48,520  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:48,912  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:48,912  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:49,292  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:49,293  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:49,683  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:49,683  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:44:50,135  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.
java.lang.ArrayIndexOutOfBoundsException
20:44:50,135  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream, waiting for 250 ms before restarting
20:45:06,533  INFO main-EventThread server.ContainerRegistrar:260 - Undeploying module [ModuleDescriptor@707a9713 moduleName = 'twittersearch', moduleLabel = [null], group = 's2', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['query' -> 'clinton'], children = list[[empty]]]
20:45:06,533  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=twittersearch, type=source, group=s2, index=0 @21839092]
20:45:06,539  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar:83 - Path cache event: /deployments/modules/db6bb769-0764-41a6-8080-7ca4870cb364/s2.source.twittersearch-0, type: CHILD_REMOVED
igopinathan:spring-xd-1.0.0.M7 igopinatha$ 20:46:08,739  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar:83 - Path cache event: /deployments/modules/db6bb769-0764-41a6-8080-7ca4870cb364/s2.source.twittersearch-0, type: CHILD_ADDED
20:46:08,739  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar:545 - Deploying module 'twittersearch-0' for stream 's2'
{noformat}",XD-1799,Ilayaperumal Gopinathan,Twittersearch: ArrayIndexOutOfBoundsException
1948,Glenn Renfro,Glenn Renfro,"Need to update the Rabbit & MQTT test to use the Acctest account instead of guest.  As of Rabbit 3.3, the guest account can only accept connections from localhost.  For now I've setup a loop back so that guest can be accessed from other manchines.  ",XD-1798,Glenn Renfro,Rabbit Tests need to use another another account besides guest.
1949,Glenn Renfro,Glenn Renfro,,XD-1797,Glenn Renfro,Create System Tests for Partitioning
1950,,Glenn Renfro,"* Create infrastructure to retrieve container data.
* Create infrastructure to retrieve  Stream data and the associated container
* Create tests that verify default behavior without group 
* Create tests that verify behavior with sink belonging to specific group
* Create tests that verify behavior with processor belonging to specific group 
* Also generate tests for the scenarios above where the count >1",XD-1796,Glenn Renfro,Create Acceptance tests for Container Groups
1951,Glenn Renfro,Glenn Renfro,"XD-EC2 applies the environment variables to all container instances that are created.  This behavior has to be altered such that a environment variable can be applied to to a specific container instance.  

For example if we create a 3 node cluster Admin, Container1, Container2 & Container3.
For Example:
* XD1_XD_CONTAINER_GROUPS=GROUP1
* XD2_XD_CONTAINER_GROUPS=GROUP2

* In this example XD1_XD_CONTAINER_GROUPS=GROUP1 would apply XD_CONTAINER_GROUPS=GROUP1 to container1's environment.  
* XD2_XD_CONTAINER_GROUPS=GROUP2 would apply XD_CONTAINER_GROUPS=GROUP2 to container2's environment.  
* While container3 would not receive a specific environment setting for XD_CONTAINER_GROUPS.
",XD-1795,Glenn Renfro,XD-EC2 Needs to support XD_CONTAINER_GROUPS for created containers
1952,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"In case of module count > 1, the module deployments path for each deployed module always has: {""count"":""1""}

For a scenario:
The stream test1: ""http | log""
with the deployment manifest:
module.log.count=3,module.log.criteria=groups.contains('test')

get /xd/deployments/streams/test1 module.log.count=3,module.log.criteria=groups.contains('test')
get /xd/deployments/modules/9ecaf59a-a1f5-4ed9-984d-f5dff8cc9b57/test1.sink.log-1 {""count"":""1""}
get /xd/deployments/modules/1bbdb2dd-97ed-48a2-a3cd-3633c3e82f52/test1.sink.log-1 {""count"":""1""}",XD-1794,Ilayaperumal Gopinathan,Module count value at module deployments path
1953,,Glenn Renfro,"Deploy Type: Admin/Container on EC2 (Rabbit Transport)
SHA: 8fba31d

[Steps to reproduce]
1) Using Rabbit 3.3 above create a user that does not have privileges to write to /
* sudo rabbitmqctl add_user joe password
* (omit this step) sudo rabbitmqctl set_permissions -p / joe "".*"" "".*"" "".*""
2) Set the rabbitmq user name and password
* export spring_rabbitmq_username=acctest
* export spring_rabbitmq_password=acctest23
3) Start container.
4) Create stream or job ""foo""
5) Error will occur
6) delete stream or job ""foo""
7)  stop container
8) set privilege
* sudo rabbitmqctl set_permissions -p / joe "".*"" "".*"" "".*""
9) Start container
10) create stream or job ""foo""
11)  System will report that foo exists.",XD-1793,Glenn Renfro,Jobs  are not completely removed from Jobstore 
1954,David Turanski,David Turanski,"MessageBusSupport creates an 'original content type' message header to support serialization for remote transports. The form of the header application/x-java-object;type=<classname>.  For java array types, the ""["" prefix causes an error when converting this value to a MimeType.    This can be avoided by quoting the classname. However, a further complication is if the array element is an object. In this case the classname is '[L<classname>;'. The trailing colon causes a parse exception even in a quoted string.  A simple fix is to check for the trailing colon, remove it and add it back if MimeType.getParameter(""type"").contains(""[L"").   See http://docs.oracle.com/javase/7/docs/api/java/lang/Class.html#getName for more info.  Preliminary testing indicates primitive array and multi-dimensional arrays will work fine with quoting, but tests should be added for these cases.  ",XD-1792,David Turanski,Array class names cannot be parsed to MimeType
1955,Ilayaperumal Gopinathan,Thomas Risberg,"Create OOTB batch job that executes a job on Spark as a tasklet

could be something along this:

job create yarnJob --definition ""sparkjob --master=spark://localhost:7077 --class=SimpleApp""
",XD-1791,Thomas Risberg,New job that executes a Spark job
1956,,Thomas Risberg,"Create OOTB batch job that executes a job on YARN

could be:

job create yarnJob --definition ""yarnjob --containerCount=4 --applicationDir=/apps/mystuff --archiveFile=yarn-job-0.1.0.jar --arguments=#{payload[value]}""
",XD-1790,Thomas Risberg,New job that executes a job on YARN
1957,,Thomas Risberg,"Create OOTB batch job that executes SQL script using JDBC - can be used for Hive2 jobs or HAWQ jobs etc.

Christian Tzolov provided the following baed on Dave Syers JdbcTasklte (https://src.springframework.org/svn/spring-batch-admin/sandbox/cloud-sample/src/main/java/org/springframework/batch/admin/sample/job/JdbcTasklet.java):

Attached is a simple job module that can run sql commands on Hawq or other DB over jdbc.  Just unzip it in <springxd>/xd/modules/job folder and create something like this:
xd> job create analyticsJob  --definition ""
    jdbc --driverClassName=org.postgresql.Driver
            --url=jdbc:postgresql://<HAWQ master host>:5432/gpadmin
            --username=gpadmin --password=''
             --sql='CREATE TABLE fonecta_demo.analytics AS
                             SELECT segmenttiluokka, count(*) as cnt FROM fonecta_demo.segmenttiluokka
                                   GROUP BY segmenttiluokka;'"" --deploy
",XD-1789,Thomas Risberg,New job that executes SQL script using JDBC
1958,Eric Bottard,Gary Russell,"stream create foo --definition=""bar | baz""

stream deploy foo --properties=module.qux.fiz",XD-1788,Gary Russell,Detect Module Properties for Non-existent Modules
1959,Gary Russell,Gary Russell,Detect properties the bus doesn't support.,XD-1787,Gary Russell,Detect Invalid Deployment Properties in the Bus
1960,Gary Russell,Gary Russell,PR: https://github.com/spring-projects/spring-xd/pull/926,XD-1786,Gary Russell,Support Partitioning/Bus Properties in the RedisMessageBus
1961,Florent Biville,Ilayaperumal Gopinathan,"We could have a XD startup script something like this:

'xd-distributed --admins=1 --containers=3'

We could possibly provide a configuration option to specify the admin port so that multiple admin servers can be started.",XD-1785,Ilayaperumal Gopinathan,Create startup script to start one admin & multiple containers
1962,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"We need a way to access the deployment properties for the deployed modules.

For example: 'runtime module foo.sink.bar-2'",XD-1784,Ilayaperumal Gopinathan,REST endpoint/command interface for runtime module deployment properties
1963,Patrick Peralta,Mark Fisher,"When a deployment fails, the supervisor will clean up failed deployment attempts. If the deployment path is removed while the supervisor is waiting (for instance if the target container departs the cluster) then a NoNodeException will be thrown:

{code}
17:22:59,702  WARN ContainersPathChildrenCache-0 server.ModuleDeploymentWriter:361 - Error while cleaning up failed deployment /deployments/modules/40494bdb-0d8c-4b5d-a895-bf94432d9d3b/s.sink.log-1
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/40494bdb-0d8c-4b5d-a895-bf94432d9d3b/s.sink.log-1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)
	at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239)
	at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230)
	at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215)
	at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.processResults(ModuleDeploymentWriter.java:355)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:325)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:247)
	at org.springframework.xd.dirt.server.ContainerListener.redeployStreamModule(ContainerListener.java:432)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
17:22:59,718 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:557 -

java.lang.IllegalStateException: Container 40494bdb-0d8c-4b5d-a895-bf94432d9d3b experienced the following error deploying module log-1 of type sink: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.validateResults(ModuleDeploymentWriter.java:523)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.validateResult(ModuleDeploymentWriter.java:474)
	at org.springframework.xd.dirt.server.ContainerListener.redeployStreamModule(ContainerListener.java:436)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
{code}

Additionally, if the supervisor tries to remove a failed deployment after the container has written to it, the following appears in the log:

{code}
WARN ContainersPathChildrenCache-0 server.ModuleDeploymentWriter:361 - Error while cleaning up failed deployment /deployments/modules/18c7b4d7-991c-487b-a6e3-006b2dbf87fa/s.source.http-0
org.apache.zookeeper.KeeperException$NotEmptyException: KeeperErrorCode = Directory not empty for /xd/deployments/modules/18c7b4d7-991c-487b-a6e3-006b2dbf87fa/s.source.http-0
{code}

The supervisor has to force the removal of the node, including children.",XD-1783,Mark Fisher,Make failed deployment cleanup more robust
1964,Patrick Peralta,Patrick Peralta,"If all containers are shut down and there's a stream deployed this exception is thrown on the admin:

{noformat}
java.util.NoSuchElementException
	at java.util.ArrayList$Itr.next(ArrayList.java:839)
	at org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:260)
	at org.springframework.xd.dirt.server.ContainerListener.redeployStreamModule(ContainerListener.java:432)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
{noformat}

This is a regression caused by the earlier code refactoring for stream deployment.",XD-1782,Patrick Peralta,Exception thrown when all containers are shut down
1965,Glenn Renfro,Glenn Renfro,"Create Acceptance Test
Add Mongo to Ec2 Acceptance Test Environment.",XD-1781,Glenn Renfro,Add HdfsMongoDb Acceptance Test.
1966,Glenn Renfro,Glenn Renfro,"* Environment: 
** Admin/Container on separate EC2 instances with rabbit transport.
*** Redis, Rabbit & Zookeeper deployed on admin instance
** Admin/Container on separate EC2 instances with redis transport.
*** Redis, Rabbit & Zookeeper deployed on admin instance
* XD Deployment Type: XD-SingleNode 
* Commit: https://github.com/spring-projects/spring-xd/commit/8fba31d21e96a371dacf26b40eeb542c3564b2e3

Both Redis and Rabbit clusters failed acceptance tests.  I've attached the portion of the admin log that was available.  ",XD-1780,Glenn Renfro,Upgrade ZK installation on EC2 to 3.4.6
1967,Glenn Renfro,Glenn Renfro,"Environment: Running on local Mac Instance:
XD Deployment Type: XD-SingleNode 
SHA: 66c28e3

While running a test that deployed and undeployed a stream over 500 times the following exception is thrown:
org.apache.zookeeper.KeeperException$NotEmptyException: KeeperErrorCode = Directory not empty for /xd/deployments/modules/54ef010f-3d5d-4f86-a50f-44453e48633d/streamfoo.source.http-0

[Steps to reproduce]
* Created the following Job and Stream using xd-shell:
** stream create streamfoo --definition ""http --port=9000 | hdfs --directory=/xd/streamfoo --fileName=streamfoo "" 
** job create foo --definition ""hdfsjdbc --resources=/xd/streamfoo/*.txt --names=data --tableName=streamfoo --initializeDatabase=true "" --deploy
* Repeated the following 500 times using xd-shell --cmdfile
** Ran a script that would deploy streamfoo
** Ran a script that would execute the following 25 times
*** http post --data ""hello world0 ""
** Ran a script to undeploy streamfoo
** Ran a script that would launch the job

[Artifacts]
The logfile of the singlenode is attached.",XD-1779,Glenn Renfro,Exception thrown when running undeploy and redeploy a stream tests
1968,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"job create bogus --definition ""jdbchdfs --sql='select * from bogus' --restartable=false""
job deploy bogus
job launch bogus

http://localhost:9393/admin-ui/#/jobs/executions

click ""Restart Job Execution"" on the failed job execution

get message ""Job was relaunched""

container log has:

12:36:27,231 ERROR task-scheduler-10 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: org.springframework.batch.core.repository.JobRestartException: JobInstance already exists and is not restartable",XD-1778,Ilayaperumal Gopinathan,"Check job ""restartable"" flag for JobExecution restart action"
1969,Ilayaperumal Gopinathan,Patrick Peralta,"As part of XD-1338 we modified how module deployment works. Now module deployment requests include deployment properties as the data for the ZooKeeper node. This allows us to reuse those properties when a container exit the cluster and the module is redeployed to another container.

However if there are no other containers to handle the deployment, the module deployment node is erased, along with the properties. This mean no module will ever handle the partition that module was responsible for.

This condition needs to be handled so that partitioned streams continue to function in cases where the cluster temporarily doesn't have enough containers to support the stream.",XD-1777,Patrick Peralta,Restore deployment properties for orphaned modules
1970,,Glenn Renfro,"Need to be able to setup a gemfire server that has locators enabled such that we can enable the gemfire modules locator features.

run tests for the use_server (default) and tests for locator.

They are enabled by activating the use-locator profile for the container(s) .
For example: if you are running singlenode the profile would be:
export spring_profiles_active=singlenode,use-locator",XD-1776,Glenn Renfro,Need to support the ability to test Gemfire Locators
1971,Glenn Renfro,Glenn Renfro,,XD-1775,Glenn Renfro,HdfsJdbc Acceptance Test
1972,Gunnar Hillert,Gunnar Hillert,"* Automatically close notification messages
* Polish UI",XD-1774,Gunnar Hillert,UI Automatically close notification messages
1973,Mark Fisher,Mark Fisher,,XD-1773,Mark Fisher,Upgrade Curator to 2.5.0
1974,Eric Bottard,Mark Pollack,"A stream definition such as http | transform | transform | file 

will limit functionality such as taps since you can't reference which specific module to apply the tap. 

Should be proactive in parsing the DSL and force the use of a label to disambiguate.  ",XD-1772,Mark Pollack,Do not allow a stream definition to contain ambiguous module references
1975,Glenn Renfro,Glenn Renfro,"The changes to twitterSearch means that it will send multiple messages during the duration of the test.
To support these changes:
1) Remove assertReceived.  Since the number of messages is indeterminate
2) Change file sink that captures the results to append mode.  Because each message will overwrite the previous messages result.",XD-1771,Glenn Renfro,Update twitterSearchTest to handle the latest release of twitterSearch
1976,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When trying to deploy a stream module, the ContainerRegistrar throws NPE if the deployment loader couldn't load a non-null stream based on the stream name.

07:10:29,902 ERROR DeploymentsPathChildrenCache-0 server.ContainerRegistrar:450 - Exception deploying module
java.lang.NullPointerException
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:549)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:436)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$800(ContainerRegistrar.java:96)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:803)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)",XD-1770,Ilayaperumal Gopinathan,Handle NPE while deploying stream module at the Container
1977,,Ilayaperumal Gopinathan,"At the job definitions page, user should be able to provide the job deployment manifest (module count, criteria etc.,)",XD-1769,Ilayaperumal Gopinathan,User should be able to provide job deployment properties
1978,Gunnar Hillert,Ilayaperumal Gopinathan,"When clicking deploy from the job definitions page, user should be able to specify the deployment manifest (module count, module criteria etc.,)",XD-1768,Ilayaperumal Gopinathan,User should be able to specify deploy properties for Jobs
1979,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"At the JobExecution page, if the job execution is failed and restartable, then we should enable the ""restart"" action only if the job is deployed.

Please see https://github.com/spring-projects/spring-xd/pull/884 for the discussion related to this.",XD-1767,Ilayaperumal Gopinathan,JobExecution restart action should depend on job deployment status
1980,Janne Valkealahti,Mark Pollack,"build	22-May-2014 08:45:04	Creating stream tcptofile with definition 'tcp+--port%3D21234+--socketTimeout%3D2000+%7C+file+--dir%3D%2Ftmp%2Fxdtest%2Fbasic' ...
build	22-May-2014 08:45:04	{""name"":""tcptofile"",""deployed"":null,""definition"":""tcp --port=21234 --socketTimeout=2000 | file --dir=/tmp/xdtest/basic"",""links"":[{""rel"":""self"",""href"":""http://127.0.0.1:9393/streams/tcptofile""}]}
build	22-May-2014 08:45:04	
build	22-May-2014 08:45:11	Destroying stream tcptofile ...
build	22-May-2014 08:45:11	
build	22-May-2014 08:45:11	
build	22-May-2014 08:45:11	Expected blahblah does not match actual value (98,108,97,104,98,108,97,104)
simple	22-May-2014 08:45:11	Failing task since return code of [/bin/sh /tmp/XD-SCRIPTS-RS-513-ScriptBuildTask-7280766559152712153.sh] was 1 while expected 0
simple	22-May-2014 08:45:11	Finished task 'Run basic_stream_tests'

See https://build.spring.io/download/XD-SCRIPTS-RS/build_logs/XD-SCRIPTS-RS-513.log",XD-1766,Mark Pollack,Failing tcp to file in script tests
1981,Thomas Risberg,Mark Pollack,After spring hadoop 2.0 RC4 update.,XD-1765,Mark Pollack,Update documentation to list supported Hadoop distributions
1982,Janne Valkealahti,Mark Pollack,,XD-1764,Mark Pollack,Documentation for enhanced HDFS sink with paths based off date/time/message content
1983,Mark Pollack,Mark Pollack,,XD-1763,Mark Pollack,Update to Spring Batch 3.0 RELEASE
1984,,Mark Pollack,https://github.com/addthis/stream-lib/blob/master/src/main/java/com/clearspring/analytics/hash/MurmurHash.java,XD-1762,Mark Pollack,Update data partitioning functionality to use murmur hash function
1985,Gary Russell,Mark Pollack,,XD-1761,Mark Pollack,"Documentation for data partitioning, and all Rabbit Bus properties"
1986,Gary Russell,Girish Lingappa,"We are looking to speed up the message passing from source to sink  and wondering if we could use a in-memory transport whenever we know that source and sink modules are co-located on the same container. Currently we do not see a straight forward way of doing it

Option 1 : Create a composite module and let users deploy a composite module by itself or in other words deploy a stream with one module

Option 2 : Let users define a transport as in-memory when defining a stream. This could be used along with the deployment manifest feature enforcing co-location of a source and sink module, with in-memory transport

cc @adenissov
",XD-1760,Girish Lingappa,Support in-memory transport for co-located modules
1987,Glenn Renfro,Glenn Renfro,"Deployment: xd-shell local, xd-singlenode (ec2)
SHA: 942c7868e3e0d0cf7730b536170438a0291f5cab

[Description]
<Case 1>
Once successfully connected to a server, if you connect to a server that is not present.  The prompt still shows XD when it should show server-unknown.  Can be reproduced consistently.
Conversely:
<Case 2>
Attempted to connect to a xd-singlenode on ec2 using a local xd-shell.  
The xd-singlenode was not running.  After bringing up the xd-singlenode, I was able to connect however the status did not change from ""server-unknown""  *This behavior, can not be consistently reproduced, but have seen it happen on multiple accounts.* 

[Steps to reproduce]
<Case 1>
1. Bring up shell while xd-singlenode is not running.
2. Bring up xd-singlenode
3. Connect to xd-singlenode
* xd:>admin config server http://localhost:9393

4. Connect to a fake address
* xd:>admin config server http://foo.bar:9393

<Case 2>
1.  Attempt to connect to remote server that is not available
* xd:>admin config server http://ec2-54-237-186-186.compute-1.amazonaws.com:9393
* Unable to contact XD Admin Server at 'http://ec2-54-237-186-186.compute-1.amazonaws.com:9393'.

2. Bring up xd-singlenode on remote
* server-unknown:>admin config server http://ec2-54-237-186-186.compute-1.amazonaws.com:9393
* Successfully targeted http://ec2-54-237-186-186.compute-1.amazonaws.com:9393

3. Still see the incorrect prompt.
server-unknown:>
server-unknown:>",XD-1759,Glenn Renfro,Status on Shell command prompt is inconsistent
1988,Glenn Renfro,Glenn Renfro,"Deployed on: SingleNode Ec2, SingleNode Mac
SHA: 942c7868e3e0d0cf7730b536170438a0291f5cab

[Description]
JMS Source (Activemq) tried to access a broker on localhost.  
The current deployment uses the following to set the JMS Broker:
* export amq_url=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616

[Analysis]
After reviewing the configuration of the jms-activemq-infrastructure-context.xml, it was noted that the brokerUrl environment variable has been changed from amq.url to amqUrl.  While the jms-activemq.properties has not been changed (still amq.url).  
After setting the following, the test still failed:
* export amqUrl=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616

After going into the jms-activemq-infrastructure-context.xml and replacing the amqUrl with amq.url, the jms source (activemq) returned to normal operation.


[Incident]
Acceptance tests reported a failure on Saturday Morning's build that the JMS Source failed.",XD-1758,Glenn Renfro,JMS Source (ActiveMQ) failing to use jmsUrl environment variable
1989,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Since the module metadata properties are resolved at runtime (when the module gets deployed), we can resolve the module options values that are already resolved in there.

For example, currently the ""runtime modules"" command for ""log"" module would show this:

runtime modules

[7m[27;32m  Module            Container Id                          Options
  ----------------  ------------------------------------  --------------------------------------------------------
  s1.source.http-0  633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {port=9000}
  s1.sink.log-1     633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {name=${xd.stream.name}, expression=payload, level=INFO}

In this case, we can resolve the module option ""name"" from the module metadata.


",XD-1757,Ilayaperumal Gopinathan,Resolve runtime module option properties using module metadata
1990,Thomas Risberg,Thomas Risberg,Update spring-data-hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.,XD-1756,Thomas Risberg,Update spring-data-hadoop version to 2.0.0.RC4
1991,David Turanski,Glenn Renfro,,XD-1755,Glenn Renfro,gemfire source does not offer --host nor --port options
1992,David Turanski,Glenn Renfro,"* OS - Mac
* XD Deployment Type - Singlenode
* SHA - bb4dd58
* Required Software - XD Gemfire Sample Server

[Description]
After creating and destroying 3 streams with gemfireJsonServer sink the 4th will fail with this error:  
* 44707 refused connection: The number of clients, 4, exceeded the limit of 3 allowed by the default evaluation license.

[Steps to reproduce]
* From your shell execute the following 4 times:
** stream create --name stocks --definition ""http --port=9090 | gemfire-json-server --regionName=Stocks --host=ec2-54-221-32-82.compute-1.amazonaws.com --port=40404 --keyExpression=payload.getField('symbol')"" --deploy
** stream destroy stocks",XD-1754,Glenn Renfro,Assess if GemfireJsonServer & gemfireServer sinks should close the client cache
1993,Gunnar Hillert,Thomas Risberg,We have some places where we us a default data format specified as 'yyyy/MM/dd'. In Spring for Apache Hadoop we use 'yyyy-MM-dd' for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.,XD-1753,Thomas Risberg,Change default date formats to be 'yyyy-MM-dd'
1994,,Araceli Henley,"Using a singleXD VM

I can create multiple streams with the same http port.

  Stream Name  Stream Definition  Status
  -----------  -----------------  ------

xd:>stream create --definition ""http --port=8081|file --dir=/tmp/test3"" --name test1 --deploy
Created and deployed new stream 'test1'
xd:>stream create --definition ""http --port=8081|file --dir=/tmp/test3"" --name test1 --deploy
Created and deployed new stream 'test1'
xd:>stream create --definition ""http --port=8081|file --dir=/tmp/test3"" --name test2 --deploy
Created and deployed new stream 'test2'
xd:>stream create --definition ""http --port=8081|file --dir=/tmp/test3"" --name test3 --deploy
Created and deployed new stream 'test3'
xd:>stream list
  Stream Name  Stream Definition                       Status
  -----------  --------------------------------------  --------
  test1        http --port=8081|file --dir=/tmp/test3  deployed
  test2        http --port=8081|file --dir=/tmp/test3  deployed
  test3        http --port=8081|file --dir=/tmp/test3  deployed

ISSUES
1) No error is returned for the duplicate use of the port. In M5 an error was returned.
2) The status shows as ""deployed"" for all three. 
3) Even though there are three streams. Only the first stream is active. I can post to the first stream that was declared and it will successfully post to the  directory. If  I post to the remaining streams, I don't get an error and I no data is written to the flle.
4) If I remove the working stream, the remaining stream still don't work.
",XD-1752,Araceli Henley,multiple streams with same port for HTTP Source 
1995,Glenn Renfro,Glenn Renfro,"filejdbc, hdfsjdbc, jdbchdfs & jdbc modules each support a tomcat connection  pool.  At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file.
We need to allow the user to configure them via yml, property file and environment variables.
",XD-1751,Glenn Renfro,Modules that use tomcat connection pool need to expose configurations
1996,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When not prefixing with appropriate module type, module info command throws StringIndexOutOfBoundsException:


xd:>module info file
java.lang.StringIndexOutOfBoundsException: Failed to convert 'file' to type QualifiedModuleName for option 'name,'
String index out of range: -1",XD-1750,Ilayaperumal Gopinathan,Exception handling at Module info command
1997,Mark Fisher,Mark Pollack,We have 13 skipped tests now...,XD-1749,Mark Pollack,"Investigate skipped tests in build, enable or remove."
1998,Gary Russell,Gary Russell,Add messages store optimization to the `hdfs-dataset`,XD-1748,Gary Russell,Update to Spring Integration 4.0.1
1999,Patrick Peralta,Mark Pollack,"We are getting test failures such as

https://build.spring.io/browse/XD-MASTER-1381

quite often in the CI environment recently.  I suspect the ordering of checks in AbstractSingleNodeStreamDeploymentIntegrationTests

			// Deploys in reverse order
			assertModuleRequest(streamName, ""log"", false);
			assertModuleRequest(streamName, ""filter"", false);
			assertModuleRequest(streamName, ""transform"", false);
			assertModuleRequest(streamName, ""http"", false);
			// Undeploys in stream order
			assertModuleRequest(streamName, ""http"", true);
			assertModuleRequest(streamName, ""transform"", true);
			assertModuleRequest(streamName, ""filter"", true);
			assertModuleRequest(streamName, ""log"", true);

isn't happening

perhaps  changing nextUndeployEvent poll time from 5 seconds to higher is appropriate (no idea why CI environment seems so slow)
",XD-1747,Mark Pollack,Module deployment order is not guaranteed
2000,,Gary Russell,"As a developer, I'd like to have an OOTB MVC-aware HTTP module (with embedded tomcat), so I can use this module to leverage spring-mvc and spring-security features, instead of rewriting them within the existing HTTP source module. 

* Adds richer support for content-type in the HTTP Source module. See [~jbrisbin] comments: https://github.com/spring-projects/spring-xd/pull/879.

* Adds full header mapping in the source (see comments)

* See SO request: http://stackoverflow.com/questions/29353471/spring-xd-as-a-rest-endpoint",XD-1746,Gary Russell,Add MVC-aware HTTP source module
2001,Janne Valkealahti,Girish Lingappa,"Hadoop supports namenode HA with two name nodes running, one being active and other in standby. If the active name node fails the standby name node has all the data readily available and can start serving requests. In this configuration name node url is no longer a host:port url but a logical name that translates to any active name node at runtime. 

This is to ensure spring xd stream can handle a name node failure, for instance when writing a hdfs sink, seamlessly",XD-1745,Girish Lingappa,Support for hadoop name node HA configuration
2002,Mark Pollack,Mark Pollack,,XD-1744,Mark Pollack,Update CI server to run tests that depend on rabbit/redis and hadoop
2003,,Gunnar Hillert,"Using Rabbit as a transport, I get the below error when creating the following stream:

{code}
stream create mytweets --definition ""twittersearch --query='spring' | log"" --deploy true
{code}

In local mode, the stream executes just fine. Of course it works with *--outputType=application/json*. Nevertheless, I was not expecting that exception (see below)

Issue was also verified by [~grenfro]. 

{code}
org.springframework.amqp.rabbit.listener.ListenerExecutionFailedException: Listener threw exception
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.wrapToListenerExecutionFailedExceptionIfNeeded(AbstractMessageListenerContainer.java:758)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:653)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:576)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:75)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:154)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:69)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:255)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:162)
	at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:87)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy102.invokeListener(Unknown Source)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:1111)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:559)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:904)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:888)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$500(SimpleMessageListenerContainer.java:75)
	at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:989)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.messaging.MessageHandlingException: error occurred in message handler [se.0.convert.bridge]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.amqp.inbound.AmqpInboundChannelAdapter.access$400(AmqpInboundChannelAdapter.java:44)
	at org.springframework.integration.amqp.inbound.AmqpInboundChannelAdapter$1.onMessage(AmqpInboundChannelAdapter.java:90)
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:650)
	... 24 more
Caused by: org.springframework.xd.dirt.integration.bus.serializer.SerializationException: unable to deserialize [null]. Class not found.
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:381)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:363)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:346)
	at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.access$500(RabbitMessageBus.java:70)
	at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus$ReceivingHandler.handleRequestMessage(RabbitMessageBus.java:448)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 37 more
Caused by: java.lang.ClassNotFoundException: org.springframework.social.twitter.api.Tweet
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:190)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:375)
	... 43 more
{code}",XD-1743,Gunnar Hillert,ClassNotFoundException: o.s.social.twitter.api.Tweet with Rabbit-transport
2004,Gary Russell,Gary Russell,"The TCP source unconditionally converts to String. This prevents binary transfers.

Remove the transformer; if the user wants a String; (s)he can use

{{tcp --outputType=text/plain;charset=UTF-8}} (assuming the byte stream has valid UTF-8 encoding).

Another option would be to add a {{--binary}} option, but since conversion can already handle it, it's probably better to use that.

On the other hand, a {{--binary}} option would enable backwards compatibility.

The http source also unconditionally converts to String.",XD-1742,Gary Russell,Remove toStringTransformer from tcp Source; Add Binary Support to the http Source
2005,David Turanski,David Turanski,"The converter was not configured, therefore String to byte[] for --outPutType application/octet-stream fails for a String payload.",XD-1741,David Turanski,Register StringToByteArrayMessageConverter
2006,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"It would be useful to store admin server ip address in ZooKeeper leadership group node (/xd/admins) to identify admin server and it's admin port.

",XD-1740,Ilayaperumal Gopinathan,ZooKeeper Admin server node data to have admin server host address
2007,Patrick Peralta,Patrick Peralta,"As reported by Matt Stine:

After closing and reopening a laptop, the following stack trace appears in the container log:

{noformat}
00:47:28,226  INFO main-EventThread state.ConnectionStateManager:194 - State change: RECONNECTED
00:47:28,226  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:255 - >>> Curator connected event: RECONNECTED
00:47:28,322 ERROR ConnectionStateManager-0 listen.ListenerContainer:96 - Listener (org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener@6abf4158) threw an exception
java.lang.RuntimeException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a
        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:301)
        at org.springframework.xd.dirt.server.ContainerRegistrar.access$100(ContainerRegistrar.java:93)
        at org.springframework.xd.dirt.server.ContainerRegistrar$ContainerAttributesRegisteringZooKeeperConnectionListener.onConnect(ContainerRegistrar.java:316)
        at org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener.stateChanged(ZooKeeperConnection.java:257)
        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:222)
        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:218)
        at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
        at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
        at org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:215)
        at org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:42)
        at org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:110)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a
        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:75)
        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:42)
        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:295)
        ... 15 more
Caused by: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)
        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
        at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)
        at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)
        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)
        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:69)
        ... 17 more
{noformat}

This can occur if ZK does not remove the ephemeral node before the container creates a new one. This can be fixed in the following ways:

* Remove the existing ephemeral node if it already exists
* Register containers with a new UUID upon every new connection

For now I'll implement the first solution.",XD-1739,Patrick Peralta,Container reconnection to ZK fails intermittently
2008,,Glenn Renfro,"In short if you attempt to destroy a stream that has had its modules removed, the destroy will fail.
1) So if I create my own processor:x and use the processor in a stream.
2) I then shutdown the admin and container.
3) Delete the processor:x from the $XD_HOME/modules directory
4) Restart the admin and container.
5) if you do a stream list the stream that used the processor.x is still present.
6) but you can not delete the stream because of the exception below. 

[To Reproduce using Payload Conversion example]
1) Follow the instructions to install and use the myTupleProcessor module in a stream.
2) Now shutdown the admin and container
3) rm -rf $XD_HOME/modules/processor/myTupleProcessor.xml 
4) rm -rf $XD_HOME/lib/payload-conversion.jar
5) Startup your admin and container
6) stream all destroy.  Then type 'y'<return>
   6a) The shell will report ommand failed org.springframework.xd.rest.client.impl.SpringXDException: No content to map due to end-of-input at [Source: java.io.StringReader@5b8bd3d0; line: 1, column: 1]
   6b) The Admin Server will report
11:59:43,543 ERROR http-nio-9393-exec-1 rest.RestControllerAdvice:199 - Caught exception while handling a request
org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: No content to map due to end-of-input
 at [Source: java.io.StringReader@648849d5; line: 1, column: 1]
	at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:47)
	at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:31)
	at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapAndThrowIgnoring(ZooKeeperUtils.java:65)
	at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:95)
	at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:300)
	at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:196)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:152)
	at org.springframework.xd.dirt.stream.StreamDeployer.beforeDelete(StreamDeployer.java:116)
	at org.springframework.xd.dirt.stream.StreamDeployer.beforeDelete(StreamDeployer.java:43)
	at org.springframework.xd.dirt.stream.AbstractDeployer.delete(AbstractDeployer.java:246)
	at org.springframework.xd.dirt.stream.AbstractDeployer.deleteAll(AbstractDeployer.java:169)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:100)
	at org.springframework.xd.dirt.rest.XDController.deleteAll(XDController.java:110)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:885)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:653)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)
Caused by: com.fasterxml.jackson.databind.JsonMappingException: No content to map due to end-of-input
 at [Source: java.io.StringReader@648849d5; line: 1, column: 1]
	at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:164)
	at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3036)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:2978)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2098)
	at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:82)
	... 61 more
",XD-1738,Glenn Renfro,Stream destroy fails to remove if the underlying modules have been removed.
2009,David Turanski,David Turanski,,XD-1737,David Turanski,Add --verbose option to display all property values
2010,,Ilayaperumal Gopinathan,"Creating this enhancement story based on the discussion here:

https://github.com/spring-projects/spring-xd/pull/867",XD-1736,Ilayaperumal Gopinathan,Enhance Container object (org.springframework.xd.dirt.cluster.Container) for better matching strategies 
2011,Glenn Renfro,Glenn Renfro,"JdbcHdfsTest, FileJdbcTest works for singlenode but not for admin & Container on the same machine.",XD-1735,Glenn Renfro,FileJdbcTest & JdbcHdfsTest failing
2012,Glenn Renfro,Mark Pollack,,XD-1734,Mark Pollack,Improve JMX checks for processors taking into account error channels
2013,Eric Bottard,Mark Pollack,"We don't support using @Configuration for modules ATM.  The current code was committed during the same time as improvements to handling module configuration.  We should switch the reactor-ip.xml to include all bean definitions and remove referencing @Configuration classes or see how to add support for @Configuration.  

Another short term hack is to put the prefix 'sink.reactor-ip' in all @Value used in NetServerInboundChannelAdapterConfiguration.",XD-1733,Mark Pollack,Investigate fall through of server.yml values when running in YARN
2014,Dave Syer,Mark Pollack,,XD-1732,Mark Pollack,Remove dependency on Sprint Boot in xd-dirt tests
2015,Glenn Renfro,Glenn Renfro,,XD-1731,Glenn Renfro,Support for UUID suffix for hdfs file names in acceptance tests
2016,Patrick Peralta,Adam Skogman,"Same problem on M6 and using BUILD-SNAPSHOT.

When deploying a stream that has a slow-starting component (that connects to Gemfire), the deployment fails with a ZK NoNode exception.

No log from the component seen, but in all honesty, the component could be waiting on a timeout.

org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/2af8624b-777c-4084-aa1a-9d675b53afe3/test1.sink.reactor-batching-client-1/metadata
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:370)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$800(ContainerRegistrar.java:93)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:706)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)",XD-1730,Adam Skogman,Zookeeper NoNode exception when deploying stream
2017,Mark Pollack,Glenn Renfro,,XD-1729,Glenn Renfro,Update dependencies in Spring XD Sample Repository
2018,Gunnar Hillert,Gunnar Hillert,"Hitting this issue in Chrome:

http://stackoverflow.com/questions/22891611/google-font-varela-round-doesnt-support-font-weight-in-chrome

Looks like Chrome has some issues with making text bold if the font does not explicitly support it.
",XD-1728,Gunnar Hillert,Add Support for Bold/Strong Fonts 
2019,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Add an option to destroy the stream/job definitions.
Also add confirm action that asks for user to confirm to proceed with destroy.",XD-1727,Ilayaperumal Gopinathan,Add Stream/Job destroy option at the UI
2020,Kashyap Parikh,Kashyap Parikh,"https://build.spring.io/browse/XD-JDK8-5

apply plugin: 'jacoco'

jacoco {
    toolVersion = ""0.7.0.201403182114""
}",XD-1726,Kashyap Parikh,Change jacoco to 0.7 for jdk 8 builds
2021,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Based on the discussion here:

https://github.com/spring-projects/spring-xd/pull/852#issuecomment-43356579

we would like to have tests created for verifying the Stream/Job deployments path ""data"" ",XD-1725,Ilayaperumal Gopinathan,Create tests for Stream/Job deployments path data verification
2022,Eric Bottard,Derek Beauregard,"All of the CLI module commands that require the module name (e.g., 'module display source:mqtt') require that you preface the name with the module type.  If you forget to do this, e.g., 'module display mqtt', you get a fairly cryptic exception which can confuse end users.  The exception is:

java.lang.StringIndexOutOfBoundsException: Failed to convert 'mqtt' to type QualifiedModuleName for option 'name,'
String index out of range: -1",XD-1724,Derek Beauregard,CLI error when not specifying module type in module commands is cryptic an not helpful
2023,Eric Bottard,Derek Beauregard,"In the Module Composition example here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#composing-modules on of the examples is ""module delete --name foo --type sink"" which fails as the '--type' argument is not supported by the CLI.  

There are 3 other references to the '--type' argument in the documentation which may not be supported by the CLI anymore. ",XD-1723,Derek Beauregard,'--type=' not supported by module delete as shown in documentation examples
2024,Gunnar Hillert,Gunnar Hillert,"The current screen layout is problematic in cases where there are many deployments. Having a dedicated page for Launching or Scheduling jobs may be desirable. 

Alternatively, a light-box-based approach may be possible but I personally don't favor that.",XD-1722,Gunnar Hillert,UI: Refactor Schedule and Launch Screen under Deployments
2025,Eric Bottard,Eric Bottard,,XD-1721,Eric Bottard,Add a test for ${xd.stream.name} inside the DSL definition of a stream
2026,Eric Bottard,Eric Bottard,"As a consequence of not fixing XD-1289, we should document keys of the form ${xd.stream.name} that are available to users

${xd.[stream|job].name} and ${xd.container.???} come to mind, there may be others",XD-1720,Eric Bottard,Document OOTB available ${xd.???} keys
2027,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"After successful job deployment, the Job deployments path in ZK doesn't get updated with the data {""state"": ""deployed""}

Though this data is not used for deployed instance repository (org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository) to check for the deployment status, it may be better to have this state updated like stream deployment path.",XD-1719,Ilayaperumal Gopinathan,ZooKeeper Job deployments path state is not updated after successful deployment
2028,Glenn Renfro,Glenn Renfro,The TwitterSearch does a case insensitive search.  Tests need to do a insensitive check for the keywords in the search result.,XD-1718,Glenn Renfro,Twitter Search test uses case sensitive search when it should be case insensitive.
2029,,Ilayaperumal Gopinathan,"Based on the discussion from here:

https://github.com/spring-projects/spring-xd/pull/849#issuecomment-43215168

we need a better strategy to handle some of the queries and updates to the batch domain objects.",XD-1717,Ilayaperumal Gopinathan,Optimize JobService queries and batch domain object usages
2030,Eric Bottard,Mark Pollack,"Modules can use property values in servers.yml which is very handy to keep batch and hdfs functionality working without duplication of config values in servers.yml and modules.yml (or individual modules).   The configuration section should highlight the common cases where this occurs, batch, hdfs, rabbitmq/mqtt where using the server config values as defaults is useful and that they can still be overridden.
",XD-1716,Mark Pollack,Document that modules can reference property values in servers.yml
2031,Mark Pollack,Mark Pollack,"Create a new section in the docs regaring shell usage, in particular how to represent single and double quotes.

Include some discussion of basic commands to manipulate streams, jobs and list modules.  How to pass in a file that can be executed when the shell starts up.

Also point to spring-shell ref docs for extensibility in terms of adding custom commands.",XD-1715,Mark Pollack,Create documentation section for the shell
2032,Gunnar Hillert,Gunnar Hillert,"It would be neat if streams could be easily formatted. E.g:

* Make the definition name bold
* use different colors for parameter names and values

",XD-1714,Gunnar Hillert,Add AngularJS Directive to format Stream Definition Strings
2033,Ilayaperumal Gopinathan,Mark Pollack,,XD-1713,Mark Pollack,Show visual representation of stream in admin UI
2034,Glenn Renfro,Glenn Renfro,Update StreamUtils based on Code Review comments.,XD-1712,Glenn Renfro,StreamUtil Cleanup
2035,Glenn Renfro,Glenn Renfro,Also check the JMX output to see that the filter rejected the entry.,XD-1710,Glenn Renfro,ProcessorTest.testfailedSink needs to use http as its test source
2036,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the flag ""stoppable"" on JobExecutionInfoResource is used to find if the jobExecution can be stopped.

Since this flag is set to true even if the JobExecution status is COMPLETED, the jobExecution can still say it can be stopped.",XD-1709,Ilayaperumal Gopinathan,Handling JobExecution stop action if the JobExecution is COMPLETED
2037,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Upon container departure, the ContainerListener's onChildLeft() event triggers redeployment of stream/job modules that were deployed into the leaving container. During the redeployment, it happens that the container candidates from the DefaultContainerMatcher *sometimes* (based on the subset from distributeForRequestedCount(List<Container> candidates, int count))  includes the container which already have the module of the *same* stream/job definition deployed. This causes the re-deployment silently swallowing the NodeExistsException and the module being re-deployed doesn't actually get deployed.
",XD-1708,Ilayaperumal Gopinathan,Re-deployment of stream/job modules upon container departure doesn't choose appropriate container candidates
2038,Gary Russell,Derek Beauregard,"The example in the M6 documentation for the Dynamic Router (here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#dynamic-router) for the SpEL-Based Routing throws an exception when processing the message (from the HTTP post) saying ""No bean named 'queue:foo' is defined"", when using RabbitMQ as the transport.  I do not know a workaround.

Steps to reproduce:
1) Run RabbitMQ locally
2) Run xd-singlenode --transport rabbit
3) xd:>stream create f --definition ""queue:foo > transform --expression=payload+'-foo' | log"" --deploy

xd:>stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log"" --deploy

xd:>stream create r --definition ""http | router --expression=payload.contains('a')?'queue:foo':'queue:bar'"" --deploy

4) xd:>http post --data ""a""

5) This should give a stacktrace:
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'queue:foo' is defined
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)
	... 83 more
",XD-1707,Derek Beauregard,The Dynamic Router example in the docs throws an exception with Rabbit Transport
2039,Eric Bottard,Derek Beauregard,"Tab completion doesn't currently list/support ""queue"" as a source.  For example if typing the following stream:
stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log"" --deploy

Tab completion doesn't recognize or suggest ""queue"" or anything after it until after the first bar ""|"".  

The same applies to named channels, ""queue"", as a sink.",XD-1706,Derek Beauregard,"Add tab completion for named channels (i.e., queue:xyz >)"
2040,Thomas Risberg,Thomas Risberg,"Each Hadoop distro uses different settings for ""yarn.application.classpath"" and we should provide some starting points for the distros we support running XD on YARN for.

We should add a commented out stub ""defaultYarnClasspath"" entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros.
",XD-1705,Thomas Risberg,"Add defaultYarnClasspath entry for phd20, cdh5 and hdp21"
2041,Eric Bottard,Eric Bottard,"Document the different ""onion layers"" that come in play with regard to quoting and escaping (shell, xd-parser, SpEL expressions in some cases) and provide practical examples to common scenarios

",XD-1704,Eric Bottard,Create doc section about quotes handling
2042,liujiong,Thomas Risberg,"We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN/Boot specific config options.
{code}
xd:
    adminServers: 1
    containers: 1
{code}

Proposing we do:
{code}
xd:
    adminServers: 1
    adminMemory: 512M
    containers: 1
    containerMemory: 512M
{code}

",XD-1703,Thomas Risberg,Add admin and container memory settings to servers.yml
2043,Thomas Risberg,Thomas Risberg,"Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn't be needed except for module info for hdfs sink (see XD-1701)",XD-1702,Thomas Risberg,Remove Hadoop from admin classpath
2044,liujiong,Thomas Risberg,"The hdfs sink metadata causes loading of  org.springframework.data.hadoop.store.codec.Codecs class during 'module info --name sink:hdfs' command since the type is a specific Spring Hadoop class

options.codec.description = compression codec alias name
options.codec.type = org.springframework.data.hadoop.store.codec.Codecs
options.codec.default =

Don't think we want to tie the sink module to specific Spring Hadoop classes during runtime of the admin, we can't be sure that admin has hadoop classes on classpath in all environments and there is no way of specifying the hadoop distro for admin.

Wouldn't it be better to have this option as a String to be passed in to the module's context that could then load the class",XD-1701,Thomas Risberg,hdfs sink loads Codecs class during 'module info --name sink:hdfs' command
2045,Mark Fisher,Mark Fisher,,XD-1700,Mark Fisher,Disable auto-formatting of JavaDoc
2046,Glenn Renfro,Glenn Renfro,,XD-1699,Glenn Renfro,Rabbit Sink Acceptance Tests
2047,Glenn Renfro,Glenn Renfro,"Deploy XD Sample Gemfire on Utility Machine.
Deploy stream with gemfire as a source.
Create a stream (stream2) with gemfire-server as a sink
Send data to stream 2 and verify that the data has been received by gemfire source.
Update CI tests to increase heap, to support gemfire tests..",XD-1698,Glenn Renfro,Gemfire Source Acceptance Test
2048,,Glenn Renfro,,XD-1697,Glenn Renfro,hdfsjdbc Acceptance Test
2049,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Support the ability to provide deployment properties for ""job deploy"".",XD-1696,Ilayaperumal Gopinathan,Enable Job deployment properties for job deploy
2050,Marius Bogoevici,Sabby Anandan,"As a user, I'd like to have the option to provide security configurations so that I can access REST endpoints in a secured manner. 

Ideally, all the listed [REST|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] endpoints needs to be wrapped within a security layer. 

*Scope of this spike:*

* Research Spring Security and Spring Boot and the OOTB features 
* Design considerations and approach for XD
* Developer experience
** How users will be configuring security credentials?
** How DSL shell will be handled?
** How Admin UI will be handled?",XD-1695,Sabby Anandan,Research how to secure Admin's REST endpoints
2051,,Sabby Anandan,"Acceptance Criteria:
- Users should be able to gain access using username/password
- Both username/password are mandatory
- Invalid user credentials should be displayed as error messages and the user will not be able to gain access",XD-1694,Sabby Anandan,Provide security integration
2052,,Sabby Anandan,"We would like to experiment with “GraphLab”, a graph based, high performance, distributed computation framework written in C++. 

Features:
* HDFS integration
* Maching learning toolkits

Website -> http://graphlab.org/projects/index.html
GitHub -> https://github.com/graphlab-code/graphlab

_Note: Could be part of unified offering of PHD_",XD-1693,Sabby Anandan,GraphLab - enhance machine learning and computations
2053,,Sabby Anandan,"We would like to experiment with “stream-lib”, a stream summarizer and cardinality (counting distinct elements) estimator to further enrich Spring XD's analytics feature-set.

GitHub -> https://github.com/addthis/stream-lib",XD-1692,Sabby Anandan,Stream-lib - analytics operators
2054,,Sabby Anandan,"We would like to experiment with “ELK” stack. It’s the combination of Elasticsearch, Logstash and Kibana to extract end-to-end real-time insights from structured and unstructured data source. Possibly provide integration endpoints to some of the components.

Features:
* Search and analyze in real-time
* Scrub, parse and enrich data
* Visualization

Website -> http://www.elasticsearch.org/overview/
GitHub -> http://www.elasticsearch.org/overview/elkdownloads/",XD-1691,Sabby Anandan,ELK - log analysis
2055,,Sabby Anandan,"We would like to experiment with “Riemann”, a Clojure library to aggregate events from servers and applications through stream processing. 

Features:
* Tracking latency distribution
* Email for exceptions
* Memory and CPU statistics

This will help understand the behavior of critical components to eventually orchestrate workflows to proactively monitor and notify important contacts/groups as needed. 

Webiste -> http://riemann.io/
GitHub -> https://github.com/aphyr/riemann",XD-1690,Sabby Anandan,Riemann - measure based alerts
2056,,Sabby Anandan,"We would like to experiment with “metrics”, a Java library to extract insights of production code. This will help understand the behavior of critical components to eventually orchestrate workflows to proactively monitor and notify important contacts/groups as needed.

Website -> http://metrics.codahale.com/
GitHub -> https://github.com/dropwizard/metrics",XD-1689,Sabby Anandan,Metrics - measure based alerts
2057,,Sabby Anandan,"We would like to experiment with open source libraries to further enrich Spring XD’s service offerings and feature-set.

This epic remains the anchor point for following categories and the respective experimentation outcomes will be documented in the associated stories.

* Measure based alerts
* Log analysis
* Machine learning and graph computation",XD-1688,Sabby Anandan,New libraries to experiment
2058,Gunnar Hillert,Mark Pollack,"* StepExecutionContext
* StepExecutionProgress
* JobScheduler
* Stream page
* Job definition (XD1615)

",XD-1687,Mark Pollack,Add UI screen shots to docs for new features in Alpha 
2059,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the admin nodes that participate in the leadership election are grouped under /xd/admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to /xd/admins.",XD-1686,Ilayaperumal Gopinathan,Pluralization of admin nodes leadership selector group path (/xd/admin)
2060,Glenn Renfro,Glenn Renfro,,XD-1685,Glenn Renfro,Rabbit Source AcceptanceTest
2061,Gary Russell,sivan gopalsamy,"I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e ""stream create --name TEST-LOG  --definition ""jms | file"" --deploy"". I am trying to configure the ""spring-xd-1.0.0.M6\xd\modules\common\jms-jbossmq-infrastructure-context.xml"" to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",XD-1684,sivan gopalsamy,Test integration with jboss queue message
2062,,Glenn Renfro,"XD Deployment 
Description	XD Cluster (1 Container)
Environment	EC2
Type Of Test	Manual test via shell
Test Failed On	syslog-tcp (only test that was run)
Build Used	Built May 7, 10:29 UTC

[Setting up the Environment]
* Used the wiki instructions to setup the syslog on the ec2 instance. 
* Deploy the stream below:
stream create mystream --definition ""syslog-tcp | file --binary=true --mode=REPLACE"" --deploy 
* On the EC2 Instance execute the line below:
logger -p local3.info -t TESTING ""Test Syslog Message""

[What occurred]
Stream fails to process inbound syslog information and throws the exception below: 

Exception in thread ""inbound.mystream.0-redis:queue-inbound-channel-adapter17"" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)
	at org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)
	at org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)
	at java.lang.Thread.run(Thread.java:724)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)
	... 5 more",XD-1683,Glenn Renfro,syslog-tcp throws exception when receiving syslog data
2063,Glenn Renfro,Glenn Renfro,,XD-1682,Glenn Renfro,Syslog Acceptance Tests
2064,,Glenn Renfro,"If a user wishes to run the acceptance tests from their local machine against an XD instance on EC2  the only way to establish container and admin server is via the artifact ec2servers.csv. And this has to be copied to the spring-xd-integration-test subdirectory.  
The user should be able to set the xd_admin_host and xd_containers in the application-<profile>.properties file. ",XD-1681,Glenn Renfro,Need to support XD_admin_host and xd_containers in test properties
2065,Glenn Renfro,Glenn Renfro,,XD-1680,Glenn Renfro,jdbchdfs Acceptance Test
2066,David Turanski,Gary Russell,"The xd-dirt log4j.properties includes the calling line number {{%L}} which is not recommended for production.

https://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/PatternLayout.html

{{WARNING Generating caller location information is extremely slow and should be avoided unless execution speed is not an issue.}}",XD-1679,Gary Russell,Remove %L from Log4j PatternLayout
2067,Glenn Renfro,Glenn Renfro,"XD Deployment Description	XD Cluster (1 Container)
Environment	EC2
Type Of Test	Shell Command Line
Test Failed On	hdfs (only test that was run)
Build Used	Built May 7, 10:29 PST

[Overall issue]
XD Admin and container lost connectivity to the the jobstore (MySql on RDS) and did not reconnect.  
Exception Displayed in log.
Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: The last packet successfully received from the server was 54,321,927 milliseconds ago.  The last packet sent successfully to the server was 54,321,928 milliseconds ago. is longer than the server configured value of 'wait_timeout'. You should consider either expiring and/or testing connection validity before use in your application, increasing the server configured values for client timeouts, or using the Connector/J connection property 'autoReconnect=true' to avoid this problem.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1117)
	at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3871)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2484)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2664)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2788)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2738)
	at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1617)
	at org.springframework.jdbc.core.JdbcTemplate$1QueryStatementCallback.doInStatement(JdbcTemplate.java:452)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:402)
	... 57 more

[Side Effects]
[Unable to create new Job with same name]
User executed a job list and then removed the jobs in the list.  When the user tried to create new jobs using the same names the application reported:
""Command failed org.springframework.xd.rest.client.impl.SpringXDException: StatementCallback; SQL [SELECT JOB_NAME FROM JOB_REGISTRY_NAMES]; No operations allowed after connection closed.; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed.""
The only way to resolve it completely was to: 
1) shutdown the admin and the containers.  
2) Clear the jobs from the Batch job tables by hand
3) restart XD admin and containers.
",XD-1678,Glenn Renfro,"XD does not reconnect to jobstore if connection is  lost, leaving Jobs in inconsistent state."
2068,Gary Russell,Gary Russell,Allows looking at message headers without turning on debugging.,XD-1677,Gary Russell,"Add ""log-full-message"" Property to the Log Sink"
2069,Glenn Renfro,Glenn Renfro,,XD-1676,Glenn Renfro,FileJdbc Acceptance Test
2070,,Glenn Renfro,"XD Deployment 
Description:		XD Cluster (1 Container)
Environment:		EC2
Type Of Test:		Manual Test
Test Failed On		filepollhdfs (only test that was run)
Build Used		Built May 7, 10:29 UTC

From the shell, attempted to create filepollhdfs however no results were written to hdfs (hadoop22).  

The commands executed were the following:
job create myjob --definition ""filepollhdfs  --names=forename,surname,address"" --deploy
stream create mystream --definition ""file --dir=67fc27a6-224d-4c67-a02a-40730bcf8906 --pattern='*.out' > queue:job:myjob"" --deploy

No warnings nor exceptions were displayed till I changed the log4j.logger.org.springframework to INFO and restarted the container. 
Then when I copied the sample file to the monitored directory the log reported:
21:30:07,605  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer:118 - deployed SimpleModule [name=file, type=source, group=mystream, index=0 @61612c7c]
Exception in thread ""inbound.job:myjob-redis:queue-inbound-channel-adapter1"" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)
	at org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)
	at org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)
	at java.lang.Thread.run(Thread.java:724)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)

When using the attached sample file, you need to rename the file to try2.out.",XD-1675,Glenn Renfro,FilePollHdfs is not writing results to hdfs
2071,Eric Bottard,Gunnar Hillert,"This source exists:
{code}
http://localhost:9393/modules/source/time
{code}
But trying to access a non-existing source such as:
{code}
http://localhost:9393/modules/source/time2
{code}
Triggers in the UI: 
{code}
[{""links"":[],""logref"":""NullPointerException"",""message"":""NullPointerException""}]
{code}
On the server-side:
{code}
6:03:45,387 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:199 - Caught exception while handling a request
java.lang.NullPointerException
	at org.springframework.xd.dirt.rest.DetailedModuleDefinitionResourceAssembler.toResource(DetailedModuleDefinitionResourceAssembler.java:49)
	at org.springframework.xd.dirt.rest.ModulesController.info(ModulesController.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:621)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
{code}

Accessing a non existing resource should probably result in a 404 status code.",XD-1674,Gunnar Hillert,Accessing non-existing module causes NullPointerException
2072,Eric Bottard,Glenn Renfro,currently the documentation only shows the --name as an option.  Review the FilePollHdfsJobOptionsMetadata to find all the available options.,XD-1673,Glenn Renfro,filepollhdfs documentation needs to be updated with all of the options available.
2073,Glenn Renfro,Glenn Renfro,,XD-1672,Glenn Renfro,Add filepollhdfs Acceptance Tests
2074,Michael Minella,Michael Minella,"When running a query against a large dataset, JDBC will attempt to load the entire result set into memory by default.  If this isn't desired (which would be the case in the prepackaged jobs), you can set the fetchSize on the JdbcCursorItemReader to set the number of rows to return with each fetch.  It is good practice to make this match the commit interval.  

If the fetch size is not set with large datasets, the stack blows with an OutOfMemoryException.",XD-1671,Michael Minella,Set fetch size when reading from database in pre-packaged jobs
2075,Patrick Peralta,Patrick Peralta,"When a container departs the cluster the admin will try to redeploy any modules that container was running. If the stream was *destroyed* and the container exited before it had the chance to clean up its deployments under {{/xd/deployments/modules}} (for example, with {{kill -9}}) the following NPE occurs:

{noformat}
java.lang.NullPointerException
	at org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:347)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:158)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)
{noformat}

If the stream was *undeployed* the following stack appears:
{noformat}
15:13:06,002 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 - 
java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:468)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)
	at org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:358)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:417)
	... 16 more
{noformat}

In short, this logic makes the assumption that the stream is still present and deployed. It needs to take into account the fact that neither assumption can be made.",XD-1670,Patrick Peralta,NPE when a container departs
2076,Mark Pollack,Gunnar Hillert,XD-1623 introduced the dependency to a SNAPSHOT version,XD-1669,Gunnar Hillert,Update Spring Batch Admin dependency to release version
2077,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When adding streams page to the UI (from XD-1667), it is necessary to modularize the angular app modules based on the functionality/components (job, stream, auth etc.,). 

As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",XD-1668,Ilayaperumal Gopinathan,Modularize angular app modules based on the functionality
2078,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,The streams page needs to be added to the UI at least to show the job triggers that are created while scheduling XD jobs.,XD-1667,Ilayaperumal Gopinathan,Add Steams page to show job triggers
2079,Mark Pollack,Mark Pollack,,XD-1666,Mark Pollack,Upgrade to Spring Shell 1.1 RC3
2080,Mark Pollack,Mark Pollack,,XD-1665,Mark Pollack,Update to snapshot builds of Spring Shell
2081,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The prefix ""singlenode"" in embeddedHsql option property defined in singlenode profile seems to be an overhead as it only exists in singlenode profile.

Also, we don't need a system property ""XD_SINGLENODE_EMBEDHSQL"" as config/servers.yml can be used to override the default (from application.yml)",XD-1664,Ilayaperumal Gopinathan,"Remove ""singlenode"" prefix from embeddedHsql propery in singlenode profile"
2082,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, when creating the taps for streams, the name of the pub/sub channel inside the message bus would be 

""tap:<name-of-the-stream>.<module-name>.<module-index>

For instance, the following stream with name ""test"":

http | transform --expression=payload.toLowerCase() | file

will have the exchanges as  'topic.tap:test.http.0', 'topic.tap:test.transform.1' when using rabbit message bus.

Though, the stream config parser takes care of translating what user would provide in the DSL (for example: tap:stream:test.transform.1 to use the message bus exchange topic.tap:test.transform.1), it would be better we have the consistency inside the message bus channel name as well.

Also, this would be in sync with how we name taps for jobs. (tap:job:*)",XD-1663,Ilayaperumal Gopinathan, Tap naming consistency for stream taps
2083,Glenn Renfro,Glenn Renfro,Need to update the Jackson parser.,XD-1662,Glenn Renfro,Tests are failing due to change in JMX endpoint data
2084,Mark Pollack,Mark Pollack,Sonar build is currently failing.,XD-1661,Mark Pollack,Fix package tangles
2085,Gunnar Hillert,Mark Pollack,This will reduce one extra step for getting started using XD in distributed mode 'out of the box',XD-1660,Mark Pollack,Add Zookeeper distribution in the download zip
2086,Glenn Renfro,Mark Pollack,,XD-1659,Mark Pollack,Add HDFS (apache Hadoop 2.2 distro) acceptance tests
2087,Glenn Renfro,Mark Pollack,,XD-1658,Mark Pollack,Add Twitter Stream tests acceptance tests
2088,Glenn Renfro,Mark Pollack,,XD-1657,Mark Pollack,Add Twitter search module tests acceptance tests
2089,,Rodrigo Meneses,StubDatasetOperations class needs to be either declared asbtract or implemente inherited methods from DatasetOperations,XD-1656,Rodrigo Meneses,The type StubDatasetOperations must implement the inherited abstract method DatasetOperations.getDatasetDescriptor(Class<T>)
2090,David Turanski,Mark Pollack,"Do not convert the data into a spring social tweet object, pass along the json as-is from twitter search.",XD-1655,Mark Pollack,twittersearch module to produce json data as-is from twitter
2091,David Turanski,Mark Pollack,"The current output type is a Java object - this raises issues wrt to consumers in other JVM that to no have the spring social tweet object in the main container classpath.  See https://jira.spring.io/browse/XD-1370

Will also create another issue to update twittersearch to generate the raw twitterstream output vs. the structure of the spring social tweet object ",XD-1654,Mark Pollack,Change twittersearch default outputType to be application/json
2092,Gary Russell,Gary Russell,"XD-1019 added simple (stateless) retry to the message bus.

Use stateful retry and an {{AmqpRejectAndDontRequeueRecoverer}} enabling failed messages to be requeued on the broker until successful (perhaps because another instance can handle the message); also provides a mechanism to route failed messages to a dead-letter exchange.

Requires setting the message id header in bus-generated messages.

Also add profiles and properties for common retry/backoff policies.",XD-1653,Gary Russell,Add More Sophisticated Retry Configuration to the Rabbit MessageBus
2093,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,There are intermittent test failurs in the StreamDeploymentIntegrationTests (especially Rabbit tests). We can try using EventuallyMatcher and see if that fixes this.,XD-1652,Ilayaperumal Gopinathan,Fix intermittent test failures at StreamDeploymentIntegrationTests
2094,Thomas Risberg,Thomas Risberg,"HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id (GUID) - like base-path/logfile-GUID-1.txt
",XD-1651,Thomas Risberg,Update HDFS sink to use unique id (GUID) as part of file name
2095,Janne Valkealahti,Thomas Risberg,"Add configuration for the partition strategy to HDFS sink to support writing files into subdirectories based on a partition key provided in the header or field in the message of the stream data.

The writing using HDFS Store DataWriter should pass in the partition key value to be used for the write operation.

Partition configuration could be made available to the sink using a  --format parameter:

that could then be used in XML config like:
{code}
      expression=""new java.text.SimpleDateFormat('${format}').format(${timestamp})
{code}
Similar to the time source.",XD-1650,Thomas Risberg,Update HDFS sink to accept a partition strategy
2096,Glenn Renfro,Glenn Renfro,,XD-1649,Glenn Renfro,Spring XD using Redis as data transport is failing to start in CI Acceptance Test.
2097,,Mark Pollack,"Based off http://bit.ly/spring-xd-test-matrix

Provide test coverage for all batch jobs and source/sink/processors",XD-1647,Mark Pollack,Based off http://bit.ly/spring-xd-test-matrix
2098,Glenn Renfro,Glenn Renfro,This change has to be facilitated because of the XD-1456 and XD-1455 stories.,XD-1646,Glenn Renfro,CLI needs to be setup to use the updated acceptance test structure
2099,Glenn Renfro,Glenn Renfro,"[Add JavaDocs to]
* StreamUtils
* HttpTest
* MqttTest
* JmsSource

[Exception Handling]
StreamUtils stream method should throw  IllegalStateException instead of a checked exception.
XDEc2Validation assertReceived, assertValid should throw IllegalStateException instead of a checked exception ",XD-1645,Glenn Renfro,Refactor Exception Handling and update JavaDocs for acceptance test
2100,Ilayaperumal Gopinathan,Gunnar Hillert,"In *BatchJobExecutionsController$restartJobExecution()* we need to do a better check whether a Batch Job Execution is restartable. 

This is also true when executing *BatchJobExecutionsController$list()*. The check performed under *new JobExecutionInfo(jobExecution, timeZone)* is not sufficient.

*Reason*:

Currently in the UI when I have failed Job Executions, I can restart those (good). However, if the next execution succeeds, the previously restartable jobs should NOT be marked as restartable anymore. 

Right now you can restart those jobs, resulting in a:

{code}
Caused by: org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException: A job instance already exists and is complete for parameters={random=0.5735953106895085, throwError=true}.  If you want to run this job again, change the parameters.
	at org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:126)
	at sun.reflect.GeneratedMethodAccessor211.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:98)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:262)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:95)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.batch.core.repository.support.AbstractJobRepositoryFactoryBean$1.invoke(AbstractJobRepositoryFactoryBean.java:172)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy40.createJobExecution(Unknown Source)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:125)
	at sun.reflect.GeneratedMethodAccessor209.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy42.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)
	at sun.reflect.GeneratedMethodAccessor208.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:95)
	at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	... 98 more
{code}



",XD-1644,Gunnar Hillert,Rest: Improve the determination whether a Job Execution is Restartable
2101,,Gunnar Hillert,"The classes:

* org.springframework.xd.shell.util.Table
* org.springframework.xd.shell.util.TableHeader
* org.springframework.xd.shell.util.TableRow

are now provided by *org.springframework.shell.support.table*.

Objectives:

* We should use those. (But wait for SHL-142 to be complete)
* Improve all tests that use the table classes - Avoid accessing table data using numeric keys (row/column numbers) - Instead use ""business"" keys such as table header names etc.  
	
",XD-1643,Gunnar Hillert,Use new Table classes provided by Spring Shell
2102,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn't running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",XD-1642,Ilayaperumal Gopinathan,Fail fast admin server if admin's embedded tomcat couldn't start
2103,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When there are multiple containers (A, B and C) and a batch job is deployed into one of the containers A. When the container A goes down, the admin server tries re-deploy the job module that was deployed in container A into other matching container. But, when the re-deployment happens, it tries to update the distributed job locator as if a new job is being deployed and following exception is thrown:

17:13:38,811 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 - 
java.lang.RuntimeException: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:411)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:355)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:349)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:695)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:167)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1514)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:252)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:699)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:241)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:186)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:176)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:166)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:230)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:399)
	... 20 more
Caused by: org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists
	at org.springframework.xd.dirt.plugins.job.DistributedJobLocator.addJob(DistributedJobLocator.java:114)
	at org.springframework.xd.dirt.plugins.job.BatchJobRegistryBeanPostProcessor.postProcessAfterInitialization(BatchJobRegistryBeanPostProcessor.java:106)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:421)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.postProcessObjectFromFactoryBean(AbstractAutowireCapableBeanFactory.java:1698)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:164)
	... 36 more",XD-1641,Ilayaperumal Gopinathan,"Upon a container departure, redeployment of batch job fails on an existing container"
2104,liujiong,Mark Pollack,"Information related to an xd-container process and/or machine that is not static, such as 'group', e.g. free memory, number of deployed streams, should be available for use as variables in the evaluation context of the criteria SpEL expression in the admin's container matcher.

A good candidate for the source of this information are system MBeans.

See http://docs.oracle.com/javase/7/docs/api/java/lang/management/package-summary.html


",XD-1640,Mark Pollack,Add information that is updated in real-time for use in container matching
2105,liujiong,Mark Pollack,"Just as a stream or a job may state its needs and preferences for container assignment using the 'criteria' or 'rank' expressions, the xd-containers themselves can specify needs and preferences using the same 'critera' and 'rank' expressions.  These would be sent to the xd-admin server and used in the ContainerMatcher, but is evaluated using the 'stream' or 'job' as the evaluation context.

Examples

* Requirements
** Require that this container only runs streams
** Never run jobs belonging to groupA

* Rank
** Prefer to run groupB's job.

",XD-1639,Mark Pollack,Add 'xd-container' requirements and rank expressions
2106,liujiong,Mark Pollack,"following the HTCondor model for resource assignment, the use of a 'rank' expression that evaluates to an integer is used to order the containers that match the current 'criteria' expression.  This allows you to setup ranks such as 'prefer the machine with the most free memory' or 'prefer a machine from groupa'  (higher rank values match first).

From HTCondor Presentation
Rank
* The rank expression is evaluated into a number for every potential matching machine.
* A machine with a higher number will be preferred over a machine with a lower number.

Rank Examples

* Prefer machines with more Mips:
** Rank = Mips

* Prefer more memory, but add 100 to the rank if the machine is Solaris 2.7:
** Rank = Memory + 100*(OpSys==“SOLARIS27)”

* Prefer machines with a high ratio of memory to cpu performance:
** Rank = Memory/Mips

* Prefer machines that will checkpoint in Bologna:
** Rank = (CkptServer==“ckpt.bo.infn.it”)


",XD-1638,Mark Pollack,Add a 'rank' expression to be used by the container matcher
2107,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"JSHint should be enabled in grunt build. There are few minor issues and needs to be fixed. 
",XD-1637,Ilayaperumal Gopinathan,Re-enable JSHint during grunt build
2108,David Turanski,Derek Beauregard,"When working w/ SXD xd-singlenode, out of the box, it defaults to using all embedded components (transport, analytics, hsqldb, & zookeeper), which is easy and a great way to get going.  This is also great for development.

When I then started trying out the M6 distributed mode I set my transport to rabbit in servers.yaml (now that the --transport option is gone).  Rabbit is my preferred transport here.

I then went back to running the singlenode, for simplicity, and then got an exception saying that the singlenode couldn't contact RabbitMQ/AMQP (I was no longer running rabbit).  I then had to add the '--transport local' flag back to xd-singlenode.  

Having the --transport option on xd-singlenode but not on xd-container is confusing.  Also I would expect xd-singlenode to default to local transport unless I specify another option in --transport.

-Derek",XD-1636,Derek Beauregard,servers.yaml's 'xd: -> transport: rabbit' overrides xd-singlenode's default of local transport
2109,Gunnar Hillert,Derek Beauregard,"If you mouse over any of the examples in the documentation, the grey boxes, containing code, shell commands, etc., typically in the upper right hand corner a label for the type of code/example will appear.  E.g., 'Ruby', 'Javascript' ,etc.  

1) The labels that appear seem to be random and incorrect.  Shell scripts show as 'Ruby' and 'Javascript'.

2) More importantly, on some of the examples the label appears in front of and part of the example, corrupting the example.  To see this hover your mouse over the two examples, grey boxes, here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#_xd_shell_in_distributed_mode

There may be more but this is the ones I noticed.  

-Derek",XD-1635,Derek Beauregard,Documentation: Hovering over some of the examples corrupts the text
2110,Gary Russell,Gary Russell,,XD-1634,Gary Russell,Update Spring Integration Version to 4.0.0.RELEASE
2111,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,It looks like the singlenode application used by each of the shell integration test class is shared by other test classes as well. This causes some issues that are common to these tests. We need to avoid such scenarios.,XD-1633,Ilayaperumal Gopinathan,Fix cross-talk among the shell integration tests
2112,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"There seems to be some cross talk among the shell integration tests. 
It looks like the same singlenode application might get shared among the test classes when they run in parallel.

Using unique queue names across the tests seem to fix the issue for now.",XD-1632,Ilayaperumal Gopinathan,Use unique queue names in shell tests
2113,Glenn Renfro,Glenn Renfro,"Options that are not covered:
--codec
--idleTimeout
--inUsePrefix
--inUseSuffix
--inputType
--overwrite

Options Renamed:
--filename is now --fileName",XD-1631,Glenn Renfro,Update hdfs sink docs
2114,Eric Bottard,Mark Pollack,Between M5 and M6 the size of the shell/lib directory went up ~50 MB.  Investigate and remove jars from being packaged that are not used.,XD-1630,Mark Pollack,Packaging of lib directory for shell contains many jars that are not used
2115,Gary Russell,Mark Pollack,To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored.  ,XD-1629,Mark Pollack,RabbitMessageBus should prefix all created queues with a prefix in order to support HA
2116,Gunnar Hillert,Gunnar Hillert,,XD-1628,Gunnar Hillert,UI: The user can view the job properties that were specified when the job definition was created as well as job parameters when it was launched/executed
2117,Gunnar Hillert,Gunnar Hillert,,XD-1627,Gunnar Hillert,UI: When launching a job - Required parameters should be indicated and their names prepopulated
2118,Gunnar Hillert,Gunnar Hillert,"* Show only the jobs that you have created vs. those of others. (Requires Security - e.g. XD-1616) - Probably a separate issue

* Show only jobs that are in a specific status/state,  running vs. other states.
* Show only jobs for the past x number of days.
* Show only jobs whose name matches a simple string, e.g. ‘userAnalysis’
",XD-1626,Gunnar Hillert,UI: Improve the filtering capabilities of jobs that are executing/have executed
2119,Gunnar Hillert,Gunnar Hillert,,XD-1625,Gunnar Hillert,UI: The user should be able to view metrics about an executed job.
2120,,Gunnar Hillert,"This may be broken up into multiple Jira issues. Provide a generic approach to render Batch jobs graphically. 

Second, especially for Hadoop components - Provide step-type-dependent renderings of Batch components - see: XD-1622",XD-1624,Gunnar Hillert,UI: The user should be able to view a graphical representation of the job
2121,Gunnar Hillert,Gunnar Hillert,,XD-1623,Gunnar Hillert,UI: For Hadoop Steps - provide a link to the MapReduce Job details in Hadoop. 
2122,Michael Minella,Gunnar Hillert,This may require additional support (Jiras) for Spring Batch,XD-1622,Gunnar Hillert,Add support for typed Batch Steps
2123,liujiong,Gunnar Hillert,Will require additional server-side Jiras,XD-1621,Gunnar Hillert,UI: The user should be able to view the log file for a specific job execution
2124,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row (mostly first row) like this:

String id = jobExecutions.getRows().get(0).getValue(1);
		displayJobExecution(id);

It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ",XD-1620,Ilayaperumal Gopinathan,Fix JobCommandTests' verification of shell result table rows using specific index
2125,Gunnar Hillert,Gunnar Hillert,This task will require additional Jiras in XD or also Batch. Currently we don't capture Step types.,XD-1619,Gunnar Hillert,UI: The user can view detailed information about steps for a specific job execution based on the type of the job
2126,Gunnar Hillert,Gunnar Hillert,,XD-1618,Gunnar Hillert,UI: The user can stop a specific job execution
2127,Gunnar Hillert,Gunnar Hillert,,XD-1617,Gunnar Hillert,UI: The user can view progress information about a given step
2128,Gunnar Hillert,Gunnar Hillert,Secure Admin UI to challenge users to enter username and password to gain access.,XD-1616,Gunnar Hillert,UI: The user should provide username/password to gain access to the UI
2129,Gunnar Hillert,Gunnar Hillert,,XD-1615,Gunnar Hillert,UI: The user can create a new job definition by selecting a job template and providing additional configuration properties
2130,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"If the job display command is executed for JobExecution and StepExecution list, it may be possible that the Job/Step execution's endTime still null (because the status is still unknown and not completed). In this case, the display command throws assertion failure here:

Caused by: java.lang.IllegalArgumentException: The provided date must not be null.
	at org.springframework.util.Assert.notNull(Assert.java:112)
	at org.springframework.xd.shell.util.CommonUtils.getUtcTime(CommonUtils.java:144)
	at org.springframework.xd.shell.command.JobCommands.display(JobCommands.java:249)",XD-1614,Ilayaperumal Gopinathan,Job display command handling null date value for execution endtime
2131,Andy Clement,Mark Fisher,"This fails:
{code}
xd:>stream create s --definition ""http | transform --expression='hi'+payload | log""

Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 34): unexpected data in stream definition '+'
http | transform --expression='hi'+payload | log
{code}

But this works:
{code}
xd:>stream create s --definition ""http | transform --expression=payload+'hi' | log""

Created new stream 's'
{code}
",XD-1613,Mark Fisher,Parser fails on + after literal within an expression
2132,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The UI controllers in spring-xd/spring-xd-ui/app/scripts/controllers.js definitions look overly complicated to get the modularization work. 

We can possibly refactor and make it look clean; especially we will follow this as the example for subsequent controllers definitions.",XD-1612,Ilayaperumal Gopinathan,Simplify/Refactor UI controllers
2133,Glenn Renfro,Glenn Renfro,,XD-1611,Glenn Renfro,XD-EC2 will have to support the --hadoopDistro command line for xd-container
2134,,Mark Pollack,,XD-1610,Mark Pollack,Management Features
2135,,Mark Pollack,,XD-1609,Mark Pollack,allows users to override defaults used in the XD runtime
2136,,Mark Pollack,,XD-1608,Mark Pollack,UI functionality for batch job managment
2137,,Mark Pollack,,XD-1607,Mark Pollack,XD Runtime Features
2138,,Mark Pollack,,XD-1606,Mark Pollack,Improvements to various parser options/grammar
2139,,Mark Fisher,,XD-1605,Mark Fisher,complete test matrix for EC2
2140,,Peter Rietzler,"-) start single node application
-) point browser to: http://localhost:9393/admin-ui/

The following error message is displayed in the browser (no additional info is displayed in terminal):

Whitelabel Error Page

This application has no explicit mapping for /error, so you are seeing this as a fallback.

Tue Apr 22 16:15:27 CEST 2014
There was an unexpected error (type=Not Found, status=404).
",XD-1604,Peter Rietzler,M6 admin UI displays only an error page
2141,,Peter Rietzler,"""module list"" output does not display anything for ""Sink"" and ""Job"". Tested with single node mode.

    Source              Processor           Sink      Job
  ------------------  ------------------  --------  -------
      file                aggregator
      gemfire             http-client
      gemfire-cq          bridge
      http                filter
      jms                 json-to-tuple
      mail                object-to-json
      mqtt                script
      post                splitter
      rabbit              transform
      reactor-ip
      reactor-syslog
      syslog-tcp
      syslog-udp
      tail
      tcp
      tcp-client
      trigger
      twittersearch
      twitterstream
      time
",XD-1603,Peter Rietzler,"""module list"" does not show sinks and jobs"
2142,Glenn Renfro,Glenn Renfro,"[Problem]
On a EC2 container jms-activemq.properties was configured to use a activemq broker on a different host, it still referred to localhost.  
On my local mac, I was able to updated the jms-activemq.properties with an activemq on a different host and it worked.

[work-around]
While not recommended you can set the amq.url in the jms-activemq-infrastructure-context.xml.

[Steps to reproduce]
1) Deploy a single admin/container using xd-ec2.  
2) create a jms-activemq.properties file in the spring-xd-1.0.0.BUILD-SNAPSHOT/xd/ where it refers to a broker on another machine (ec2-54-221-32-82.compute-1.amazonaws.com).  
3) Create a stream with JMS as its source.",XD-1602,Glenn Renfro,JMS Source on EC2 only uses localhost for activemq broker
2143,,Ilayaperumal Gopinathan,"There seems to be some inconsistency with the naming strategy for the named channels.

For example:

If we create a job ""j1"", the job launching request queue name in the message broker would ""job:j1"". To send a launching request, we can either use ""queue:job:j1"" or ""job:j1"" (both seems to work).

If we create a stream with the named p2p channel ""foo"" we expect to use the syntax ""queue:foo"" and the message broker will have the queue name ""queue:foo""

The StreamConfigParser resolves the source/sink channel names for tap to deduce the module index from the channel component: ChannelNode.resolve(StreamLookupEnvironment env)

But, in case of the named channels that have prefix ""topic:"" or ""queue:"", their names are used as is the only exception in a case where (From StreamConfigParser's eatChannelReference(boolean tapAllowed)
 
{code:java}
// queue:XXX
// topic:XXX
if (firstToken.data.equalsIgnoreCase(""queue"")) {
    channelType = ChannelType.QUEUE;
}
else if (firstToken.data.equalsIgnoreCase(""topic"")) {
    channelType = ChannelType.TOPIC;
}
// TODO: DT not sure if this is the best way to handle
// StreamConfigParserTests.substreamsWithSourceChannels()
if (channelScopeComponents.size() >= 3) {
    channelScopeComponents.remove(0);
}
{code}
The above code makes sure, ""queue:job:jobname"" still points ""job:jobname"".

We need some consistency when referring to the names of queues for the named channels above. Something like this:
""queue:job:j1"" for job launching request queue
 and ""queue:foo"" for the named p2p channel queue

or, a better strategy the has consistency across the named channels.",XD-1601,Ilayaperumal Gopinathan,Naming consistency for named channels
2144,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Since the batch job repository is not intended to be deleted, it is possible to have a batch job that already exists in the batch job repo even if the batch job definition is destroyed in XD. When a new job definition is created, we need to add a validation for the same job definition name against the batch job repository. Currently, we will only see a failure when the job is actually deployed into the container (when the batch job repository is updated during the deployment).",XD-1600,Ilayaperumal Gopinathan,Validate existence of batch job at the admin side
2145,Mark Fisher,Thomas Risberg,"This is currently in the M6 pom:

  <organization>
    <name>SpringSource</name>
    <url>http://springsource.org</url>
  </organization>
",XD-1599,Thomas Risberg,Change SpringSource references in pom.xml to Spring/spring.io
2146,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The messagebus implementations, upon registration of consumer and producer from/to messagebus the corresponding endpoints start. Instead of directly calling the start() on adapter/consumer we can call the corresponding Binding's start() which calls the underlying endpoint to start.
 This is in-line with the way the corresponding endpoints are stopped (using Binding's stop()) during undeploy/destroy.",XD-1598,Ilayaperumal Gopinathan,Use MessageBus Binding to start() underlying endpoint
2147,Gary Russell,Gary Russell,"If the rabbit source receives a message it can't convert, a {{MessageConversionException}} is thrown and the message is rejected (and requeued), causing an endless loop.

Add an {{ErrorHandler}} to the inbound adapter to detect and convert {{MCE}} to {{AmqpRejectAndDontRequeueException}}.

Also consider adding a retry interceptor to do the same for exceptions in modules (when using local transport).",XD-1597,Gary Russell,Update to Spring AMQP 1.3.2
2148,Gary Russell,Gary Russell,"acknowlege-more, tx-size, prefetch-count, concurrency etc.",XD-1596,Gary Russell,Rabbit Source Should Expose More Container Options
2149,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The MessageBus interface uses the aliasHint flag when binding consumer/producer on a point-to-point channel. 

Actually, the aliasHint is only needed when computing Source/Sink channel names in case named channel names. Otherwise, indexed channel names will be used for the input/output channel name. 

The only place where aliasHint is used in the message bus is on the LocalMessageBus where it provides a way to choose the channel provider (direct/queue channel) based on the alias hint. Otherwise, it is not needed in message bus bindproducer/consumer.

We need to simplify this.",XD-1595,Ilayaperumal Gopinathan,Remove aliasHint flag usage when binding producer/consumer to MessageBus 
2150,,Eric Bottard,"The analytics project has been used as a host for common repository classes because it was easily visible by both -dirt and other stuff (can't remember which)

This should be cleaned and a dedicated project for ""core"", ""utility"", ""re-usable"", ""whatever"" classes should be created

",XD-1594,Eric Bottard,Move resusable analytics repository classes to a new project.
2151,David Turanski,David Turanski,"The refactoring done for M6 prevents overriding ""codec"" bean configured for MessageBus. Since MB is now in SharedServerContext, that context can only be altered by a custom OrderedContextInitializer, for example. There is currently no mechanism provided by the BootStrapContext for dynamically loading a user's OrderedContextInitializer. ",XD-1593,David Turanski,Make transport serialization configurable
2152,David Turanski,David Turanski,"Change message-bus.xml to read 

<import resource=""classpath*:/META-INF/spring-xd/transports/${XD_TRANSPORT}-bus.xml""/>

So new transports may be configured in external jars",XD-1592,David Turanski,Make transport configuration extensible. 
2153,Patrick Peralta,Patrick Peralta,"Flatten out ephemeral nodes written by containers when deploying modules. For instance, instead of {{.../streams/moduleType/moduleLabel/container}} use {{.../streams/moduleType.moduleLabel.container}}.

This change allows us to derive state for a stream/job without having to traverse multiple layers of znodes. This is a big deal because:
* each level of children requires a network call
* Curator can only cache one level of children
",XD-1591,Patrick Peralta,Flatten out ephemeral nodes 
2154,Patrick Peralta,Patrick Peralta,"To have a clear separation of definition vs runtime information, move the ephemeral nodes written by containers from {{/xd/streams/stream-name}} to {{/xd/deployments/streams/stream-name}}. Same for jobs.",XD-1590,Patrick Peralta,Move ephemeral nodes from /xd/streams to /xd/deployments/streams
2155,David Turanski,David Turanski,Modify the PluginContextExtensionsInitializer to consume .groovy bean definitions as well as XML. ,XD-1589,David Turanski,Support Groovy bean definitions as XD extensions
2156,Eric Bottard,Eric Bottard,"in EnvironmentAwareModuleOptionsMetadataResolver::loadPropertySources, the call to merge(parentEnv) was added to inherit the active profiles of the runtime.

Sadly, it added the parentEnv property sources by side effect.

Note that the jdbc module defaults rely on this bug",XD-1588,Eric Bottard,PropertySource leakage between runtime and modules
2157,Ilayaperumal Gopinathan,David Turanski,Provide module templates including required property keys but not values for  $XD_MODULE_CONFIG/source/twitter*/twitter*.properties. Also look for any other packaged modules that have required properties that should be statically configured and we cannot provide defaults.  The Source modules document should be more clear regarding the configuration of these properties.,XD-1587,David Turanski,Provide module configuration templates for twitter sources
2158,Patrick Peralta,David Turanski,"Run singlenode. Ensure twitterstream credentials are not valid. e.g.,  no consumerKey property. This is the default state.

>stream create tweets --definition ""twitterstream | log"" --deploy
Created and deployed stream 'tweets'

Meanwhile, Singlenode throws an exception, the stacktrace below 

xd:>stream list
  Stream Name  Stream Definition    Status
  -----------  -------------------  --------
  tweets       twitterstream | log  deployed

{code}
15:54:07,298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 -
java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""
{/code}",XD-1586,David Turanski,Stream should not be in deployed state following module failure. 
2159,Eric Bottard,David Turanski,">stream create ""tap:stream:foo > 

does not suggest modules",XD-1585,David Turanski,Tab completion does not work for stream definition following > 
2160,,Thomas Darimont,"Create an example application that demonstrates the processing / analysis from a stream of network packets.

A potential scenario could be the detection of ongoing cyber attacks by scanning for TLS packets that what to abuse a SSL vulnerability aka ""heart bleed"".

A library that could help with this is: http://jnetpcap.com/",XD-1584,Thomas Darimont,Sample app that can process and analyze network packets
2161,liujiong,Eric Bottard,"This has been encountered in a POC.

Could take the form of a processor (bson -> json) or better yet if possible, be added at the automatic type conversion level",XD-1583,Eric Bottard,Add support for BSON
2162,Mark Fisher,Thomas Risberg,"The ""runtime modules"" command can show a failure between the deployment command and the actual deployment on the container node, especially if there is a network hop. This clears up once the module is fully deployed.

{code}
xd:>stream create --name trois3 --definition ""time | jdbc"" --deploy 
Created and deployed new stream 'trois3'
xd:>runtime modules 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/bc95653e-9da5-4738-beb2-f215e4003318/trois3.source.time-0/metadata

xd:>runtime modules 
  Module                Container Id                          Options
  --------------------  ------------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  trois3.source.time-0  bc95653e-9da5-4738-beb2-f215e4003318  {format=yyyy-MM-dd HH:mm:ss, fixedDelay=1}
  wintu.sink.jdbc-1     bc95653e-9da5-4738-beb2-f215e4003318  {tableName=${xd.stream.name}, url=jdbc:hsqldb:hsql://carbon:9102/xdjob, columns=payload, driverClassName=org.hsqldb.jdbc.JDBCDriver, initializeDatabase=false, initializerScript=init_db.sql, username=sa}
  trois3.sink.jdbc-1    d0ad8eda-be27-46ac-86be-e43b5d9921af  {tableName=${xd.stream.name}, url=jdbc:hsqldb:hsql://carbon:9102/xdjob, columns=payload, driverClassName=org.hsqldb.jdbc.JDBCDriver, initializeDatabase=false, initializerScript=init_db.sql, username=sa}
  wintu.source.time-0   befa5f27-aac3-4d94-9171-77c07036ec75  {format=yyyy-MM-dd HH:mm:ss, fixedDelay=1}
{code}

 ",XD-1582,Thomas Risberg,"Temporary race condition between deployment and ""runtime modules"" command"
2163,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"If XD_CONFIG_LOCATION is set, then XD runtime's xd.config.home should use that. otherwise, they point to two different paths.",XD-1581,Ilayaperumal Gopinathan,XD config home should use XD_CONFIG_LOCATION if this is set
2164,Patrick Peralta,Patrick Peralta,"Consider a module running in a container when it is disconnected from ZK:

{noformat}
12:30:13,021  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:13
12:30:14,025  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:14
12:30:15,029  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:15
12:30:16,031  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:16
12:30:32,590  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:32
12:37:42,985  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:42
12:37:43,398  INFO main-SendThread(fe80:0:0:0:0:0:0:1%1:2181) zookeeper.ClientCnxn:1096 - Client session timed out, have not heard from server in 430809ms for sessionid 0x145662be03e0002, closing socket connection and attempting reconnect
12:37:43,985  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:975 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
12:37:43,986  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:852 - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session
12:37:43,988  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:43
12:37:43,989  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:1094 - Unable to reconnect to ZooKeeper service, session 0x145662be03e0002 has expired, closing socket connection
{noformat}

Currently the module for the disconnected container continues to execute:

{noformat}
12:37:45,994  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:45
12:37:46,997  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:46
12:37:48,000  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:47
12:37:48,094 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exception
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /xd
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:127)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)
	at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:609)
	at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
12:37:48,097  INFO main-EventThread state.ConnectionStateManager:194 - State change: SUSPENDED
12:37:48,097  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:262 - >>> Curator disconnected event: SUSPENDED
12:37:48,097  WARN ConnectionStateManager-0 server.ContainerRegistrar:325 - >>> disconnected container: 88ba115b-6190-497a-a67c-df1e295bf158
12:37:49,001  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:49
12:37:50,004  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:50
12:37:51,008  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:51
12:37:52,012  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:52
12:37:53,016  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:53
12:37:54,021  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:54
12:37:55,023  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:55
...
{noformat}

This container should not continue executing the module because the leader admin will likely select another container to execute this module. If and when this container reconnects to ZK, it can be (re)assigned modules for deployment.

This can be done via a simple undeployment; or we may even consider closing and reopening the application context.",XD-1580,Patrick Peralta,Undeploy modules when container disconnected from ZK
2165,Mark Fisher,Mark Fisher,,XD-1579,Mark Fisher,Release 1.0.0.M6
2166,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Once the container starts up and the module is deployed, the externalized module configuration properties could not be changed for the subsequent modules of same type.

Here is the scenario for a stream ""http | transform | log"", with XD_MODULE_CONFIG_LOCATION and XD_MODULE_CONFIG_NAME using their default values. 
In, ${xd.config.home}/modules/modules.yml, I have:
processor:
  transform:
    expression: ""'Inside modules.yml'""

and, in, ${xd.config.home}/modules/processor/transform/transform.properties, I have:
expression: ""'First module: inside transform.properties'""

Now, I deploy this stream: ""http | transform | log"".

Lets say, I have another stream that uses the transform module, but this time I want to change the expression in ${xd.config.home}/modules/processor/transform/transform.properties to,
expression: ""'Second module'""

Now, when the stream containing this transform module gets deployed, it uses the same transform.properties that is used by the previously deployed transform module.

What I understand from this behavior is that, the EnvironmentAwareModuleOptionsMetadataResolver caches the module environments for a given module type and name. When the same module is deployed from a given stream again, it uses the stored module environment and doesn't refresh/load the property sources from the module config locations mentioned above. Though this is good in one way that same module environment is re-used, changing the externalized module config properties would have no affect after the first module of same type/name is deployed.

Though the EnvironmentAwareModuleOptionsMetadataResolver is used by both admin and container, this JIRA focuses more on the container side.
There is one valid point with the current behavior where the module environment is cached and won't change. But is this by design?",XD-1577,Ilayaperumal Gopinathan,Changing externalized module config properties at runtime
2167,Eric Bottard,Thomas Risberg,There are some properties files in the config directory that no longer are needed. We should clean that up and also remove/update any documentation references to these files,XD-1576,Thomas Risberg,Remove unused .properties files in config and update docs
2168,Jon Brisbin,Mark Fisher,"Currently the reactor-syslog source module only supports TCP.

Once we add UDP support, we can probably remove the existing syslog-tcp and syslog-udp modules.",XD-1575,Mark Fisher,Add UDP support to reactor-syslog source module
2169,Glenn Renfro,Glenn Renfro,In this case we will use environment variables to set the JDBC sink settings.  Thus we will just remove code.,XD-1574,Glenn Renfro,JDBC Acceptance tests must jdbc props vs. configProps setting.
2170,Mark Fisher,Mark Fisher,"The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper.

https://github.com/spring-projects/spring-xd/wiki/Architecture",XD-1573,Mark Fisher,Update diagrams that show control transport
2171,,Glenn Renfro,"After creating a composed module, I am unable to delete it.

[Steps to reproduce]
xd:>module compose doo --definition ""filter --expression=payload.contains('doo') | file""
Successfully created module 'doo' with type sink
xd:>module 
module compose    module delete     module display    module info       module list       
xd:>module delete --name doo --type sink
java.lang.StringIndexOutOfBoundsException: Failed to convert 'doo' to type QualifiedModuleName for option 'name,'
String index out of range: -1
xd:>
",XD-1572,Glenn Renfro,Unable to delete composed module
2172,Mark Fisher,Eric Bottard,"We don't want jline1 anymore.
This shows in IDE only (either run shell integration tests, or run the shell as Gunnar mentioned)",XD-1571,Eric Bottard,JLine 1 is brought up (and shows in IDE) through ZK/curator
2173,David Turanski,Ilayaperumal Gopinathan,"When a module is deployed, it doesn't use Jolokia auto configuration (which requires an embedded servlet container configuration). But, the module context isn't using a servlet context.

From SimpleModule:

application = new SpringApplicationBuilder().sources(PropertyPlaceholderAutoConfiguration.class).web(false);

 and hence, the MBeans that are exposed by the deployed modules aren't accessible via Jolokia.
We definitely don't want SimpleModule to use web application context but we need to figure out if we can use the container's management port to expose the deployed modules MBeans via jolokia.
",XD-1570,Ilayaperumal Gopinathan,Deployed modules MBeans are not accessible via Jolokia
2174,Mark Fisher,Mark Pollack,the --transport option allows 'udp' as well as 'tcp/,XD-1569,Mark Pollack,Rename reactor-tcp module to reactor-ip since it also supports udp
2175,David Turanski,Mark Fisher,"e.g. Need to update this section (maybe others):
https://github.com/spring-projects/spring-xd/wiki/Running-Distributed-Mode

Remove all mentions of Control Bus, and replace any mentions of the --transport cmd line arg with the xd.transport property in yml.
",XD-1568,Mark Fisher,Update documentation related to transport and controlTransport
2176,Glenn Renfro,Glenn Renfro,XD-EC2 must use environment variable XD_TRANSPORT instead of --transport to declare data-transport for XD.,XD-1567,Glenn Renfro,Update XD-Ec2 deployer to use XD_TRANSPORT 
2177,Glenn Renfro,Glenn Renfro,"Similar to XD-1565  so I'd link these 2 together.

[Steps to reproduce on Hadoop12]
1) Created Table People with columns forename,surname and address (use the result from filejdbc)
2) job create myjob --definition ""jdbchdfs --sql='select col1,col2,col3 from some_table'""
3)job launch myjob
4) myjob is created on hdfs but with zero bytes
5) throws an exception, stack trace attached.",XD-1566,Glenn Renfro,"Document append configuration, else jdbchdfs writes empty file to hdfs"
2178,Thomas Risberg,Glenn Renfro,"When testing in both singlenode and cluster (redis), XD throws exception (stacktrace attached).  The file is created on hdfs, but it is empty.

[Steps to recreate Using Hadoop12]
1) job create myjob --definition ""filepollhdfs --names=forename,surname,address"" --deploy 
2) stream create csvStream --definition ""file --ref=true --dir=/tmp/dug --pattern=*.csv > queue:job:myjob"" --deploy
3) use excel to create a 3 column spreadsheet and save as csv. 
4) Copy csv to /tmp/dug directory",XD-1565,Glenn Renfro,"Document append support, else filepollhdfs writes empty file to hdfs"
2179,Eric Bottard,Ilayaperumal Gopinathan,"Following stream fails to work:

tream create s3 --definition ""http | rabbit --routingKey='mytest1'"" --deploy 
Created and deployed new stream 's3'
xd:>http post --data ""testing""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 testing
> 500 INTERNAL_SERVER_ERROR
> 500 INTERNAL_SERVER_ERROR

Error sending data 'testing' to 'http://localhost:9000'

The exception at the container log is:

07:24:57,245 ERROR pool-18-thread-4 http.NettyHttpInboundChannelAdapter:171 - Error sending message
org.springframework.messaging.MessageHandlingException: Expression evaluation failed: mytest1
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)
	at org.springframework.integration.handler.ExpressionEvaluatingMessageProcessor.processMessage(ExpressionEvaluatingMessageProcessor.java:76)
	at org.springframework.integration.amqp.outbound.AmqpOutboundEndpoint.handleRequestMessage(AmqpOutboundEndpoint.java:196)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy109.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy54.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy111.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$300(NettyHttpInboundChannelAdapter.java:69)
	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:168)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:43)
	at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:67)
	at org.jboss.netty.handler.execution.OrderedMemoryAwareThreadPoolExecutor$ChildExecutor.run(OrderedMemoryAwareThreadPoolExecutor.java:314)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1008E:(pos 0): Property or field 'mytest1' cannot be found on object of type 'org.springframework.messaging.support.GenericMessage' - maybe not public?
	at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:215)
	at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:85)
	at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:78)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:119)
	... 91 more",XD-1564,Ilayaperumal Gopinathan,Rabbit Sink with explicit routingKey as 'string' SpEl literal expression fails
2180,Eric Bottard,Glenn Renfro,"Steps to reproduce:
stream create --name test --definition ""http --port=9090 | log""  
stream create --name simplegauge --definition ""tap:stream:test > gauge"" 
http post --target http://localhost:9090 --data ""10""
redis-cli
get gauges.simplegauge

[the result]
redis 127.0.0.1:6379> get gauges.simplegauge
(nil)

Note:  It worked with admin/container but failed only on xd-singlenode.",XD-1562,Glenn Renfro,Gauge & Rich Gauge fail to write results to redis for singlenode
2181,,Glenn Renfro,"When trying to create the stream for the gemfire example:
stream create hashtags --definition ""tap:stream:tweets  > transform --script=tweetSummary.groovy | gemfire-server --keyExpression=payload['id']"" --deploy

The shell displays: 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module transform of type processor:
    valid: the 'script' and 'expression' options are mutually exclusive
 I get the following error ",XD-1561,Glenn Renfro,When using transform --script=foo.groovy shell displays error
2182,Gunnar Hillert,Glenn Renfro,"After updating the dependency to use the snapshot (even with M5) the conversion throws an exception.
Stacktrace attached. ",XD-1560,Glenn Renfro,Payload Conversion Sample throws exception.
2183,Gunnar Hillert,Glenn Renfro,Currently uses m5 dependency. ,XD-1559,Glenn Renfro,Payload Conversion will need to migrated to M6 as soon as M6 is available
2184,Mark Pollack,Mark Fisher,"(from the wordcount sample):

{code}
xd:>! cp /tmp/nietzsche-chapter-1.txt /tmp/xd/input/wordCountFiles
You cannot specify option '' more than once in a single command
{code}",XD-1558,Mark Fisher,shell cp command fails
2185,Glenn Renfro,Glenn Renfro,"if user already has /count/in on their hdfs the input file will not copy the sample file to hdfs.  need to make sure that a file is already present

if the hdfs 
Documents have to be updated to mention that hadoopDistro needs to be added both xd-singlenode and xd-shell",XD-1557,Glenn Renfro,Batch wordcount sample returns zero counts
2186,Thomas Risberg,Glenn Renfro,"1) Update Instructions to mention --hadoopDistro for both singlenode and shell.  Else demo will not work.
2) Pom needs to be updated to use 1.2.1 at the least.
3) I can see where hdfs is writing the results
4) throws NPE   Stacktrace is attached.",XD-1556,Glenn Renfro,Batch hashtag count throws exception when launched
2187,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Creating the following stream throws exception:

stream create s1 --definition ""http | transform --script=transform.groovy | log""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module transform of type processor:
    valid: the 'script' and 'expression' options are mutually exclusive

The ExpressionOrScriptMixin's assertions to check if script and expression options are mutually exclusive `always` fails.",XD-1555,Ilayaperumal Gopinathan,transform processor with script option is broken
2188,,Glenn Renfro,"Can't connect to remote activemq instance.  
Setup a jms-activemq.properties file with amq.url=tcp://:ec2-54-198-157-91.compute-1.amazonaws.com:61616.  
Source always refers to defaults of tcp://localhost:61616.  Localhost works",XD-1554,Glenn Renfro,JMS source can only connect to localhost
2189,Gary Russell,Glenn Renfro,"Keep in mind.  This could be pbkac, on my part.  Please review and see if you can get it to work.",XD-1553,Glenn Renfro,syslog source is not capturing log info.
2190,David Turanski,David Turanski,"Since transport is now shared by Admin and Container, a command line arg is not appropriate since it allows the user to set them to different values which would break XD. The recommend way to configure transport is in servers.yml.  The command line arg is still valid for single node",XD-1552,David Turanski,Remove --transport option except for single node
2191,,David Turanski,"Started container : AdminServerApplication
Documentation: https://github.com/SpringSource/spring-xd/wiki",XD-1551,David Turanski,Fix Startup Messages
2192,Gary Russell,David Turanski,"5:27:47,887 WARN DeploymentsPathChildrenCache-0 org.springframework.integration.context.IntegrationContextUtils:195 - No 'beanFactory' supplied; cannot find MessageBuilderFactory, using default.
a lot of those",XD-1550,David Turanski,Fix 'cannot find MessageBuilderFactory' warning
2193,Patrick Peralta,Patrick Peralta,"When a deployment fails on a container due to a misconfiguration, the container does not notify the admin. Instead the admin waits for the container to write out an ephemeral node to the definition path {{/xd/streams}} or {{/xd/jobs}} to indicate a successful deployment and if the path isn't written in 10 seconds the deployment is considered failed.

This ""timeout"" should be considered a heuristic failure, meaning that the container was not able to write out a response of success or failure. If the deployment fails, the container needs to indicate this by writing a node to ZK.",XD-1549,Patrick Peralta,Proactively handle failed deployments
2194,Patrick Peralta,Patrick Peralta,"{{ContainerListener}}, {{StreamListener}}, and {{JobListener}} have duplicate code for deploying and undeploying modules. This needs to be consolidated. One possibility is for the deployment code to live in classes named {{StreamDeployer}} and {{JobDeployer}}.",XD-1548,Patrick Peralta,Refactor duplicate code in Listeners
2195,Patrick Peralta,Thomas Risberg,"When starting and stopping xd containers there are entries left in the /xd/deployments/modules directory that will cause 'runtime modules' command to fail.

xd:>runtime modules 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/5201ac3f-e952-48a2-a807-4f0bb2dab82b/test.sink.hdfs-1/metadata

here the ""/xd/deployments/modules/5201ac3f-e952-48a2-a807-4f0bb2dab82b"" container is no longer running, but there is some data left over.
",XD-1547,Thomas Risberg,clean up dead entries in ZooKeeper /xd/deployments/modules
2196,Mark Fisher,Glenn Renfro,"* payment_with_error.txt is not present in the project
* --makeUnique is not available for this command anymore
* Syntax for http post needs to be updated
* Need to add a job deploy command or --deploy
* Throws Exception when deployed (stacktrace attached).",XD-1546,Glenn Renfro,Batch Notification Sample fails to execute
2197,Glenn Renfro,Glenn Renfro,need the ability to support the --group option.,XD-1545,Glenn Renfro,Support deploying to multiple containers in EC2 acceptance tests
2198,Glenn Renfro,Glenn Renfro,"Currently in order to deploy a user created job we copy the job to the containers and admin server, and then bounce the servers.  The tests will need the ability to copy these jobs to the containers, & admin and then bounce the servers.  
These sample jobs are located at https://github.com/spring-projects/spring-xd-samples",XD-1544,Glenn Renfro,Need to be able setup ec2 env to test  job samples in spring-xd-samples repo
2199,Glenn Renfro,Glenn Renfro,Need to update instructions to discuss the setup of the relational database requirement for the xd-admin.,XD-1543,Glenn Renfro,Update instructions to how to setup admin to use RDBMS.
2200,Thomas Risberg,Duncan McIntyre,"Use of FsShell in AbstractHdfsWriter.initializeCounterIfNecessary() causes MaprFS to throw an unimplemented operation exception.

Replacing the FsShell code with FileSystem.listStatus allows it to be used with MaprFs.",XD-1542,Duncan McIntyre,HdfsTextFileWriter incompatible with MaprFS
2201,Glenn Renfro,Glenn Renfro,"Deployed the batch basic as instructions prescribe.
Tests work for both singlenode and redis as a data transport.  However, while the job does deploy using rabbit  it does not launch.",XD-1541,Glenn Renfro,Batch Basic Fails to launch job when rabbit is data transport
2202,Patrick Peralta,Mark Fisher,"(the trace below occurs in the admin console but the Admin continues to handle subsequent deployment requests fine it seems)

To reproduce:

* start xd-admin and xd-container (just 1 of each)
* deploy 'time | log'
* kill both xd-admin and xd-container
* start xd-container by itself
* wait 10 seconds or so, then start xd-admin

result:
{code}
21:35:01,575 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 -
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/f89e5fdc-7dc1-49fb-93cc-d536ab853f12/s.source.time-0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:411)
	at org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:319)
	at org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:255)
	at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:272)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:152)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
{code}
",XD-1540,Mark Fisher,stack trace on xd-admin restart when redploying streams
2203,Mark Fisher,Mark Fisher,"After deploying stream (such as ""time | log""), the xd-container emits the following stacktrace(s) if the stream is in a deployed state when that xd-container process is halted via CTRL-C:

{code}
20:15:31,415  INFO main-EventThread module.ModuleDeployer:215 - removed SimpleModule [name=log, type=sink, group=s, index=1 @128936ff]
20:15:31,417 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exception
java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@7bf4bc83 has been closed already
	at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)
	at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:214)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:140)
	at org.springframework.xd.dirt.plugins.stream.StreamPlugin.beforeShutdown(StreamPlugin.java:74)
	at org.springframework.xd.dirt.module.ModuleDeployer.beforeShutdown(ModuleDeployer.java:267)
	at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:197)
	at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:169)
	at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:252)
	at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:580)
	at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
20:15:31,420  INFO main-EventThread server.ContainerRegistrar:250 - Undeploying module time-0: time type=source, deploymentProperties={count=1}
20:15:31,420  INFO main-EventThread module.ModuleDeployer:215 - removed SimpleModule [name=time, type=source, group=s, index=0 @51a42578]
20:15:31,420 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exception
java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@6d223732 has been closed already
	at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)
	at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:214)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:144)
	at org.springframework.xd.dirt.plugins.stream.StreamPlugin.beforeShutdown(StreamPlugin.java:74)
	at org.springframework.xd.dirt.module.ModuleDeployer.beforeShutdown(ModuleDeployer.java:267)
	at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:197)
	at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:169)
	at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:252)
	at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:580)
	at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
{code}
",XD-1539,Mark Fisher,Eliminate stack trace on xd-container shutdown when active module running
2204,Mark Fisher,Mark Fisher,,XD-1538,Mark Fisher,Update docs and samples now that deploy is false on job/stream creation
2205,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,,XD-1537,Ilayaperumal Gopinathan,Create documentation for Job listeners support
2206,Michael Minella,Michael Minella,,XD-1536,Michael Minella,Add ability to inject delimiter on pre-packaged jobs that deal with files.
2207,Patrick Peralta,Glenn Renfro,"if you mess up you consumerSecret,  then deploy the stream, it will throw a 403, which is correct.
Then you destroy, recreate, and redeploy with the correct key, source will not retrieve  any results.  The only solution was to bounce the single node.

Steps to repeat.
1) create a stream.  stream create twit --definition ""twittersearch --consumerKey=goodkey --consumerSecret=badsecret --query='Letterman'|log""
2) deploy stream and get 403
3) destroy stream
4) create twittersearch stream with good keys
5) deploy stream
6) No twitter data is displayed",XD-1535,Glenn Renfro,TwitterSearch does not deploy correctly if previous deploy fails
2208,,Glenn Renfro,"Data is returned, but not human readable i.e. ""org.springframework.social.twitter.api.Tweet@4b20a104"". 
Needs to be readable in log and or file.  ",XD-1534,Glenn Renfro,Twitter Search results are not deserialized
2209,Patrick Peralta,Patrick Peralta,"If a container fails to deploy a module, the admin needs to clean up the {{/xd/deployments/modules/CONTAINER-ID/module}} path so that another attempt can be made to deploy that module to that container.",XD-1533,Patrick Peralta,Admin needs to clean up failed deployment attempts
2210,Ilayaperumal Gopinathan,Patrick Peralta,"When a module fails to deploy (for instance an http module configured with a port that is already bound) subsequent attempts to deploy the module fail due to a JMX exception:

{noformat}
java.lang.RuntimeException: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:447)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:346)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:92)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:655)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:112)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:773)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:485)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:240)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:184)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:174)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:164)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:227)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:429)
	... 18 more
Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)
	at org.springframework.integration.monitor.IntegrationMBeanExporter.registerChannels(IntegrationMBeanExporter.java:837)
	at org.springframework.integration.monitor.IntegrationMBeanExporter.doStart(IntegrationMBeanExporter.java:459)
	at org.springframework.integration.monitor.IntegrationMBeanExporter.start(IntegrationMBeanExporter.java:410)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)
	... 33 more
Caused by: javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:606)
	... 37 more
{noformat}",XD-1532,Patrick Peralta,Clean up MBean registration for failed module deployments
2211,Thomas Risberg,Thomas Risberg,Make changes to XD on YARN config that correspond to XD-1499 changes,XD-1531,Thomas Risberg,Rename xd-config.yml to servers.yml and add modules/modules.yml to spring-xd-yarn
2212,Thomas Risberg,Thomas Risberg,"I get this:

{code}
xd:>hadoop fs rm /xd/test/time-3.log
Error: run HDFS shell failed. Message is: org.apache.hadoop.fs.FileStatus.isDirectory()Z
{code}

so far I have seen this with --hadoopDistro hdp13 and hadoop12

same command works fine using shell from M5 release
",XD-1530,Thomas Risberg,Error when removing HDFS files in shell
2213,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When using hdp13, the XdConfigLoggingInitializer throws this info:

12:02:06,064  INFO main util.XdConfigLoggingInitializer:77 - Hadoop Distro: hdp13
12:02:06,068  WARN main util.XdConfigLoggingInitializer:84 - Hadoop version detected from classpath: 1.2.0 but you provided '--hadoopDistro hdp13'. Did you mean '--hadoopDistro hdp20'?
12:02:06,069  WARN main util.XdConfigLoggingInitializer:84 - Hadoop version detected from classpath: 1.2.0 but you provided '--hadoopDistro hdp13'. Did you mean '--hadoopDistro hadoop12'?

Since hdp13 uses hadoop 1.2.0, we need to fix that in the versions map ContainerOptions.getHadoopDistroVersions()",XD-1529,Ilayaperumal Gopinathan,Correct hadoop classpath versions for the distros
2214,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts.

We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",XD-1528,Ilayaperumal Gopinathan,Support external datasource for single node application
2215,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When the runtime modules command displays the the modules metadata properties, we can exclude the default module properties such as 'xd.stream.name', 'xd.module.index' and show only the other properties such as resolved module options etc.,",XD-1527,Ilayaperumal Gopinathan,Modify module metadata to exclude default module properties
2216,Thomas Risberg,Thomas Risberg,"Get exception when accessing cdh4 from shell -

java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.
	at com.google.protobuf.GeneratedMessage.getUnknownFields

most likely due to protobuf-java-2.5.0.jar being on the main classpath now


Full stack trace:
{code}
trisberg@carbon:~/Test$ ./spring-xd-1.0.0.BUILD-SNAPSHOT/shell/bin/xd-shell --hadoopDistro cdh4
16:55:22,680  WARN main conf.Configuration:824 - fs.default.name is deprecated. Instead, use fs.defaultFS
 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
eXtreme Data
1.0.0.BUILD-SNAPSHOT | Admin Server Target: http://localhost:9393
Welcome to the Spring XD shell. For assistance hit TAB or type ""help"".
xd:>hadoop config fs --namenode hdfs://cdh4:8020
xd:>hadoop fs ls /
Hadoop configuration changed, re-initializing shell...
16:55:28,853  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
-ls: Fatal internal error
java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.
	at com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:30108)
	at com.google.protobuf.AbstractMessageLite.toByteString(AbstractMessageLite.java:49)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.constructRpcRequest(ProtobufRpcEngine.java:149)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:193)
	at com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:164)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:83)
	at com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:629)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1545)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:819)
	at org.apache.hadoop.fs.FileSystem.globStatusInternal(FileSystem.java:1646)
	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1592)
	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1567)
	at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:271)
	at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224)
	at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207)
	at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:154)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:254)
	at org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412)
	at org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407)
	at org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:196)
	at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)
	at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48)
	at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)
	at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:530)
	at org.springframework.shell.core.JLineShell.run(JLineShell.java:178)
	at java.lang.Thread.run(Thread.java:744)
{code}",XD-1526,Thomas Risberg,Exception when accessing CDH4 namenode
2217,Eric Bottard,David Turanski,"Would be better to provide a more useful message, e.g. ""The module name must be of the form <module-type>:<module-name>""
xd:>module info --name time
java.lang.StringIndexOutOfBoundsException: Failed to convert 'time' to type QualifiedModuleName for option 'name,'
String index out of range: -1
xd:>module info --name sink/time
java.lang.StringIndexOutOfBoundsException: Failed to convert 'sink/time' to type QualifiedModuleName for option 'name,'
String index out of range: -1
xd:>module info --name sink:time
Command failed org.springframework.xd.rest.client.impl.SpringXDException: NullPointerException

xd:>module info --name source:time
Information about source module 'time':",XD-1525,David Turanski,Need better error handling for module info shell command
2218,Ilayaperumal Gopinathan,Mark Pollack,"Should mention jolokia, how to turn on/off boot/jolokia http metric/monitoring and jmx.

Mention the naming strategy to identify modules running in a stream.",XD-1524,Mark Pollack,Create small documentation section on jmx/monitoring functionalty
2219,Mark Fisher,Mark Fisher,,XD-1523,Mark Fisher,"stream list should show ""undeployed"" rather than blank if a stream is not deployed"
2220,Eric Bottard,Mark Fisher,,XD-1522,Mark Fisher,parser should only allow one label instance per module
2221,Eric Bottard,Eric Bottard,"The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin, etc
Moreover, there is no strong String constant to reference it

Create a plugin dedicated to those matters (namely making bits of DeploymentMetadata available to the module environment)",XD-1521,Eric Bottard,Create a dedicated plugin for ${xd.stream.name} and similar
2222,Eric Bottard,Eric Bottard,"See XD-1283.
We've been waiting for 1283 to change constructs like
{noformat}
attr=""${name:${xd.stream.name}}""

to just
{noformat}
attr=""${name}""
{noformat}


Turns out we can simply push down the ${xd.stream.name} bit in the default value (most likely initialization of a field in a POJO metadata class) and it will work just fine.

We can also consider:
- providing a fake value for those placeholders to use when doing ""module info"" (ie user will see  ""<name of the stream>"" instead of ""${xd.stream.name}""


",XD-1520,Eric Bottard,Push ${xd.stream.name} into POJO defaults
2223,Mark Pollack,Mark Pollack,"oracle, gemfire xd (derby should be the dialect), and sybase",XD-1519,Mark Pollack,Provide job repository creation schema for additonal databases
2224,David Turanski,Mark Fisher,,XD-1518,Mark Fisher,Add test cases for DefaultContainerMatcher
2225,David Turanski,Mark Pollack,Currently _deployments - with an understore in XDController should be something else.  Need to segment up the url space better for stream/jobs to avoid a clash.,XD-1517,Mark Pollack,Change request mapping for removing a stream deployment in XDController
2226,Patrick Peralta,Patrick Peralta,"When a container joins the cluster, the leader admin will assign modules to it that are unassigned. It needs to also check for job modules and deploy them if required.",XD-1516,Patrick Peralta,"Deploy ""orphaned"" jobs to new containers"
2227,Eric Bottard,Mark Pollack,This will allow us to use multiple instances of  hdfs/file sinks and not have any filename/path collisions.,XD-1515,Mark Pollack,Allow the value of xd.module.number to be used as property placeholder value
2228,David Turanski,Mark Pollack,,XD-1514,Mark Pollack,Create documentation for the deployment manifest
2229,Mark Fisher,Mark Pollack,"With the introduction of the deployment manifest setting this to false makes it easier to use the deployment manifest, which is the main use-case scenario.
",XD-1513,Mark Pollack,Change the default deploy option to false for stream/job deploy commands
2230,David Turanski,Mark Pollack,https://jira.spring.io/browse/XD-1343 and related issues.,XD-1512,Mark Pollack,Create documentation for how to extend the XD containers
2231,David Turanski,Mark Pollack,,XD-1511,Mark Pollack,Create documentation for ZK runtime
2232,Eric Bottard,Mark Pollack," INFO main zookeeper.ZooKeeper:100 - Client environment:java.class.path

produces a huge amount of output and is rather distracting, if that specific entry could be at a log level of debug it would make the startup of the server look cleaner.",XD-1510,Mark Pollack,Reduce amount of logging at server startup
2233,Ilayaperumal Gopinathan,Mark Pollack,"See the various module.xyz directories here 

https://repo.spring.io/libs-snapshot/org/springframework/xd/",XD-1509,Mark Pollack,Clean up publishing to maven repositories of empty module projects
2234,Patrick Peralta,Thomas Risberg,"The jobs aren't spread evenly across available container nodes as they are created/deployed. I had 3 nodes but only one has the job modules.

[zk: localhost:2181(CONNECTED) 56] ls /xd/deployments/modules/621230e0-a089-4fbe-afc8-611ae527fcbc
[myjob9.job.jdbchdfs-0, myjob5.job.jdbchdfs-0, myjob8.job.jdbchdfs-0, myjob4.job.jdbchdfs-0, myjob6.job.jdbchdfs-0, myjob7.job.jdbchdfs-0]
[zk: localhost:2181(CONNECTED) 57] ls /xd/deployments/modules/6969579c-0cf4-4cc1-8e21-e01d73a70965
[]
[zk: localhost:2181(CONNECTED) 58] ls /xd/deployments/modules/d0667cd1-a57a-4279-b7fb-dd63e4dd40d4
[]

",XD-1508,Thomas Risberg,All jobs end up on the same container node
2235,Ilayaperumal Gopinathan,Thomas Risberg,"Job modules ""Launch"" and ""Schedule"" command buttons are active even if the job module isn't deployed or has been destroyed.

Get errors like:
 ""Yikes, something bad happened while launching job myjob4""
""The job named 'myjob4' is not currently deployed""",XD-1507,Thomas Risberg,Prevent submiting jobs that are not currently deployed using Admin UI
2236,Thomas Risberg,Thomas Risberg,,XD-1506,Thomas Risberg,Add admin-ui to YARN zip packaging
2237,Mark Pollack,Derek Beauregard,"In the JSON SPEL Filter twitter example here:
http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#filter

""hashTags"" should not have a capital 'T'.  Should be ""hashtags"".",XD-1505,Derek Beauregard,Documentation typo in JSON SPEL filter
2238,Patrick Peralta,Mark Fisher,See: ContainerListener.loadStream() and StreamListener.onChildAdded(). Both require the stream definition as well as stream deployment manifest.,XD-1504,Mark Fisher,Avoid duplication when loading streams for deployment
2239,Patrick Peralta,Patrick Peralta,"The admin leader performs module deployment requests by listening to stream deployment requests under {{/xd/deployments/streams}} and by listening to containers joining and leaving the cluster under {{/xd/containers}}. Refactor any duplicate code into a common class/component that can be used by both listeners.

*Edit:* the listener duplication will be handled in XD-1548. This issue is for the duplicate code in {{ModuleDeploymentRequest}} and {{ModuleDescriptor}}.",XD-1503,Patrick Peralta,Refactor duplicate code for modules
2240,David Turanski,Patrick Peralta,"Investigate the failing test LocalSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus:

{noformat}
java.lang.AssertionError: expected:<3> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus(AbstractSingleNodeStreamDeploymentIntegrationTests.java:270)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
{noformat}

This can be most easily reproduced on Ubuntu.",XD-1502,Patrick Peralta,Investigate failing LocalSingleNodeStreamDeploymentIntegrationTests
2241,Ilayaperumal Gopinathan,Patrick Peralta,"Invoking {{Paths.ensurePath}} is creating a default value of the host IP address instead of the expected ""empty"" value. ",XD-1501,Patrick Peralta,IP address used as default data when creating paths
2242,Patrick Peralta,Patrick Peralta,"When a container is started, the leader admin will scan the deployed streams to determine if any have modules that need to be deployed on the new container. 

When a stream is deployed, the leader admin will select containers to deploy modules to.

If a new container and stream are deployed at the same time, there is the window for a race condition where both attempt to deploy a module to a container. This can be solved by (at least one) of the following:

* Consider using a single thread in the admin leader to handle all ZooKeeper updates. This means that the handling of new containers and stream deployment requests will not happen concurrently.
* Trap the {{NodeExists}} exception when creating the {{/xd/deployments/modules/...}} node in ZooKeeper",XD-1500,Patrick Peralta,Stream deployment race condition
2243,Luke Taylor,Mark Pollack,,XD-1499,Mark Pollack,change xd-config.yml and xd-modules-config.yml to servers.yml and modules.yml
2244,Mark Pollack,Mark Pollack,"Describe the algorithm as defined in https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharing

",XD-1498,Mark Pollack,Create documentation for module property configuration
2245,Ilayaperumal Gopinathan,Glenn Renfro,Update code to use the management/jolokia endpoint.,XD-1497,Glenn Renfro,Move JMX Endpoints from /jolokia to management/jolokia
2246,Ilayaperumal Gopinathan,Glenn Renfro,"When trying to access Jolokia via the management/jolokia (http://localhost:9393/management/jolokia) I get the following exception.   

{""error_type"":""java.lang.IllegalArgumentException"",""error"":""java.lang.IllegalArgumentException : No type with name 'management' exists"",""status"":400,""stacktrace"":""java.lang.IllegalArgumentException: No type with name 'management' exists\n\tat org.jolokia.util.RequestType.getTypeByName(RequestType.java:69)\n\tat org.jolokia.request.JmxRequestFactory.createGetRequest(JmxRequestFactory.java:94)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:78)\n\tat org.jolokia.http.AgentServlet$3.handleRequest(AgentServlet.java:298)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:229)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:194)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:621)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:728)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:154)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:120)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:621)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:728)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)\n\tat org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)\n\tat org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)\n\tat org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:724)\n""}",XD-1496,Glenn Renfro,Exception thrown when accessing Jolokia via the management context path
2247,Mark Fisher,Derek Beauregard,"xd:>runtime modules
Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/4dc55d87-125b-4e4a-a76e-82bb6980820d/TickTock.sink.log-1/metadata

This is on OSX running in distributed mode with --transport rabbit --hadoopDistro hadoop22, redis 2.8.8, rabbit 3.2.3, hadoop 2.2.0, and zookeeper 3.4.5.",XD-1495,Derek Beauregard,xd:>runtime modules gives error from CLI
2248,Mark Fisher,Derek Beauregard,"OS commands, i.e., ""!"" doesn't support arguments in M6; it did in M5.  

The following gives an error:
xd:>! ls /
You cannot specify option '' more than once in a single command

No arguments or whitespace works:
xd:>! ls
command is:ls
spring-shell.log
xd-shell
xd-shell.bat",XD-1494,Derek Beauregard,OS commands no longer supports whitespace/arguments in M6
2249,Eric Bottard,Derek Beauregard,"xd-shell tab completion missing for 'http post' and 'http get' cli commands.  Typing ""xd:>http post"" <tab> <tab> gives no suggestions event though --file or --data are required.  ",XD-1493,Derek Beauregard,xd-shell tab completion missing for http post/get
2250,David Turanski,David Turanski,A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as xd.container.groups=<comma delimited string> or an environment variable or --groups command line argument. ,XD-1492,David Turanski,Support groups container attribute
2251,David Turanski,David Turanski,Allow users to configure arbitrary key value pairs for a container instance that may be referenced in deployment descriptors to target specific container instances. ,XD-1491,David Turanski,Allow users to set attribute values on a container
2252,David Turanski,Derek Beauregard,"Absolute paths fail: gemfire-server /Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml  (This failse, see error below)

You have to add an extra forward slash at the beginning (//Users) to get it to work: gemfire-server //Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml (This works)

---------------- The log and error ----------------------

dbeauregard-mbp:~ dbeauregard$ gemfire-server /Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml
09:39:33,772  INFO main gemfire.CacheServer:50 - Starting Cache Server
09:39:33,884  INFO main support.FileSystemXmlApplicationContext:513 - Refreshing org.springframework.context.support.FileSystemXmlApplicationContext@2ba119b3: startup date [Fri Apr 04 09:39:33 MDT 2014]; root of context hierarchy
09:39:33,949  INFO main xml.XmlBeanDefinitionReader:316 - Loading XML bean definitions from file [/Users/dbeauregard/Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml]
Exception in thread ""main"" org.springframework.beans.factory.BeanDefinitionStoreException: IOException parsing XML document from file [/Users/dbeauregard/Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml]; nested exception is java.io.FileNotFoundException: Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml (No such file or directory)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:343)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:251)
	at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:127)
	at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:93)
	at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:129)
	at org.springframework.context.support.AbstractApplicationContext.obtainFreshBeanFactory(AbstractApplicationContext.java:540)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:454)
	at org.springframework.context.support.FileSystemXmlApplicationContext.<init>(FileSystemXmlApplicationContext.java:140)
	at org.springframework.context.support.FileSystemXmlApplicationContext.<init>(FileSystemXmlApplicationContext.java:84)
	at org.springframework.xd.gemfire.CacheServer.main(CacheServer.java:52)
Caused by: java.io.FileNotFoundException: Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at org.springframework.core.io.FileSystemResource.getInputStream(FileSystemResource.java:114)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:329)
	... 13 more",XD-1490,Derek Beauregard,SXD's gemfire-server wrapper script can't handle absolute paths w/o extra slash
2253,Eric Bottard,Mark Pollack,"the algorithm and approach in 

https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit#

needs to be added to the section on application configuration",XD-1489,Mark Pollack,Add documentation for new module property configuration support
2254,Eric Bottard,Mark Pollack,"For PR https://github.com/spring-projects/spring-xd/pull/682

see if one can have a test case such that a test module would have a 'PATH' property that overlaps with the environment variable.  It should never resolve to the real unix/windows path.",XD-1488,Mark Pollack,Create a test case for insulating environment variables in module property lookup
2255,Ilayaperumal Gopinathan,Mark Pollack,,XD-1487,Mark Pollack,Test scripts on windows that use XD_MODULE_CONFIG_LOCATION/NAME
2256,Ilayaperumal Gopinathan,Mark Fisher,"see:
https://sonar.springsource.org/drilldown/measures/7173?metric=package_tangle_index&rids%5B%5D=7717",XD-1486,Mark Fisher,eliminate package tangle
2257,Patrick Peralta,Mark Fisher,"Currently it watches /xd/deployments/[containerid], but due to the reuse of that top level node for XD-1483 and XD-1484, we should instead use /xd/deployments/modules/[containerid]",XD-1485,Mark Fisher,The Container's DeploymentListener should watch /xd/deployments/modules
2258,Patrick Peralta,Mark Fisher,,XD-1484,Mark Fisher,JobListener should watch /xd/deployments/jobs
2259,Patrick Peralta,Mark Fisher,,XD-1483,Mark Fisher,StreamListener should watch /xd/deployments/streams
2260,Mark Fisher,Mark Fisher,"The REST API for deploy should accept parameters, which provide manifest key/value pairs (e.g. ?http.instances=5). Ultimately we will want to support passing a named manifest which had been stored previously.

The 'stream deploy' shell command should support passing these as --options.

Initially we should support [modulename].instances and [modulename].group.",XD-1482,Mark Fisher,Add initial support for DeploymentManifest
2261,Eric Bottard,Mark Pollack,AGPL license issues,XD-1481,Mark Pollack,Remove spring-xd-analytics-ml-pmml project and module xml - to be put in seperate repository
2262,Patrick Peralta,Mark Fisher,"Also likely rename, remove, or replace that Module (maybe can be supplanted by ModuleDescriptor when used in the refactored parser).

Also, considering the ""url"" property is not necessary (vestige of the prototype), all we'd be left with here is the Module name and type, which are used to identify a Module uniquely. Therefore this Module could be renamed to ModuleKey or something. It could be used within the StreamDefinition itself (e.g. getDescriptor(moduleKey)).",XD-1480,Mark Fisher,Merge Module.Type and ModuleType
2263,David Turanski,Mark Fisher,Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.,XD-1479,Mark Fisher,DefaultContainerMatcher should make a better attempt at round-robin distribution
2264,Ilayaperumal Gopinathan,Mark Fisher,"All of the following are currently defined in META-INF/spring-xd/internal/repositories.xml (among others, like Stream/StreamDefinition and Job/JobDefinition repos):

{code}
combine some of these (in repositories.xml) and reconsider the use of Repository abstractions everywhere:
   <bean id=""containerMetadataRepository"" class=""org.springframework.xd.dirt.container.store.ZooKeeperContainerMetadataRepository""/>
   <bean id=""moduleMetadataRepository"" class=""org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository"" />
   <bean id=""moduleDependencyRepository"" class=""org.springframework.xd.dirt.module.store.ZooKeeperModuleDependencyRepository""/>
   <bean id=""moduleDefinitionRepository"" class=""org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository""/>
{code}

At the very least the Module repositories could be combined, and also we should remove ModuleDefinitionRepositoryUtils that provides static utility methods (since we no longer need that for reuse across multiple repo impls).

Finally, we should reconsider the use of actual Repository interfaces for these, since in most cases there are only one or two methods being called. Thus, it's not necessary to support the full range of CRUD operations for which those Repository interfaces are intended.",XD-1478,Mark Fisher,Refactor the Module and Container Repositories
2265,Ilayaperumal Gopinathan,Mark Fisher,"The two classes in question are:
* org.springframework.xd.dirt.cluster.Container
* org.springframework.xd.dirt.container.ContainerMetadata

The former is currently used by the Admin when making decisions about Module deployment. That latter was a replacement for RuntimeContainerInforEntity as we migrated the various Redis/InMemory Repositories to use the data that is now available in ZooKeeper instead.

The ContainerRepository is currently used by the Admin leader, and the ContainerMetadataRepository is used by the REST endpoint that supports the xd-shell's 'runtime containers' command. Perhaps those can also be merged.

In any case, if not addressed by a larger refactoring, the ContainerRepository should probably support an Iterable return rather than an Iterator. Having finders (e.g. for attribute key/values such as ""group""==""foo"") might be convenient for various Module deployment strategies.",XD-1477,Mark Fisher,"Merge Container and ContainerMetadata as well as their ""repositories"""
2266,David Turanski,Mark Fisher,"This should be included on the wiki, providing a thorough overview of how the distributed runtime works under-the-hood, including details of the various ZooKeeper nodes and associated watchers, etc. For example, it should describe the role of *any* Admin as a provider of the REST API as well as the specific roles allocated to the single *leader* Admin. It should describe Module recovery after Container failure, as well as some description of various failure scenarios (crashed JVM, network partition, etc) and how the recovery should be expected to occur (e.g. in some cases it will be nearly immediate, and in other cases it will be after a timed out connection). Intentional Container shutdown should be included in that discussion as well. At many points, this doc could link back to items that we also need to add to the main User Guide, such as the description of ContainerMatcher as the strategy for an Admin to determine which Container(s) should deploy a given Module, since that ContainerMatcher is used not only for the initial deployment, but also any redeployment that may be necessary.",XD-1476,Mark Fisher,Update document for the distributed runtime based on RC1 changes
2267,David Turanski,Mark Fisher,"Currently we have many catch(Exception) blocks that simply wrap and rethrow RuntimeExceptions. We should create at least a top-level RuntimeException of our own, within the XD Exception hierarchy, and possibly a hierarchy of RuntimeExceptions extending from that, and mapping to the various checked Exceptions that can occur in ZooKeeper data access.

Also, we should not be re-wrapping those Exceptions that are already RuntimeExceptions, so we should consider a ZooKeeperExceptionHandler (and although I'm typically hesitant to recommend it, this might be a case where a static util method is the right approach).
",XD-1475,Mark Fisher,Improve Exception handling for ZooKeeper data access
2268,Mark Fisher,Mark Fisher,"{code}
StreamDefinition sd = streamParser.parse(name, dslText);
{code}

We should also consider explicit methods such as parseStream (so that parseJob and parseComposedModule are at least separate methods, if not separate parser classes that share the common parser support class that is the core of today's parser). The parsing for ""completion providers"" should probably be spun off to its own class as well. In the end, there should be no need for a ParsingContext enum but rather, more explicitly named methods and dedicated classes if that seems like the right approach.

the StreamDefinition should be composed of ""ModuleDescriptors"" (that name is not set in stone) and other Stream-level metadata like source/sink channels

consider merging some of StreamFactory code there, and the rest into StreamDeployer

merge ModuleDescriptor and ModuleDeploymentRequest as part of this effort (again, a new name could be considered, but ModuleDescriptor should take precedence over ModuleDeploymentRequest), and note in the process that ModuleDescriptor was originally designed to be immutable (taking constructor args), but as we migrated the prototype code into XD itself, this was violated. We may want to consider a builder approach, and we likely want to avoid the need for a ModuleDefinition within the ModuleDescriptor.",XD-1474,Mark Fisher,Refactor StreamParser to return a StreamDefinition
2269,,Mark Fisher,,XD-1473,Mark Fisher,ZooKeeper runtime cleanup and refactoring
2270,David Turanski,Peter Rietzler,"If a module e.g. always expects the payload of the message to be of a certain java type if would be good for documentation and convenience reasons in order to specify a default value for the --inputType option. 

documentation = output for module info
convenience = we could e.g. support to always accept a Json payload (or automatic message payload conversion once it is extensible)

currently, adding
options.inputType.default
to the module's property file has no effect

I've also tried to ""redefine"" it using
options.inputType.description
This leads to the following exception:

Command failed org.springframework.xd.rest.client.impl.SpringXDException: Module option named 'outputType' is present in several delegates: [org.springframework.xd.module.options.SimpleModuleOptionsMetadata@3c1d635a, FlattenedCompositeModuleOptionsMetadata
[outputType] => PojoModuleOptionsMetadata backed by class org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPluginMetadataResolver$OutputOptionsMetadata, defining options [[ModuleOption [name=outputType, type=class org.springframework.util.MimeType, defaultValue=null, description=how this module should emit messages it produces]]]
[inputType] => PojoModuleOptionsMetadata backed by class org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPluginMetadataResolver$InputOptionsMetadata, defining options [[ModuleOption [name=inputType, type=class org.springframework.util.MimeType, defaultValue=null, description=how this module should interpret messages it consumes]]]]",XD-1472,Peter Rietzler,Let modules define a default value for --inputType option
2271,Mark Fisher,Mark Fisher,"all state about the running system (containers, streams, and jobs) should be available via ZK, and ultimately the --store option should not be needed

1. Refactor ModuleDefinitionRepository to use ZooKeeper
   * remove RedisModuleDefinitionRepository
   * remove InMemoryModuleDefinitionRepository

2. Refactor ModuleDependencyRepository to use ZooKeeper
   * remove RedisModuleDependencyRepository
   * remove InMemoryModuleDependencyRepository

3. Refactor RuntimeModuleInfoRepository to use ZooKeeper (rename ModuleMetadata...)
   * remove RedisRuntimeModuleInfoRepository
   * remove AbstractRedisRuntimeModuleInfoRepository
   * remove InMemoryRuntimeModuleInfoRepository

4. Refactor RuntimeContainerModuleInfoRepository to use ZooKeeper (rename ContainerMetadata...)
   * remove RedisRuntimeContainerModuleInfoRepository
   * remove InMemoryRuntimeContainerModuleInfoRepository

5. Remove support for --store
   * remove the memory-store.xml and the redis-store.xml
   * instead include just one repositories.xml in shared server config
   * remove the associated property key and the *Options properties

6. Remove the events and listeners that were being used",XD-1471,Mark Fisher,Migrate repositories to ZooKeeper
2272,Luke Taylor,Mark Pollack,"To avoid CL conflicts, a short term solution to this problem is to make sure that there is only one copy of jackson related classes and have them live in xd/lib.  

using 
jackson-core-2.3.2.jar
jackson-databind-2.3.2.jar
jackson-core-asl-1.9.13.jar
jackson-mapper-asl-1.9.13.jar

are the latest versions and the ones to use.

There maybe other libraries that we duplicate in the same manner, we will need to investigate as well as part of another issue.

Typical error is:

java.lang.LinkageError: loader constraint violation: when resolving method ""org.springframework.http.converter.json.MappingJackson2HttpMessageConverter.setObjectMapper(Lcom/fasterxml/jackson/databind/ObjectMapper;)V"" the class loader (instance of org/springframework/xd/module/support/ParentLastURLClassLoader) of the current class, org/springframework/social/twitter/api/impl/TwitterTemplate, and the class loader (instance of sun/misc/Launcher$AppClassLoader) for resolved class, org/springframework/http/converter/json/MappingJackson2HttpMessageConverter, have different Class objects for the type com/fasterxml/jackson/databind/ObjectMapper used in the signature
",XD-1470,Mark Pollack,Rationalize inclusion of JSON jars in xd/lib and in modules
2273,Eric Bottard,Mark Pollack,"{noformat}
	correlation-strategy-expression=""${correlation:'${xd.stream.name}}'""
{noformat}
should be
{noformat}
	correlation-strategy-expression=""${correlation:'${xd.stream.name}'}""
{noformat}
Add a test to make sure correlation expressions here work.",XD-1469,Mark Pollack,Error in correlation strategy in aggregator.xml
2274,Jon Brisbin,Mark Pollack,,XD-1468,Mark Pollack,Update to Reactor 1.1.0 M3
2275,Eric Bottard,Eric Bottard,,XD-1467,Eric Bottard,Do not eagerly use repositories in completion's *Strategy
2276,Glenn Renfro,Mark Pollack,"change 

""/jolokia/list"";

to 

""/management/jolokia/list"";

etc.",XD-1466,Mark Pollack,Update XdEc2Validation to reference <root>/management endpoint
2277,Ilayaperumal Gopinathan,Mark Pollack,,XD-1465,Mark Pollack,Update management context path to <root>/management
2278,Mark Pollack,Mark Pollack,"Currently on snapshots, which is oddly pulling in groovy 2.1.0",XD-1464,Mark Pollack,Upgrade to Spring Integration 4.0.0.M4
2279,liujiong,Mark Pollack,"This would get rid of the CF specific post module, keeping the general abstraction of 'http' source across CF and non-CF environments.",XD-1463,Mark Pollack,Delete post module and CF profile
2280,Eric Bottard,Mark Pollack,AggregateCounter needs a test case along the lines of of org.springframework.xd.analytics.metrics.integration.FieldValueCounterHandlerTests that will demonstrate the base functionality of the module as well as use of the  timeField and dateFormat options.,XD-1462,Mark Pollack,Validate time field processing with AggregateCounter
2281,Janne Valkealahti,Mark Pollack,"The tests that use HDFS currently require an external Hadoop installation and is hard to set up/update version in all the environments where we want to run tests, e.g. bamboo, travis.

See if the mini-cluster described in 

http://docs.spring.io/spring-hadoop/docs/2.0.0.RC1/reference/html/testing.html#testing:yarn:minicluster

can be used in the test cases instead.",XD-1461,Mark Pollack,Use Hadoop mini-cluster test support in XD tests
2282,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"After some discussion and voting, we decided to remove ""jmxEnabled"" as a command line option and have JMX enabled by default.
This can be disabled from xd-config.yml externally.",XD-1460,Ilayaperumal Gopinathan,Remove jmxEnabled as a cmdLine option and enable JMX by default
2283,Eric Bottard,Eric Bottard,"Typical case is with a module that contains
{noformat}
... user=""${username}"" ... />
{noformat}

(say, as part of a jdbc connection configuration)
and no value has been given at deployment time.

The module may pickup a value from the environment by mistake (typically from an environment variable of the same name).
This was even more problematic when ordering of property sources was unclear, but should be prevented entirely anyway.",XD-1459,Eric Bottard,Prevent accidental pickup of ENV var as module option
2284,Thomas Risberg,Mark Pollack,,XD-1458,Mark Pollack,Upgrade to Spring Hadoop 2.0 RC2
2285,Glenn Renfro,Glenn Renfro,"Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD.  And to allow for faster downloads.  However XD Jars are already placed on S3, so this feature is no longer needed.",XD-1457,Glenn Renfro,Remove the S3 XD Jar Cache
2286,Glenn Renfro,Glenn Renfro,"With the addition of sinks and sources that require connections with external entities (hadoop, JMS, JDBC, ...)  the environment setup is getting unwieldy.

* Integrate SpringJUnit4ClassRunner.class into acceptance tests.
* Retrieve environment variables via Dependency injection from application.properties.
* Utilize profiles for 
  --local single node
  --local cluster
  --ec2 single node
  --ec2 cluster",XD-1456,Glenn Renfro,Allow user to configure tests with DI 
2287,Glenn Renfro,Glenn Renfro,"Replace tests and throws in the XdEc2Validation with asserts in the following methods:
verifyTestContent
verifyLogContent
verifySendCounts

VerifySendCounts should check for the exact number of Jmx events instead of >0.",XD-1455,Glenn Renfro,Environment checkers in acceptance tests should use Asserts
2288,Glenn Renfro,Glenn Renfro,"With the addition of zookeeper, a user does not have to specify rabbit or redis for the control channel.  
This story should allow a user to specify redis, rabbit or no control channel.",XD-1454,Glenn Renfro,User should not be required to specify a control channel
2289,Gary Russell,Gary Russell,,XD-1453,Gary Russell,Update Spring-AMQP to 1.3.1.RELEASE 
2290,Luke Taylor,Eric Bottard,"Attempts to create/use/undeploy a stream involving the http module will result in an OOME stating that VM could not create native thread.

Other modules should be checked as well.
{noformat}
	at java.lang.Thread.run(Thread.java:724)
Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.x.http.NettyHttpInboundChannelAdapter#0'; nested exception is java.lang.OutOfMemoryError: unable to create new native thread
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)
	at org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:91)
	at org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1180)
	at org.springframework.xd.module.core.SimpleModule.start(SimpleModule.java:273)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:251)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:239)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:179)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:150)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 80 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.$$YJP$$start0(Native Method)
	at java.lang.Thread.start0(Thread.java)
	at java.lang.Thread.start(Thread.java:693)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1371)
	at org.jboss.netty.util.internal.DeadLockProofWorker.start(DeadLockProofWorker.java:38)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:343)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:95)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:53)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.newWorker(AbstractNioWorkerPool.java:99)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:69)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:115)
	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.doStart(NettyHttpInboundChannelAdapter.java:114)
	at org.springframework.integration.endpoint.AbstractEndpoint.start(AbstractEndpoint.java:84)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)
	... 91 more
{noformat}
",XD-1452,Eric Bottard,http module leaks threads
2291,Mark Pollack,Mark Pollack,Get minimal compilation going in Travis.  Redis/Rabbit services can be done in a separate story.,XD-1451,Mark Pollack,Support CI build in Travis
2292,David Turanski,David Turanski,There are a couple of tests in spring-xd-dirt that extend StreamTestSupport. They should be rewritten so we don't support 2 different SingleNode fixtures.,XD-1450,David Turanski,Refactor StreamTestSupport tests to use SingleNodeIntegrationTestSupport
2293,Mark Pollack,Mark Pollack,,XD-1449,Mark Pollack,Update to Spring Shell 1.1 RC1
2294,Mark Fisher,Derek Beauregard,"When a REST client of SpringXD (i.e., a dashboard) attempts to query (GET) a metric (e.g., counter, gauge, etc.) that does not exist the admin sever logs an ERROR and a large stack trace (attached).  In usage of Spring XD we see this frequently because a dashboard is running but the streams and counters have not been created quite yet, or initialized by messages flowing through the streams.  With a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues.  

I would suggest logging a one line warning or info message instead of the error and stack trace. ",XD-1448,Derek Beauregard,SpringXD logs error and large stack trace when metric can't be found. Distracting.
2295,Luke Taylor,Mark Pollack,"In order to support ingestion from stdin, the suggested approach is to do the following.

xd:>stream create --definition ""tcp --decoder=LF | log"" --name foo

$ cat my.log | netcat localhost 1234

So while this is really a tcp based ingestion case, once can use pipe or redirect of stdin/err in order to achieve the same goal.  It should appear as a source module in the docs on par with other source modules in its own section.
",XD-1447,Mark Pollack,Add documentation for a 'stdin' source module
2296,Thomas Risberg,Mark Pollack,"Update to Spring for Apache Hadoop 2.0 RC3
Add support for new hadoop distros: 
- Pivotal HD 2.0 (phd20)
- Hortonworks HDP 2.1 (hdp21)
- Cloudera CDH5 (cdh5) 
",XD-1446,Mark Pollack,Update spring-data-hadoop dependency and add new Hadoop distros
2297,Eric Bottard,Eric Bottard,,XD-1445,Eric Bottard,Don't swallow unexpected exceptions in StacktraceFingerprintingCompletionRecoveryStrategy
2298,Luke Taylor,Mark Pollack,,XD-1444,Mark Pollack,Update to Spring Boot 1.0 GA
2299,Luke Taylor,Mark Pollack,,XD-1443,Mark Pollack,Update Spring Framework dependency to 4.0.3 GA
2300,Eric Bottard,Ilayaperumal Gopinathan,"Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/655/files#r10892925",XD-1442,Ilayaperumal Gopinathan,Remove Hadoop distro Enum options
2301,Eric Bottard,Eric Bottard,"The description in the google doc 

https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharing

describes the usage of XD_MODULE_CONFIG_LOCATION and XD_MODULE_CONFIG_NAME",XD-1441,Eric Bottard,Implement XD_MODULE_CONFIG_LOCATION & NAME
2302,,Eric Bottard,"See report at https://github.com/spring-projects/spring-xd/issues/661

It would be good indeed to allow this (eg by having a WeakHashMap<Classloader, type+name> map in the global context).
The caveat though, is that any statics used by the module would be shared too.
We can make this an opt-out though (I think that sharing by default makes sense) by having a flag in the module .properties manifest",XD-1440,Eric Bottard,Allow re-use of a module classloader
2303,Eric Bottard,Eric Bottard,"See report at https://github.com/spring-projects/spring-xd/issues/661

This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.",XD-1439,Eric Bottard,Investigate module classloader leakage
2304,Glenn Renfro,Derek Beauregard,The documentation (http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#_using_rabbitmq) list the default RabbitMQ port as 5674.  It is 5672 and is correct in the SXD config.  ,XD-1438,Derek Beauregard,RabbitMQ port wrong in Docs
2305,Gary Russell,Mark Pollack,,XD-1437,Mark Pollack,Exclude slf4j Transitive Dependencies
2306,Ilayaperumal Gopinathan,Mark Pollack,"0. Remove home page with sign in and upper right hand corner with user login info.
1. Change the word template to modules in the tab
2. Different text for each of the tabs, “modules, definition, deployments, scheduled”
3. Definitions tab to have text along the lines ""“allows you to deploy  and undeploy batch job definitions"" add links to help on how to do that in the CLI.
4. Deployments tab
 a   creating new definitions, - parameters needs to be space on parameters,  “Job Parameters for Job XYZ” after clicking launch.
 b. comment out scheduler button
 c. add quick filter
5. Scheduler tab
 a. comment out tab
",XD-1436,Mark Pollack,Misc cleanup in UI
2307,Ilayaperumal Gopinathan,Mark Pollack,"1. Add quick filter
2. The table should have columns for          
                                name | instance | execution id

Getting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch.

3. The restart action should appear only if the job is restartable and the status was failed.
",XD-1435,Mark Pollack,Improvements to Executions Tab
2308,Gunnar Hillert,Mark Pollack,"1. Get listing of job modules
2. Remove version and action column
3. Text to say creating definitions from available modules in the UI is forthcoming, link to https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#creating-a-job for how to do this in the command line.

 4. Hardcode an association between spring xd out of the box module names and a description.
 5. Add button to display the XML file that defines the job module
",XD-1434,Mark Pollack,Improvements to Modules Tab
2309,Luke Taylor,Mark Pollack,,XD-1433,Mark Pollack,Update to Spring Boot RC5
2310,Ilayaperumal Gopinathan,Mark Pollack,The standard SimpleHealthIndicator that boot performs a database test that fails in xd-container since it does not require the use of a database.  ,XD-1432,Mark Pollack,Configure servers to use VanillaHealthEndpoint
2311,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",XD-1431,Ilayaperumal Gopinathan,Support multiple admin servers on a same host
2312,Glenn Renfro,Glenn Renfro,,XD-1430,Glenn Renfro,Add JMS Acceptance Tests
2313,David Turanski,David Turanski,Create a Shared Server Context to the Container hierarchy. This is a child of Global Beans which contains beans that are only shared by the Admin and Container contexts but not Modules. The ZooKeeper components go here to support the ZK deployment architecture. The MessageBus also goes here to support a clean way to launch jobs from the Admin process. ,XD-1429,David Turanski,Create Shared Server Context
2314,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"It would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up.
",XD-1428,Ilayaperumal Gopinathan,Log Hadoop Distro and ZK client connect info on Container startup
2315,Mark Fisher,Mark Fisher,"3.4.6 was released on 2014.03.10:
http://zookeeper.apache.org/doc/r3.4.6/releasenotes.html

Especially relevant for us, they updated Netty from 3.2.2 to 3.6.6:
https://issues.apache.org/jira/browse/ZOOKEEPER-1715
",XD-1427,Mark Fisher,Upgrade to ZooKeeper 3.4.6
2316,Florent Biville,Ilayaperumal Gopinathan,"With requireJS r.js and ngmin, we need to make sure the XD admin JS files are appropriately minified. Currently, the JS files are not minified.",XD-1426,Ilayaperumal Gopinathan,Minification of XD Admin UI JS files 
2317,Gunnar Hillert,Ilayaperumal Gopinathan,The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ,XD-1425,Ilayaperumal Gopinathan,Fix existing Karma unit tests + Migrate E2E tests to Protractor
2318,Glenn Renfro,Derek Beauregard,"The Tuple documentation, http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#tuples, has no link or reference to the Jar(s) and/or Maven artifacts required to use Tuples in a project.  Took me a bit of searching to find the Maven artifacts.  Would be nice to include the jar name and maven/gradle config.  

In Gradle (from the spring repo maven { url ""http://repo.spring.io/libs-snapshot"" }):
compile 'org.springframework.xd:spring-xd-tuple:1.0.0.M5'",XD-1424,Derek Beauregard,Docs could use link to Tuple artifacts
2319,Eric Bottard,Mark Pollack,"The ordering of the lookup should be described, in particular detail on how environment variables can overrride properties.

Some details will necessarily change based on outcome of current discussion, but the overall ordering is going to remain.",XD-1423,Mark Pollack,Create documentation for how module properties are resolved.
2320,Thomas Darimont,Mark Pollack,"The sample application should primarily show the 'round trip' that is possible in that ""offline"" analysis in R can generate a pmml flle that can be imported and evaluated in an ""online"" stream definition.  The specific use case can be as simple as the IRIS data set or other existing examples, such as the fraud demo.

The sample application resides in https://github.com/spring-projects/spring-xd-samples",XD-1422,Mark Pollack,Create a simple sample application for the jpmml module
2321,Thomas Darimont,Mark Pollack,,XD-1421,Mark Pollack,Create documentation for the core analytical model abstractions and use of jpmml processor
2322,Thomas Darimont,Mark Pollack,"A analytical model should be evaluated as a processor in a stream.  The model evaluation will take the input variables from a Tuple and output variable will be placed into the tuple as well.

A strawman of the stream definition can be 

stream create --definition "" SOURCE | jpmml ‘fraud-detection’ | PROC1 … | PROCN "" --name stream1

Using profiles and playing all implementations of the analytical model in the same module lib directory, it maybe possible to select one of multiple implementations in the form

 "" SOURCE | analytic --library=jpmml --name=‘fraud-detection’ | PROC1 … | PROCN ""

such that the core module name is the same but parameterized by what library type to use.  This may be problematic in that different libraries may have incompatible dependencies.

The analytical model can define the names of input and output fields, so at a minimum a name is required, however to easily adapt a given analytic model evaluation to a specific source modules output, it seems desirable to specify which fields are to be used as input, overriding the names of the input fields could be done in a manner such as 

jpmml –name=linear-regresssion –inputFields=a,b,c ",XD-1420,Mark Pollack,Create a JPMML module that will evaluate a model.
2323,Thomas Darimont,Mark Pollack,"Using the jppml evaluator, provide an implementation of the core abstractions in the spring-xd-machine-learning.

The initial code for this has been developed in a separate github repo and is located here

https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics-jpmml/src/main/java/org/springframework/xd/analytics/model/jpmml ",XD-1419,Mark Pollack,Create subproject spring-xd-machine-learning-analytics-jpmml
2324,Thomas Darimont,Mark Pollack,"This project contains core abstractions that will allow for multiple implementations of a machine learning algorithm to be implemented via integration with various existing libraries or custom code implementations.  

The initial code for this has been developed in a separate github repo and is located here 

https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics/src/main/java/org/springframework/xd/analytics/model

The model can assume its use in evaluation of the model inside a stream where the data structure is a Tuple.  Note, it maybe useful to consider Message<Tuple> in case any metadata outside the core 'input data' is required to help guide the evaluation.

The build.gradle file should be updated such that there is a new build artifact spring-xd-machine-learning-analytics.jar along the lines of our other build artifacts.  Open to other naming suggestions.",XD-1418,Mark Pollack,Create subproject spring-xd-machine-learning-analytics
2325,Kashyap Parikh,Mark Pollack,"Package SpringXD into an RPM
install path = /opt/pivotal/spring-xd-1.0.0.M5
with symlink /opt/pivotal/spring-xd -> current version
init.d scripts to start/stop/status
service springxd-admin start|stop|status
service springxd-container start|stop|status
user/group = springxd/pivotal
Host springxd rpm in Pivotal repo
yum install springxd
Support RHEL/CentOS version 5 and 6? (tested on latest updates)
Support for 32 and 64 bits
Support Java 1.6 and 1.7
",XD-1417,Mark Pollack,Create RPM for distribution
2326,Mark Fisher,Charlie Black,"Being able to listen to a stream at any point has a significant performance impact.  The reason for the impact is the message needs to be ""serialized + transported + deserialized"" to other members even if there is no one listening.  This ""serialized + transported + deserialized"" processes happens for each step in a flow - source | process | sink.

Recommend creating some kind of protocol for wiretaps that allows members to know if there is someone listening in the grid so they will emit the data.  Likewise we need to deregister the listener if the wiretap is deleted.",XD-1416,Charlie Black,When there are no wiretap listeners don't publish messages
2327,Kashyap Parikh,Ilayaperumal Gopinathan,"mqtt_tests under src/tests/scripts fail inconsistently with the following exception stacktrace:

SEVERE: xd.mqtt.client.id.src: Timed out as no activity, keepAlive=60,000 lastOutboundActivity=1,395,174,955,434 lastInboundActivity=1,395,174,895,434
13:36:55,442 ERROR http-nio-9393-exec-7 inbound.MqttPahoMessageDrivenChannelAdapter:66 - Exception while connecting and subscribing, retrying
Client is currently disconnecting (32102)
	at org.eclipse.paho.client.mqttv3.internal.ExceptionHelper.createMqttException(ExceptionHelper.java:27)
	at org.eclipse.paho.client.mqttv3.internal.ClientComms.disconnect(ClientComms.java:409)
	at org.eclipse.paho.client.mqttv3.MqttAsyncClient.disconnect(MqttAsyncClient.java:524)
	at org.eclipse.paho.client.mqttv3.MqttClient.disconnect(MqttClient.java:250)
	at org.eclipse.paho.client.mqttv3.MqttClient.disconnect(MqttClient.java:243)
	at org.springframework.integration.mqtt.inbound.MqttPahoMessageDrivenChannelAdapter.connectAndSubscribe(MqttPahoMessageDrivenChannelAdapter.java:104)
	at org.springframework.integration.mqtt.inbound.MqttPahoMessageDrivenChannelAdapter.doStart(MqttPahoMessageDrivenChannelAdapter.java:63)
	at org.springframework.integration.endpoint.AbstractEndpoint.start(AbstractEndpoint.java:84)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)
	at org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:91)
	at org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1180)
	at org.springframework.xd.module.core.SimpleModule.start(SimpleModule.java:270)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:250)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:238)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:179)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:150)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)
	at org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:163)
	at org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:204)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)
	at org.springframework.xd.dirt.rest.XDController.deploy(XDController.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:690)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doPut(FrameworkServlet.java:874)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:650)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:128)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:85)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:84)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
13:36:55,465  INFO http-nio-9393-exec-7 module.ModuleDeployer:240 - deployed SimpleModule [name=mqtt, type=source, group=mqttSourceTest, index=0 @38946002]
HTTP/1.1 200 OK
Server: MochiWeb/1.1 WebMachine/1.10.0 (never breaks eye contact)
Date: Tue, 18 Mar 2014 20:36:55 GMT
content-type: application/json
Content-Length: 16
Cache-Control: no-cache

{""routed"":false}cat: /tmp/xdtest/basic/mqttSourceTest.out: No such file or directory
bamboo@w1-kodiak-hd006:/data/bamboo-home/xml-data/build-dir/XD-SCRIPTS-RS/spring-xd/src/test/scripts$ Mar 18, 2014 1:38:55 PM org.eclipse.paho.client.mqttv3.internal.ClientState checkForActivity
SEVERE: xd.mqtt.client.id.src: Timed out as no activity, keepAlive=60,000 lastOutboundActivity=1,395,175,075,488 lastInboundActivity=1,395,175,015,488
13:38:55,490 ERROR task-scheduler-2 inbound.MqttPahoMessageDrivenChannelAdapter:141 - Exception while connecting and subscribing
Client is disconnected (32101)
	at org.eclipse.paho.client.mqttv3.internal.ExceptionHelper.createMqttException(ExceptionHelper.java:27)
	at org.eclipse.paho.client.mqttv3.internal.ClientComms.disconnect(ClientComms.java:405)
	at org.eclipse.paho.client.mqttv3.MqttAsyncClient.disconnect(MqttAsyncClient.java:524)
	at org.eclipse.paho.client.mqttv3.MqttClient.disconnect(MqttClient.java:250)
	at org.eclipse.paho.client.mqttv3.MqttClient.disconnect(MqttClient.java:243)
	at org.springframework.integration.mqtt.inbound.MqttPahoMessageDrivenChannelAdapter.connectAndSubscribe(MqttPahoMessageDrivenChannelAdapter.java:104)
	at org.springframework.integration.mqtt.inbound.MqttPahoMessageDrivenChannelAdapter.access$300(MqttPahoMessageDrivenChannelAdapter.java:37)
	at org.springframework.integration.mqtt.inbound.MqttPahoMessageDrivenChannelAdapter$1.run(MqttPahoMessageDrivenChannelAdapter.java:137)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:165)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:267)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:679)
",XD-1415,Ilayaperumal Gopinathan,Inconsistent test failure with mqtt script test in CI environment
2328,Thomas Risberg,Mark Pollack,,XD-1414,Mark Pollack,Create one xd-yarn shell script that encompases the functionality of seperate shell scripts
2329,Glenn Renfro,Glenn Renfro,"Acceptance tests has a direct library reference to spring-xd-shell.  This causes problems with eclipse.  It needs a intermediate main project to resolve the dependencies.  This is based on the conversation I had with Mark Fisher.

you cant depend on another projects' src/test
what is needed is an intermediate project… some test support project
that project would depend on spring-xd-shell (and others) … but then the spring-xd-integration-test project would depend on the intermediate one
lib dependencies should only be under src/main
src/test is intended to be scoped to the project it sits in… tests FOR that project - not reusable base classes, etc",XD-1413,Glenn Renfro,Create spring-xd-test-fixtures project
2330,,Eric Bottard,"I was in the process of rewriting transform using profiles (see ExpressionOrScriptMixin).

This broke eg ModuleCommandTests.testComposedModulesValuesInDefinition because basically composed module options activate no profile.

The problem is that there is no real way to know what to activate currently, because when deploying a part of a composed module, its metadata is actually a link to the *whole* metadata, but does not really know which part.

Long story short, something we may be able to do is to activate the union of all profiles, but this breaks very easily :
module compose foo --definition ""transform --expr=foo | transform --script=bar"" 
would try to activate both ""script"" and ""expression"" profiles for both modules.",XD-1412,Eric Bottard,Composed options does not trigger profile activation
2331,Thomas Risberg,Thomas Risberg,"Create an xd-yarn script that is more ""Cloud Foundry"" like - 

xd-yarn push -p <path-to-unzipped-yearn-distro>
xd-yarn start admin
xd-yarn start container
",XD-1411,Thomas Risberg,Create xd-yarn script
2332,Glenn Renfro,Glenn Renfro,Startup zookeeper on EC2 cluster instances.,XD-1410,Glenn Renfro,XD EC2 needs to bootstrap ZOOKEEPER at installation time.
2333,Eric Bottard,Derek Beauregard,The documentation lists the gemfire-server sink module's attributes to be 'gemfireHost' and 'gemfirePort'.  In the module/code they are 'host' and 'port'.  The other attributes are correct.  ,XD-1409,Derek Beauregard,GemFire sink properties missmatch 
2334,David Turanski,Ilayaperumal Gopinathan,"The ContainerServerApplication has a bean ContainerMetaData whose ID is equal to the ContainerServerApplication context's ID. 

The ContainerMetadata is alway referred (using @Autowired) in ContainerConfiguration class and this injects a new bean whose containerID is different from that of the containerID created at ContainerServerApplication. Also, this is the ID that gets stored as the container ID in znode for /xd/containers by ContainerRegistrar.

We should avoid having duplicate container metadata and the container ID needs to be same as that of the ContainerServerApplication's context ID.",XD-1408,Ilayaperumal Gopinathan,Container ID is not equal to its application context ID
2335,Jon Brisbin,Mark Pollack,"The throughput module would expect a payload of the type Message<byte[]> and look for the byte[] to be START or STOP strings to trigger a throughput measurement.

https://github.com/spring-projects/spring-xd/tree/master/extensions would be the place for the module to live.",XD-1407,Mark Pollack,Create a throughput sink
2336,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, XD hast ""testCompile"" dependency to use org.codehaus.groovy:groovy-all:2.2.1. 

The spring-integration-groovy uses ""2.2.2"" and it is what spring IO platform uses as well. To keep it all same, we can change this ""testCompile"" dependency to use ""2.2.2""",XD-1406,Ilayaperumal Gopinathan,Upgrade groovy version to 2.2.2
2337,,Ilayaperumal Gopinathan,"All the XD artifacts dependencies need to be updated with the versions that in line with Spring IO platform's standard versioning.

",XD-1405,Ilayaperumal Gopinathan,Version XD dependencies with Spring IO platform versioning
2338,Glenn Renfro,Mark Pollack,,XD-1404,Mark Pollack,Test against Spring Boot Snapshot build
2339,Jon Brisbin,Mark Pollack,"The application should live in  in spring-xd-samples repository.

The stream created in https://jira.spring.io/browse/XD-1402 should be documented how to run a benchmark and made easy to execute.  Can use ruby/bash-awk-sed to generate traffic via sendfile in order to saturate the stream.
",XD-1403,Mark Pollack,Create benchmarking application to demonstrate high performance message processing
2340,Jon Brisbin,Mark Pollack,"A module that could be used in a stream definition such as 

reactor --bind tcp://0.0.0.0:3000/length?codec=bytes | do-stuff | throughput-sampler

where throughput-sampler could start measurements once a key 'START' is found in a Message and stop when the key 'STOP' is found in a Message, listing the number of msgs/sec etc.",XD-1402,Mark Pollack,Create a ‘throughput-sampler’ module for benchmarking
2341,Jon Brisbin,Mark Pollack,"A reactor based TCP module that would support some basic CODECS.

Should evaluate if this new TCP module would subsume the current reactor-syslog module functionality or if the reactor-syslog module should be enhanced/upgradted.",XD-1401,Mark Pollack,Add new reactor tcp module
2342,Mark Fisher,Mark Fisher,"The Admin leader will write each Module deployment request to a child node of /xd/deployments for a selected Container (see XD-1399). That Container-specific (persistent) child node needs to be created by the Container at the same time as it creates its ephemeral node under /xd/containers.

The Container should then deploy the Module. If that same node is subsequently deleted, the Container should undeploy the Module.",XD-1400,Mark Fisher,Containers should listen for Module deployment requests and their deletions
2343,Mark Fisher,Mark Fisher,"The Stream deployment requests will be written to /xd/streams/streamname and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed.

When a Stream is deployed, the leader will consult its Container cache and write the modules to the various /xd/deployments child nodes (see XD-1400).",XD-1399,Mark Fisher,Admin leader should watch ZooKeeper for Stream deployment requests
2344,Mark Fisher,Mark Fisher,"This should also enable removal of any StreamDefinitionRepository code.

The state should be written as a data node at the stream level (e.g. /xd/streams/mystream {state=...})

For now we at least need to support the boolean --deploy=true|false flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers (XD-1399)",XD-1398,Mark Fisher,Admin servers should write streams to and delete them from ZooKeeper
2345,Mark Fisher,Mark Fisher,"This will require a ZooKeeperConnection in AdminServerApplication, based on singlenode vs. distributed (via profiles, see: ContainerServerApplication for an example).

Then a PathChildrenCache should be established for the /xd/containers node.",XD-1397,Mark Fisher,Admin leader should watch Container nodes in ZooKeeper
2346,Ilayaperumal Gopinathan,Glenn Renfro,"   The container will not start with JMX enabled and the management_port set.  The stacktrace is attached and the settings for the container are enumerated below:

    export endpoints_jmx_enabled=true
    export endpoints_jmx_uniqueNames=true
    export endpoints_jolokia_enabled=true
    export XD_JMX_ENABLED=true
    export management_port=15005",XD-1396,Glenn Renfro,Container fails to start if JMX is enabled and manage_port is set
2347,,Glenn Renfro,"After the container/singlenode is up and running, the application does not update the singlenode.log or containernode.log.

create a stream ""time|log"".  you will see the timestamp in your console, but it will not be in the log.",XD-1395,Glenn Renfro,Container and Single Node do not update their associated log
2348,Luke Taylor,Mark Fisher,,XD-1394,Mark Fisher,Upgrade to Spring 4.0.2.RELEASE
2349,David Turanski,Mark Fisher,"This will have an effect on both singlenode and distributed mode as 
described below...

*singlenode:*

Currently, when running in singlenode mode, an embedded ZooKeeper server is started, and it discovers an available port for client connections and exposes it via a getClientPort() method.

With this change, IF a client connect string is provided explicitly, the embedded ZooKeeper server should not be started, but instead the client connection should be established using that explicitly provided connect string. SEE the ""todo"" comment above the `SpringApplicationBuilder admin` line within `SingleNodeApplication`.

*distributed:*

Currently, when running in distributed mode, the client connect string is hardcoded to `localhost:2181`. Obviously that is only a short term solution since a real-world distributed runtime would span multiple machines (including the ZooKeeper ensemble itself). That is also why the connect string must support a comma-delimited list of `host:port` values (for redundancy), but the constructor for `ZooKeeperConnection` that accepts a client connect string already supports that via the underlying `CuratorFramework` builder.

With this change, a command-line argument for the client connect string will be passed into the `ZooKeeperConnection` constructor, within the configuration (e.g. SEE the ""todo"" statement within `ContainerServerApplication.DistributedZooKeeperConnectionConfiguration`).",XD-1393,Mark Fisher,Support explicit client connect string for ZooKeeper
2350,,Mark Pollack,,XD-1392,Mark Pollack,Clean up mismatches and bugs in how mdoule options and server configuration is handled.
2351,Gunnar Hillert,Mark Pollack,,XD-1391,Mark Pollack,Rewrite of the existing UI to use AngluarJS
2352,Michael Minella,Ilayaperumal Gopinathan,"When the job is run with its jobParameters by SimpleJobLauncher, its lastJobExecution's stepExecutions are checked for UNKNOWN status to throw JobRestartException.
It looks like the stepExecutions for the lastJobExecution are never set and the collection 'stepExecutions' is not fetched from job repository.

Hence, not sure if the following condition in SimpleJobLauncher's run(final Job job, final JobParameters jobParameters)
would ever get executed:

for (StepExecution execution : lastExecution.getStepExecutions()) {
				if (execution.getStatus() == BatchStatus.UNKNOWN) {
					//throw
					throw new JobRestartException(""Step ["" + execution.getStepName() + ""] is of status UNKNOWN"");
				}//end if
			}//end for",XD-1390,Ilayaperumal Gopinathan,Investigate missing stepExecutions in JobRepository.getLastJobExecution() 
2353,Gary Russell,Thomas Risberg,"Depending in the ftp server used there seems to be an error condition that generates an NullPointerException. 

These are the steps to reproduce this:

{code}
job create --name myftphdfs --definition ""ftphdfs --host=ftp.sunet.se --port=21""
job launch --name myftphdfs --params {""remoteDirectory"":""/pub/music/Abba"",""hdfsDirectory"":""/xd/ftp""}
{code}

Exception:
{code}
16:31:38,385 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 step.AbstractStep:225 - Encountered an error executing the step
java.lang.NullPointerException
	at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:140)
	at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:105)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:144)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:163)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:142)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy40.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)
	at org.springframework.expression.spel.ast.MethodReference.access$100(MethodReference.java:44)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:85)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:113)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:163)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.xd.dirt.plugins.job.JobPlugin.launch(JobPlugin.java:176)
	at org.springframework.xd.dirt.module.ModuleDeployer.launchModule(ModuleDeployer.java:380)
	at org.springframework.xd.dirt.module.ModuleDeployer.processLaunchRequest(ModuleDeployer.java:330)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleLaunch(ModuleDeployer.java:316)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:169)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:724)
{code}",XD-1389,Thomas Risberg,Sometimes getting NPE when master step runs for ftphdfs job
2354,Luke Taylor,Mark Pollack,,XD-1388,Mark Pollack,Upgrade to Spring Batch 3.0.0 M3
2355,Thomas Risberg,Mark Pollack,,XD-1387,Mark Pollack,Add documentation on how to deploy XD to YARN
2356,Thomas Risberg,Mark Pollack,,XD-1386,Mark Pollack,Add option to xd-admin and xd-container YARN scripts to allow copying ot HDFS and no execution.
2357,Glenn Renfro,Glenn Renfro,,XD-1385,Glenn Renfro,Add JDBC Sink to acceptance tests
2358,Mark Fisher,Thomas Risberg,"When sending a launch request, the message is not targeted to the container node that hosts the deployed job.  With RabbitMQ, the message is not ack'd so it will get picked up eventually by the container that hosts the deployed job.  This should change to a targeted message.

-----
Original description from Thomas below

Tried deploying some batch jobs and they all seem to fail when running admin and one container using redis as transport

xd:>job create mongojob --definition ""hdfsmongodb --resources=/data/*.log --names=col1,col2,col3 --idField=col1 --collectionName=test""

fails with this:
{quote}
18:19:01,612  WARN redisInboundAdapter-redis:queue-inbound-channel-adapter6 boot.SpringApplication:635 - Error handling failed (Error creating bean with name 'integrationRequestMappingHandlerMapping': Initialization of bean failed; nested exception is java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@25e7506f has not been refreshed yet)
18:19:01,614 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter6 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [moduleDeployer]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:724)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'readResourcesStep': Cannot create inner bean '(inner bean)' of type [org.springframework.batch.core.listener.StepListenerFactoryBean] while setting bean property 'listeners' with key [0]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name '(inner bean)#4': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: interface org.springframework.batch.core.StepListener is not visible from class loader
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:282)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:351)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:154)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1197)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:681)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:616)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:306)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:225)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:270)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:260)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:201)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:172)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 18 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name '(inner bean)#4': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: interface org.springframework.batch.core.StepListener is not visible from class loader
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:151)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:110)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:272)
	... 41 more
Caused by: java.lang.IllegalArgumentException: interface org.springframework.batch.core.StepListener is not visible from class loader
	at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:487)
	at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:722)
	at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)
	at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)
	at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:98)
	at org.springframework.batch.core.listener.AbstractListenerFactoryBean.getObject(AbstractListenerFactoryBean.java:163)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:144)
	... 43 more
{quote}

I'll post more errors as I collect them",XD-1384,Thomas Risberg,Improve job launch functionality with distributed nodes
2359,Glenn Renfro,Glenn Renfro,"Need to be able to test the following sources:
TCP, HTTP, Time,",XD-1383,Glenn Renfro,"Add acceptance tests for stream with sources of TCP, HTTP, and Time and sinks of File and Log"
2360,,Glenn Renfro,"When sending data to the TCP Source if the data is not terminated with a \r\n when the socket is closed by the client, XD throws an exception.

",XD-1382,Glenn Renfro,tcp source requires a \r\n to suffix all inbound data
2361,,Glenn Renfro,"If stream fails to create while using sources or sinks that need ports.  Ports are not released.

If while creating a stream you see:
""Command failed org.springframework.xd.rest.client.impl.SpringXDException: Failed to bind to: 0.0.0.0/0.0.0.0:9000. Possibly the port is already in use.""
then destroy the stream (or all streams for that matter) you will not be able to create another stream that uses that port.  

The work around is to cycle the container.",XD-1381,Glenn Renfro,XD does not release ports on failed stream creates.
2362,,Glenn Renfro,"[Problem]
Can't use tcp source, sink and http together on Single Node.

While creating tests for CI I tried to create the following:
[Steps to Reproduce]
xd:>stream create fooOut --definition ""tcp|file""
Created new stream 'fooOut'
xd:>stream create fooIn --definition ""http --port=9002|tcp""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Failed to bind to: 0.0.0.0/0.0.0.0:9000. Possibly the port is already in use.
Even if I use different ports for the tcp I still get failures pointing to 9000.
[Extra Notes]
The stream below is works.
xd:>stream create fooOut --definition ""tcp|file""
Created new stream 'fooOut'
xd:>stream create fooIN --definition ""time|tcp""

*Stack Trace Attached*",XD-1380,Glenn Renfro,Can't create http source while TCP is used as a source and sink on singlenode
2363,Ilayaperumal Gopinathan,Mark Fisher,"When executing tests and failures occur (should be easy to simulate with a forced failure), several other side-effect failures occur with the following error:

{code}
Caused by: java.lang.IllegalArgumentException: HSQLDB could not be started. Maybe another instance is already running on 0.0.0.0:13583 ?
{code}

It seems that the failing tests are not properly cleaning up, so the HSQLDB instance they started is still running thereby causing the other failures.

In the case I last witnessed this on a dev branch, I had a valid failure in LocalControlRedisDataInitializationTests (the environmentMatchesTransport method, specifically) and TypeConvertingStreamTests. So, perhaps a good way to start exploring this issue is to simulate a failure in one or both of those classes. The false negatives I'm seeing are in the following:

{code}
LocalSingleNodeInitializationTests.environmentMatchesTransport
RabbitSingleNodeInitializationTests.environmentMatchesTransport
RedisSingleNodeInitializationTests.environmentMatchesTransport
FileSourceModuleTests.classMethod
LocalSingleNodeStreamDeploymentIntegrationTests.classMethod
RabbitSingleNodeStreamDeploymentIntegrationTests.classMethod
RabbitSingleNodeStreamDeploymentIntegrationTests.classMethod
{code}

They all seem to be tests that start the SingleNodeApplication.",XD-1379,Mark Fisher,Avoid false negative test failures related to HSQLDB
2364,Eric Bottard,Mark Pollack,"e.g. rabbit.xml source.

	<context:property-placeholder
location=""${xd.config.home}/${configProperties:rabbit}.properties""
ignore-resource-not-found=""true"" />

would be removed and

	<rabbit:connection-factory id=""rabbitConnectionFactory"" host=""${host:${spring.rabbitmq.host:localhost}}""
port=""${port:${spring.rabbitmq.port:5672}}"" virtual-host=""${vhost:${spring.rabbitmq.virtualHost:/}}""
username=""${username:${spring.rabbitmq.username:guest}}"" password=""${password:${spring.rabbitmq.password:guest}}""/>

would look like
port=""${port}"" and a property file in the module directory or POJO in the module lib would specify the default value of the port.

For POJO it would be
options_class = org.springframework.xd.dirt.modules.metadata.RabbitSourceOptionsMetadata

For property file it would be
option.port.default=5672
option.port.description=""cool port number""

This needs to be consistently done across all the modules.






",XD-1378,Mark Pollack,Change module placeholder names and remove context:property-placeholder usage
2365,Mark Fisher,Mark Fisher,"This applies to a few places (when addressing the issue, a search should be done to uncover any others), e.g.:

ContainerServerApplication:
    public static final String NODE_PROFILE = ""node"";

*Options classes:
     ""The transport to use for data messages (from node to node)""
     ""The transport to use for control messages (between admin and nodes)""
",XD-1377,Mark Fisher,"Rename ""node"" references to ""container"""
2366,Eric Bottard,Ilayaperumal Gopinathan,"The XD shell crashes when the following command issued:

stream create test --definition ""http | filter --expression=!payload.contains('test') | log""

It looks like the JLine ConsoleReader's expandEvents is set to true by default and this causes the issue:

Exception in thread ""Spring Shell"" java.lang.IllegalArgumentException: !payload.contains('test') | log"": event not found
	at jline.console.ConsoleReader.expandEvents(ConsoleReader.java:734)
	at jline.console.ConsoleReader.finishBuffer(ConsoleReader.java:604)
	at jline.console.ConsoleReader.accept(ConsoleReader.java:1912)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2537)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)
	at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)
	at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:517)
	at org.springframework.shell.core.JLineShell.run(JLineShell.java:178)
	at java.lang.Thread.run(Thread.java:722)
",XD-1376,Ilayaperumal Gopinathan,"XD Shell crashes when the stream DSL has ""!"""
2367,Gunnar Hillert,Mark Pollack,,XD-1375,Mark Pollack,Create spike of web app that maps UI design docs to MVC components in Angluar
2368,Thomas Risberg,Mark Pollack,,XD-1374,Mark Pollack,Update to use spring-data-hadoop 2.0 M6
2369,Ilayaperumal Gopinathan,Thomas Risberg,"I set the config/xd-config.yml properties to use MySQL including this

 profiles:
    active: default,mysql

When XD ADmin starts I still see HSQL server started and localhost:9393/env shows:

""profiles"": [
    ""adminServer"",
    ""hsqldb"",
    ""default""
],
",XD-1373,Thomas Risberg,"HSQL always started, even when using other database"
2370,Jon Brisbin,Jon Brisbin,Need to update the spring-xd-extension-reactor support to reflect the changes to Reactor refactorings introduced in v1.1.,XD-1372,Jon Brisbin,Update Reactor integration to align 1.1 changes
2371,Luke Taylor,Anas Taud,"Suppose we have 3 environements of Spring XD :
- Dev environment 
- Test environment 
- Prod environement (

Suppose whe develop the script bellow:
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
stream1 = http | filter --expression=payload.contains('toto') | file --dir=/tmp/toto 
stream2 = http | filter --expression=payload.contains('titi') | file --dir=/tmp/titi //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

When we need to deploy the script in Test and Prod environements , we must modify ""dir"" option of ""file"" sink. This is very easy when there is not a lot of options and when we have a small factory team. But in a big factory environment this will be problematic. 

In order to industrialize deployment, it would be convenient to implement in DSL a directory interface API or something equivalent like below:

Suppose we call this directory interface XDDI ... like ""XD Directory Interface"" :-)

The script can be like that:
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
stream1 = http | filter --expression=payload.contains('toto') | file --dir=XDDI('totoKey') 
stream2 = http | filter --expression=payload.contains('titi') | file --dir=XDDI('titiKey') 
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

The XDDI keys are defined in a centralized directory interface (admin console or XDDI.properties)

The XDDI keys/values in Dev environment:
/////////////////////////////////////
totoKey=/tmp/toto
titiKey=/tmp/titi
/////////////////////////////////////

The XDDI keys/values in Test environment:
//////////////////////////////////////////
totoKey=/tartempion/toto
titiKey=/petaouchnok/titi
/////////////////////////////////////////

The XDDI keys/values in Prod environment:
/////////////////////////////////////////////////////
totoKey=/vavoirlabasijysuis/toto
titiKey=/vavoirlabasijysuis/titi
/////////////////////////////////////////////////////

When the script is deployed in Test or Prod environement, if the script contain a key that is not defined in centralized directory, the deployment fail. 

This will reduce errors risks in a big factory environnement (several hundred parameters and signifiant team turnover). 
",XD-1371,Anas Taud,Clarify API or syntax for managing deployment parameters
2372,Ilayaperumal Gopinathan,Duncan McIntyre,"Given:

  the counter example from the guide is run with redis enabled:

xd-singlenode --transport redis --store redis

When:

 a stream is created

stream create --name springtweets --definition ""twittersearch --consumerKey=<your_key> --consumerSecret=<your_secret> --query=spring | file --dir=/tweets/""

Then:

An exception is thrown:

Exception in thread ""inbound.springtweets.0-redis:queue-inbound-channel-adapter35"" org.springframework.integration.MessageHandlingException: error occurred in message handler [springtweets.0.convert.bridge]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:94)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:42)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:86)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:207)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:286)
	at java.lang.Thread.run(Thread.java:724)
Caused by: org.springframework.integration.x.bus.serializer.SerializationException: unable to deserialize [null]. Class not found.
	at org.springframework.integration.x.bus.MessageBusSupport.deserializeConsumerPayload(MessageBusSupport.java:247)
	at org.springframework.integration.x.bus.MessageBusSupport.transformPayloadForConsumer(MessageBusSupport.java:191)
	at org.springframework.integration.x.bus.MessageBusSupport.transformPayloadForConsumerIfNecessary(MessageBusSupport.java:168)
	at org.springframework.integration.x.redis.RedisMessageBus.access$300(RedisMessageBus.java:57)
	at org.springframework.integration.x.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:176)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	... 13 more
Caused by: java.lang.ClassNotFoundException: org.springframework.social.twitter.api.Tweet
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:190)
	at org.springframework.integration.x.bus.MessageBusSupport.deserializeConsumerPayload(MessageBusSupport.java:241)
	... 19 more",XD-1370,Duncan McIntyre,Serialization over data transport fails for classes that are module specific
2373,Thomas Risberg,Ketan Deshmukh,"I am trying to use HDFS as sink while creating streams and I am encountering the following error :

Please refer attached document :
Exception - localhost - 8020.txt 

The fs.default.name set in hadoop.properties is :
fs.default.name=hdfs://localhost:8020

I have also tried the following variation in the hadoop.properties file :
fs.default.name=hdfs://127.0.0.2:8020
fs.default.name=hdfs://127.0.0.2:50070

Using these values are also throwing me exceptions as mentioned in the following files attached :

Exception - 127.0.0.2 - 8020.txt 
Exception - 127.0.0.2 - 50070.txt 

We are using :
Pivotal HD 1.0.1
spring-xd-1.0.0.M5-dist

Kindly let us know the way around for this issue.


",XD-1369,Ketan Deshmukh,Using hdfs sink throwing an error
2374,David Turanski,David Turanski,The main container context becomes the shared context for modules.,XD-1368,David Turanski,Refactor container to remove shared module context as a separate context 
2375,Luke Taylor,Luke Taylor,"xd/lib includes jcl-over-slf4j so we don't need additional commons-logging jars in the modules or extensions:

https://github.com/spring-projects/spring-xd/pull/610",XD-1367,Luke Taylor,Exclude commons-logging from final distro1
2376,,Glenn Renfro,"When destroying a stream that contains an http source, an exception is thrown.  Thus even though the stream is destroyed all resources are not released i.e. port 9000 is still in use.  

NettyHttpInboundChannelAdapter is currently setup with child.tcpNoDelay set to true.  And when running on my system and on EC2 the http needs more time to release the port.  

My recommendation is to set bootstrap.setOption(""child.tcpNoDelay"", false)
instead of true. ",XD-1366,Glenn Renfro,Unable to destroy stream when using http source
2377,Ilayaperumal Gopinathan,Eric Bottard,"create a composed module, use it in a stream, delete ALL streams.
Try to delete the composed module => fails thinking that it's still used by the stream

",XD-1365,Eric Bottard,StreamDeployer.deleteAll() does not handle dependency tracking
2378,Thomas Risberg,Thomas Risberg,"The YARN support in M6 changes most of the config properties, need to update XD to use new ones.",XD-1364,Thomas Risberg,Upgrade to SHDP 2.0 M6
2379,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, job module only has an input channel that receives the job launching requests. If we have an output channel for the job module, we get the following benefits:

1) The output channel reflects the JobExecution from the job launching message handler's reply channel
2) This can be different from JobExecution listener's notification channel where we would get both the beforeJob() and afterJob() notification.
3) We can tap the output channel to send the job results to some other sinks.

Along with this improvement, planning to do some more refactoring on the Plugins so that some of the common implementation methods are handled in the base class.
",XD-1363,Ilayaperumal Gopinathan,Tap XD batch Job output
2380,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the job notification channels are direct channels. We need to make these pub/sub channels.

With XD-885 (allowing automatic job listeners registration),  this would allow us to create named channel syntax like:

topic:job:myjobname-jobExecution > log
topic:job:myjobname-stepExecution > log 

",XD-1362,Ilayaperumal Gopinathan,Make Job notification channels subscribable
2381,,Philippe Soares,"I've installed spring xd for the first time today on my mac, using the homebrew distribution.

I tried to create the following stream :

{{xd> stream create --definition ""http --port=6666 | log"" --name httptest}}

This produced the following error : 

org.springframework.integration.MessageHandlingException: error occurred in message handler [moduleDeployer]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)
	at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:183)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:153)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:228)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:212)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:171)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:149)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:183)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:153)
	at org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)
	at org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:163)
	at org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:204)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:229)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:748)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:931)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:833)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:807)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:126)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Cannot find class [org.springframework.integration.x.http.NettyHttpInboundChannelAdapter] for bean with name 'org.springframework.integration.x.http.NettyHttpInboundChannelAdapter#0' defined in URL [file:/Users/philippe/springsource/spring-xd-1.0.0.M1/xd/modules/source/http.xml]; nested exception is java.lang.ClassNotFoundException: org.springframework.integration.x.http.NettyHttpInboundChannelAdapter
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1327)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:594)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1396)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:959)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:680)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:609)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:181)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:264)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:254)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:249)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleSingleModuleMessage(ModuleDeployer.java:227)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:154)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	... 79 more
Caused by: java.lang.ClassNotFoundException: org.springframework.integration.x.http.NettyHttpInboundChannelAdapter
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedWebappClassLoader.loadClass(TomcatEmbeddedWebappClassLoader.java:68)
	at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1559)
	at org.springframework.util.ClassUtils.forName(ClassUtils.java:238)
	at org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:392)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1348)
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1319)
	... 95 more

I managed to create the exact same stream successfully after installing the release manually from the zip file and setting up XD_HOME and my path as documented, so I guess it's a problem specific to the homebrew installation.",XD-1361,Philippe Soares,Classpath issue with homebrew version on MacOSX 10.9.1
2382,Florent Biville,Karl I Lopes,"The Json information returned by curl does not reflect deployed status correctly.
To recreate:
1. Start xd-singlenode
2. start xd-shell
In the xd-shell
    (i). stream create --definition ""time | log"" --name ticktock
   (ii). stream list
Note the status of the ticktock stream is deployed
3. open a new command prompt & type curl http://localhost:9393/streams/ticktock
4. Note the returned json stream:
  {""name"":""ticktock"",""deployed"":null,""definition"":""time | log"",""links"":[{""rel"":""self"",""href"":""http://localhost:9393/streams/ticktock""}]}
5. I would expect the json attribute ""deployed"" to be ""true"", but it is null.",XD-1360,Karl I Lopes,Json information returned by curl does not reflect deployed status correctly
2383,Mark Fisher,Mark Fisher,"This will be used by SingleNodeApplication if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user's run ZooKeeper externally, at least in standalone mode, when running SingleNodeApplication. We should clarify that in the documentation and logs.

It should implement SmartLifecycle so that it can be managed as a bean within an ApplicationContext.",XD-1359,Mark Fisher,Create an embedded ZooKeeper server process
2384,Mark Fisher,David Turanski,"These are no longer used post boot.
",XD-1358,David Turanski,Remove launcher.xml and [transport]-launcher.xml configuration.
2385,Mark Fisher,Mark Fisher,"The /xd/containers node is the parent where each Container will write an ephemeral child node. The node name should be the Container's ID, and the node data should be the Container's attributes (host, pid, and much more to be added later).

When a Container shuts down cleanly, it should eagerly delete the ephemeral node so that watchers are notified immediately. For any other case (including a network partition), the ephemeral node will disappear after the timeout elapses.",XD-1357,Mark Fisher,Container nodes should write attributes to ZooKeeper
2386,Thomas Risberg,Thomas Risberg,"Starting the shell with --hadoopDistro hdp20 causes this:

Exception in thread ""main"" org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Unable to locate Spring NamespaceHandler for XML schema namespace [http://www.springframework.org/schema/hadoop]
Offending resource: URL [jar:file:/Users/trisberg/Demo/spring-xd-1.0.0.BUILD-SNAPSHOT/shell/lib/spring-xd-shell-1.0.0.BUILD-SNAPSHOT.jar!/META-INF/spring/spring-shell-plugin.xml]

Creating a stream ""time | hdfs"" in xd-singlenode started with --hadoopDistro hdp20 causes this:

java.lang.IllegalStateException: Can't find class used for type of option 'codec': org.springframework.data.hadoop.store.codec.Codecs
",XD-1356,Thomas Risberg,Hadoop distro option hdp20 is broken
2387,,Ilayaperumal Gopinathan,"When the container shuts down, ContainerStoppedEvent should be published so that appropriate listeners would act on.

Please refer to this discussion here:

https://github.com/spring-projects/spring-xd/pull/612",XD-1355,Ilayaperumal Gopinathan,Publish ContainerStoppedEvent when the container shutsdown
2388,Mark Fisher,David Turanski,Post-boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into LauncherApplication. Rename LauncherApplication to ContainerServerApplication (consistent with AdminServerApplication).  ,XD-1354,Mark Fisher,Remove XDContainer and rename LauncherApplication
2389,Mark Pollack,Thomas Risberg,"The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn't had any update activity for several months. Jedis is actively maintained.

We might also want to investigate Redisson which is a fork of Lettuce - https://github.com/mrniko/redisson",XD-1353,Thomas Risberg,Switch to use Jedis driver for Redis
2390,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"While processing the ""Job Launch"" request, the ModuleDeployer checks if the job is already deployed, if not it deploys the job before launching it.
This approach causes issue in case of multiple containers environment where the job is deployed in one container(1) but the ""job launch"" request is picked up by other container(2). Because the container(2) that processes ""job launch"" request deploys the job again, it conflicts with an existing job that is deployed in conatiner(1) with the same name in the JobRepository.

Initially, the idea behind 'deploy before launch' was to enable launch shell command to also deploy. Because of the issue mentioned above, it is ok to assume that job launch needs to be performed on an existing deployed job.",XD-1352,Ilayaperumal Gopinathan,Job Launch should throw exception if the job is not deployed in the container
2391,David Turanski,David Turanski,"This will allow us to control the order of plugins and use plugin(s) to manage the common module context, replacing BeanDefinitionAddingBeanPostProcesser",XD-1351,David Turanski,Replace BeanDefinitionAddingBeanPostProcessor with Ordered Plugins
2392,Eric Bottard,Mark Fisher,"The enum unnecessarily restricts the ability to add new transport (MessageBus implementations) whereas the config location path is open for extensions since it uses wildcards (in message-bus.xml):

{code}
<import resource=""../../transports/${XD_TRANSPORT}-bus.xml""/>
{code}
",XD-1350,Mark Fisher,Remove enum for transport options
2393,Thomas Risberg,Thomas Risberg,We currently pull all hdfs config properties from hdfs.properties - change that to use application.yml,XD-1349,Thomas Risberg,Make hdfs configurable via application.yml
2394,Gary Russell,David Turanski,This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ,XD-1348,David Turanski,"Allow end users to configure Rabbit MQ properties on the MessageBus (for acks, txs, etc)."
2395,Eric Bottard,Eric Bottard,"Following merge of https://github.com/spring-projects/spring-xd/pull/601, expose a unique id under which a module is known inside a stream. That id (which defaults to the module name) is what should be used as the qualifier for an option name inside a composed module, ie

{noformat}
module compose foo --definition ""f1: filter | filter""

==>
f1.expression and filter.expression are available
{noformat}",XD-1347,Eric Bottard,Expose a getter for a module unique id inside a stream definition
2396,Eric Bottard,Eric Bottard,"Following merge of https://github.com/spring-projects/spring-xd/pull/601, allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity",XD-1346,Eric Bottard,Add aliases concept to module options and use in composed modules
2397,Eric Bottard,Eric Bottard,"Following merge of https://github.com/spring-projects/spring-xd/pull/601, use dot as the separator for a composed module option.

Need change to the parser to accept dots",XD-1345,Eric Bottard,Use dot as the composed module option separator
2398,Andy Clement,Esteban Serrano,"eserrano-mbp:spring-xd-1.0.0.M5 eserrano$ ./shell/bin/xd-shell
 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
eXtreme Data
1.0.0.M5 | Admin Server Target: http://localhost:9393
Welcome to the Spring XD shell. For assistance hit TAB or type ""help"".
xd:>stream list
  Stream Name    Stream Definition                                          Status
  -------------  ---------------------------------------------------------  --------
  eesstream.log  http | transform --expression=payload.toUpperCase() | log  deployed
  httptest       http | file
  tictac         time | log

xd:>stream 

stream all         stream create      stream deploy      stream destroy     stream list        stream undeploy    

xd:>stream undeploy --name 
stream undeploy --name 
required --name: the name of the stream to un-deploy; no default value
xd:>stream undeploy --name eesstream.log 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: The stream named 'eesstream' is not currently deployed

xd:>
",XD-1344,Esteban Serrano,"Cannot undeploy stream that was created and deployed with a ""."" in the name"
2399,David Turanski,David Turanski,"Provide an easy way for users to add beans (e.g., Gemfire cache configuration) or modify default XD configuration such as serializers, and message converters. A simple approach is to add a well known resource selector such as classpath*:META-INF/spring/xd/extensions or include this path in an extensible @Configuration base class.  In addition, we should adopt conventional names for beans that are meant to be extended, e.g. use an xd. prefix.",XD-1343,David Turanski,Provide a conventional way to extend XD Container configuration
2400,Gary Russell,Ilayaperumal Gopinathan,By having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.,XD-1342,Ilayaperumal Gopinathan,Configuration for RabbitMQ message bus concurrent consumers
2401,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.",XD-1341,Ilayaperumal Gopinathan,Support oracle jdbc configuration for XD batch job repository
2402,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the XD container uses embedded tomcat only to support management server that acts as the RESTful server for boot's actuator MVC and jolokia endpoints.

If the configuration is set to use a specific management port (using the fixes addressed via XD-1122), then we don't need to have embedded tomcat servlet container in XD container. ",XD-1340,Ilayaperumal Gopinathan,XD container doesn't need embedded servlet container if it uses specific management port
2403,Patrick Peralta,Charlie Black,"Need some kind of hint that a given deployment is to be run on a group of servers.  That deployment would then be part of a partitioned work flow.

Another item on this would be the ""group"" that the server is running in can be added to removed dynamically.  The use case on this would be if the group of servers are running a max CPU capacity we can easily add another compute node.  Likewise we can remove a server from the group if the servers are not being fully utilized. 


This issue is lightly linked to:
https://jira.springsource.org/browse/XD-1337",XD-1339,Charlie Black,Deployment manifest to support directing deployment to run on a group of servers
2404,Gary Russell,Charlie Black,"We need a methodology for providing partitioning hints.

A current proposal uses message headers to provide:

* partition_key – the item to partition on
* destination_region – what to target

In the proposal the developer used ""partition_key"" to route the stream message to the node where data was stored in process.  This was done so downstream stream operations could work on the data with out suffering any network IO.

The ""destination_region"" was used to target the type of data the downstream streams were going to use in their stream processing.


",XD-1338,Charlie Black,Deployment manifest to support partitioning a stream
2405,liujiong,Charlie Black,"In a running system some times the algorithm for partitioning the data might overload a given server with work.  When that happens we might need to ""rebalance"" the partitioned work / data to achieve a even balance of stream throughput across servers in a given compute group.

We can think of this dynamic rebalancing behavior as an extension of a failure use case.   In the failure scenario we need to re-partition the stream to other servers in the group.

We should allow third parties to plug-in to help with this capability.  As an example GemFire will report the new partitioning meta-data when this type failure / rebalance happens.
",XD-1337,Charlie Black,Stream partitioning metadata should allow updating at runtime - dynamically / anytime
2406,,Charlie Black,"If a third party messaging solution wants to be the transport layer in SpringXD they must currently fork the SpringXD code base and change the enums.

Example: CommonDistributedOptions.ControlTransport currently limits to the following options (rabbit, redis).  So if a third party like messaging system, like ZeroMQ, wanted to plug-in they would have to add to the enum.  Here is another example where GemFire was used as the messaging system: 

https://github.com/charliemblack/spring-xd/blob/master/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/CommonDistributedOptions.java#L38

All messaging enums should be removed for an extensible model.",XD-1336,Charlie Black,Allow easy integration with other types of message transports - remove enums for transport layers
2407,Gary Russell,Gary Russell,"When importing XD as a gradle project into STS, it fails with

Missing directories spring-xd-hadoop/hdp20 and spring-xd-yarn

mkdir on these directories solves the problem.

The hdp20 case relates to XD-599 - it is not clear why spring-xd-yarn is needed.
",XD-1335,Gary Russell,STS Gradle Import Broken
2408,Thomas Risberg,David Turanski,"Currently samples use separate build scripts, so the XD versions, etc. may all be different. There should be a top level build script or at least a way to ensure the same version dependencies",XD-1334,David Turanski,Ensure XD Samples share common version dependencies
2409,,Ilayaperumal Gopinathan,"The external configuration fragment file support by setting spring.config.location in the XD startup scripts are not updated in xd-admin, xd-container and xd-singlenode .bat scripts. 

Please refer: https://github.com/spring-projects/spring-xd/issues/582
",XD-1333,Ilayaperumal Gopinathan,Add config file fragment support configuration in XD windows bat scripts
2410,Glenn Renfro,Glenn Renfro,"While the current setting work while running from your laptop to local deployments.  Or running from your laptop to ec2, they are not long enough for CI to Ec2.
This should have good defaults and have CI set them to what it needs.",XD-1332,Glenn Renfro,XD Integration pauses should be configurable
2411,Gunnar Hillert,Gunnar Hillert,See also XD-1320.,XD-1331,Gunnar Hillert,Make Batch Job Restarts Work using Single Node
2412,Janne Valkealahti,Ilayaperumal Gopinathan,"It looks like the HadoopFileSystemTestSupport test rule by default runs against hadoop 1.2 and we can add a way to support running the hadoop centric tests to run against a given hadoop distro. 

Currently, if the test is run against a version other than 1.2, the rule says:

15:47:34,469 ERROR main hadoop.HadoopFileSystemTestSupport:95 - HADOOP_FS IS NOT AVAILABLE, SKIPPING TESTS
org.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4
	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)
	at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)
	at org.springframework.xd.test.hadoop.HadoopFileSystemTestSupport.obtainResource(HadoopFileSystemTestSupport.java:49)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport.apply(AbstractExternalResourceTestSupport.java:58)
	at org.junit.rules.RunRules.applyAll(RunRules.java:26)
	at org.junit.rules.RunRules.<init>(RunRules.java:15)
	at org.junit.runners.BlockJUnit4ClassRunner.withTestRules(BlockJUnit4ClassRunner.java:379)
	at org.junit.runners.BlockJUnit4ClassRunner.withRules(BlockJUnit4ClassRunner.java:340)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:256)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
",XD-1330,Ilayaperumal Gopinathan,Enhance HadoopFileSystemTestSupport to obtain resource for a specific hadoop distro
2413,Ilayaperumal Gopinathan,David Geary,"This would use the Kafka Spring Integration Extension. We have a version of this working but had to modify the adapter code as its not currently compatible with Spring Integration 4. See INTEXT-97

",XD-1329,David Geary,Add a Kafka Source
2414,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,From https://jira.springsource.org/browse/XD-1231 we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.,XD-1328,Ilayaperumal Gopinathan,Modularize XD UI
2415,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"To replicate the issue:

Create stream: 
stream create rabbittest --definition ""rabbit --queues=test --outputType=text/plain | log""

Stacktrace thrown:

17:59:56,436 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:191 - Caught exception while handling a request
java.lang.IllegalArgumentException: Module option named outputType is already present
	at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.<init>(FlattenedCompositeModuleOptionsMetadata.java:56)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:49)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:117)
	at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:73)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:227)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:690)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:131)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
",XD-1327,Ilayaperumal Gopinathan,Rabbit source module with outputType fails to deploy
2416,,Mark Pollack,"Command such as

yarn app list
yarn deploy-xd --zipFile /tmp/myapp.zip --config /tmp/myconfig.yml
",XD-1326,Mark Pollack,Provide xd-shell integration for deploying XD on YARN
2417,Thomas Risberg,Mark Pollack,Suggest trying with Hortonworks 2.0,XD-1325,Mark Pollack,Deploy XD on YARN for a distribution other than Apache Hadoop 2.2
2418,Thomas Risberg,Mark Pollack,,XD-1324,Mark Pollack,Make Hadoop22 the default for the build
2419,,Mark Pollack,,XD-1323,Mark Pollack,Create shell script to retrieve list of xd components running on YARN
2420,Thomas Risberg,Thomas Risberg,"There seems to be some intersection with the work for this issue and the rationalization of how module properties are handled.  There will be changes to configuration/property management support such that each module (source, sink, etc) will be able to also be overridden in spring-xd.yml (or wherever -Dspring.config.location points to.  The HDFS sink module for example, will have default values based on it's OptionsMetadata and will be of the form <type>.<module>.<option>


That means in the configuration for hdfs.xml sink, there would be a config section such as

{code:xml}
    <configuration>
      fs.default.name=${sink.hdfs.hd.fs}
      mapred.job.tracker=${sink.hdfs.hd.jt}
      yarn.resourcemanager.address=${sink.hdfs.hd.rm}
      mapreduce.framework.name=${sink.hdfs.mr.fw}
    </configuration>
{code}

With default values defined by a HdfsSinkOptionsMetadata class.  The hdfs.xml module file would not contain any references to a properties file.

A file specified by -Dspring.config.location could override the values in a config section such as

sink:
  hdfs:
    hd.fs : hdfs://foobarhost:8020
    hd.jt : 10.123.123.123:9000

etc.

",XD-1322,Thomas Risberg,Add way to provide module config options for XD on YARN
2421,Thomas Risberg,Thomas Risberg,"Add YARN specific code based on Janne's prototyping

Add YARN Client and AppMaster implementations and startup config files

This includes shell scripts to deploy XD to YARN

Test working on Apache 2.2 distribution

We can modify config files, everything should be possible to override by providing command-line args or env variables.
./xd-yarn-deploy --zipFile /tmp/spring-xd-yarn.zip --config /tmp/spring-xd-yarn.yml

",XD-1321,Thomas Risberg,Add XD deployment for YARN
2422,Ilayaperumal Gopinathan,Gunnar Hillert,"Job restart fails with NPE. See PR for XD-1090:

https://github.com/spring-projects/spring-xd/pull/572
",XD-1320,Gunnar Hillert,Make Batch Job Restarts Work with Distributed Nodes 
2423,,Eric Bottard,"A lot of modules have similar options. Moreover, job modules often have options that belong to at least two domains (eg jdbc + hdfs).

I think that by using FlattenedCompositeModuleOptionsMetadata, we could come up with a way to combine several options POJOs into one. Something like:

public class JdbcHdfsOptionsMetadata {

  @OptionsMixin
  private JdbcOptionsMetadata jdbc;

  @OptionsMixin
  private HdfsOptionsMetadata hdfs;
}

this would expose eg ""driverClass"" as well as ""rolloverSize"" as top level options. Values could be actually injected into the fields, so that eg custom validation could occur (default validation for the mixin class would occur by default)",XD-1319,Eric Bottard,Allow mixins of ModuleOptionsMetadata
2424,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The job single partitioned step support (from singlestep-partitioner-support.xml) has the batch job DAOs (loaded from batch.xml).

During container startup, when the jobExecutionDao bean is initialized it makes the db connection to the underlying batch database (which admin server initializes). 

Here is the exception:

15:30:03,600  INFO main xml.XmlBeanDefinitionReader:316 - Loading XML bean definitions from class path resource [META-INF/spring-xd/batch/batch.xml]
15:30:06,154  WARN main annotation.ConfigurationClassEnhancer:318 - @Bean method StepScopeConfiguration.stepScope is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean Javadoc for complete details
15:30:06,705  INFO main support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'org.springframework.xd.dirt.server.ParentConfiguration$JmxConfiguration' of type [class org.springframework.xd.dirt.server.ParentConfiguration$JmxConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:30:07,266  INFO main annotation.AnnotationMBeanExporter:416 - Registering beans for JMX exposure on startup
15:30:07,291  INFO main annotation.AnnotationMBeanExporter:896 - Bean with name 'XDParentConfigMBeanExporter' has been autodetected for JMX exposure
15:30:07,299  INFO main annotation.AnnotationMBeanExporter:659 - Located managed bean 'XDParentConfigMBeanExporter': registering with JMX server as MBean [org.springframework.integration.monitor:name=XDParentConfigMBeanExporter,type=IntegrationMBeanExporter]
15:30:09,637  INFO main concurrent.ThreadPoolTaskScheduler:165 - Initializing ExecutorService  'scheduler'
15:56:08,788  INFO main concurrent.ThreadPoolTaskScheduler:203 - Shutting down ExecutorService 'scheduler'
15:56:08,806  INFO main annotation.AnnotationMBeanExporter:434 - Unregistering JMX-exposed beans on shutdown
15:56:08,853  INFO main autoconfigure.AutoConfigurationReportLoggingInitializer:118 - 

Error starting ApplicationContext. To display the auto-configuration report enabled debug logging (start with --debug)


15:56:08,854  INFO main listener.ClasspathLoggingApplicationListener:54 - Application failed to start with classpath: [file:/Users/iperumal/workspace/spring-xd/modules/processor/scripts/, file:/Users/iperumal/workspace/spring-xd/spring-xd-dirt/bin/, file:/Users/iperumal/workspace/spring-xd/spring-xd-test/bin/, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-test/4.0.0.M3/74e696bad60aab349c74f52839eb43ed0e1ce0e2/spring-integration-test-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-amqp/4.0.0.M3/32dd5001acffd82391d756cf3b5ba73ca4075aed/spring-integration-amqp-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-redis/4.0.0.M3/ed5e47b6844212bb88c112c559556b4cb3d6b087/spring-integration-redis-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop/2.0.0.M4/9f1acbf66f3a97d42a8f5b00eb0c0cad11562730/spring-data-hadoop-2.0.0.M4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-redis/1.1.1.RELEASE/e2d5e9cfdaaa3fbcc2a8d4bdbe06daf771cb4e39/spring-data-redis-1.1.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.0.1.RELEASE/cb996939c8d48ae55ec933041f17e7fba4d9e27d/spring-context-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context-support/4.0.1.RELEASE/94dc23c49a74f3f4b894b29416b08202e5976f49/spring-context-support-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.0.1.RELEASE/b93b2c39b09ff858a42db85a0a9a8ce232a6779/spring-tx-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.0.1.RELEASE/367212c3b84c63a48220efa0fe8e9a3a937fcf68/spring-test-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.lambdaworks/lettuce/2.3.3/1366615be02807a568c5f2d3a4475a3d27a879a6/lettuce-2.3.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hsqldb/hsqldb/2.3.0/93306187b1a782f2b929d12536022185487037d2/hsqldb-2.3.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/7.0.42/3827da9ca05ff115f239a2372bd44cfd729c692d/tomcat-jdbc-7.0.42.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/2.4/b1b6ea3b7e4aa4f492509a4952029cd8e48019ad/commons-io-2.4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.1.0/a14306a090eec2fa91017b77ac079361f68e1830/groovy-all-2.1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.0/9b473564e792c2bdf1449da1f0b1b5bff9805704/objenesis-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.9.5/c3264abeea62c4d2f367e21484fbb40c7e256393/mockito-core-1.9.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.1/5043bfebc3db072ed80fbd362e7caf00e885d8ae/commons-logging-1.1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.0.1.RELEASE/e39774d97c9dadfe49e6dfd16e3868bc1e390554/spring-core-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.0.1.RELEASE/605582e95fb62b43fb4a843babdcf739f3497e92/spring-beans-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/aopalliance/aopalliance/1.0/235ba8b489512805ac13a8f9ea77a1ca5ebe3e8/aopalliance-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.0.1.RELEASE/ff68e4cfdbb2be3e8d8a7f34e7cbacc1860dfe75/spring-aop-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.0.1.RELEASE/452cb22401e868a1e79677dd22b6a3097fc603fa/spring-expression-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.0.3.RELEASE/33b967f6abaa0a496318bff2ce96e6da6285a54d/spring-retry-1.0.3.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.0.1.RELEASE/829829afd9135368faa1e3a5261404f602a2e939/spring-messaging-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-core/4.0.0.M3/12b445cfa896b906facd2be289adcdfe839f6104/spring-integration-core-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.amqp/spring-amqp/1.3.0.M2/e668db16a4206e96531b978e5978868ba0ebf4e9/spring-amqp-1.3.0.M2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.rabbitmq/amqp-client/3.2.2/9e4485e734415e84ea3caea25650f8651f388a3a/amqp-client-3.2.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.amqp/spring-rabbit/1.3.0.M2/ceb54c437d2d00c3a22d59982922f24fbf78c8a/spring-rabbit-1.3.0.M2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.6/ce53b0a0e2cfbb27e8a59d38f79a18a5c6a8d2b0/slf4j-api-1.6.6.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.6.6/ec497945fdcaf7fd970ae9931b9bbfaf735d385e/jcl-over-slf4j-1.6.6.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.0.1.RELEASE/7d46d07d44f56af7cdcbba53ff671c5487f9547/spring-jdbc-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.2/2bf96b7aa8b611c177d329452af1dc933e14501c/commons-cli-1.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/xmlenc/xmlenc/0.52/d82554efbe65906d83b3d97bd7509289e9db561a/xmlenc-0.52.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.4/4216af16d38465bbab0f3dff8efa14204f7a399a/commons-codec-1.4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-httpclient/commons-httpclient/3.0.1/d6364bcc1b2b2aa69d008602d36a700453648560/commons-httpclient-3.0.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-math/2.1/b3c4bdc2778ddccceb8da2acec3e37bfa41303e9/commons-math-2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-collections/commons-collections/3.2.1/761ea405b9b37ced573d2df0d1e3a4e0f9edc668/commons-collections-3.2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.4/16313e02a793435009f1e458fa4af5d879f6fb11/commons-lang-2.4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils/1.7.0/5675fd96b29656504b86029551973d60fb41339b/commons-beanutils-1.7.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-digester/commons-digester/1.8/dc6a73fdbd1fa3f0944e8497c6c872fa21dca37e/commons-digester-1.8.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils-core/1.8.0/175dc721f87e4bc5cc0573f990e28c3cf9117508/commons-beanutils-core-1.8.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-configuration/commons-configuration/1.6/32cadde23955d7681b0d94a2715846d20b425235/commons-configuration-1.6.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/oro/oro/2.0.8/5592374f834645c4ae250f4c9fbb314c9369d698/oro-2.0.8.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-net/commons-net/1.4.1/abb932adb2c10790c1eaa4365d3ac2a1ac7cb700/commons-net-1.4.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-el/commons-el/1.0/1df2c042b3f2de0124750241ac6c886dbfa2cc2c/commons-el-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.eclipse.jdt/core/3.1.1/88c83ce444cf46d02494da37c9fa1eebc9ce9cea/core-3.1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-core/1.2.1/3e5874122a26a735162a380627210779b41bfd59/hadoop-core-1.2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-streaming/1.2.1/4baac190cf4cd4a6d085780cbcab1a89493f932b/hadoop-streaming-1.2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-tools/1.2.1/b08c16bd0448fbcadab67c4f8df837c094fdc91e/hadoop-tools-1.2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-core/2.0.0.M4/ff4cefb0870d61fdc9efe26d118310c02b5eafbb/spring-data-hadoop-core-2.0.0.M4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-batch/2.0.0.M4/47de250d5d9b48ed1319a747e3b06fdc46d939ef/spring-data-hadoop-batch-2.0.0.M4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.6.6.Final/e4e40738ce9bee0a92389cb739c94d7839778647/netty-3.6.6.Final.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/7.0.42/f0049ac94514d69231c41ed96238efb94ffdd9cf/tomcat-juli-7.0.42.jar, file:/Users/iperumal/workspace/spring-xd/spring-xd-analytics/bin/, file:/Users/iperumal/workspace/spring-xd/spring-xd-tuple/bin/, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.2.2/3c8f6018eaa72d43b261181e801e6f8676c16ef6/jackson-databind-2.2.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-infrastructure/3.0.0.BUILD-SNAPSHOT/cfaea737589c43c54ff338ae27e1bee477620176/spring-batch-infrastructure-3.0.0.BUILD-SNAPSHOT.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.eaio.uuid/uuid/3.2/77ba5105d949cd589aff75400d9f7d3676691a46/uuid-3.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.2.2/285cb9c666f0f0f3dd8a1be04e1f457eb7b15113/jackson-annotations-2.2.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.2.2/d20be6a5ddd6f8cfd36ebf6dea329873a1c41f1b/jackson-core-2.2.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.6.2.RELEASE/e96a0458cdc3179ca70c880f42315bb75df4faf5/spring-data-commons-1.6.2.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.1/8f79e353ef77da6710e1f10d34fc3698eaaacbca/joda-time-2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.5/cd5970bd13fa85f7bed41ca606d6daf7cbf1365/jcl-over-slf4j-1.7.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.5/6edffc576ce104ec769d954618764f39f0f0f10d/slf4j-log4j12-1.7.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/nl.jqno.equalsverifier/equalsverifier/1.1.3/60cd685f314a9cebfd0595d88fea45fba2f47918/equalsverifier-1.1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.5/6b262da268f8ad9eff941b25503a9198f0a0ac93/slf4j-api-1.7.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.1/63db1176f16448172611266154e4f6d39a0e1e68/objenesis-1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/2.2/59afed7ab65e7ec6585d5bc60556c3cbd203532b/cglib-nodep-2.2.jar, file:/Users/iperumal/workspace/spring-xd/spring-xd-rest-domain/bin/, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.hateoas/spring-hateoas/0.8.0.RELEASE/819c25e1ff12b7fca483d76b4e7d20221f621fcd/spring-hateoas-0.8.0.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-admin-manager/1.3.0.M1/5afc7442417af8c46ae51480ed2b83943283d449/spring-batch-admin-manager-1.3.0.M1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-core/3.0.0.BUILD-SNAPSHOT/8168f58716cd305040eaa87c82dc61822b03415c/spring-batch-core-3.0.0.BUILD-SNAPSHOT.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-core-asl/1.9.13/3c304d70f42f832e0a86d45bd437f692129299a4/jackson-core-asl-1.9.13.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.0.1.RELEASE/2ace92025f042e1d3ddfdbba093172e3572ac130/spring-web-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.0.1.RELEASE/2dbc91a6413115f7ffbe94f0fa9bc9fda3281d90/spring-webmvc-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.3/dc13ae4faca6df981fc7aeb5a522d9db446d5d50/objenesis-1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.2/81d61b7f33ebeab314e07de0cc596f8e858d97/slf4j-api-1.7.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjrt/1.6.6/ff58f520e1a304b8a02b8cea8b96b1b8e5b25b0/aspectjrt-1.6.6.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.6.6/c0383be877cfa4ec6b62202c942a89a6264a2be6/aspectjweaver-1.6.6.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-pool/commons-pool/1.3/3231230c1d7631b66a74d1c4653cfd65a6f9ea0/commons-pool-1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-dbcp/commons-dbcp/1.2.2/4fd4c6110e9bca3a655b717eb2e5920febb8403d/commons-dbcp-1.2.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/1.4/a8762d07e76cfde2395257a5da47ba7c1dbd3dce/commons-io-1.4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.1/4763ecc9d78781c915c07eb03e90572c7ff04205/commons-lang-2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-fileupload/commons-fileupload/1.2.1/384faa82e193d4e4b0546059ca09572654bc3970/commons-fileupload-1.2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/net.sf.ehcache/ehcache-core/2.3.0/e59473c71a31e8e19da4fbc7028585c8ed51d69f/ehcache-core-2.3.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-collections/commons-collections/3.2/f951934aa5ae5a88d7e6dfaa6d32307d834a88be/commons-collections-3.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.freemarker/freemarker/2.3.15/c8cfe522476fcec8da5c980d58bf62d6ab0cf27c/freemarker-2.3.15.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-admin-resources/1.3.0.M1/bdf7d5afc02397385fce8731409f606e54d4d033/spring-batch-admin-resources-1.3.0.M1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.0.2.RELEASE/d673c90a9fd8f0de5f20d53d61047849f707f42b/spring-retry-1.0.2.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/javax.batch/javax.batch-api/1.0/65392d027a6eb369fd9fcd1b75cae150e25ac03c/javax.batch-api-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.ibm.jbatch/com.ibm.jbatch-tck-spi/1.0/8ac869b0a60bff1a15eba0fb6398942410396938/com.ibm.jbatch-tck-spi-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/xpp3/xpp3_min/1.1.4c/19d4e90b43059058f6e056f794f0ea4030d60b86/xpp3_min-1.1.4c.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.thoughtworks.xstream/xstream/1.3/3f755b1a46744302712b1b962c4ab64de392f477/xstream-1.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jettison/jettison/1.1/1a01a2a1218fcf9faa2cc2a6ced025bdea687262/jettison-1.1.jar, file:/Users/iperumal/workspace/spring-xd/spring-xd-module/bin/, file:/Users/iperumal/workspace/spring-xd/spring-xd-module-spi/bin/, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.0.0.RC1/7830d0dd26f75841d8b5c2c72c42b864b1192ddb/spring-boot-autoconfigure-1.0.0.RC1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.0.0.GA/b6bd7f9d78f6fdaa3c37dae18a4bd298915f328e/validation-api-1.0.0.GA.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/4.3.1.Final/49b31d8ea51fa21cc78a89e9d4ddb11d6bfb4669/hibernate-validator-4.3.1.Final.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.0.0.RC1/7e53b72a368c495a482d3a213ad6338f8f7afcfa/spring-boot-1.0.0.RC1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.1.0.CR2/28725380c07f917ace4e511db21cc45e9ae5a72b/jboss-logging-3.1.0.CR2.jar, file:/Users/iperumal/workspace/spring-xd/spring-xd-hadoop/bin/, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-store/2.0.0.M4/1d3d691c0e6952ba26724339668e17040c368683/spring-data-hadoop-store-2.0.0.M4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.0/71c46e2313e92887de4247f2aabce4d09d65d82/snappy-java-1.1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/2.1/fd51f906669f49a4ffd06650666c3b8147a6106e/commons-io-2.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.7/9cd61d269c88f9fb0eb36cea1efcd596ab74772f/commons-codec-1.7.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.google.code.findbugs/jsr305/1.3.9/40719ea6961c0cb6afaeb6a921eaa1f6afd4cfdf/jsr305-1.3.9.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.google.guava/guava/11.0.2/35a3c69e19d72743cac83778aecbee68680f63eb/guava-11.0.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-mapper-asl/1.9.13/1ee2f2bed0e5dd29d1cb155a166e6f8d50bbddb7/jackson-mapper-asl-1.9.13.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.thoughtworks.paranamer/paranamer/2.3/4a85963a752c0a2f715c3924bfc686865e7e1bc6/paranamer-2.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.tukaani/xz/1.0/ecff5cb8b1189514c9d1d8d68eb77ac372e000c9/xz-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-compress/1.4.1/b02e84a993d88568417536240e970c4b809126fd/commons-compress-1.4.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.4/2396d74b12b905f780ed7966738bb78438e8371a/slf4j-api-1.6.4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro/1.7.5/8343a5b33f56fa16306ed27fa7b1a79278c26c2d/avro-1.7.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-common/1.2.5/fd1e6d42b3cb63f05ea5a1d22ded5ab63837b70f/parquet-common-1.2.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-generator/1.2.5/f16fd52b93d6677be340e7ac61609d6b91ba5ab0/parquet-generator-1.2.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-encoding/1.2.5/e96b9cd40f0eebc4ae483b0187401aa444ba36c0/parquet-encoding-1.2.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-column/1.2.5/1b1c618df93b16eb684c120662d56cde1b2caa99/parquet-column-1.2.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-format/1.0.0/ffaa2809ce56db3d7288ae118d876be30e9d1eb0/parquet-format-1.0.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-hadoop/1.2.5/6c87620226b4e156dac44af45171055b9ea78c8/parquet-hadoop-1.2.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.twitter/parquet-avro/1.2.5/8e7ad3c7f06b40e6d09417f82b0e4c703d8918ad/parquet-avro-1.2.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-jexl/2.1.1/6ecc181debade00230aa1e17666c4ea0371beaaa/commons-jexl-2.1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/net.sf.opencsv/opencsv/2.3/c23708cdb9e80a144db433e23344a788a1fd6599/opencsv-2.3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/0.10.0/916792f62bb1177ec4e9f3dedc53f19d9ae869a/kite-data-core-0.10.0.jar, file:/Users/iperumal/workspace/spring-xd/extensions/spring-xd-extension-reactor/bin/, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.projectreactor/reactor-spring/1.0.0.RC1/1652e63c473f1824ca7185d12be70981f97913e0/reactor-spring-1.0.0.RC1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.projectreactor/reactor-tcp/1.0.0.RC1/d275a1bdb5a449a1e9638dcd99f9a97a97c26b45/reactor-tcp-1.0.0.RC1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.jayway.jsonpath/json-path/0.8.1/fbcad75a02160def33c4359b24015cca2d91ccce/json-path-0.8.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.lmax/disruptor/3.2.0/ac62995678dd4b906e85b26354aa2ebfda130c32/disruptor-3.2.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.projectreactor/reactor-core/1.0.0.RC1/202718fd7bbe443de0004e305edb075355b0b340/reactor-core-1.0.0.RC1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/io.netty/netty-all/4.0.6.Final/1ce815d4d1ab73b17e20a5f9c206f422014deb4a/netty-all-4.0.6.Final.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/net.minidev/json-smart/1.1.1/24a2f903d25e004de30ac602c5b47f2d4e420a59/json-smart-1.1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.6/ce1edb914c94ebc388f086c6827e8bdeec71ac2/commons-lang-2.6.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.cloud/spring-service-connector/0.9.2/75e716e825fe66db6047cf1e026ca7581a5c933a/spring-service-connector-0.9.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.cloud/cloudfoundry-connector/0.9.2/d0f4df0a67f13704db02e688fc9d85d1c9ed5498/cloudfoundry-connector-0.9.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-actuator/1.0.0.RC1/88bf421071c1a38a9fda606c5f3cab609c74bf71/spring-boot-actuator-1.0.0.RC1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-event/4.0.0.M3/d0abb5b6a6d8050a71cbb6e95c69d484bb26c005/spring-integration-event-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-file/4.0.0.M3/ba6b17b85f2847326bf5ea0444872c62de0f5e8f/spring-integration-file-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-ftp/4.0.0.M3/6ddfabd427c6edb5114595903eead0cd042a6ec7/spring-integration-ftp-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-groovy/4.0.0.M3/53203058a9f6d703ae0e1d86ebb59c6ee2515c14/spring-integration-groovy-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-http/4.0.0.M3/b78a8227736b84aa857dbec75a6ef4c47a0563be/spring-integration-http-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-jmx/4.0.0.M3/d2b332cc945281327fc91b8641fa71b7340dfdcf/spring-integration-jmx-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jolokia/jolokia-spring/1.1.5/e9a8d8710c19381327afe4a7e5af9cc4aa5e7ef4/jolokia-spring-1.1.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jolokia/jolokia-client-java/1.1.5/e0f24b062d3f359737a24a0130986e20f0a77e5c/jolokia-client-java-1.1.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.esotericsoftware.kryo/kryo/2.22/1b624c2db8eb3a40d84362f22c2078ebde3e8c81/kryo-2.22.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/args4j/args4j/2.0.16/9f00fb12820743b9e05c686eba543d64dd43f2b1/args4j-2.0.16.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-integration/3.0.0.BUILD-SNAPSHOT/e11f30ff7b6da07e7f630752c5d92c41eorg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'jobExecutionDao' defined in class path resource [META-INF/spring-xd/batch/batch.xml]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Could not inspect meta data for database type.  You have to supply it explicitly.
84de90a/spring-batch-integration-3.0.0.BUILD-SNAPSHOT.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.plugin/spring-plugin-core/0.8.0.RELEASE/4390edad56632d97fec6abe8dba96531234b9603/spring-plugin-core-0.8.0.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/7.0.35/3efe5c4c44215a514fa804c5ef829569f6652b8b/tomcat-embed-core-7.0.35.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-logging-juli/7.0.35/5e92715a81731f6615053a399e1d3e9a2c05d4b9/tomcat-embed-logging-juli-7.0.35.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jsp-api/7.0.35/30a8560fad20cf681da4b26a5100d474559fda8a/tomcat-jsp-api-7.0.35.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.sun.mail/javax.mail/1.5.0/ec2410fdf7e0a3022e7c2a2e6241039d1abc1e98/javax.mail-1.5.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.12/ebe66a6b88caab31d7a19571ad23656377523545/snakeyaml-1.12.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.postgresql/postgresql/9.2-1002-jdbc4/a535facdcc0b4c488798e0c19499c08b1bc3a2e/postgresql-9.2-1002-jdbc4.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/mysql/mysql-connector-java/5.1.23/c264e2114579474d13dd808a510fc74e762dda8c/mysql-connector-java-5.1.23.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.activemq/activemq-core/5.6.0/9996dd23872b8588d63cf8a6cc8522b6ad8caa85/activemq-core-5.6.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jms/4.0.1.RELEASE/7d74a1414cd45349ed61ee3f3e1fca019090358c/spring-jms-4.0.1.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.0.0.RC1/15b007421d5419e435cf508057d458a065126d00/spring-boot-1.0.0.RC1-tests.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.social/spring-social-twitter/1.0.5.RELEASE/6c4b7e69b060862d98c87588d827d4feabbcd68/spring-social-twitter-1.0.5.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.3.1/c4096a8323bbbcbeda072e3def123a9b66783361/jackson-databind-2.3.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hsqldb/hsqldb/2.3.1/bd7153caa30958e1c64a3dd38b93e5a7442d9a0e/hsqldb-2.3.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.cloud/core/0.9.2/32631d9bd70d432e77df0ca64db21b49d28f9589/core-0.9.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.3.0/f5e853a20b60758922453d56f9ae1e64af5cb3da/jackson-annotations-2.3.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.3.1/f9f7185c92ca5fefe2fb3efdeb477a67c96ea2d0/jackson-core-2.3.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-net/commons-net/3.0.1/643cc426b9f75aa111fac0fac0e52ff5d991a337/commons-net-3.0.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-scripting/4.0.0.M3/6b0260ca4709da0bdd230d7bca41f3764a91ed4c/spring-integration-scripting-4.0.0.M3.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.googlecode.json-simple/json-simple/1.1/5e303a03d04e6788dddfa3655272580ae0fc13bb/json-simple-1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jolokia/jolokia-core/1.1.5/56bdd8956fb2bb3a9241267a7cb22d43f27d0a71/jolokia-core-1.1.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jolokia/jolokia-jvm/1.1.5/c59f18d004d64bea982d5128fbf08b4a177c1720/jolokia-jvm-1.1.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jolokia/jolokia-jmx/1.1.5/c7026c2cf9111a138538cc6705ca4c41f70be8fa/jolokia-jmx-1.1.5.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.1.2/39e30fb2ddfcf32b9dd663039ca6e847b698aa6f/httpcore-4.1.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.1.2/9003011c1b6d28a7331f04251a25e7ccf63c98f8/httpclient-4.1.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpmime/4.1.2/c78eaaea68d0f36f73b646f08cdb34f1a784239b/httpmime-4.1.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient-cache/4.1.2/6906f34467097e240ca451652f5738245a2face0/httpclient-cache-4.1.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient-osgi/4.1.2/c7577b4f8877a0a29ae5cc65331dcbe9960f8cce/httpclient-osgi-4.1.2.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-el-api/7.0.35/5e117f3f62c49d52cb72d028e76c5d16a8d148ca/tomcat-el-api-7.0.35.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-servlet-api/7.0.35/87bd606eef7d42ff3ec324d198549ccd8ccb56fc/tomcat-servlet-api-7.0.35.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/javax.activation/activation/1.1/e6cb541461c2834bdea3eb920f1884d1eb508b50/activation-1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.geronimo.specs/geronimo-jms_1.1_spec/1.1.1/c872b46c601d8dc03633288b81269f9e42762cea/geronimo-jms_1.1_spec-1.1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.activemq/kahadb/5.6.0/ab90275013deb4a1652a49dc6b01a894b8138a48/kahadb-5.6.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.activemq.protobuf/activemq-protobuf/1.1/26682eb801f70563511f7c424dc10e8b3e66340e/activemq-protobuf-1.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.fusesource.hawtdispatch/hawtdispatch/1.9/cbfeed0be226850799a7ef819b0dfa3346198af6/hawtdispatch-1.9.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.fusesource.hawtdispatch/hawtdispatch-transport/1.9/5e29bb84478f8f2526e0cae2cb74b9978f3c01d0/hawtdispatch-transport-1.9.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.fusesource.hawtbuf/hawtbuf/1.9/4a42b835d1df77db8c9a144a11ebb4600a372f5f/hawtbuf-1.9.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.fusesource.mqtt-client/mqtt-client/1.0/4af519e42c765b78aedd63c872706f5fa1621a9c/mqtt-client-1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.osgi/org.osgi.core/4.1.0/b88cd082b5b6774e9db939e28c0e3dc526c92d89/org.osgi.core-4.1.0.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.geronimo.specs/geronimo-j2ee-management_1.1_spec/1.0.1/5372615b0c04c1913c95c34a0414cef720ca2855/geronimo-j2ee-management_1.1_spec-1.0.1.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jasypt/jasypt/1.8/b14e87ad376dee74bb2d088279fe2df179cfc9e0/jasypt-1.8.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.social/spring-social-core/1.0.3.RELEASE/44e648f23b45162c698e255a16759832dfcfc004/spring-social-core-1.0.3.RELEASE.jar, file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.security/spring-security-crypto/3.1.3.RELEASE/a0db20c52e8281bffc200429b7fcd7c2cbeeb0e0/spring-security-crypto-3.1.3.RELEASE.jar, file:/Users/iperumal/workspace/spring-xd-samples/batch-notifications/target/batch-notifications-1.0.0.BUILD-SNAPSHOT.jar]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:658)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:355)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:116)
	at org.springframework.xd.dirt.server.LauncherApplication.run(LauncherApplication.java:76)
	at org.springframework.xd.dirt.server.LauncherApplication.main(LauncherApplication.java:56)
Caused by: java.lang.IllegalArgumentException: Could not inspect meta data for database type.  You have to supply it explicitly.
	at org.springframework.batch.item.database.support.SqlPagingQueryProviderFactoryBean.getObject(SqlPagingQueryProviderFactoryBean.java:159)
	at org.springframework.batch.admin.service.JdbcSearchableJobExecutionDao.getPagingQueryProvider(JdbcSearchableJobExecutionDao.java:134)
	at org.springframework.batch.admin.service.JdbcSearchableJobExecutionDao.getPagingQueryProvider(JdbcSearchableJobExecutionDao.java:113)
	at org.springframework.batch.admin.service.JdbcSearchableJobExecutionDao.getPagingQueryProvider(JdbcSearchableJobExecutionDao.java:104)
	at org.springframework.batch.admin.service.JdbcSearchableJobExecutionDao.afterPropertiesSet(JdbcSearchableJobExecutionDao.java:92)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549)
	... 15 more
Caused by: org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLTransientConnectionException: java.net.ConnectException: Connection refused
	at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:293)
	at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:320)
	at org.springframework.batch.support.DatabaseType.fromMetaData(DatabaseType.java:95)
	at org.springframework.batch.item.database.support.SqlPagingQueryProviderFactoryBean.getObject(SqlPagingQueryProviderFactoryBean.java:155)
	... 21 more
Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLTransientConnectionException: java.net.ConnectException: Connection refused
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80)
	at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:280)
	... 24 more
Caused by: java.sql.SQLTransientConnectionException: java.net.ConnectException: Connection refused
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source)
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source)
	at org.hsqldb.jdbc.JDBCConnection.<init>(Unknown Source)
	at org.hsqldb.jdbc.JDBCDriver.getConnection(Unknown Source)
	at org.hsqldb.jdbc.JDBCDriver.connect(Unknown Source)
	at org.apache.tomcat.jdbc.pool.PooledConnection.connectUsingDriver(PooledConnection.java:278)
	at org.apache.tomcat.jdbc.pool.PooledConnection.connect(PooledConnection.java:182)
	at org.apache.tomcat.jdbc.pool.ConnectionPool.createConnection(ConnectionPool.java:702)
	at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:634)
	at org.apache.tomcat.jdbc.pool.ConnectionPool.init(ConnectionPool.java:488)
	at org.apache.tomcat.jdbc.pool.ConnectionPool.<init>(ConnectionPool.java:144)
	at org.apache.tomcat.jdbc.pool.DataSourceProxy.pCreatePool(DataSourceProxy.java:116)
	at org.apache.tomcat.jdbc.pool.DataSourceProxy.createPool(DataSourceProxy.java:103)
	at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)
	at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:111)
	at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:77)
	... 25 more
Caused by: org.hsqldb.HsqlException: java.net.ConnectException: Connection refused
	at org.hsqldb.ClientConnection.openConnection(Unknown Source)
	at org.hsqldb.ClientConnection.initConnection(Unknown Source)
	at org.hsqldb.ClientConnection.<init>(Unknown Source)
	... 39 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:391)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.hsqldb.server.HsqlSocketFactory.createSocket(Unknown Source)
	... 42 more


",XD-1318,Ilayaperumal Gopinathan,XD container can not be started before the admin server
2425,Thomas Risberg,Thomas Risberg,,XD-1317,Thomas Risberg,Support for deploying and running XD on YARN
2426,Gunnar Hillert,Gunnar Hillert,"When running E2E tests the following warning may be observed:

{code}
Running ""karma:e2e"" (karma) task
INFO [karma]: Karma v0.10.9 server started at http://localhost:7070/_karma_/
INFO [launcher]: Starting browser PhantomJS
TypeError: Cannot read property 'verbose' of undefined
    at enableWebsocket (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:101:18)
    at Object.utils.proxyRequest [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:109:5)
    at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)
    at Object.livereload [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect-livereload/index.js:147:5)
    at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)
    at Function.app.handle (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:201:3)
    at Server.app (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/connect.js:65:37)
    at Server.EventEmitter.emit (events.js:98:17)
    at HTTPParser.parser.onIncoming (http.js:2108:12)
    at HTTPParser.parserOnHeadersComplete [as onHeadersComplete] (http.js:121:23)
    at Socket.socket.ondata (http.js:1966:22)
    at TCP.onread (net.js:525:27)
{code}
",XD-1316,Gunnar Hillert,UI:Fix E2E test warning
2427,Eric Bottard,Glenn Renfro,This is so that we can have an ENUM that can show the possible values and autocomplete.  Using just the XML the user has a greater chance to enter an invalid mode.   ,XD-1315,Glenn Renfro,Create POJO based FileSink module metadata
2428,Thomas Risberg,Thomas Risberg,"Create XD .zip distribution for YARN that adds an additional sub-project to the spring-xd repo for building the xd-YARN.zip

Link into main build file

Produce a new artifact spring-xd-v-xyz-yarn.zip as part of the nightly CI process -- will now have 2 artifacts, main xd.zip distribution and xd-yarn.zip

Does not include any Hadoop distribution libraries

Does include spring-hadoop jars for Apache22 ‘unflavored’
",XD-1314,Thomas Risberg,Create XD .zip distribution for YARN
2429,Ilayaperumal Gopinathan,Eric Bottard,See discussion at https://github.com/spring-projects/spring-xd/pull/572,XD-1313,Eric Bottard,Commands that start a job should return a representation of the JobExecution
2430,Gunnar Hillert,Eric Bottard,"Create a job, launch it but make it fail (eg filejdbc with missing file)

job execution list => it's there, as FAILED. Good

job execution restart <theid> ==> Fails with NPE:

{noformat}
16:59:42,160 ERROR http-nio-9393-exec-7 rest.RestControllerAdvice:191 - Caught exception while handling a request
java.lang.NullPointerException
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:351)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy39.run(Unknown Source)
	at org.springframework.batch.admin.service.SimpleJobService.restart(SimpleJobService.java:179)
	at org.springframework.xd.dirt.plugins.job.DistributedJobService.restart(DistributedJobService.java:77)
	at org.springframework.xd.dirt.rest.BatchJobExecutionsController.restartJobExecution(BatchJobExecutionsController.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springfram
{noformat}",XD-1312,Eric Bottard,Job execution restart fails with NPE
2431,Ilayaperumal Gopinathan,Eric Bottard,"Create a job, execute it a couple of times, destroy it and then invoke job execution list.

The job name column should mention that a job is defunct (even though a job with the same name could have been re-created in the interim)",XD-1311,Eric Bottard,Job execution list should mention jobs that have been deleted
2432,Ilayaperumal Gopinathan,Eric Bottard,"Disregard the missing date that is caused by another problem.
Here is the setup:
{noformat}
xd:>job execution list
  Id  Job Name  Start Time                        Step Execution Count  Status
  --  --------  --------------------------------  --------------------  ---------
  13  foo         Europe/Paris                    0                     STARTING
  12  foo       2014-02-12 15:39:46 Europe/Paris  1                     FAILED
  11  foo       2014-02-12 15:39:29 Europe/Paris  1                     COMPLETED
  10  foo       2014-02-12 15:38:36 Europe/Paris  1                     COMPLETED
  9   foo       2014-02-12 15:38:21 Europe/Paris  1                     COMPLETED
  8   foo         Europe/Paris                    0                     STARTING
  7   foo       2014-02-12 15:25:41 Europe/Paris  1                     COMPLETED
  6   foo       2014-02-12 15:25:04 Europe/Paris  1                     FAILED
  5   foo       2014-02-12 15:14:32 Europe/Paris  1                     FAILED
  4   foo       2014-02-12 15:14:13 Europe/Paris  1                     FAILED
  3   foo       2014-02-12 15:13:54 Europe/Paris  1                     FAILED
  2   foo       2014-02-12 15:13:18 Europe/Paris  1                     FAILED
  1   foo       2014-02-12 15:12:58 Europe/Paris  1                     FAILED
  0   foo       2014-02-12 15:11:44 Europe/Paris  1                     FAILED

xd:>job execution restart --id 12
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Job Execution 12 is already running.
{noformat}

while the server exception is a bit better:
{noformat}
Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobInstance: id=11, version=0, Job=[foo]
	at org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:120)
{noformat}

I'd argue we should not speak in terms of execution ids if possible, but rather in terms of job names
",XD-1310,Eric Bottard,Misleading error message when trying to restart a job exec
2433,Eric Bottard,Eric Bottard,"When using a JSR303 annotated class for module options, the binding failures should be bypassed, as they interfere with completion proposals.
",XD-1309,Eric Bottard,JSR303 validation of options interferes with dsl completion
2434,Mark Fisher,Eric Bottard,"When trying some of the examples of XD-159, came up with weird behavior of the transform module.

This boils down to:
{noformat}
stream create foo --definition ""http |transform --expression='new java.lang.Integer(payload)' |  transform --expression=payload.getClass() | log""
http post --data 42   ==> Integer (OK)
http post --data WTH => WTH (!)
{noformat}

Seems that when the expression can not be evaluated, the incoming payload is transmitted as is",XD-1308,Eric Bottard,Weird behavior of the transform module
2435,Eric Bottard,Eric Bottard,HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg /streams/{id} instead of using string concatenation,XD-1307,Eric Bottard,Use HATEOAS Link templates
2436,David Turanski,Eric Bottard,"Commit https://github.com/spring-projects/spring-xd/commit/761cd5e8250c055878caf3a789ab5b3254ba48e8 introduced support for FTP and added a bunch of .x classes.

These should not belong to DIRT proper though, and should be added to an extension style project. The job(s) module would then depend on them",XD-1306,Eric Bottard,Move ftp support from .x package to spring-xd-dirt batch package
2437,Glenn Renfro,Glenn Renfro,currently the file sink only supports append.  User should support an overwrite feature.,XD-1305,Glenn Renfro,File Sink should support Replace as an option
2438,Eric Bottard,Mark Pollack,,XD-1304,Mark Pollack,Create shell command for getting information on a given job instance
2439,Ilayaperumal Gopinathan,Mark Pollack,,XD-1303,Mark Pollack,Create REST API for getting information on a given job instance
2440,Janne Valkealahti,Mark Pollack,,XD-1302,Mark Pollack,Add documentation for using FTP->HDFS partitioned jobs
2441,Glenn Renfro,Glenn Renfro,"Problem: The container that the stream was deployed to, will not allow new streams to be deployed.  Once the error occurs, the only solution is to terminate the XD Container and restart it.

To reproduce create a stream foo and destroy the stream, then create the stream  foo again.  This best done programmatically, taking the same steps using the ""shell"" may not reproduce the problem.  i.e. if you put a Sleep of 1-2 seconds between the destroy and the next create, it works fine

",XD-1301,Glenn Renfro,MBeans are not destroyed if stream is created and destroyed with no delay
2442,Luke Taylor,Ilayaperumal Gopinathan,"There are few boolean type module option properties whose default values are specified in the module definitions than their corresponding ModuleOptionsMetaData. 

Also, when using boolean we need to have module option using primitive type boolean than Boolean type.

Currently, these are some of the module options that require this change:

""initializeDatabase"" in modules filejdbc, hdfsjdbc job modules, aggregator processor module, jdbc sink module

""restartable"" in all the job modules

""deleteFiles"" in filejdbc, filepollhdfs job modules






",XD-1300,Ilayaperumal Gopinathan,Handling boolean type module option properties defaults in option metadata
2443,Eric Bottard,Ilayaperumal Gopinathan,"Currently, the fileDeletion listeners are added to filepollhdfs and filejdbc OOTB job modules so that the files are deleted after successful completion of jobs that write the file into hdfs/jdbc.

We have ""--deleteFiles"" option in ResourcesIntoJdbcJobModuleOptionsMetadata (from https://github.com/spring-projects/spring-xd/pull/562)  which makes it available for hdfsjdbc job module as well. But it is not supported yet as it involves deletion of HDFS files.

We need the file deletion listeners for the hdfsjdbc and hdfsmongodb job modules so that if opted to delete files, it can be supported.

",XD-1299,Ilayaperumal Gopinathan,Move --deleteFiles out of ResourcesIntoJdbcJobModuleOptionsMetadata
2444,Eric Bottard,Eric Bottard,"Most likely due to https://github.com/spring-projects/spring-shell/commit/296e4d2ff0e6e91d91209ab8717335357c587de0

When the user submits with ENTER, the shell appears to hang",XD-1298,Eric Bottard,Commands that prompt the user are now broken
2445,Eric Bottard,Eric Bottard,"Commit 96de9fcfaf32719413015a1a6bace1b30b6b9610 strengthened module type inference, but some corner cases remain (marked as TODOs and commented out assertions in tests).

To be effective, we need to look at the whole deployed stream (or composed module). Modify ParsinContext accordingly.",XD-1297,Eric Bottard,Fix module type guessing heuristics
2446,Luke Taylor,Ilayaperumal Gopinathan,"If JMX is enabled, some of the integration tests fail.

This is similar to what we see in XD-1295.

One example of this case is, the test classes that extend StreamTestSupport.

In StreamTestSupport, the @BeforeClass has this line:

moduleDeployer = containerContext.getBean(ModuleDeployer.class);

When JMX is enable, the IntegrationMBeanExporter creates JdkDynamicProxy for the ModuleDeployer (since it is of type MessageHandler) and thereby the above line to get bean by the implementing class type (ModuleDeployer) fails.

There are few other places where we use to refer the implementing classes on getBean().
Looks like we need to fix those as well.

",XD-1296,Ilayaperumal Gopinathan,Few integration tests fail if JMX is enabled
2447,Luke Taylor,Ilayaperumal Gopinathan,"If JMX is enabled for modules (enabling the IntegrationMBeanExporter), the ModuleTypeConversionPlugin fails to get the reference to input/output channel (for adding the ContentTypeHeaderInterceptor) and results in exception.

It seems like the IntegrationMBeanExporter (when JMX is enabled) creates JdkDynamicAopProxy for all the integration components and thereby the following check on ModuleTypeConversionPlugin to retrieve the AbstractMessageChannel fails.

AbstractMessageChannel channel = null;
			if (isInput) {
				channel = module.getComponent(""input"", AbstractMessageChannel.class);
			}
			else {
				channel = module.getComponent(""output"", AbstractMessageChannel.class);
			}

I see the reason why AbstractMessageChannel is used here (to use some of the methods in the implementing class that didn't exist in the interfaces) but IntegrationMBeanExporter creating JdkDynamicAopProxy for the channel fails to resolve as AbstractMessageChannel here.

Following is the full stack trace:

To replicate,

stream create testing --definition """"http --outputType=text/plain | log""
3:45,238 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [moduleDeployer]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy62.handleMessage(Unknown Source)
	at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:152)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:121)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:108)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:218)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:188)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy61.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:96)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:212)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.springframework.xd.dirt.plugins.ModuleConfigurationException: Bean named 'output' must be of type [org.springframework.integration.channel.AbstractMessageChannel], but was actually of type [com.sun.proxy.$Proxy70]
	at org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.configureModuleConverters(ModuleTypeConversionPlugin.java:144)
	at org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.postProcessModule(ModuleTypeConversionPlugin.java:70)
	at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:378)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:282)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:271)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:266)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleSingleModuleMessage(ModuleDeployer.java:244)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:171)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	... 42 more
Caused by: org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'output' must be of type [org.springframework.integration.channel.AbstractMessageChannel], but was actually of type [com.sun.proxy.$Proxy70]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:376)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:979)
	at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:156)
	at org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.configureModuleConverters(ModuleTypeConversionPlugin.java:100)
	... 50 more",XD-1295,Ilayaperumal Gopinathan,Module message conversion fails to work if JMX is enabled
2448,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the reactorEnv bean is defined in module-common context and the spring-xd-dirt has the runtime dependency over spring-xd-extension-reactor project. 

This enables boot's ReactorAutoConfiguration to initialize the reactor environment, we have the reactor setup configured for both admin and container server applications.

Since reactor environment is not being used by container and only used by the reactor-syslog module, we can move the reactorEnv bean definition in reactor-syslog module.

There is one caveat in this approach as the reactor environment gets setup everytime a new reactor-syslog module is deployed.",XD-1294,Ilayaperumal Gopinathan,Update spring-xd-extension-reactor dependency
2449,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the job module's batch job's bean id should be ""job"". This also causes the job name to be 'actual-job-name + "".job""' and the batch job controllers require to search for job with suffix "".job"". 

Removing this constraint would help us avoiding these.",XD-1293,Ilayaperumal Gopinathan,"Remove the constraint on job module batch job id to be ""job"""
2450,Eric Bottard,Eric Bottard,"There is no point in providing completion with something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used",XD-1292,Eric Bottard,module delete command should only provide completions with composed modules
2451,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, ModuleDeployer is a disposable bean. When the container context is closed, the ModuleDeployer bean is destroyed along with its associated common context and deployed modules. Issue arises, if the connectionfactory bean associated with the deployed modules' message bus bindings  is destroyed before the ModuleDeployer bean, there is exception stacktrace (at least in case of Redis MessageBus) saying ""Connection closed"". 

Adding SmartLifecycle support to ModuleDeployer will make sure all the beans are destroyed during Lifecycle processor's stop() method before any of the singletonbeans are destroyed.

The stacktrace (when using Redis MessageBus is):

org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Connection closed
at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:45)
at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:35)
at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:158)
at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:237)
at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1449)
at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:154)
at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:50)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:181)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:149)
at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)
at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:151)
at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:92)
at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)
at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)
at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)
at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
at java.lang.Thread.run(Thread.java:722)
Caused by: com.lambdaworks.redis.RedisException: Connection closed
at com.lambdaworks.redis.RedisAsyncConnection.await(RedisAsyncConnection.java:1079)
at com.lambdaworks.redis.RedisConnection.await(RedisConnection.java:820)
at com.lambdaworks.redis.RedisConnection.brpop(RedisConnection.java:101)
at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1447)
... 12 more
13:19:00,897 WARN Thread-5 support.DefaultLifecycleProcessor:257 - Failed to stop bean 'org.springframework.integration.redis.inbound.RedisInboundChannelAdapter#0'
com.lambdaworks.redis.RedisException: Connection is closed
at com.lambdaworks.redis.RedisAsyncConnection.dispatch(RedisAsyncConnection.java:1065)
at com.lambdaworks.redis.pubsub.RedisPubSubConnection.unsubscribe(RedisPubSubConnection.java:82)
at org.springframework.data.redis.connection.lettuce.LettuceSubscription.doUnsubscribe(LettuceSubscription.java:68)
at org.springframework.data.redis.connection.util.AbstractSubscription.unsubscribe(AbstractSubscription.java:186)
at org.springframework.data.redis.connection.util.AbstractSubscription.unsubscribe(AbstractSubscription.java:146)
at org.springframework.data.redis.listener.RedisMessageListenerContainer$SubscriptionTask.cancel(RedisMessageListenerContainer.java:836)
at org.springframework.data.redis.listener.RedisMessageListenerContainer.stop(RedisMessageListenerContainer.java:210)
at org.springframework.integration.redis.inbound.RedisInboundChannelAdapter.doStop(RedisInboundChannelAdapter.java:127)
at org.springframework.integration.endpoint.AbstractEndpoint.stop(AbstractEndpoint.java:100)
at org.springframework.integration.endpoint.AbstractEndpoint.stop(AbstractEndpoint.java:115)
at org.springframework.context.support.DefaultLifecycleProcessor.doStop(DefaultLifecycleProcessor.java:229)
at org.springframework.context.support.DefaultLifecycleProcessor.access$300(DefaultLifecycleProcessor.java:51)
at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.stop(DefaultLifecycleProcessor.java:363)
at org.springframework.context.support.DefaultLifecycleProcessor.stopBeans(DefaultLifecycleProcessor.java:202)
at org.springframework.context.support.DefaultLifecycleProcessor.onClose(DefaultLifecycleProcessor.java:118)
at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:888)
at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.doClose(EmbeddedWebApplicationContext.java:157)
at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:809)",XD-1291,Ilayaperumal Gopinathan,Handle container shutdown gracefully
2452,Eric Bottard,Eric Bottard,"The current configuration prevents modules to have default values that evaluate to null.
The workaround is to either:

- have the module have its own PPC (which allows nulls)
- rid the placeholders with ${foo:}",XD-1290,Eric Bottard,Module context PropertyPlaceholderAutoConfiguration should have allowNulls = true
2453,,Eric Bottard,"Need a way to tell the user that this option will be determined at runtime,late bindings.
In the module info command, references to ${xd.stream.name} could read ""<use stream name>"" for example)",XD-1289,Eric Bottard,Use descriptive texts for some module options defaults
2454,Eric Bottard,Eric Bottard,,XD-1288,Eric Bottard,Remove references to XD-1050 in documentation
2455,Luke Taylor,Mark Pollack,"xd:>stream create --name simple --definition ""http | transform | filter | transform | file""
Created new stream 'simple'
xd:>stream create --name tapSimple --definition ""tap:stream:mystream.transform > file""
Created new stream 'tapSimple'

There isn't a stream named ""mystream""... I don't remember if we want to allow for this (set up taps before there is a stream) or if it should be an error.

Otherwise, works as expected

xd:>stream create --name tapSimple2 --definition ""tap:stream:simple.transform > file""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD144E:(pos 11): Reference to 'transform' is not unique in the target stream 'http | transform | filter | transform | file', please label the relevant module and use the label, or use a suffix index to indicate which occurrence of the module, e.g. 'transform.0'
tap:simple.transform",XD-1287,Mark Pollack,Tap definitions should verify stream name
2456,Eric Bottard,Eric Bottard,see discussion at https://github.com/spring-projects/spring-xd/pull/495#discussion-diff-9291037,XD-1286,Eric Bottard,Use dedicated modules for code completion fingerprinting
2457,Eric Bottard,Eric Bottard,"see CompletionProviderTests#testUnfinishedModuleNameShouldReturnCompletions()

Ideally, would require a change in the parser so that it knows which kind of module was expected when it failed.",XD-1285,Eric Bottard,Support shell completions for module names
2458,,Eric Bottard,"When doing dsl completion in a stream definition and a module option accepts a value that has a closed set of possible values (eg booleans, enums), we can provide completions for those.

",XD-1284,Eric Bottard,Support shell completions for closed set of values in stream definitions
2459,,Eric Bottard,"This is about computing the value to support expressions such as ${xd.stream.name} as a default.

Initial discussion suggested to leverage the work done in XD-1175 by having a custom @LateValue (or @DeployTimeValue, etc) be resolved at deployment time",XD-1283,Eric Bottard,Allow for late-binding of module options defaults
2460,Eric Bottard,Eric Bottard,Will likely involve having the module identity (type+name) be part of the OptionsMetadata identity/cache key,XD-1282,Eric Bottard,Add caching to ModuleOptionsMetadataResolver
2461,Gunnar Hillert,Gunnar Hillert,"Create a better UI instead of Boot's default ""Whitelabel Error Page""",XD-1281,Gunnar Hillert,"Create Better UI instead of Boot's default ""Whitelabel Error Page"""
2462,,Glenn Renfro,I cannot access the JMX/Jolokia endpoints using the Spring Boot RC1 and Snapshot.  Works with XD-M5 and Boot-M7,XD-1280,Glenn Renfro,JMX endpoints not functioning 
2463,,Mark Pollack,,XD-1279,Mark Pollack,The HDFS Sink should roll over based on the number of events.
2464,Thomas Risberg,Mark Pollack,The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.,XD-1278,Mark Pollack,Rename avro sink to hdfs-dataset and add support for parquet format
2465,Eric Bottard,Eric Bottard,"May want to fix ""properly"" when tackling the module options for composed modules, but this is currently broken (and wasn't at some point):

module compose upperHttp --definition ""http | transform --expression=payload.toUpperCase()""
stream create foo --definition ""upperHttp | log""

This will fail saying that ${port} can't be resolved

This will work though:
module compose upperHttp --definition ""http --port=9000 | transform --expression=payload.toUpperCase()""
stream create foo --definition ""upperHttp | log""


Note that 
stream create foo --definition ""upperHttp --port=xxx | log"" should work too wut won't, but that's another bug (will create after this one)",XD-1277,Eric Bottard,Default option values broken for composed modules
2466,Luke Taylor,Mark Pollack,"To show best practice, our batch jobs should include these listeners so that notifications can be sent.  In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move/delete the file",XD-1276,Mark Pollack,Out of the box batch jobs should add xdJobExecutionListener and xdStepExecutionListener
2467,,Mark Pollack,,XD-1275,Mark Pollack,Use Spring Boot to create an uberjar that contributes modules.
2468,Gary Russell,Gary Russell,,XD-1274,Gary Russell,spring-integration-hadoop.xsd (and reactor) Imports the SI 3.0 Instead of SI 4.0 Schema
2469,David Turanski,David Turanski,"https://github.com/spring-projects/spring-xd/wiki/Taps mentions this but the explanation needs more elaboration and example, e.g. 
mystream -> 
""http | flibble: transform --expression=payload.toUpperCase() | file""

""tap:stream:mystream.flibble > transform --expression=payload.replaceAll('A','.') | log"");",XD-1273,David Turanski,The use of labelled modules and taps needs more explanation
2470,Eric Bottard,Eric Bottard,"Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job (and will benefit from code completion soon), so they can be removed from the shell (where they currently allow for a misconfiguration if set at both the job and shell level)",XD-1272,Eric Bottard,Remove job options that are handled at module level from shell
2471,Glenn Renfro,Ilayaperumal Gopinathan,"Currently, few of the boot's actuator endpoints go missing in the EndpointHandler mapping.
They are: BeansEndpoint, dumpEndpoint, traceEndpoint, healthEndpoint, infoEndpoint.

Also, the EndpointHandler mapping doesn't even happen in case of LauncherApplication.
I think this is because the LauncherApplication context starts with port '0' and the TomcatEmbeddedServletContainer sets the local port for it later. With port '0', the Endpointhandler mapping is disabled during the EndpointHandler mapping bean creation.",XD-1271,Ilayaperumal Gopinathan,Investigate missing boot's actuator endpoints in XD
2472,Patrick Peralta,Mark Pollack,"Improve how the state of the stream is managed.

A deploy command moves the stream from the undeployed state to the deploying state. If all modules in the stream are successfully deployed, the stream state is ‘deployed’ If one or more module deployments failed, the stream state is failed.  Any modules that were successfully deployed, are still running.  

Sending an undeploy command will stop all modules of the stream and return the stream to the undeployed state.

For the individual modules that failed, we will be able to find out which ones failed.  Not yet sure if we can try to redeploy just those parts of the stream that failed.

See the [design doc|https://docs.google.com/a/gopivotal.com/document/d/1kWtoH_xEF1wMklzQ8AZaiuhBZWIlpCDi8G9_hAP8Fgc/edit#heading=h.2rk74f16ow4i] for more details.

Story points for this issue are the total of all the story points for the subtasks.",XD-1270,Mark Pollack,Add states to the deployment of stream
2473,,Ilayaperumal Gopinathan,"There are explicit Thread.sleep() calls after deploy() in some of the test methods in 
AbstractSingleNodeStreamDeploymentIntegrationTests.

Also, the test method deployAndUndeploy() doesn't have explicit Thread.sleep() and fails inconsistently with this error:

java.lang.AssertionError: stream test0 not undeployed 
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.waitForUndeploy(AbstractSingleNodeStreamDeploymentIntegrationTests.java:332)
	at org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.deployAndUndeploy(AbstractSingleNodeStreamDeploymentIntegrationTests.java:221)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:103)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)",XD-1269,Ilayaperumal Gopinathan,Investigate and remove explicit thread sleep in AbstractSingleNodeStreamDeploymentIntegrationTests
2474,David Turanski,Mark Pollack,,XD-1268,Mark Pollack,Remove unused code related to 'accepted media type' in MessageBus
2475,Eric Bottard,Mark Pollack,There are inconsistencies in our current approach for handling module options (using property file for default vs. classes has different behavior in terms of over-riding with system properties.  Need to rationalize the behavior.,XD-1267,Mark Pollack,Improve configuration option handling
2476,Luke Taylor,Luke Taylor,,XD-1266,Luke Taylor,Twitterstream is broken
2477,,Eric Bottard,"In trying to upgrade to latest SI, I encountered a failing test because it expects an error message to contain something, but SI changes make it disappear (the problem is an SI exception now has an explicit message and so does not expose its cause message anymore)

This, however is the manifest of a deeper ""problem"". We currently expose the getMessage() of any generic Exception caught, in the VndError REST construct. But this is not enough.

Things that we can consider are:
1) adding the whole stacktrace of the caught exception, as a String. This is not very good at it leaks java specific details
2) unwrap the caught exception to get to the deepest cause. This may not be what we want everytime
3) construct a VndErrors (note the 's') made of each layered exception
4) similar to 1), but not using the stacktrace, only the messages of each cause

etc ",XD-1265,Eric Bottard,Surface better exception information to client
2478,Gary Russell,Eric Bottard,"The Rabbit endpoint suffers from a problem similar to XD-1067.
Seems like spring-[rabbit/amqp] needs to be bumped to 1.3.0.M1 to fix it.
Sadly, we get this error:
noformat
java.lang.NoSuchMethodError: org.springframework.amqp.core.MessageProperties.getContentLength()J
at org.springframework.integration.amqp.support.DefaultAmqpHeaderMapper.extractStandardHeaders(DefaultAmqpHeaderMapper.java:102)
at org.springframework.integration.amqp.support.DefaultAmqpHeaderMapper.extractStandardHeaders(DefaultAmqpHeaderMapper.java:53)
at org.springframework.integration.mapping.AbstractHeaderMapper.toHeaders(AbstractHeaderMapper.java:205)
at org.springframework.integration.mapping.AbstractHeaderMapper.toHeadersFromRequest(AbstractHeaderMapper.java:148)
at org.springframework.integration.amqp.inbound.AmqpInboundChannelAdapter$1.onMessage(AmqpInboundChannelAdapter.java:75)
at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:584)
at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:482)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:69)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:144)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:920)
at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:454)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:728)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:712)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$400(SimpleMessageListenerContainer.java:69)
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:812)
at java.lang.Thread.run(Thread.java:724)
noformat
Updating to latest SI snapshot does not help (as of Jan 23rd)",XD-1264,Eric Bottard,Update SI to latest 4.0 M3 and Spring AMQP to 1.3.0.M2
2479,Glenn Renfro,Glenn Renfro,,XD-1263,Glenn Renfro,Copy latest build to S3 after a XD Build
2480,Ilayaperumal Gopinathan,David Turanski,"Currently the message bus is only obtained via Module.getComponent(MessageBus.class). Stream testing scenarios that depend on sending and receiving payloads via named channels do not require a deployed module instance per se, but any stream flow control uses the MessageBus directly. Getting a deployed module instance in general is expensive, e.g., you have to wait for the module to deploy asynchronously, whereas the MessageBus implementation could be known a priori when the application starts. An improvement would be to ask the container for its MessageBus.",XD-1262,David Turanski,Provide a clean way to get a reference to the MessageBus running in SingleNodeApplication
2481,Eric Bottard,Eric Bottard,The logic can be found in DefaultModuleOptionsMetadataCollector but caused problems in the initial PR. Revisit if needed,XD-1261,Eric Bottard,Support default values for options derived out of ${} placeholders
2482,Gary Russell,Mark Pollack,,XD-1260,Mark Pollack,Batch Job that uses partitioning and can poll FTP directory and transfer to HDFS directly via output streams
2483,,Mark Pollack,,XD-1259,Mark Pollack,Have supported distributions of Hadoop 'always on' in EC2.
2484,,Mark Pollack,,XD-1258,Mark Pollack,Get basic project infrastructure based on new JS stack in place
2485,Glenn Renfro,Mark Pollack,,XD-1257,Mark Pollack,"Deploy XD nightly builds to EC2 and perform basic stream testing across singlenode, and distributed mode 1 server on redis, rabbitmq"
2486,,Enrique Ruiz (DiSiD),"It is useful to configure operating system so that it will start Spring XD automatically on boot.

For example, in Linux it would be great if Spring XD distro contains init.d script to run it as service. A typical init.d script gets executed with arguments such as ""start"", ""stop"", ""restart"", ""pause"", etc. In order for an init.d script to be started or stopped by init during startup and shutdown, the script needs to handle at least ""start"" and ""stop"" arguments.
",XD-1256,Enrique Ruiz (DiSiD),Running XD as service
2487,Glenn Renfro,Mark Pollack,"The modules are exposed via JMX and in turn exposed over http via jolokia.  See https://jira.springsource.org/browse/XD-343.  This issue is to develop a helper method that given a stream id and/or module name, assert that the number of messages processed after sending stimulus messages is as expected. e.g.

int originalCount = getCount(""testStream"", ""file"");

//do stuff that generates 100 messages
assertCount(""testStream"", ""file"", 100, originalCount)

For now we can assume we know the location of where the modules are located by assuming we have only one container deployed.",XD-1255,Mark Pollack,Create assertion to get count of messages processed by a specific module in a stream
2488,David Turanski,David Turanski,"XD singlenode currenly initialized in @Before, should be @BeforeClass. In this case must be re-initialized for each transport, but not for each @Test.",XD-1254,David Turanski,Optimize AbstractSingleNodeStreamDeploymentIntegrationTests
2489,,Ilayaperumal Gopinathan,"I see the topics/exchanges created for Redis/Rabbit message buses have the prefix ""topic.""
Is there any reason why we didn't have the prefix ""queue."" for the name of the queue created in Rabbit message bus in compared with the queue created in Redis message bus which has prefix ""queue.""

",XD-1253,Ilayaperumal Gopinathan,RabbitMessageBus queue name prefix
2490,,David Turanski,"Currently, if we want to bind values to script variables we need to put them in a properties file like so:

xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log

Ideally it should be:

xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --foo=bar --baz=boo | log


",XD-1252,David Turanski,Allow processor script variables to be passed as module parameters
2491,Luke Taylor,Gunnar Hillert,See also XD-451 as reference.,XD-1251,Gunnar Hillert,Access-Control-Allow-Origin header should not be hard-coded
2492,Gary Russell,David Turanski,This test is very slow (2x the Redis version). Lots of stacktraces when running. Could be related. ,XD-1250,David Turanski,Investigate RabbitSingleNodeStreamDeploymentIntegrationTests performance
2493,David Turanski,David Turanski,"e.g., make application static and check for initialization. Need to ensure each test restores the initial state of the server",XD-1249,David Turanski,AbstractShellIntegrationTests should start and stop server once.
2494,David Turanski,David Turanski,We do not need two base classes for this,XD-1248,David Turanski,Merge AbstractStreamDeploymentIntegrationTests and AbstractSingleNodeStreamDeploymentIntegrationTests
2495,David Turanski,David Turanski,These are duplicates of *SingleNodeDeploymentIntegrationTests,XD-1247,David Turanski,Remove RedisStreamDeploymentIntegrationTests and RabbitStreamDeploymentIntegrationTests
2496,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"In line with what we address at https://jira.springsource.org/browse/XD-1223, there are cases where tests fail when there is an existing instance of hsqldb running.

Since hsqldb uses the same port and database, it causes issues.",XD-1246,Ilayaperumal Gopinathan,To be able to run the tests without conflicting with an existing XD admin server/launcher
2497,Glenn Renfro,Glenn Renfro,"Create a first pass at an acceptance test app for a stream definition of http | log.  

This will involve creating two new projects in xd

1. spring-xd-integration-test
2. spring-xd-acceptance-tests

#1 will contain generally useful utility methods for acceptance test, such as sending data over http, obtaining and asserting JMX values of specific modules.
#2 will contain tests that use #1 to test the various out of the box modules provides in XD.",XD-1245,Glenn Renfro,Develop basic acceptance test application to exercise based XD-EC2 deployment from CI
2498,Glenn Renfro,Glenn Renfro,"* Use the cleanup app from XD-1243 to stop previous CI runs of XD on EC2.
* Build XD-EC2 deployer from github.
* Use XD-EC2 Deployer to deploy the CI XD-Instance
* Should produce artifact that contains the URL 
   * admin server of the XD cluster.
   * container servers of the XD cluster",XD-1244,Glenn Renfro,Create CI Plan for XD EC2 deployment
2499,Glenn Renfro,Glenn Renfro,"Application will shutdown all servers with a specific name.  
Application will take a --cluster-name parameter.   
Generate artifact to state success or failure  ",XD-1243,Glenn Renfro,Create App for CI to Shutdown XD EC2 Cluster
2500,Eric Bottard,Mark Pollack,"The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",XD-1242,Mark Pollack,Optimize deployment of xd-admin and multiple nodes in spring-xd-ec2 to occur in parallel.
2501,,Mark Pollack,"See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements

""Stages are comprised of one or more Jobs, which run in parallel""

we would like the tests across the rabbit and redis transport to occur in parallel.",XD-1241,Mark Pollack,Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis
2502,,Mark Pollack,"See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements

""Stages are comprised of one or more Jobs, which run in parallel""

we would like the tests across the rabbit and redis transport to occur in parallel.
",XD-1240,Mark Pollack,Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit
2503,Glenn Renfro,Mark Pollack,"Run test application developed in XD-1245

",XD-1239,Mark Pollack,Add stage to Acceptance Test EC2 build plan that runs a basic acceptance test application against the single-node deployment
2504,Glenn Renfro,Mark Pollack,"Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit.

https://build.springsource.org/browse/XD-ATEC2 was created as an empty shell.

The running of across different transports will be handled in a separate story along with adding a stage to run a 'hello world' acceptance test.

",XD-1238,Mark Pollack,Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments
2505,Glenn Renfro,Mark Pollack,This functionality should be added as a command line option to the main app in the spring-xd-ec2 project,XD-1237,Mark Pollack,Add option to stop all running XD EC2 instances that match a given naming pattern
2506,Thomas Risberg,Mark Pollack,,XD-1236,Mark Pollack,Create EC2 AMI for single-node install of Hortonworks Data Platform 1.3
2507,Thomas Risberg,Mark Pollack,,XD-1235,Mark Pollack,Create EC2 AMI for single-node install of Cloudera CDH 4.5.0
2508,Janne Valkealahti,Mark Pollack,,XD-1234,Mark Pollack,Create EC2 AMI for single-node install of  Pivotal HD 1.1
2509,Janne Valkealahti,Mark Pollack,,XD-1233,Mark Pollack,Create EC2 AMI for single-node install of Apache Hadoop 2.2.0
2510,Janne Valkealahti,Mark Pollack,,XD-1232,Mark Pollack,Create EC2 AMI for single-node install of Apache Hadoop 1.2.1
2511,Ilayaperumal Gopinathan,Mark Pollack,,XD-1231,Mark Pollack,Investigate if we should use RequreJS with Angular
2512,Gunnar Hillert,Mark Pollack,Blog post http://naleid.com/blog/2013/01/24/calling-gruntjs-tasks-from-gradle/  seems to be the definitive reference....,XD-1230,Mark Pollack,Integrate grunt based UI build into the XD's gradle build
2513,Gunnar Hillert,Mark Pollack,"Create a project that includes build and test automation for a new Angular based UI.  This work is independent of calling the UI build step from gradle.  A super minimal UI, just to have some basic code, is all that is required. 

This should use 

Grunt
Jasmine
Karma
Bower
YUIdoc (separate story?)

UI Components from backbone should be available in the base project.

",XD-1229,Mark Pollack,Create build infrastructure for Angular based UI
2514,David Turanski,Mark Pollack,"AbstractSingleNodeStreamDeploymentIntegrationTests is the basis of 'state of the art' testing for a stream that allows you to get a reference to the input and output channel of the stream

http | filter | transform | file.

One can send messages to the channel after the http module, but before filter and one can retrieve the messages that were sent to the channel after the transform module but before file.

The current implementation inside AbstractSingleNodeStreamDeploymentIntegrationTests can be improved in terms of ease of use for end-users.  

The issue is to create as simple a way as possible for a user to test their processing modules/stream definitions without having to actually do a real integration test by sending data to the input module.

Either as a separate issue or as part of this one, the documentation 

https://github.com/spring-projects/spring-xd/wiki/Creating-a-Processor-Module

should be updated to explicitly show how to use this issue's test functionality.
",XD-1228,Mark Pollack,"Provide a easy, prescriptive means to perform unit and basic stream integration tests."
2515,David Turanski,Mark Pollack,"https://sonar.springsource.org/dashboard/index/7173?did=3

Shows which of our current tests take the most time to execute.

xd.dirt.stream and xd.shell.command are where the most time is spent.

In xd.dirt.stream it seems likely that time can be reduced by not restarting a new single node server per test, but sharing it across tests, e.g.

 RabbitSingleNodeStreamDeploymentIntegrationTests 	
 LocalSingleNodeStreamDeploymentIntegrationTests
 RedisSingleNodeStreamDeploymentIntegrationTests 	

As a first pass, the test that take longer than 15 seconds in that report should be investigated.
",XD-1227,Mark Pollack,Investigate long running tests and create refactoring issues
2516,,Mark Pollack,,XD-1226,Mark Pollack,Review abstract base classes used in test cases to ensure proper resource cleanup.
2517,Luke Taylor,Mark Pollack,"Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master...

Open question is if we want to fail a build do to code coverage levels.",XD-1225,Mark Pollack,Integrate code coverage reports into the CI process
2518,Luke Taylor,Mark Pollack,"Build should be able to generate code coverage reports.

After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle.

http://www.gradle.org/docs/current/userguide/jacoco_plugin.html
",XD-1224,Mark Pollack,Add code coverage to gradle build
2519,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, there are test data(e.g: stream name) not being cleaned up during teardown especially when there is a test case failure. This breaks the test suite when the same test data is used by other tests.

We need to move the cleanup logic at an appropriate level so that the test data is always cleaned up irrespective of the test result.",XD-1223,Ilayaperumal Gopinathan,Unit/Integration tests need appropriate cleanup of test data during teardown
2520,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The MBeanServer is referred by XD admin/launcher when JMX is enabled (by setting --jmxEnabled option) and this is defined in xd-global-beans.xml.

The MBeans that are exposed by the modules also use the same MBeanServer define above and there is a duplicate MBeanServer definition (from jmx/common.xml) which the MBeanExportingPlugin adds as a component to the module which doesn't seem to be needed.

Also, currently the flag ""jmxEnabled"" is generic and used by adminserver/launcher as well as the module MBeanExportingPlugin. If we have a separate flag to enable the JMX *only* for modules then, a separate definition of MBeanServer could be necessary.
",XD-1222,Ilayaperumal Gopinathan,Duplicate MBean server definition by MBeanExportingPlugin
2521,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the 'modules' project is marked as java project to enable eclipse/idea metadata files generation. But it generates a 'build' directory with a jar that has empty MANIFEST file.

This build directory also gets copied into the bundle after 'dist'.",XD-1221,Ilayaperumal Gopinathan,XD modules should not have 'build' directory upon running gradle build
2522,Thomas Risberg,Thomas Risberg,Batch jobs should use application.yml provided connection as default. They now have their own configuration in batch-jdbc.properties. This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.,XD-1220,Thomas Risberg,Batch jobs should use application.yml provided connection as default
2523,Mark Pollack,Mark Pollack,,XD-1219,Mark Pollack,Release 1.0.0.M5
2524,Dave Syer,Mark Pollack,Server startup is done using Spring  Boot as well as starting a module application context at runtime.,XD-1218,Mark Pollack,Base server implementation on Spring Boot
2525,David Turanski,David Turanski,"Currently twitterstream emits native twitter json whereas twittersearch uses SI/Spring Social and emits spring social Tweet types. This makes it difficult to replace twitter sources and reuse XD stream definitions.  This requires coordination with SS 1.1.0 and SI 4.0 GA releases. NOTE: I think it's a good idea to continue to support native twitter JSON, keep as an option for twitterstream, but the default should be Tweet types.",XD-1217,David Turanski,twittersearch and twitterstream should support compatible formats
2526,Gunnar Hillert,Gunnar Hillert,,XD-1216,Gunnar Hillert,Serialization of ChunkContext fails using Kryo
2527,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"In distributed batch processing in XD, the JobLocator implementation for getJob(String jobName) should return a valid Job (FlowJob/SimpleJob).

Since we won't we relying on the MapJobRegistry's joblocator implementation which doesn't work in distributed use case, we need to have an appropriate way to return FlowJob/SimpleJob using XD's BatchJobLocator.",XD-1215,Ilayaperumal Gopinathan,Distributed JobLocator should return a valid job
2528,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The job names used by the tests should be unique across the tests when use the same JobRepository.

",XD-1214,Ilayaperumal Gopinathan,Make job names unique across tests that use the same JobRepository
2529,Eric Bottard,Eric Bottard,"Using JSR303 groups, which should be derived from injected values",XD-1213,Eric Bottard,Allow conditional validation for module options
2530,Luke Taylor,Luke Taylor,Some boot classes we compile against have changed or been replaced.,XD-1212,Luke Taylor,Boot updates post 0.5 M7
2531,Glenn Renfro,Glenn Renfro,"batchHashtagCount and batchWordCount  projects need ""hadoop fs ls"" instructions need to be updated.  ",XD-1211,Glenn Renfro,Update hadoop instructions in the xd-samples
2532,Gunnar Hillert,Gunnar Hillert,Currently the shell assumes that the 'makeUnique'job parameter is by default *false*. That is not true. As a consequence the parameter has currently no impact/does not work.,XD-1210,Gunnar Hillert,Shell - 'makeUnique' Job Parameter is true by default 
2533,Ilayaperumal Gopinathan,Mark Pollack,This was added in bash scripts as part of XD-1186.,XD-1209,Mark Pollack,Add support for XD_CONFIG environment variable in windows shell scripts
2534,Ilayaperumal Gopinathan,Eric Bottard,,XD-1208,Luke Taylor,Create Module options metadata for OOTB jobs
2535,Gunnar Hillert,Gunnar Hillert,,XD-1207,Gunnar Hillert,Job Plugin - Notification Channel not correctly bound to MessageBus
2536,Gunnar Hillert,Gary Russell,"For some reason, the partitioned batch jobs are storing  {{StepExecutions}}s in the DB with a null ID.

This causes {{JobCommandTests.testListStepExecutionsForSpecificJobExecution()}} to fail because the HATEOS code asserts not null...

{code}
18:25:26,185 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:186 - Caught exception while handling a request
java.lang.IllegalArgumentException: [Assertion failed] - this argument is required; it must not be null
	at org.springframework.util.Assert.notNull(Assert.java:112)
	at org.springframework.util.Assert.notNull(Assert.java:123)
	at org.springframework.hateoas.mvc.ResourceAssemblerSupport.createResourceWithId(ResourceAssemblerSupport.java:87)
	at org.springframework.xd.dirt.rest.StepExecutionInfoResourceAssembler.toResource(StepExecutionInfoResourceAssembler.java:39)
	at org.springframework.xd.dirt.rest.BatchStepExecutionsController.list(BatchStepExecutionsController.java:107)
{code}

For some reason, the query for objects with the {{jobExecutionId}} also returned these two objects with null keys.

Blowing away my data directory fixes the problem (until I run another partitioned batch job).

I need to figure out why spring batch is creating these bad records, but we should probably add some defensive code to protect against null IDs.

You can reproduce by building against my XD-1146 branch.
",XD-1206,Gary Russell,Garbage in Job Repo Causes List Failure
2537,Thomas Risberg,Thomas Risberg,The filejdbc jobs isn't included in the test scripts,XD-1205,Thomas Risberg,Add test for filejdbc to test scripts
2538,Thomas Risberg,Thomas Risberg,"We should use fileName, fileExtension properties and default to /xd/jobname as directory",XD-1204,Thomas Risberg,Update jdbchdfs properties and defaults to better match hdfs sink  
2539,Gunnar Hillert,Gunnar Hillert,"Use containsKey when checking for Parameters
Add tests",XD-1203,Gunnar Hillert,JobPlugin - Use containsKey when checking for Parameters
2540,Thomas Risberg,Thomas Risberg,,XD-1202,Thomas Risberg,Update build script to use correct version of spring-data-hadoop based on distro
2541,Eric Bottard,Mark Pollack,"xd-shell is using the default spring-shell help command.  Need to create a help command specific to XD so that it can list the --hadoopDistro command line option.  Note, the hadoopDistro command line option is actually processed by the xd-shell bash script",XD-1201,Mark Pollack,Create custom help command for xd-shell so that hadoopDistro option is listed
2542,Thomas Risberg,Thomas Risberg,"hdfsjdbc throws an exception:
{code}
org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'itemReader' defined in URL [file:/Users/trisberg/Projects/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Could not resolve placeholder 'columns' in string value ""${columns}""
{code}

The hdfsjdbc job uses 'columns' instead of 'names' as the parameter for the column-names. Should we make this usage consistent between jobs?

There is a comment in the docs - ""there is also a limitation in that the database table must be created manually. This is due to a bug in Spring Hadoop and will be fixed in the future."" Think this is this solved in Spring Hadoop now?

initializeDatabase should default to false now to be consistent with jdbc sink

Rename batch-jdbc/mongo-import.properties to batch-jdbc/mongo.properties since these aren't just for import",XD-1200,Thomas Risberg,Fix hdfsjdbc batch job
2543,Thomas Risberg,Thomas Risberg,"filejdbc throws an exception: 
{code}
java.lang.IllegalArgumentException: Could not resolve resource location pattern [/mycsvdir/*.csv]: class path resource [mycsvdir/] cannot be resolved to URL because it does not exist
{code}

This can be solved by using a file:// prefix

Maybe just update the docs?
",XD-1199,Thomas Risberg,Fix filejdbc batch job
2544,Glenn Renfro,Gunnar Hillert,"This works:

{code}
job launch helloSpringXD --params ""{""myStringParameter"":""foobar"",""secondParam"":""hello""}""
{code}

This fails:

{code}
job launch helloSpringXD --params ""{""myStringParameter"":""foobar"", ""secondParam"":""hello""}""
{code}

Notice the space between the parameters. This fails with:

{code}
spring> job launch helloSpringXD --params ""{""myStringParameter"":""foobar"", ""secondParam"":""hello""}""
14/01/06 12:00:07 WARN client.RestTemplate: PUT request for ""http://localhost:9393/jobs/helloSpringXD/launch"" resulted in 500 (Internal Server Error); invoking error handler

Command failed org.springframework.xd.rest.client.impl.SpringXDException: org.springframework.integration.MessageHandlingException: java.lang.IllegalArgumentException: Unable to convert provided JSON to Map<String, Object>

{code}

Internally the parameters are parsed to:

{code}
{""myStringParameter"":""foobar"",secondParam"":""hello""}
{code}

The curly brace is missing.

",XD-1198,Gunnar Hillert,Shell: Job Parameters are whitespace sensitive
2545,,Thomas Risberg,"In the shell:

job launch doesn't do completion of --name, this is different behavior compared to job destroy

typing 'job destroy' and hitting tab completes with '--name'

typing 'job launch' and hitting tab does nothing",XD-1197,Thomas Risberg,job launch doesn't do tab completion of --name
2546,Thomas Risberg,Thomas Risberg,"The batch jobs use different defaults compared to some of the sink/source modules.

filehdfs puts data in a /data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an /xd/<streamname> directory using .txt as the default file extension.

filehdfs needs a more descriptive naming",XD-1196,Thomas Risberg,Align filehdfs batch job defaults with those of corresponding hdfs sink
2547,,Eric Bottard,see discussion at https://github.com/spring-projects/spring-xd/commit/2f0e80b5e337b71c9c70de510a44d2f050d10fa7,XD-1195,Eric Bottard,Add paging and sorting to Field Value Counter API
2548,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"If we have default values from Container/Admin options, then they can not be overridden by the system properties or system environment. 

Currently, the only default we have for the Container/Admin options is for ""jmxEnabled"" option and since it is a boolean it can never be overridden by sys/env property XD_JMX_ENABLED.

I think we need to make sure there are no default values assigned for the non-boolean Container/Admin options and handle the boolean type option separately.",XD-1194,Ilayaperumal Gopinathan,CommandLine default values from container & admin options can not be overridden
2549,Mark Pollack,Mark Pollack,,XD-1193,Mark Pollack,Update to Spring Batch 2.2.4
2550,Luke Taylor,Mark Pollack,"Add docs to section 

https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#pre-packaged-batch-jobs",XD-1192,Mark Pollack,Add documentation for JDBC to HDFS batch job
2551,Thomas Risberg,Thomas Risberg,The jdbc sink deletes existing table and creates a single column payload one even if properties file has 'initializeDatabase=false',XD-1191,Thomas Risberg,JDBC sink destroys existing table
2552,Eric Bottard,Ilayaperumal Gopinathan,"The PropertyResolver needs to follow the below precedence order on PropertySources when resolving the module properties:

From lowest to the highest order,

0 application.yml
1 applicaiton.yml fragment
2 property placeholders
2a  property placeholder under 'shared' config directory 
2b property placeholder under module/(source/sink/processor)/config directory
3. environment variables
4. system properties
5. command line


",XD-1190,Ilayaperumal Gopinathan,Setup precedence order for module properties' property resolver
2553,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently RabbitMQ sink module's connection properties could not be overridden by ""${xd.config.home}/${configProperties:rabbit}.properties"" even if ""local-override"" is set to true.

It looks like the AmqpTemplate used by the AMQP outbound channel adapter doesn't use the connection factory defined in the sink module.",XD-1189,Ilayaperumal Gopinathan,Could not override rabbit sink module's rabbit connection factory properties
2554,Eric Bottard,Ilayaperumal Gopinathan,We need to add ModuleOptions support for Rabbit sink.,XD-1188,Ilayaperumal Gopinathan,Add ModuleOptions support for Rabbit sink
2555,Glenn Renfro,Glenn Renfro,--transport as an alias for --controlTransport,XD-1187,Glenn Renfro,xd-admin server to --transport as an option.
2556,Luke Taylor,Ilayaperumal Gopinathan,"Since spring boot (by default) looks for property sources from file:./config/application.yml and file:./application.yml

In XD bundles, the CLASSPATH of our XD startup scripts'(admin, container, singlenode startup scripts) set to use APP_HOME and APP_HOME/config.

But, if we have an application.yml fragment on $APP_HOME/config, then it is considered as classpath resource and the actual ""application.yml"" (from dirt lib/ classpath) is not loaded. 

Also, we need to separate out the properties files we have inside $APP_HOME/config as by default, boot uses ""config"" directory as well.",XD-1186,Ilayaperumal Gopinathan,Support use of application.yml fragments
2557,Ilayaperumal Gopinathan,Thomas Risberg,"We need to add a connection pool to the Redis connection factory used for the transport, otherwise we'll see exceptions like these:

12:57:54,842 ERROR inbound.tictoc.0-redis:queue-inbound-channel-adapter1 inbound.RedisQueueMessageDrivenEndpoint:183 - Failed to execute listening task. Will attempt to resubmit in 5000 milliseconds.
org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Unable to connect
  at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:46)
  at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:36)
  at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:159)
  at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:253)
  at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1508)
  at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:163)
  at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:51)
  at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)
  at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)
  at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)
  at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:160)
  at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:105)
  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)
  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)
  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)
  at java.lang.Thread.run(Thread.java:724)
Caused by: com.lambdaworks.redis.RedisException: Unable to connect
  at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
  at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
  at org.springframework.data.redis.connection.lettuce.LettuceConnection.getAsyncDedicatedConnection(LettuceConnection.java:2924)
  at org.springframework.data.redis.connection.lettuce.LettuceConnection.getDedicatedConnection(LettuceConnection.java:2932)
  at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1506)
  ... 11 more
Caused by: java.net.BindException: Cannot assign requested address
  at sun.nio.ch.Net.connect0(Native Method)
  at sun.nio.ch.Net.connect(Net.java:465)
  at sun.nio.ch.Net.connect(Net.java:457)
  at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
  at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)
  at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)
  at org.jboss.netty.channel.Channels.connect(Channels.java:634)
  at org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:207)
  at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:165)
  ... 15 more
",XD-1185,Thomas Risberg,Add redisConnectionFactory with connection pool
2558,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When exporting of MBeans are enabled via XD_JMX_ENABLED (also, jmxEnabled as in application.yml), the Admin and Lancher server application fail to start.

Since the admin applications has the same 'integrationMbeanExporter' bean name for IntegrationMBeanExporter as that its ParentConfiguration, there is a naming conflicts and the exception thrown as:

(Same is the case for launcher and its parent configuration)

Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mbeanExporter' defined in class org.springframework.context.annotation.MBeanExportConfiguration: Invocation of init method failed; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter'; nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExporter,type=IntegrationMBeanExporter
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1553)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:124)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:609)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:60)
	at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:42)
Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter'; nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExporter,type=IntegrationMBeanExporter
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)
	at org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:535)
	at org.springframework.jmx.export.MBeanExporter.afterPropertiesSet(MBeanExporter.java:417)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549)
	... 15 more
Caused by: javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExporter,type=IntegrationMBeanExporter
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:513)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:600)
	... 19 more
",XD-1184,Ilayaperumal Gopinathan,Admin & Launcher startup fails when XD_JMX_ENABLED is set to true
2559,Glenn Renfro,Glenn Renfro,Changed field back to topic,XD-1183,Glenn Renfro,topic in mqtt source was marked as topics
2560,Thomas Risberg,Thomas Risberg,"Update to spring-data-hadoop 2.0.0.M5 when it is released and remove the temporary DatasetTemplateAllowingNulls in spring-xd-hadoop

We should also review the supported hadoop distros - think we should support anything that is current/stable:
- hadoop12
- hadoop22
- phd1 (PHD 1.1)
- hdp13
- hdp20
- cdh4
",XD-1182,Thomas Risberg,Update to spring-data-hadoop 2.0.0.M5
2561,Eric Bottard,Eric Bottard,"When using @Value for providing a default value in a module options POJO, make it so that the REST API (and hence the module info command) advertises that 

1) the expression was ${foo.something}
2) to the best extent possible (value may come from another property source), tell which config file it came from (introspecting the @PropertySource annotation)",XD-1181,Eric Bottard,Surface the provenance of a default to the user
2562,Ilayaperumal Gopinathan,Eric Bottard,"However this is triggered (depending on whether https://github.com/spring-projects/spring-xd/pull/477/files is merged yet or not), jmx seems to be broken because of duplicate beans / mbeans names",XD-1180,Eric Bottard,Enabling of JMX support is broken
2563,Glenn Renfro,Glenn Renfro,"This has happened more than once, where a node fails for whatever reason, and when it is restarted, it does not receive requests from the admin server.

This could be file handle count based.  Since this is not Rabbit as a transport I'm not chasing this down yet.  But felt it needed to be recorded.",XD-1179,Glenn Renfro,Nodes can not connect with Admin using Redis as transport
2564,Thomas Risberg,Thomas Risberg,,XD-1178,Thomas Risberg,Make avro sink options consistent with hdfs and add docs
2565,Andy Clement,Mark Pollack,"Labels should only be used help uniquely identify a module in a stream.

The stream definition a | x: b | x: c | d should throw an error since the label x is applied to two modules.

Also ambiguity exists with a stream definition such as 

http | transform | transform | filter | hdfs

since a module with the name 'transform' will exist twice, meaning a tap on transform will result in message from both transform modules.

To make the naming unique and the usage with taps, the following naming strategy is proposed demonstrated by example.

http | transform | transform | filter | hdfs
http, transform.0, transform.1, filter, hdfs

If a use tries to tap on transform, an error would be shown saying that  you could try to tap on transform.0 or transform.1 or alternatively use labels.

http | transform | filter | transform | hdfs
http, transform.0, filter, transform.1, hdfs

http | x: transform | filter | transform | hdfs
http, x, filter, transform, hdfs

",XD-1177,Mark Pollack,Change module naming strategy in parser taking into account no duplicate labels and repeated modules
2566,Thomas Risberg,Thomas Risberg,Update dependencies to spring-data-hadoop 2.0.0.M4,XD-1176,Thomas Risberg,Update to spring-data-hadoop 2.0.0.M4
2567,Eric Bottard,Eric Bottard,"The current behavior when there are ""global"" external defaults to module options is to set them in the placeholder construct: ${foo:${the_default}} where ${the_default} is sourced from some properties file.

The downside is that the module options infrastructure is unaware of them.

Provide support for such defaults (at least when using PojoModuleOptions) in the form of

* Annotate a field (or the setter?) with @Value(""${the_default}"")
* (maybe) Annotate the pojo with @PropertySource to indicate the location of the properties file
* (maybe) come up with a general naming scheme for the properties file",XD-1175,Eric Bottard,Support external defaults for PojoModuleOptions
2568,Janne Valkealahti,Mark Pollack,,XD-1174,Mark Pollack,Update HDFS sink documentation to reflect new functionality introduced in XD-990 and XD-991
2569,David Turanski,Mark Pollack,"If I fiddle with the testTappingWithLabels method I can reproduce the same issue:

HttpSource source = newHttpSource();

FileSink sink = newFileSink().binary(true); FileSink tapsink1 = newFileSink().binary(true); stream().create(""myhttp"", ""%s | flibble: transform
--expression=payload.toUpperCase() | flibble2: transform
--expression=payload.toUpperCase() | %s"", source, sink); stream().create(""mytap4"", ""tap:stream:myhttp.flibble > transform
--expression=payload.replaceAll('A','.') | %s"", tapsink1); source.ensureReady().postData(""Dracarys!"");

assertThat(sink, eventually(hasContentsThat(equalTo(""DRACARYS!""))));

assertThat(tapsink1, eventually(hasContentsThat(equalTo(""DR.C.RYS!""))));


java.lang.AssertionError:
Expected: ""DR.C.RYS!"", trying at most 10 times
      but: failed after 10*100=1000ms:
""DR.C.RYS!DR.C.RYS!"",
",XD-1173,Mark Pollack,Duplicate messages on tap
2570,Eric Bottard,Eric Bottard,"Expected benefits are
--key<space>value as well as --key=value on the command line (eg XD-1108)

nice usage screen 
",XD-1172,Eric Bottard,Restore previous CmdLine library to populate options
2571,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"XD container's id is set to use its application context id which is derived from:

${vcap.application.name:${spring.application.name:${spring.config.name:application}}}:${vcap.application.instance_index:${spring.application.index:${server.port:${PORT:null}}}}

With the *default* values[the PORT is not set and embedded tomcat uses local port], the launcher id is set to ""application:0""

When I have multiple launchers then all the launchers have the same id as ""application:0"" which doesn't seem correct.

Do we need to use the Id that is generated at the XDContainer's constructor here?

public XDContainer() {
		this.id = UUID.randomUUID().toString();
	}

",XD-1171,Ilayaperumal Gopinathan,Container (Launcher) id is not unique
2572,Glenn Renfro,Daigo Kobayashi,"Splunk sink module doesn't work at all. It throws java.lang.VerifyError exception like following.

nested exception is java.lang.VerifyError: class org.springframework.integration.splunk.outbound.SplunkOutboundChannelAdapter overrides final method onInit.()V

This is because SplunkOutputChannelAdapter refers old spring integration jar, but recent AbstractReplyProducingMessageHandler (which SplunkOutputChannelAdapter extends) set final to onInit method. Hence it doesn't work.

SplunkOutboundChannelAdapter should be fixed to not override onInit method and replace the jar file spring-integration-splunk-1.0.0.M1.jar.",XD-1170,Daigo Kobayashi,Splunk module is broken
2573,Thomas Risberg,Daigo Kobayashi,"Current implementation of JDBC sink module insert data into ""payload"" column. But I can't just change the default column ""payload"" to something else using --columns option. Because JdbcMessagePayloadTransformer compare the columnName to ""payload"" and it hard coded.


",XD-1169,Daigo Kobayashi,"Column name of JDBC sink module should not hard code to ""payload""."
2574,,Luke Taylor,"Test case is here:

https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/basic_stream_tests#L49

We would expect one message in the counter, but get 3.",XD-1168,Luke Taylor,Tapping a stream with multiple labelled filters causes duplicate messages
2575,,Eric Bottard,,XD-1167,Eric Bottard,Mail Source ModuleOptions (+ profiles)
2576,David Turanski,David Turanski,,XD-1166,David Turanski,Create Gemfire Integration Test Scripts
2577,David Turanski,David Turanski,"The Gemfire CQ source needs some enhancements:

* enable locator configuration
* consider decoupling from JSON. Currently designed to work with gemfire-json-server to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance(s) stored in the cache.  ",XD-1165,David Turanski,Enhancements to Gemfire CQ Source
2578,Gary Russell,Mark Pollack,,XD-1164,Mark Pollack,Update Spring Integration version to 4.0.M2
2579,Gary Russell,Mark Pollack,,XD-1163,Mark Pollack,Update Spring Framework dependency to 4.0 GA
2580,Thomas Risberg,Daigo Kobayashi,"Current implementation of column option of JDBC sink convert underscore to java property name. If database column contains underscore, there is no way to store data.

So JdbcMessagePayloadTransformer should not use JdbcUtils.convertUnderscoreNameToPropertyName even if column contains ""_"".",XD-1162,Daigo Kobayashi,Column option of JDBC sink should not convert underscore to property name.
2581,Thomas Risberg,Thomas Risberg,Need to check for existing files with the same file counter,XD-1161,Thomas Risberg,Re-deployment of hdfs sink reuses filename of first deployment
2582,,Thomas Risberg,"We should standardize on the options between modules:

idleTimeout - timeout
rolloverSize - rollover

Also, need to standardize on unit used for timeout - should this be s or ms?
",XD-1160,Thomas Risberg,Standardize naming and unit for options across modules
2583,Eric Bottard,David Geary,"This should be quite straightforward, since the Spring Data Mongo jars are already included. We have this working by just adding the attached sink context file and the spring-integration-mongodb jar.

(This works for JSON string streams, but a mongo converter probably needs added to support Tuple conversion)
",XD-1159,David Geary,Add a MongoDB Sink
2584,Mark Pollack,Glenn Renfro,Create a script to sanity check JMS and MQTT,XD-1158,Glenn Renfro,Create integration test script for JMS & MQTT
2585,David Turanski,David Turanski,,XD-1157,David Turanski,Update docs for gemfire sink to include locator configuration
2586,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code (like it doesn't do anything with preProcessSharedContext()) in there. ",XD-1156,Ilayaperumal Gopinathan,Refactor/Simplify JobPlugin
2587,Thomas Risberg,Thomas Risberg,"This causes issues depending on which version of the core/common jar gets loaded first - like:

xd:>hadoop fs ls
-ls: Fatal internal error
java.lang.UnsupportedOperationException: Not implemented by the DistributedFileSystem FileSystem implementation
  at org.apache.hadoop.fs.FileSystem.getScheme(FileSystem.java:213)
  at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:2401)
  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2411)
  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2428)
  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:88)
  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2467)
  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2449)
  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:367)
  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:166)
  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:351)
  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:287)
  at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:325)
  at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224)
  at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207)
  at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)
  at org.apache.hadoop.fs.shell.Command.run(Command.java:154)
  at org.apache.hadoop.fs.FsShell.run(FsShell.java:255)
  at org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412)
  at org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407)
  at org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:606)
  at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:191)
  at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)
  at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48)
  at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)
  at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:483)
  at org.springframework.shell.core.JLineShell.run(JLineShell.java:157)
  at java.lang.Thread.run(Thread.java:724)
",XD-1155,Thomas Risberg,The lib directory for hadoop12 contains mix of hadoop versions
2588,Ilayaperumal Gopinathan,Eric Bottard,"Trigger has been changed to be one single modules, taking params (as opposed to 3 before)

Update doc at https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs

Also, arguably, the module could be advertised as a source itself (it is only mentioned in the context of batch)",XD-1154,Eric Bottard,Update doc about trigger changes
2589,Gary Russell,Gary Russell,Support all available options,XD-1153,Gary Russell,Fix Tail Source to Use Native Adapter by Default
2590,,Ilayaperumal Gopinathan,"Instead of using jobExecutionId and stepExecutionId as two separate options for the ""job execution step progress"" command, we can have a single option with id mentioned as (jobExecutionId:stepExecutionId)",XD-1152,Ilayaperumal Gopinathan,Step execution progress Shell command to use coherent Id (jobExecutionId:stepExecutionId)
2591,Eric Bottard,Eric Bottard,,XD-1151,Eric Bottard,Apply Composite GoF pattern to ModuleDefinition
2592,Glenn Renfro,David Turanski,,XD-1150,David Turanski,Update docs for separate control and data transport
2593,Gary Russell,Derek Marley,"As a system administrator I need to connect to SonicMQ as jms provider

When setting up the correct spring xml file and added the correct jar files to the lib directory I received the following exception---  

Question: is there a spot I should be defining the conversion strategy?

{code}
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::             (v0.5.0.M6)

15:04:36,092 ERROR http-bio-9393-exec-1 rest.RestControllerAdvice:157 - Caught exception while handling a request
org.springframework.integration.MessageHandlingException: error occurred in message handler [moduleDeployer]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)
	at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:94)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:42)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:86)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:228)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:212)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:171)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:149)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)
	at org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:137)
	at org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:157)
	at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:242)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:748)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:947)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:878)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:946)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:848)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:822)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionFactory' defined in file [/Users/dmarley/sandbox/spring-xd/build/dist/spring-xd/xd/modules/source/jms/config/../../../common/jms-sonic-infrastructure-context.xml]: Initialization of bean failed; nested exception is org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy found
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:547)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:300)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:296)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:660)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:552)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:293)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.SimpleModule.initialize(SimpleModule.java:135)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:239)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:229)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:214)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploymentRequest(ModuleDeployer.java:196)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:137)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	... 63 more
Caused by: org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy found
	at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:474)
	at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:505)
	at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:499)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1497)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1192)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	... 81 more
Caused by: java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy found
	at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:267)
	at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:459)
	... 87 more

{code}",XD-1149,Derek Marley,source jms --- connect to another jms provider
2594,David Turanski,David Turanski,"Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. ,--transport=local should fail. ",XD-1148,David Turanski,Allow local data transport option for the container
2595,,David Turanski,"Need to clarify if this means alternate transports within a stream, e.g 

source |[rabbit] | processor |[redis]| sink 

or specifying that a stream use an alternate transport to the one configured for the container.  ",XD-1147,David Turanski,Allow alternate transports to be used within a stream
2596,Gary Russell,Gary Russell,,XD-1146,Gary Russell,"With Partitioned Jobs, Wire Partitioner and StepExecutionHandlers with the MessageBus"
2597,,Eric Bottard,"The TriggerSourceOptionsMetadata class should be able to use an actual Date object, thanks to Spring binding conversion.

BUT, the ${date} construct will receive a toString version of it. Make sure this works properly",XD-1145,Eric Bottard,Add --date option to the trigger module
2598,Mark Pollack,Mark Pollack,"The initial parsing of a stream/job definitions into a list of ModuleDeploymentRequests needs to be transformed into a Physical Deployment Model that takes into account 

1) module co-location
2) partitioning
3) number of instances
4) node assignment

an potentially other data related to the runtime properties of a module (e.g. concurrency settings) 

The an external DeploymentManifest will be used to capture this information.

A deployment of a stream or job will then need to optionally provide a reference to deployment manifest.",XD-1144,Mark Pollack,Spike for transformation of the parsed stream/job definition to a Physical Deployment Model taking into account a Deployment Manifest
2599,Mark Pollack,Mark Pollack,"Base matching algorithm on the model used in http://research.cs.wisc.edu/htcondor/ 

Jobs/Stream - specify their requirements and preferences
Nodes - specify their requirements and preferences

e.g.  

A job/stream module ""requires"" a linux x85-64 platform and ""prefers"" the machine with the most free memory

A node ""requires"" that only only can run jobs when there is 25% or more free memory and it ""prefers"" to run stream modules over job modules.

The requirements and preferences are represented as SpEL expressions in a ""Advertisement"" data structure.  There is a 'require' expression and a 'preference' expression. 

Matching occurs between Node Ads and Job/Stream Ads so that the requirements of both Ads evaluate to true and the matching nodes are ranked according to the preference expression.

The Job/Streams Ads can make use of well defined attributes about the nodes, such as it's memory/cpu usage.",XD-1143,Mark Pollack,Spike for matching algorithm for stream/job deployments and nodes
2600,Mark Fisher,Mark Pollack,"Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them.  The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group.

The project https://github.com/spring-projects/spring-data-grid is the start of this model.",XD-1142,Mark Pollack,Spike to model the cluster nodes.
2601,Mark Fisher,Mark Pollack,,XD-1141,Mark Pollack,"Models the cluster, matches processors/jobs to nodes, and transforms stream defitions to a physical model"
2602,Gary Russell,Gary Russell,,XD-1140,Gary Russell,Add (S)FTP Gateway and Batch Partitioner to List/Process Remote Files
2603,Gary Russell,Gary Russell,,XD-1139,Gary Russell,Add TaskLet to Stream from (S)FTP to HDFS
2604,,Gunnar Hillert,"For several Batch Job related JSON endpoints, we serialize too much information.",XD-1138,Gunnar Hillert,Review and Optimize the Serialized JSON Nodes for Batch Objects
2605,Eric Bottard,Eric Bottard,"When a ModuleOption is backed by an enum, change the (currently String) type representation to be the possible values

ie java.lang.String -> String
but
traffic.Light -> Red | Green | Orange",XD-1137,Eric Bottard,Have the REST info about a module advertise enum properties
2606,Thomas Risberg,Thomas Risberg,,XD-1136,Thomas Risberg,Failure in writing to HDFS when undeploying and redeploying a stream with numbers in directory and/or file name
2607,David Turanski,David Turanski,This causes intermittent test failures when testing streams with other transports since ModuleDeployer receives duplicate requests from multiple threads. Fix is to check for local transport before invoking setUpControlChannels(),XD-1135,David Turanski,Local control channels enabled in SingleNodeApplication when alternate transport is selected.
2608,Glenn Renfro,Glenn Renfro,"* need to add a -Dxd.home=$XD_HOME to the start scripts else all files will write to the /logs directory.
* Need to update .bat files to use % for env variables instead of $.
* Need to rename logger.config to logging.config so that boot will pick up the log config files.
* Admin needs to use xd-admin-logger configs instead of xd-container-logger
* Renamed logging file for singlenode from admin.log to singlenode.log",XD-1134,Glenn Renfro,Logging is not producing a log file
2609,Luke Taylor,Mark Pollack,"See https://github.com/spring-projects/spring-xd/pull/415#issuecomment-29024329

This test should be created so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code

",XD-1133,Mark Pollack,Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream
2610,Gary Russell,Derek Marley,"As a Spring XD user I need to listen on a JMS Topic and ingest the messages, so I can process the messages.

Currently the module only allows for Queues",XD-1132,Derek Marley,JMS Module - add support for TOPICS
2611,Eric Bottard,Eric Bottard,"Pending a better approach and extension point (see XD-1050), provide a way to factor out common recurring options for modules:
* inputType
* outputType
* job parameters",XD-1131,Eric Bottard,Basic support for Plugin contributed Module Options Metadata
2612,Glenn Renfro,Glenn Renfro,"EC2 Deployer 
Needs to change its configuration behavior to use environment variables vs. the property files
* Remove ConfigureSystem class, since we will use environment variables instead
* Allow users to set environment variables via the xd-ec2 properties.
* If properties are not present use those that are available in the application.yml
* Utilize JClouds environment variable setup features to implement this behavior.",XD-1130,Glenn Renfro,Update the EC2 deployer 
2613,Luke Taylor,Mark Pollack,This could be inside gradlew or a .settings file.,XD-1129,Mark Pollack,Enable --refresh-dependencies into be present when executing gradlew
2614,Dave Syer,Dave Syer,,XD-1128,Dave Syer,Disable JMX by default (and extend to other contexts than modules)
2615,Gary Russell,Mark Pollack,"This is a very big story, needs some planning/discussion before starting work.  Should be able to be implemented as a plugin. ",XD-1127,Mark Pollack,Add support for deploying a batch job with partitioning across multiple XD nodes.
2616,David Turanski,Dave Syer,,XD-1126,Dave Syer,Switch CAPITAL_LETTERS to system.property style in application config
2617,,Eric Bottard,"Following merge of XD-953, provide module options using the ""simple"" approach where applicable",XD-1125,Eric Bottard,Provide ModuleOptionsMetadata using simple approach
2618,Eric Bottard,Eric Bottard,"Example:
{noformat}
xd:>module delete --name sink:file
12:31:19,495  WARN Spring Shell client.RestTemplate:566 - DELETE request for ""http://localhost:9393/modules/sink/file"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Cannot delete non-composed module sink:file
{noformat}

The WARN log is redundant with the command result and should be silenced",XD-1124,Eric Bottard,Turn off RestTemplate logging in shell
2619,Eric Bottard,Eric Bottard,,XD-1123,Eric Bottard,Add profile activation on top of XD-953
2620,Ilayaperumal Gopinathan,Eric Bottard,"Following merge of XD-1109.

See discussion at https://github.com/spring-projects/spring-xd/commit/eaf886eab3b2ef07da55575029ccabb2c8a36af9#commitcomment-4701947",XD-1122,Eric Bottard,Add jmxPort to list of coerced cmd line options
2621,,Eric Bottard,"2 forces at heand here:
* Spring binding/validation itself
* jsr303 (for eg @NotNull)",XD-1121,Eric Bottard,Better error messages following XD-1109
2622,Gunnar Hillert,Gunnar Hillert,"We should we centrally standardize on date/time formats so that we don't create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC (or make that the default config option).

Ultimately, whatever the user sees is just a formatting concern.",XD-1120,Gunnar Hillert,Standardize Date/Time/TimeZone handling
2623,Glenn Renfro,Ilayaperumal Gopinathan,"We need to create a shell script that calls the batch DB creation sql files for the JDBC option selected. 
",XD-1119,Ilayaperumal Gopinathan,Create scripts for batch DB creation
2624,Luke Taylor,Mark Pollack,,XD-1118,Mark Pollack,"Add starting of newly build XD server, running of smoketest bash script, and killing of XD server to CI test"
2625,Luke Taylor,Mark Pollack,,XD-1117,Mark Pollack,Add bash based scripts of simple module create to src/main/scripts
2626,Eric Bottard,Eric Bottard,,XD-1116,Eric Bottard,Add documentation about message store to aggregator doco
2627,,Thomas Risberg,"We no longer validate the --hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot.

We do this validation in the xd-shell script",XD-1115,Thomas Risberg,We no longer validate the --hadoopDistro options in the xd scripts
2628,,David Turanski,We have observed in unit tests (see AbstractSingleNodeStreamIntegrationTests) that(Redis/SingleNode) occasionally fail. The root cause must be investigated further but there is some evidence to suggest that the control messages (ModuleDeploymentRequests) are not always received and handled by the ModuleDeployer. This does not produce an error but results in runtime stream failures. This problem may be resolved as part of the planned Deployment SPI but is being tracked here until we are certain that it has been resolved.,XD-1114,David Turanski,Investigate dropped Module Deployment Requests
2629,,Dave Syer,"ApplicationContext ID generation is difficult in general.  Cloud Foundry solves this problem for us by providing unique instance ids to all running instances of an app. I don't suppose that helps much in the general case though, and we need something (a rule of thumb) that is unique and preferably deterministic, so that nodes retain their ID across process and connector restarts.

In Cloud Foundry the instance id plays a vital role (and will be automatically picked up by the app and applied - need to look at how that plays in a context hierarchy). User can set the context id manually using {{spring.application.name}} and {{spring.application.index}}.",XD-1113,Dave Syer,ApplicationContext ID generation
2630,Dave Syer,Dave Syer,"Spring Boot support port scanning if you set server.port=0 (and disable with -1), so we could make that the default for the container node.",XD-1112,Dave Syer,Add port scan (and ability to disable) to container launcher
2631,David Turanski,Mark Fisher,"The following keys remain after running the test suite:

{code}
redis 127.0.0.1:6379> keys *
1) ""containers""
2) ""containers.application:9292""
{code}

",XD-1111,Mark Fisher,Clear Redis after tests
2632,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the JobRepoTests use the same batch job repository that the XD runtime uses. Since the batch job repo doesn't delete the job instances, there would be stale data from this test. ",XD-1110,Ilayaperumal Gopinathan,Fix JobRepoTests to use different batch job repo
2633,Eric Bottard,Eric Bottard,"Wherever they come from (cmd line args or ENV_VARS), options such as transport, analytics, etc should be validated and issues should be reported to users",XD-1109,Eric Bottard,Provide cmdline options validation
2634,Eric Bottard,Eric Bottard,"Restore --foo=bar as well as --foo bar

Validation of values should be done as a separate story",XD-1108,Eric Bottard,Restore lax command line options
2635,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the tests use instantiated DistributedJobService object instead of a simple mock. We can just use mock object for the tests.",XD-1107,Ilayaperumal Gopinathan,Create Mock on DistributedJobService instead of instantiating object
2636,Luke Taylor,Mark Pollack,Basic inverse of current hdfsjdbc job.,XD-1106,Mark Pollack,Create OOTB batch job that moved data from JDBC to HDFS
2637,Luke Taylor,Eric Bottard,"Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is

somesource | mqtt --topic=foo

with 

mqtt --topics=foo | somesink


And asserting that what is emitted to somesource ends up in somesink.

",XD-1105,Eric Bottard,Add some test coverage to mqtt modules
2638,Eric Bottard,Eric Bottard,"Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD.

Use of an in memory db where we expose eg a JdbcTemplate to assert state",XD-1104,Eric Bottard,Create Shell Integration test fixture for jdbc related sink
2639,Luke Taylor,Thomas Risberg,"The JDBC sink is broken. Simple ""time | jdbc"" results in:

org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback; bad SQL grammar [insert into test (payload) values(?)]; nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: TEST

Looks like some config options got clobbered during bootification. ",XD-1103,Thomas Risberg,JDBC sink is broken - looks like some config options got booted
2640,Eric Bottard,Mark Pollack,would be good to have a general feel for the general performance of these two options.  Redis can run on the same node as the benchmark.,XD-1102,Mark Pollack,Create microbenchmark for performace of redis and jdbc based aggregators
2641,Eric Bottard,Mark Pollack,"Similar to XD-1100.  SI has the jdbc based message store.

<int-jdbc:message-store id=""messageStore"" data-source=""dataSource""
    table-prefix=""MY_INT_""/>

The configuration of this aggregator would be configured so that it uses an embedded database, hsqldb or H2 depending if there is any real perf benefit to one or the other, and store the data on the local file system.",XD-1101,Mark Pollack,Create aggregator module that uses an embedded database stored in the local filesystem
2642,Eric Bottard,Mark Pollack,"There is a need for a persistent store for messages so that they can survive the crash of a container node.  The redis implementation in SI is useful since users may already be using redis for other features such as analytics.

This module would sit alongside the current in-memory based aggregator.  It brings in redis as a dependency and there should be configuration options exposed so that one can use a different version of redis as compared to the one that maybe used for analytics.  

Due to the need to have redis on the CP, and the large number of different options that each message store implementation provides and the different 3rd party library dependencies, I would like to avoid going down the path of using a profile here as it would seem to go beyond what we had discussed for profile support.  We can revisit as the module contribution story based on boot unfolds.",XD-1100,Mark Pollack,Create aggregator module that uses redis as a message store
2643,,Gunnar Hillert,"Currently you can specify negative pageSize values - The controllers should validatate that. Right now an internal exception is being return, leaking internal details to the caller - 

E.g.: 

**http://localhost:9393/batch/executions?pageSize=-1** results in:

{code}
<errors>
<error logref=""BadSqlGrammarException"">
<message>
StatementCallback; bad SQL grammar [SELECT TOP -1 E.JOB_EXECUTION_ID, E.START_TIME, E.END_TIME, E.STATUS, E.EXIT_CODE, E.EXIT_MESSAGE, E.CREATE_TIME, E.LAST_UPDATED, E.VERSION, I.JOB_INSTANCE_ID, I.JOB_NAME FROM BATCH_JOB_EXECUTION E, BATCH_JOB_INSTANCE I WHERE E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID ORDER BY E.JOB_EXECUTION_ID DESC]; nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: TOP
</message>
</error>
</errors>
{code}

",XD-1099,Gunnar Hillert,Controllers - Disallow negative pageSize values
2644,Glenn Renfro,Glenn Renfro,,XD-1098,Glenn Renfro,Integration tests for XD Installer
2645,Eric Bottard,Thomas Risberg,The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.,XD-1097,Thomas Risberg,Redo Hadoop distribution dependency management
2646,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the BatchJobsController and BatchJobExecutionsController are not HATEOAS compliant and we need make them so.",XD-1096,Ilayaperumal Gopinathan,Make Batch Job controllers HATEOAS compliant
2647,Ilayaperumal Gopinathan,Mark Pollack,,XD-1095,Mark Pollack,Create a shell command for stopping all job executions
2648,Ilayaperumal Gopinathan,Mark Pollack,,XD-1094,Mark Pollack,Create shell command for stopping a specific job
2649,Gunnar Hillert,Mark Pollack,,XD-1093,Mark Pollack,Create shell command for getting information on a given step execution
2650,Gunnar Hillert,Mark Pollack,,XD-1092,Mark Pollack,Create shell command for getting information on all steps of a given job execution
2651,Ilayaperumal Gopinathan,Mark Pollack,,XD-1091,Mark Pollack,Create shell command for getting information on the progress of a given step execution
2652,Eric Bottard,Mark Pollack,,XD-1090,Mark Pollack,Create shell command for restarting a specific job instance
2653,Gunnar Hillert,Mark Pollack,,XD-1089,Mark Pollack,Create shell command for getting information on all job executions for a given name
2654,Ilayaperumal Gopinathan,Mark Pollack,"There is a NPE in the current spring batch admin functionality.

Should be springmvc test framework style tests.

GET /batch/jobs/executions/{jobExecutionId}/steps/{stepExecutionId}/progress",XD-1088,Mark Pollack,Create REST API for getting information on the progress of a given step execution
2655,Gunnar Hillert,Mark Pollack,"Functionality adopted from spring-batch admin
Should include springmvc test framework style tests

POST /batch/jobs/{jobName}/{jobInstanceId}/executions - restart a specific job instance

",XD-1087,Mark Pollack,Create REST API for restarting a specific job instance
2656,Ilayaperumal Gopinathan,Mark Pollack,"Adopted functionality from spring batch admin
Should include SpringMVC test framework style tests.

DELETE /batch/jobs/executions/ - stop all job executions",XD-1086,Mark Pollack,Create REST API for stopping all job executions
2657,Ilayaperumal Gopinathan,Mark Pollack,"Functionality adopted from spring batch admin
Should include springmvc test framework style tests

DELETE /batch/jobs/executions/{executionId} Stop a specific job",XD-1085,Mark Pollack,Create REST API for stopping a specific job
2658,Gunnar Hillert,Mark Pollack,"Functionality adopted from spring batch admin
Should include springmvc test framework style tests

GET /batch/jobs/executions/{executionId}/steps/{stepId} - Get information on a given step execution",XD-1084,Mark Pollack,Create REST API for getting information on a given step execution
2659,Gunnar Hillert,Mark Pollack,"Adopted functionality from spring batch admin
Should include springmvc test framework style tests

GET /batch/jobs/executions/{executionId}/steps - Get information on all steps of a given job execution",XD-1083,Mark Pollack,Create REST API for getting information on all steps of a given job execution
2660,Gunnar Hillert,Mark Pollack,"Adopted functionality from Spring Batch admin
Should include springmvc test framework style tests

GET /batch/jobs/executions/{executionId} - Get information on all executions of a given job name.",XD-1082,Mark Pollack,Create REST API for getting information on a job execution for a given execution id
2661,Gunnar Hillert,Mark Pollack,"This should go in the first section of the Batch Job documentation.

Here is a rough suggestion

The lifecycle of a job in XD.

1. Register a job module with the MoudleRegistry by putting a XML/jar files in the $XD_HOME/modules/jobs directory.
2. Create a job definition from a job module by providing a name and properties that apply to all job instances can be configured at this point.  The job is not yet deployed
3. Deploy the job to an xd-container.  A job instance can not be created by sending a message to a job queue that contains optional runtime job parameters
4. Launch a job by sending a message to the job queue with job parametres.  A Job Instance is created, representing a specific run of the job.  A Job Instance is the Job Definition plus the runtime job parameters.  You can query for the Job Instances associated with a given job name
5. The job is executed creating a Job Exection object that captures the success or failure of the job.  You can query for the Job Executions associated with a given job name.
6. Undeploy a job.  This removes the job from xd-container.",XD-1081,Mark Pollack,Create documentation on the lifcycle of a job in XD
2662,Gunnar Hillert,Mark Pollack,"The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.",XD-1080,Mark Pollack,Make deploy=false as the default when creating a new job
2663,Ilayaperumal Gopinathan,Mark Pollack,"BatchJobsController.listForJob should be 'executionsForJob'
BatchJobsController.jobInstances should be 'instancesForJob'

The JavaDoc for the class and each method should be more descriptive about their functionality


",XD-1079,Mark Pollack,Small method name refactorings and add Javadoc in batch controllers
2664,Gunnar Hillert,Gunnar Hillert,"Without the directory, Spring XD cannot be imported into STS using its own Gradle support.",XD-1078,Gunnar Hillert,"Add ""spring-xd-exec"" directory to Git repo"
2665,Eric Bottard,Mark Pollack,"Develop out a Proof of concept for review that allows users to easily create a new module to Spring XD. Key features to be enabled:

1. Allow existing modules to be included as a classpath dependency
2. Consolidate shared libraries in existing modules (e.g. a shared lib for all gemfire modules)
3. User develops a module as a normal Java project
4. User's project can then be added to a runtime container in the same way (as a dependency)

Nice to have: 

1. at development time container can run continuously and pick up changes from user's module project.
2. Java config for a module.
3. command line functionality to create project scaffolding.

",XD-1077,Mark Pollack,Proof of Concept for module contributions based off Boot
2666,Gary Russell,Mark Pollack,"This is along the lines of what is in this blog post

http://coreyreil.wordpress.com/2012/12/21/spring-batch-creating-an-ftp-tasklet-to-get-remote-files/

Note that there have been some new developments in SI to get at the underlying stream for FTP.

The way to test this is to create a new batch job in XD that has this as it's tasklet.  Going forward the target file system will also be HDFS.",XD-1076,Mark Pollack,Create an FTP tasklet to get remote files and put them in the local file system.
2667,,Eric Bottard,"Migrating to boot dropped the XD banner and its info.

Can be restored using eg a boot Initializer and removing the default boot banner",XD-1075,Eric Bottard,Restore XD Banner
2668,,Eric Bottard,"Summary says it all. When starting, we now get
{noformat}
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/ebottard/.gradle/caches/artifacts-24/filestore/org.slf4j/slf4j-log4j12/1.7.5/jar/6edffc576ce104ec769d954618764f39f0f0f10d/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/ebottard/.gradle/caches/artifacts-24/filestore/org.slf4j/slf4j-log4j12/1.6.1/jar/bd245d6746cdd4e6203e976e21d597a46f115802/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
{noformat}

Most certainly introduced by 1c4817ee60ae9325f6394dcc78aa803c47818546 or 72baec92f2e7bbe860b4a9dc6c994536c1670881
",XD-1074,Eric Bottard,Multiple SLF4J bindings on the classpath
2669,Glenn Renfro,Mark Pollack,Change the default port since it conflicts with the default port for the http source,XD-1073,Mark Pollack,Change default container port from 9000 to something else
2670,David Turanski,David Turanski,Add a bridge module per XD-956 to support definitions like topic:foo > queue:bar . Convenient for testing for XD-1066,XD-1072,David Turanski,Add bridge module
2671,Luke Taylor,Mark Pollack,"The File to HDFS batch job will not close the file being written to in HDFS when the job completes.  The ItemWriter for HDFS needs to incorporate functionality that is present in the standard FlatFileWriter, perhaps inheriting from AbstractItemStreamItemWriter",XD-1071,Mark Pollack,Close HDFS file when Batch job ends
2672,Luke Taylor,Mark Pollack,"The batch job for File to HDFS will try to check for the default '/data/' directory even if the target directory in HDFS is something else.  If the /data directory isn't there, the job will fail.

This should be fixed so there isn't a check on the directory that isn't the final HDFS target directory and the target directory should be created if it doesn't exist.",XD-1070,Mark Pollack,"File to HDFS batch job fails due to ""/data"" directory not available in HDFS"
2673,Ilayaperumal Gopinathan,Mark Pollack,,XD-1068,Mark Pollack,Remove existing 'purpose built' json processors and ensure all functionality is still available with #jsonPath based SpEL expression based processors
2674,Gary Russell,Mark Fisher,"This is ""harmless"" (the attempt to brpop continues even after the connection itself has been closed), but ugly:

{code}
12:45:15,084 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 inbound.RedisQueueMessageDrivenEndpoint:181 - Failed to execute listening task. Will attempt to resubmit in 5000 milliseconds.
org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Connection closed
	at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:46)
	at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:36)
	at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:159)
	at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:253)
	at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1508)
	at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:163)
	at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:51)
	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)
	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)
	at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)
	at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:160)
	at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:105)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:286)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:724)
Caused by: com.lambdaworks.redis.RedisException: Connection closed
	at com.lambdaworks.redis.RedisAsyncConnection.await(RedisAsyncConnection.java:1079)
	at com.lambdaworks.redis.RedisConnection.await(RedisConnection.java:820)
	at com.lambdaworks.redis.RedisConnection.brpop(RedisConnection.java:101)
	at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1506)
	... 12 more
{code}

We should shutdown the consumer gracefully (i.e. before the connection is closed).",XD-1067,Mark Fisher,Container with redis as transport emits stack trace on shutdown
2675,David Turanski,Mark Fisher,"This needs to work for all transports (local, rabbit, and redis), and we need to ensure that we have test coverage for each of those to avoid any regressions.

The incorrect behavior was observed with all three transports:

{code}
xd:>stream create a --definition ""topic:foo > transform --expression=payload+'-a' | log""
Created new stream 'a'

xd:>stream create b --definition ""topic:foo > transform --expression=payload+'-b' | log""
Created new stream 'b'

xd:>stream create s --definition ""http > topic:foo""
Created new stream 's'

xd:>http post --data hi
> POST (text/plain;Charset=UTF-8) http://localhost:9000 hi
> 200 OK

// only one line in log!
{code}
",XD-1066,Mark Fisher,Topic channels are not broadcasting
2676,Ilayaperumal Gopinathan,Mark Fisher,"This is most likely an issue for any transport, since it's probably happening within the JobPlugin, but I noticed when using Rabbit that every stream I created also triggered creation of ""job:[streamname]"" Queues.",XD-1065,Mark Fisher,"Extra ""job"" queues being created for all streams"
2677,David Turanski,Mark Fisher,"for example, the following should work:

{code}
xd:>stream create a1 --definition ""queue:a > transform --expression=payload+'-a' | log""
Created new stream 'a1'

xd:>stream create b1 --definition ""queue:b > transform --expression=payload+'-b' | log""
Created new stream 'b1'

xd:>stream create s1 --definition ""http | router --expression=payload.contains('a')?'queue:a':'queue:b'""
Created new stream 's1'

xd:>http post --data ""ha""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 ha
> 200 OK

// log shows: ""ha-a""

xd:>http post --data ""hi""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 hi
> 200 OK

// log shows: ""ha-b""
{code}

This needs to be tested against all transports (local, redis, and rabbit)
",XD-1064,Mark Fisher,Update router sink logic to match new channel syntax
2678,Eric Bottard,Eric Bottard,"Use of dot in property name prevents the user from specifying a value in stream definition

Also, defaults are repeated at .xml and .properties level",XD-1063,Eric Bottard,Fix mqtt module properties
2679,,Dave Syer,Add debug flag for logging globally maybe or else --trace per command?,XD-1062,Dave Syer,User would like to see request/response details (headers URLs etc) in shell
2680,Eric Bottard,Gunnar Hillert,Looks like we need to spend a cycle on Asciidoc - as we still have the author-tag-issue - I thought we can simply upgrade the asciidoctor-gradle-plugin to 0.7.0 (currently 0.4.1) but that breaks the docs being generated.,XD-1061,Gunnar Hillert,Upgrade asciidoctor-gradle-plugin to 0.7.0
2681,Thomas Risberg,Isaac Johnson,"(apologies if a ticket already exists for this, but I didn't see one)

I spun up the Hortonworks Data Platform 2.0 sandbox, but see it isn't supported by Spring XD yet.

How hard would it be to add these Distro's in?  Is it just a matter of dropping in a lib folder for hadoop22 and/or hdp20, and allowing those and options to be passed in via the --hadoopDistro option?

I'm currently trying to work through the following tutorial, but using the HDP 2.0 sandbox instead of the 1.3 sandbox

http://hortonworks.com/hadoop-tutorial/using-spring-xd-to-stream-tweets-to-hadoop-for-sentiment-analysis/

Thanks!",XD-1060,Isaac Johnson,Add support for Hortonworks Data Platform 2.0
2682,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The batch job's step execution count is retrieved from org.springframework.batch.admin.web.JobExecutionInfo in batch job repository.

But, the JobExecutionInfo always have the stepExecutionCount set to '0'.",XD-1059,Ilayaperumal Gopinathan,Batch Job's step execution count is always '0'
2683,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the bootstrap.less file has all the styles that the bootstrap supports. But we should only add/compile the LESS that are needed by XD UI.",XD-1058,Ilayaperumal Gopinathan,Remove unnecessary LESS files from XD UI styles
2684,Ilayaperumal Gopinathan,Glenn Renfro,The table background color on the Job Definition Tab is green while the others tabs have a white background.  They should be consistent.,XD-1057,Glenn Renfro,Colors on Job Definition tab are different than other tabs
2685,,Glenn Renfro,Job gets a empty key:value pair when launching the job from the admin-ui.,XD-1056,Glenn Renfro,Empty parameter sent to job when launched from UI
2686,,Glenn Renfro,"I know that the feature is not ready, but we either should post a message to the user that the feature is not available or hide the button",XD-1055,Glenn Renfro,Schedule button shows up but does not perform any task
2687,,Glenn Renfro,The deployment tab does not reflect the current state of the jobs.  User must hit browser refresh button to make it work.,XD-1054,Glenn Renfro,Deployment tab on admin-ui lags behind with changes on other pages
2688,Luke Taylor,Mark Pollack,"This will allow for some easy demonstration of how 'HATEOS' works via links in our REST API.  There are probably some quite useful commands here that could be used from the Spring Data REST shell longer term, but a good place to take a look at now.

Goal is to show how metrics such as counters are accessible w/o having to switch tabs to use wget.
The pretty printing of the returned JSON is an important feature to help understand the response, this functionality can be taken from/reused from the Spring Data REST shell",XD-1053,Mark Pollack,"Add ""http get"" command to shell"
2689,Eric Bottard,Mark Fisher,"e.g. see comment on PR #390:
https://github.com/spring-projects/spring-xd/pull/390/files#r7563787

In that case, it's ""delete"" in one place and ""destroy"" in another. There are other cases as well.",XD-1052,Mark Fisher,"Enforce consistent naming across CLI options, and command/template/operations method names"
2690,David Turanski,Mark Fisher,"note from PR #365:

{quote}
We should probably create a new story to (at least) rename ""module display"" to ""module showconfig"" or something, but possibly even reconsider it altogether. In some sense, it's even violating the encapsulation of ModuleRegistry. It wont work for java-config style modules or spring-integration Groovy DSL modules. Personally, if anything, I'd rather see those config files themselves exposed as part of an admin UI. What you are doing with the options here fits better with the encapsulation principle and the fact that typical usage should not require detailed knowledge of the actual underlying configuration of a Module.
{quote}

",XD-1051,Mark Fisher,"Rename or reconsider the ""module display"" command"
2691,Eric Bottard,Mark Fisher,"note from PR #365 - which has been merged - providing the initial level of support...

Pending issues (to be addressed in another PR?):
- [x] complex case
- [x] default values for complex case, when option is not surfaced back to the module (eg ""suffix"" in our canonical example)
- [ ] plugin provided options and values
- [ ] descriptive defaults instead of actual defaults (e.g. \<use stream name\>)
- [ ] JSR303 Validation

",XD-1050,Mark Fisher,Improve Module Options support
2692,Mark Fisher,Mark Pollack,,XD-1049,Mark Pollack,Create documentation for composed modules
2693,liujiong,David Geary,"This would be a combination of the existing aggregate counter and field value counter functionality.

For example if the stream data was for car purchases some fields might be colour, make and model. 
When analysing the aggregate data I dont just want to know how many were sold on Monday, but how many of each make or how many of each colour, 
or how many of a particular colour, make AND model. This would allow a dashboard type client to 'drill down' into each dimension or combination of dimensions (in real time without executing batch queries against the raw data)

Ideally the aggregate counter would be specified as 

stream create --name mytap --definition ""tap:mystream > aggregatecounter --name=mycount --fieldNames=colour,make,model""

The keys would be dynamically created according to the field values in each record (ie in a similar way to the field value counter you would not need to predefine field values) and keys would be created for all combinations of the fields specified eg the record 

{ ""colour"":""silver"" , ""make"":""VW"" , ""model"" : ""Golf"" } 

would increment the following key counters (in addtion to the existing time buckets)

<existing base counter - ie all fields for this time bucket>
colour:black
make:VW
model:Golf
colour:black.make:VW
colour:black.model:Golf
make:VW.model:Golf
colour:black.make:VW.model:Golf

ie the actual keys would look something like

aggregatecounters.mycount.make:VW.model:Golf.201307 etc

This may seem like it would generate a lot of key combinations but in practice the data generated will still be massively less than the raw data, and keys will only be created if that combination occurs in a time period. 
Also some fields may be dependent on each other (such as make and model in the above example) so the amount of possibilites for those composite keys would be a lot less that the number of one times the number of the other.

",XD-1048,David Geary,Extend aggregate counter to dynamically aggregate by field values in addition to time.
2694,Eric Bottard,David Geary,"Currently the aggregate counter aggerates by the current time. However the data may already have a timestamp in it (eg streams from activity events on a website). 
It would be useful as an alternative approach to be able to specify this field to aggregate on. 

This would have the following benefits:

1) The aggregate counts would be more accurate as they would reflect the acutal event times and not have any lag from an intermediate messgaging system they might have passed through.
2) If for whatever reason XD is down, comes back up and starts pulling queued messages from the messaging system the aggregate counter will reflect the correct event time. Currently you would get a gap and then a spike as a backlog of messages would get allocated to the current aggregate count.
3) Old data could be rerun through XD still creating the correct aggregate counts.

Configuration would be something like 

stream create --name mytap --definition ""tap:mystream > aggregatecounter --name=mycount --timestampField=eventtime""

without the timestampfield it would behave as currently. ",XD-1047,David Geary,Allow Aggregate Counter to use timestamp field in data.
2695,,Eric Bottard,,XD-1046,Eric Bottard,Consider a shared project for POJOs that are shareable betweed model and REST layer
2696,,Mark Fisher,"this would elminate dependencies that are currently in the codebase, such as:

* RESTModuleType and ModuleType enums
* ModuleOption and DetailedModuleDefinitionResource.Option

",XD-1045,Mark Fisher,Create project for model that is common between client and server
2697,Mark Pollack,Mark Fisher,"see comments on this PR (which is part of the code that needs to be refactored):
https://github.com/spring-projects/spring-xd/pull/390
",XD-1044,Mark Fisher,refactor module dependency tracking to be closer to stream deployment
2698,Mark Fisher,Mark Fisher,"Currently the parser returns a List<ModuleDeploymentRequest>, and the deployer works with that list directly. We need a higher level parser result (e.g. DeployableStream - or probably a better name after some thought) that can encapsulate that list while also enabling metadata to be added. That metadata may be helpful for composite module information as well as the module dependencies of a given stream (including any composed modules within that stream).",XD-1043,Mark Fisher,Encapsulate list of ModuleDeploymentRequests within a parsed Stream result object
2699,Eric Bottard,Eric Bottard,"The ModuleOptions PR currently uses FQN for types (eg java.lang.String)

Would be nice to have support for short names for common types, both in the properties files and the annotation",XD-1042,Eric Bottard,Support short names for types in ModuleOptions
2700,Thomas Risberg,Thomas Risberg,Make sure the sinks and jobs work against Pivotal HD 1.1,XD-1041,Thomas Risberg,Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1
2701,,Luke Taylor,"See the discussion in https://github.com/spring-projects/spring-xd/pull/370

There are now various superseded classes and tests which we no longer need.",XD-1040,Luke Taylor,"Remove ""legacy"" application code following Spring bootification"
2702,Eric Bottard,Eric Bottard,"Although composition of a module out of an already composed module seems to work at the 'module compose' level, trying to deploy a stream with that more complex module fails with

	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:312)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)
Caused by: java.lang.IllegalArgumentException: each module before the last must provide 'output'
	at org.springframework.util.Assert.notNull(Assert.java:112)
	at org.springframework.xd.module.CompositeModule.initialize(CompositeModule.java:132)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:234)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:224)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleCompositeModuleDeployment(ModuleDeployer.java:180)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:129)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	... 63 more",XD-1039,Eric Bottard,Composed of Composed fails at stream deployment time
2703,,David Turanski,,XD-1038,David Turanski,Source that produces JSON String as byte[] with --outputType application/json should produce JSON string
2704,Eric Bottard,Eric Bottard,"With the following semantics (assuming http | filter | transform composition):


* Fully qualified names always available (eg filter.expression)
   * using module type as key
   * or label if ambiguity
* Simple names available if no ambiguity (eg here ""port"" refers to http.port)

As per discussion:

VIII) Use of “--expression” option in composed module “filter | filter”
Should not be supported (require FQN always)
Should pertain to first filter module (always)
Should pertain to all modules with an “expression” option (here: both filters)
Should fail if not qualified and ambiguity. Use label.expression (or type.expression, eg if we had “filter | transform) (see VII ⇒ nesting1.nesting2.nesting3.expression) (MF)

VIII) Use of “--expression” option in composed module “http | filter --expression=something | transform”
Should not be supported (already valued)
Should pertain to first filter module (always)
Should pertain to all modules with an “expression” option (here: both filters)
Should fail if not qualified and ambiguity. Use label.expression (or type.expression, eg if we had “filter | transform) (see VII ⇒ nesting1.nesting2.nesting3.expression) (MF)
",XD-1037,Eric Bottard,Support ModuleOptions for composed modules
2705,Eric Bottard,Eric Bottard,"Provided it is not currently used in any stream:

V) Attempt to destroy a composed module
Should not be supported at all
Should not be supported if involved in at least one stream (EB?, MF!)
Should be supported and have no other consequences whatsoever (see IV) (EB?)
Should be supported and invalidate/destroy streams involving it
",XD-1036,Eric Bottard,Support composed module deletion
2706,Eric Bottard,Eric Bottard,"As per discussion, any attempt to create something that would collide with existing should fail:

II) Attempt to create a composed module with same name as an already existing, not composed module, with same type
should fail (EB, MF)
should work and shadow previous module from now on

III) Attempt to create a composed module with same name as an already existing composed module, with same type
should fail (EB, MF)
should work and shadow previous module from now on
should work and retroactively change definitions of streams with that module
",XD-1035,Eric Bottard,Attempt to compose a module with same name+type as existing should fail
2707,David Turanski,David Turanski,"This relates to XD-871 which provides a good scenario.

 >stream create s1 --definition ""http | log --deploy""
 >stream create s2 --definition ""http | log --deploy""

The second command results in an error message that the port is in use but the stream definition is still saved. Since create + deploy is a logical unit of work, it should follow transactional semantics. In other words if the deploy fails, the repository should be rolled back (or a compensating destroy should be performed).  Note this should not be handled the same way if create and deploy happen separately. In that case, the stream definition should remain.",XD-1034,David Turanski,Stream definitions should not be saved when auto-deploy results in an error
2708,Eric Bottard,Eric Bottard,"Add a module that can act as a tcp *client* (as opposed to our current tcp module, which acts as a server, waiting for an incoming connection)

Also, the module should allow to send ""commands"" to the remote server. The typical minimal case for such a protocol is to send ""PING"" messages, but a stateful mechanism should be put in place for more complex cases.",XD-1033,Eric Bottard,Add a tcp-client source module
2709,Thomas Risberg,Eric Bottard,"* rename spring-xd-extension-hdfs to something else, as it seems it is all spring ""data"" stuff and is not coupled to xd. But leave it in extensions/ for now
* rename and move spring-xd-hadoop inside extensions (maybe to spring-xd-extension-hadoop (or hdfs))
* make hadoop related modules depend on the latter (which itself will depend on the former)",XD-1032,Eric Bottard,Convert hadoop module to isolated classloader scheme
2710,Gunnar Hillert,Mark Pollack,"Use a modal dialog to specify runtime parameters.
There should be a little text are that gives hints as to the spring batch parameter key/value conventions, e.g. for type.

Might be a good idea to have a checkbox that lets you select to 'auto increment' job instance number.

4 columns
key, value, type, identifying and an 'add parameter' button that adds a new row.

This would appear as a modal dialog box, polling of the state of the deployments would be suspended while the job parameter modal dialog box is shown.

",XD-1031,Mark Pollack,UI - Launch a job with parameters
2711,,Artem Bilan,,XD-1030,Artem Bilan,Refactoring to JdbcMessagePayloadTransformer to extends from AbstractPayloadTransformer not JsonToObjectTransformer
2712,Gary Russell,Gary Russell,,XD-1029,Gary Russell,Migrate to SI Redis Queue and Topic Adapters
2713,Gunnar Hillert,Gunnar Hillert,"Specify the default URL as:

{code}
urlRoot: location.protocol+'//'+location.hostname+(location.port ? ':'+location.port: '')
{code}",XD-1028,Gunnar Hillert,UI - Do not hard-code server url
2714,Sabby Anandan,Luke Taylor,This would be included in the OOTB batch jobs to optionally process the loaded Tuple with a configured script.,XD-1027,Luke Taylor,Create script-based batch ItemProcessor 
2715,,Ilayaperumal Gopinathan,"The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents.

This requires changes to use user agent specific layout for the UI views.",XD-1026,Ilayaperumal Gopinathan,"UI: Responsive layout for supported user agents(Mobile, Tablet and Desktop)"
2716,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"From XD-1023, the job status(deployed/undeployed) is available from JobInstance Repository and a job can be deployed/undeployed correctly. 

Implement Job deploy/undeploy for a given job from JobDefinitions page and indicate status of the job definition (deployed/undeployed).",XD-1025,Ilayaperumal Gopinathan,UI: Implement Job Deploy/Undeploy from the Job Definitions page
2717,David Turanski,Gary Russell,"The current (XD) uses an inadequate {{MessageRedisSerializer}} when {{extractPayload}} is false (not currently being used). When porting this to SI, the serializer will be dropped.

Suggest creation of Kryo serializer for Messages for when Redis source/sinks are created.",XD-1024,Gary Russell,Kryo Redis Serializer
2718,Eric Bottard,Eric Bottard,"Job deployment currently goes through an overloaded version of deploy() that takes 4 parameters. This prohibits job handling code from benefiting from common behavior (and eg currently breaks deployAll)

Given that the 3 additional parameters are in fine handled as module parameters, let's push them to the job definition, known at creation time, rather than at deployment time (as it does not really make sense to change those between deploys)",XD-1023,Eric Bottard,Refactor job deploy to go through XDController.deploy(name)
2719,,Eric Bottard,"The module list command currently has a very simplistic two column display of (module name, module type).
The is not very readable.

Switch to a 4 column display: (Sources, Processors, Sinks, Jobs)

Additionally, mark composed module [e.g. ""myhttp (c)""]",XD-1022,Eric Bottard,"Switch ""module list"" to horizontal display"
2720,Eric Bottard,Eric Bottard,"Create a composed module
Create a stream that uses that module
Try to undeploy the stream.
Kaboom

The dispatch is not correctly implemented in ModuleDeployer",XD-1021,Eric Bottard,Fix undeploy of stream with a composed module
2721,Eric Bottard,Eric Bottard,"ModuleDeployer has many methods with very similar names that are hard to understand.

Moreover, there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names.

One should even consider splitting the class

",XD-1020,Eric Bottard,Cleanup ModuleDeployer
2722,Gary Russell,Gary Russell,Log and purge bad messages,XD-1019,Gary Russell,Add Spring Retry to Rabbit Message Bus
2723,Luke Taylor,Luke Taylor,"When deploying jobs, the following code (line 103), hides the root cause of deployment failure:

  if (exceptionClassName.equals(BEAN_CREATION_EXCEPTION) || exceptionClassName.equals(BEAN_DEFINITION_EXEPTION)) {
    throw new MissingRequiredDefinitionException(definition.getName(), cause.getMessage());
  }

For example:

org.springframework.xd.dirt.stream.MissingRequiredDefinitionException: Error creating bean with name 'dataSourceInitializer' defined in file [/Users/luke/Work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Cannot resolve reference to bean 'databasePopulator' while setting bean property 'databasePopulator'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'databasePopulator' defined in file [/Users/luke/Work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Initialization of bean failed; nested exception is java.lang.NullPointerException
	at org.springframework.xd.dirt.stream.JobDeployer.deploy(JobDeployer.java:103)
	at org.springframework.xd.dirt.stream.JobDeployer.deploy(JobDeployer.java:67)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:242)",XD-1018,Luke Taylor,JobDeployer hides root exceptions on failure
2724,Gunnar Hillert,Glenn Renfro,"Currently when you bring up a admin-ui on a browser that is not on the XD admin server, the page reports an error.

This is because the javascript is looking to localhost to get its updates.  ",XD-1017,Glenn Renfro,Spring Batch Admin UI looks to localhost when getting status updates
2725,liujiong,David Turanski,"Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally, e.g., json.pretty.print=true.  This will require some refactoring of the ModuleTypeConversion plugin, i.e., use DI in streams.xml",XD-1016,David Turanski,Provide an option to pretty print JSON output
2726,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. 

As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",XD-1015,Ilayaperumal Gopinathan,Create a reusable responsive UI layout to render the XD PagedResoures in tabular view
2727,Gunnar Hillert,Gunnar Hillert,,XD-1014,Gunnar Hillert,Command to show the XML of the job definition
2728,Gunnar Hillert,Gunnar Hillert,,XD-1013,Gunnar Hillert,Add additional REST endpoint that return the XML definition of a job
2729,Glenn Renfro,Glenn Renfro,"Currently HSQLDB is the only option for batch jobs.  This should be configurable so that a user may select another JDBC data store option.  

Steps:
* hsqldb.properties needs to be changed to batch-jdbc.properties
* hsql prefixes should be changed to batch-jdbc
* JDBC Connection String needs to be configurable
* JDBC Driver needs to be configurable
* The Setup Scripts to be used for spring batch need to be configurable.
* HSQLServerBean should be renamed to something batch-jdbc.properties

Tests:
Should be able write tests that support HSQLDB",XD-1012,Glenn Renfro,"DataSource for batch infrastructure should be configurable, not hardcoded to hsqldb"
2730,Glenn Renfro,Glenn Renfro,"When trying to use the --host command line parameter, spring shell reports the following error for this command, ""xd-shell --host localhost"" :
Oct 25, 2013 10:35:25 AM org.springframework.shell.core.SimpleParser commandNotFound
WARNING: Command '--host localhost' not found (for assistance press TAB)
",XD-1011,Glenn Renfro,Spring Shell --host option does not work
2731,Eric Bottard,Eric Bottard,See discussion at https://github.com/spring-projects/spring-xd/pull/362,XD-1010,Eric Bottard,Convert remaing FileSink assertions to eventually() constructs
2732,,Gunnar Hillert,"Assumption: The batch job *wordCountJob* does not exist. Executing the REST endpoint:

http://localhost:9393/batch/jobs/wordCountJob/executions

yields the correct response:

{code}
<errors xmlns:atom=""http://www.w3.org/2005/Atom"">
<error logref=""NoSuchBatchJobException"">
<message>
Batch Job with the name wordCountJob.job doesn't exist
</message>
</error>
</errors>
{code}

One could argue, though, that this is technically not an error but a status/application message, no??

However, the console/log logs at error level with a full stacktrace. I think the full stacktrace should only be available when debugging is allowed. In normal mode, I think we should log only at info or warn level without the full stacktrace.
",XD-1009,Gunnar Hillert,Don't perform error-level logging for normal application behavior in batch admin functionality
2733,Eric Bottard,Ilayaperumal Gopinathan,"Currently, the jobs definition list REST endpoint doesn't include deployed/undeployed status on a given job.",XD-1008,Ilayaperumal Gopinathan,Jobs list REST endpoint should include deployed/undeployed status
2734,Gunnar Hillert,Ilayaperumal Gopinathan,"On clicking the job detail page, we should display all the step executions associated with the specific job execution in a table view.",XD-1007,Ilayaperumal Gopinathan,UI: User should be able to see step execution info in a table below job detail
2735,Gunnar Hillert,Ilayaperumal Gopinathan,"On clicking ""details"" link on a job execution row, user should see the job details.

Job detail page will show all the information about the job, where as the table listing of jobs on the Execution tab may have omitted some columns or aggregated values to convey information more easily.",XD-1006,Ilayaperumal Gopinathan,UI: User should be able to view job detail from a specific job execution at Job Executions page
2736,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"On clicking the “Executions” tab, user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by “Job name”, “execution time” etc.,
",XD-1005,Ilayaperumal Gopinathan,UI: User should be able to filter the list of executions on the execution tab
2737,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"From the Deployed jobs page, by clicking the ""Schedule"" button on a specific deployed job row, user should be able to schedule this job with:
1) Cron trigger (with cron expression) as a source to job launching named channel
2) Fixed rate/delay trigger as a source to job launching named channel

",XD-1004,Ilayaperumal Gopinathan,UI: User should be able to schedule a job from Deployed jobs page
2738,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"From the Deployed jobs page, user should be able to click on the ""Launch"" button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request.

",XD-1003,Ilayaperumal Gopinathan,UI: User should be able to launch a job from Deployed jobs page
2739,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job.

User should be able to navigate back to the deployed jobs list.",XD-1002,Ilayaperumal Gopinathan,UI: User should be able to get all the job executions on a given job at deployed jobs page
2740,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"On clicking the “Deployed Jobs”, we can have a table view of all the deployed jobs.
This is again a responsive table layout with all the job definitions with status “deployed”. The deployed XD job corresponds to a single batch Job Instance. 

This story addresses the UI layout changes to display existing JobInstance information.",XD-1001,Ilayaperumal Gopinathan,User should be able to view the list of all Deployed Jobs
2741,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Create a tab view with tabs “Job Definitions”, “Runtime Jobs” (Deployed Jobs?, “Job Instances” (Is Runtime Jobs a better name here?) and “Job Executions”. On clicking “Job Definitions” tab, we can have a table view of job definitions. Since we bootstrap.js, we can have a responsive table layout to list all the available job definitions. At the REST layer, “/jobs” provides the list of job definitions. We can expand the JobsController list()’s QueryOptions to add more criteria (especially to list JobDefinition’s status (Deployed/Undeployed).
Also, this is the UI implementation for the shell command “job list”
",XD-1000,Ilayaperumal Gopinathan,User should be able to view the list of all the job definitions
2742,Gunnar Hillert,Gunnar Hillert,"Related to https://jira.springsource.org/browse/BATCH-2109

DistributedJobService#listJobExecutionsForJob overrides 
SimpleJobService#listJobExecutionsForJob

and does not include the *StepExecution*s. This is due to serializion issues with Jackson. 

In order to fix this, we need to add a Jackson MixIn.
",XD-999,Gunnar Hillert,Return the step execution information in the current job execution controller
2743,David Turanski,Mark Pollack,"Need some sample usage, docs for 

https://github.com/spring-projects/spring-xd/tree/master/modules/source/gemfire

 ",XD-998,Mark Pollack,Add documentation for gemfire cache-listener source
2744,Thomas Risberg,Mark Pollack,"Support for partitioning on a field, e.g. date.",XD-997,Mark Pollack,The HDFS Sink should support writing POJOs to HDFS using Avro/Kite SDK with support for partitioning
2745,,Mark Pollack,,XD-996,Mark Pollack,Support for executing batch functionality on and off Hadoop
2746,Eric Bottard,Eric Bottard,"Some tests (esp. ModuleClasspathTests.testModuleWithClasspathAfterServerStarted) seem to fail because of a race condition.

Add a Hamcrest matcher that knows how to read the content of a FileSink|Source and refactor those to read like e.g.

assertThat(fileSink, eventually(hasContent(""foo)))

",XD-995,Eric Bottard,Refactor tests with FileSink|FileSource to use eventually() matcher
2747,Mark Pollack,Thomas Risberg,Writing POJOs using Kite SDK ,XD-994,Thomas Risberg,The HDFS Sink should support writing POJOs to HDFS using Parquet
2748,Janne Valkealahti,Thomas Risberg,"Support for using compression when writing Sequence Files

Either block or record-based compression.
",XD-993,Thomas Risberg,The HDFS Store Library should support compression when writing to Sequence Files
2749,Janne Valkealahti,Thomas Risberg,"Support for writing Sequence Files

Without Compression

Need a means to specify the key/value to be used
",XD-992,Thomas Risberg,The HDFS Store Library should support writing to Sequence Files
2750,Janne Valkealahti,Thomas Risberg,"Need to support writing text in compressed format

should initially support:
 - bzip2
 - LZO",XD-991,Thomas Risberg,The HDFS Store Library should support compression when writing text
2751,Janne Valkealahti,Thomas Risberg,"Support writing lines of text separated by a delimiter

Support writing a CSV (comma-separated variables), TSV (tab-separated variables),

No compression",XD-990,Thomas Risberg,The HDFS Store Library should support writing text with delimiter
2752,,Mark Pollack,This is the inverse of XD-986 and will require creating a custom tasklet but with the input/output reversd.,XD-989,Mark Pollack,Create OOTB batch job that uses the Hadoop Shell to copy multiple files from HDFS to a local directory
2753,Luke Taylor,Mark Pollack,"Same setup as XD-987 for ItemReader and ItemProcessor, but should write to HDFS.  

One can assume that the table structure has been created already external to the batch job execution.",XD-988,Mark Pollack,Create OOTB batch job for export and processing multiple files from HDFS to JDBC
2754,Luke Taylor,Mark Pollack,"The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure
The ItemProcessor will be a no-op groovy script.
The ItemWriter will write the data to a MongoDB collection
** A TupleToDBObject converter will need to be developed.

*the sample job should be documented*",XD-987,Mark Pollack,Create OOTB batch job for export and processing multiple files from HDFS to MongoDB
2755,liujiong,Mark Pollack,"Create a new tasklet implementation that will use the ANT globbing like syntax found in MultiItemResourceReader to specify the input files, and use FsShell to invoke a 'copyFromLocal' command with a specified HDFS output directory.

The batch job would call the tasklet.

*the job should be documented*",XD-986,Mark Pollack,Create OOTB batch job that uses the Hadoop Shell to copy multiple files from a local directory into HDFS
2756,Luke Taylor,Mark Pollack,"Same processing as XD-984, but the job instacne is launched via an event from the input file source.  Supporting a single file per job launch is OK.

> job create blah --definition ""filehdfs""

> stream create csvStream --definition ""file --ref=true --dir=/Users/luke --pattern=*.csv > job:blah""




*the job should be documented*",XD-985,Mark Pollack,Create OOTB 'file to HDFS' batch import job that is launched by a stream.
2757,Luke Taylor,Mark Pollack,"Create a sample batch job for inclusion in the distribution that will perform the following tasks.

ItemReader
* Read a from a directory with multiple files (configurable)
* Support for CSV (assume first line has header values)
* Convert to tuple data structure
ItemProcessor
* Provide groovy based no-op ItemProcessor.  (configurable)
ItemWriter
* Write to JDBC.
** Provide 
** Assume there is an DB instance running somewhere, specify connection info (configurable)

**The sample job should be documented**
",XD-984,Mark Pollack,Create OOTB batch job for import and processing multiple files to JDBC
2758,,Mark Pollack,,XD-983,Mark Pollack,Writing to HDFS - 1.x
2759,,Mark Pollack,,XD-982,Mark Pollack,OOTB batch jobs for common cases
2760,Thomas Risberg,Thomas Risberg,"We used to have a shared guava-11.0.2.jar dependency in the lib dir. That's no longer there so hadoop distros that require this now fail (at least any hadoop 2.0.x based ones)

We should also upgrade to current Hadoop versions (Hadoop 2.2 stable)",XD-981,Thomas Risberg,Missing guava-11.0.2.jar dependency for hadoop distros
2761,,Glenn Renfro,"*Update the Deployer class to add the following methods*
* RunningInstance  deployContainer

* For each of the containers:
** Using XD-977 install distribution
** Setup XD_HOME variable
** Create configurator directory
** Copy the configurator to containers
** Run Configurators
** Verify that configuration files are setup correctly
** start container server
** Report if container started. (using jmx/Jolokia, if available) If it didn't start report failure but continue.
** Report public DNS name of container


* Integration Testing
** Verify that config files have been setup properly
** For each container:
*** Verify container has been started
*** Verify that container is working by creating a stream in admin (trigger|log).  Verify that the log on the container is being updated.

",XD-980,Glenn Renfro,Install XD Container on EC2
2762,Gunnar Hillert,Gunnar Hillert,,XD-979,Gunnar Hillert,Batch Wordcount Sample to use File Source
2763,Glenn Renfro,Glenn Renfro,"* Create a Deployer class has methods
** RunningInstance  deploySingleNode
*** takes into account machine size as specified in properties file
** void  destroyAllInstances()  
*** or whatever JClouds returns from the destroy call
** ctor gets passed in the root boostrapping credentials.
* Install Script Steps
** Setup XD_HOME variable
** Make sure privileges are set to ubuntu not root.
** start up redis and rabbit using ports as specified in xd-ec2.properties
** Use port watch to make sure they started
** Start singlenode after configuration.
** Display hostname of singlenode server
** Report successful and failed startup
** Hit root of xd-admin to see if there is a response on 9393
* Integration Testing
** Verify that config files have been setup
** Verify XD has been started
** Verify XD can process a basic http post

",XD-978,Glenn Renfro,Installer needs to launch a single node XD instance
2764,Glenn Renfro,Glenn Renfro,"* User specifies download distribution zip file from properties file.  See XD-969 for key-value pairs
* Copy the distribution from the shared EBS/S3  the ebs volume assigned to the each node/admin instance  .  
** If not on shared ebs/s3 pull from http site specified by user and put on the shared EBS volume. 
** Unzip the distribution from on the ebs volume for the instance to the /home/ubuntu directory
** make sure privileges are set to ubuntu not root.


How to verify it works
* Create a JUNit style integration test that
** Deletes a known .zip distribution from EBS/S3.
** Invoke the application functionality (should be a 1 liner) that will start up the instance and download the .zip distribution from the URI provided in xd-ec2.properties.  Verify the file is now in EBS/S3 and also on the instance
** Tear down created instance
** Create new instance passing in the same URI of the .zip distribution.  Verify as before
",XD-977,Glenn Renfro,Add functionality to download XD distribution zip to each EC2 instance as specified by user 
2765,Glenn Renfro,Glenn Renfro,"* Create a Spring application context.  (XML or Java, dealers choice…)
* Use XD eclipse code format policy
* Create Source Package structure
* Create Test Package Structure
* Gradle build
* JClouds and Spring deps

",XD-976,Glenn Renfro,Bootstrap Project for XD AWS Installer
2766,,Glenn Renfro,"we need the ability to run an XD cluster to get a handle on general issues and missing features based on running the system in a 'true' clustered environment.  We don’t need to make this an end-user facing feature in the short term, e.g. set a few keys in the shell and then install via a shell command. ",XD-975,Glenn Renfro,Users need the ability to provision an XD cluster on EC2 via command line tool.
2767,liujiong,Thomas Risberg,"Get a java.io.File and copy it into HDFS.  Could be text or binary.

Write compressed with Hadoop and third party codecs 

see: (XD-277, XD-279)

should initially support:
 - bzip2  
 - LZO

",XD-974,Thomas Risberg,The HDFS Sink should support compressing files as they are copied
2768,Glenn Renfro,Glenn Renfro,"Automated test will use directly use the Deployer class
* asserts on basic info of RunningInstance
** check that EBS was mounted
** that application was unzipped
** redis and rabbit are running via port checks

* http requests on admin port for 
** root path
** list of modules
* @AfterClass that will look for the cluster name and terminate all instances
Look at ‘live’ tag in JClouds tests for some additional tactics
",XD-972,Glenn Renfro,Create CI for XD-EC2 project
2769,Glenn Renfro,Glenn Renfro,"*Update the Deployer class to add the following methods *
** RunningInstance  deployAdminServer

* The install script steps:
** Using XD-977 install distribution
** Setup XD_HOME variable
** start up redis and rabbit using ports as specified in xd-ec2.properties on admin server
** Create configurator directory
** Copy the configurator to containers
** Use port watch to make sure they started
** start admin server
** use port watch to make sure the admin started on 9393
** Report if admin server started.  If it didn't start abort install.
** Report public DNS name of admin-server 


* Integration Testing
** Verify XD admin has been started
*** Create a basic stream (trigger>log)and make sure we get a success code from xd admin was received.
*** Query the redis to see if the stream was created.

",XD-970,Glenn Renfro,Install XD admin instance on EC2
2770,Glenn Renfro,Glenn Renfro,"* The Application should 
**  Create a Spring Application Context.
**  Should take a command line parameter --config that will point to a property file with key/value pairs specified below.  By default the file xd-ec2.properties will be looked for on the classpath
** Associate EBS shared volume for each machine instance

* Packaging 
** Use gradle application plugin to generate a ‘bin’ directory with a script to start the application.  Seehttp://www.gradle.org/docs/current/userguide/application_plugin.html
** The config file xd-ec2.properties should be in a directory (ideally a 'config' directory parallel to 'bin' and will be loaded by the application by default - loading via the CP is probably the easiest way.
** Create a POJO to easily reference these properties, vs. using a raw java Properties object.

How to verify it works

* Integration testing
** Create JUnit based tests.  JClouds itself has extensive testing, can look at those for structure.
** Verify what you created has been installed.
** Verify ports are open

Instance Information
** EBS of 50GB Base for each instance.
* Report successful and failed Instances.

Key-Value pairs in configuration file
properties may include: 
* cluster-name= a name describing the cluster you are creating
* aws-access-keys= the access key assigned to you by admin
* aws-secret-key= the secret key assigned to you by admin
* private-key-file= the private key file assigned to you by admin.  Used for ssh-ing into 
* multi-node=true/false if true then installer will run the number of nodes as enumerated in the number-nodes property value.  if false the installer will start a single node server
* number-nodes=The number of nodes(containers) to deploy for this cluster.  Value is an integer > 0
* machine-size=The size of machines to be assigned for admin and nodes.  small, medium, large
* redis-port=6379
* rabbit-port=5279
* xd-dist-url=The url to download the XD to install.  for example: http://blahblahblah.zip
* ami = The ami image to use for your cluster. for example: ami-dfadsfdadf

",XD-969,Glenn Renfro,Add functionality to provision EC2 instance and mount EBS
2771,,Glenn Renfro,"* Logging into your XD Account For Example: https://946513944028.signin.aws.amazon.com/console
* Discuss how to terminate running instances.
** Users can terminate all instances using the UI on the EC2 admin page
* Usage monitoring via CloudWatch
* Investigate what metadata in each instance is required so that cloudwatch can track
",XD-968,Glenn Renfro,Create google doc with instructions on managing EC2 Instances
2772,,Glenn Renfro,"Add instructions to github wiki on the usage of the installer
",XD-967,Glenn Renfro,User requires wiki page on how to use the XD EC2 Installer
2773,Glenn Renfro,Glenn Renfro,"* Setup groups for xd user
* Setup privileges so users can only see their instances
* Setup user accounts
** Send created access key to users
** Send username and passwords to user
",XD-966,Glenn Renfro,User requests that XD team members are issued EC2 accounts
2774,,Mark Pollack,,XD-965,Mark Pollack,Low story point/time improvements or bug fixes that can easily be picked up in a sprint in an ad-hoc manner
2775,,Mark Pollack,,XD-964,Mark Pollack,Support for common use cases using quartz
2776,,Mark Pollack,,XD-963,Mark Pollack,Features and bug fixes for named channels
2777,David Turanski,David Turanski,Currently ./gradlew clean test fails since the module dependencies are not packaged before the test task.  ,XD-962,David Turanski,fix gradle clean test
2778,Eric Bottard,Mark Pollack,"Here is an example:
the following request for streams:
http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams

Returns:
This XML file does not appear to have any style information associated with it. The document tree is shown below.
<errors xmlns:atom=""http://www.w3.org/2005/Atom"">
<error logref=""HttpMessageNotWritableException"">
<message>
Could not marshal [PagedResource { content: [links: [<http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams/ticktock>;rel=""self""]], metadata: Metadata { number: 0, total pages: 1, total elements: 1, size: 20 }, links: [] }]: null; nested exception is javax.xml.bind.MarshalException - with linked exception: [com.sun.istack.SAXException2: unable to marshal type ""org.springframework.xd.rest.client.domain.StreamDefinitionResource"" as an element because it is not known to this context.]
</message>
</error>
</errors>",XD-961,Mark Pollack,Accessing xd-admin URLs in the browser return XML and not JSON
2779,Luke Taylor,Thomas Risberg,"The gradle idea task creates a project configured with source 1.6

This results in compile failures on Java 7 specific code",XD-959,Thomas Risberg,Running gradle idea creates project configured with source 1.6
2780,,Thomas Risberg,"Build fails:

gradle clean build

...

:spring-xd-dirt:test

org.springframework.xd.dirt.stream.FileSourceModuleTests > classMethod FAILED
    java.io.IOException at FileSourceModuleTests.java:53

org.springframework.xd.dirt.stream.FileSourceModuleTests > classMethod FAILED
    java.lang.IllegalArgumentException at FileSourceModuleTests.java:130

328 tests completed, 2 failed, 11 skipped
:spring-xd-dirt:test FAILED

FAILURE: Build failed with an exception.


Looks like it is trying to create a directory under the local filesystem /

java.io.IOException: Unable to create directory /tmpfilesourcetests
	at org.apache.commons.io.FileUtils.forceMkdir(FileUtils.java:2024)
	at org.springframework.xd.dirt.stream.FileSourceModuleTests.createTempDir(FileSourceModuleTests.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:80)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:47)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:49)
	at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:103)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)
	at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:66)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)
",XD-958,Thomas Risberg,Build failure on Ubuntu
2781,Gary Russell,Gary Russell,,XD-957,Gary Russell,Update SI Dependency to 4.0.0.BUILD-SNAPSHOT
2782,Andy Clement,Andy Clement,"We have recently revised the syntax for stream definitions, this issue covers that refactoring.",XD-956,Andy Clement,Refactor DSL parser according to latest syntax proposals
2783,Glenn Renfro,Luke Taylor,This is currently missing and probably supersedes some of the stuff that's in there now.,XD-955,Luke Taylor,"Update Jobs documentation to include ""job launch"" command"
2784,Eric Bottard,Eric Bottard,"Provide the infrastructure for HTTP GET /completions?start='http | file --d"" that would return a list of possible completions (in this case returning the file option names that start with ""d"")

This story is about (and only about):
- Having that REST controller, delegating to some ""CompletionsEngine""
- Implementing the Spring Shell Converter that talks to that

It's an empty shell, useless (but easy to do) without the actual ""CompletionsEngine""",XD-954,Eric Bottard,Stream definition completion REST layer + Shell adapter
2785,Eric Bottard,Eric Bottard,"Module options are currently implemented using PropertySourcesPlaceholderConfigurer, doing simple ""text"" replacements.

This story proposes to introduce a richer model for module options, which could take the following xml representation (keeping in mind that there would be an underlying set of classes that could also apply to e.g. @Configuration approach):

{code:xml}
<xd:params>
  <xd:param name=""port"" help=""the http port to listen on"" />
</xd:params>
{code}

So, the very first obvious benefit is providing help metadata.
The second one is an easy way to list available option names, without resorting to brittle PropertySourcesPlaceholderConfigurer hacks (we wouldn't for example detect xd.stream.name or XD_TRANSPORT as a valid option)

One could also specify defaults/computations, this time benefiting from SpEL everywhere:
{code:xml}
<xd:params>
  <xd:param name=""directory"" default=""headers.directory"" />
</xd:params>
{code}

Lastly, this opens the door to better type checking / combinations / optionality support:
{code:xml}
<xd:params valid=""fixedDelay || cron"">
  <xd:param name=""fixedDelay"" type=""int"" />
  <xd:param name=""cron"" type=""string"" />
</xd:params>
{code}

The 'valid' attribute can e.g. be evaluated by SpEL.

Some final remarks:
- That construct can be compatible with our current approach by behaving as a PropertySource itself (instead of creating a PropertySource, the StreamPlugin would give this new bean the java.util.Properties)
- Plugins could benefit from a hook in that construct and advertise the fact that they expect/provide new options (e.g. --inputType)

There is a slight problem though, which is that if this construct lives in the same AppContext as the module definition itself, then the AppContext needs to be refreshed for the logic to kick in. One could circumvent that using profiles, or we could rely on a different filename convention (e.g. <module>-params.xml)


",XD-953,Eric Bottard,Richer module options metadata
2786,Janne Valkealahti,Brendan Schena,"Basically when I launch the spring-xd shell I can't interact with the namenode I receive security violations despite the fact that I try and set the proper configs. Authentication/Authorization (true/kerberos)

details of this issue can be found here:

http://stackoverflow.com/questions/19258321/the-spring-xd-xd-shell-cant-run-the-hadoop-fs-ls-command-the-command-returns

",XD-952,Brendan Schena,Spring-XD shell can't run commands with kerberized CDH 4.3.0
2787,Ilayaperumal Gopinathan,Mark Pollack,,XD-950,Mark Pollack,Spike for advanced Job Orchestration features
2788,,Mark Pollack,,XD-949,Mark Pollack,Spike for job that exports HDFS CSV data to JDBC
2789,Luke Taylor,Mark Pollack,TBD,XD-948,Mark Pollack,Spike for job that imports data from CSV file to HDFS
2790,Mark Pollack,Mark Pollack,SPI for deployment on to YARN + Local 'dirt' cluster.,XD-947,Mark Pollack,Spike for Deployment SPI
2791,Glenn Renfro,Mark Pollack,,XD-946,Mark Pollack,Spike for EC2 deployments
2792,Thomas Risberg,Mark Pollack,See Epic https://jira.springsource.org/browse/XD-234,XD-945,Mark Pollack,Spike for writing to HDFS
2793,Ilayaperumal Gopinathan,David Turanski,"There are a few obsolete classes lurking around, TypedJsonMapper comes to mind but there are likely some others",XD-944,David Turanski,Clean up unused JSON mapping classes
2794,,Eric Bottard,"If you create a simple ""http | log"" stream and list the modules, you'll see that JobPlugin adds its numberFormat, makeUnique, etc properties.

Even though they do no harm, it's really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",XD-943,Eric Bottard,JobPlugin should not add properties that are not needed
2795,David Turanski,David Turanski,,XD-942,David Turanski,Change repo links in build.gradle repo.spring.io
2796,Eric Bottard,Eric Bottard,"Now that XD-924 is merged, we can convert splunk, twitter and gemfire modules to rely on the newly created projects.

The hadoop module will get its own story, as classpath handling is a bit more tricky for that one.

From there on, no new dependency should be added to DIRT for the sole purpose of a module. Rather, it should directly be created as a CP-aware module and project.",XD-941,Eric Bottard,Convert remaining modules to be CP-aware
2797,Gary Russell,Gary Russell,,XD-940,Gary Russell,Splunk Pulls in an Old SI Jar into STS
2798,,Ilayaperumal Gopinathan,The RuntimeContainersController (from PR#340) returns the list of runtime modules. Instead we need make it pageable.,XD-939,Ilayaperumal Gopinathan,Make Runtime modules listing by ContainerId pageable
2799,Mark Fisher,Ilayaperumal Gopinathan,"With PR#340, listing of runtime modules with a non-existent containerId will display empty table. Instead, we can throw exception saying Container doesn't exist.",XD-938,Ilayaperumal Gopinathan,List runtime modules by wrong containerId should throw exception
2800,Mark Fisher,Ilayaperumal Gopinathan,"Currently, ModulesController creates the ModuleDefinitionRepository instance with ModuleRegistry. Instead, we should inject the moduleDefinitionRepository into ModulesController directly.",XD-937,Ilayaperumal Gopinathan,Inject ModuleDefinitionRepository into ModulesController
2801,,Ilayaperumal Gopinathan,"We need a way to find the runtime module info by module type(""source"", ""sink"", ""processor"", ""job"").
",XD-936,Ilayaperumal Gopinathan,Find runtime modules by type and/or name
2802,David Turanski,David Turanski,Currently TupleCodec uses JSON for serialization/deserialization. It should use Kryo. This will require some customization and potentially changes to Tuple to address the Tuple's conversionService field. ,XD-935,David Turanski,Implement Kryo serialization for Tuple
2803,David Turanski,David Turanski,Register a JSON to Object converter in the DefaultContentTypeAwareConverterRegistry. Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.,XD-934,David Turanski,Support JSON to Object
2804,Eric Bottard,Eric Bottard,"See https://github.com/spring-projects/spring-hateoas/issues/89

Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg https://github.com/spring-projects/spring-xd/blob/4919ea2498a13ef47aaa9437937308fb26a7a24f/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/XDController.java#L219",XD-933,Eric Bottard,Remove work around Spring HATEOAS#89
2805,,Glenn Renfro,"This is cause generally by someone having port 9100(hsqldb port) in use.
It is recommended that setup checks to see if port is in use.  If it is throw an exception stating that hsqldb port (9100) is in use and suggest options like.  Free up the port or change the hsqldb port.",XD-932,Glenn Renfro,Tests Fail because HSQL not started
2806,Mark Fisher,Ilayaperumal Gopinathan,"The runtime module properties requires a format option when displayed in the Shell 

Based on the PR (https://github.com/spring-projects/spring-xd/pull/340), the module properties are stored as String and displayed as is.
",XD-931,Ilayaperumal Gopinathan,Format option to display runtime module properties in shell
2807,,Luke Taylor,"The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded (down) to the resolution of the query (i.e. whole minutes, hours, days or whatever).",XD-930,Luke Taylor,Return rounded interval values from aggregate counter queries
2808,,Glenn Renfro,,XD-929,Glenn Renfro,Remove the Tabulation characters should not be used from Sonar
2809,Eric Bottard,Glenn Renfro,"* In the testmodules.source
** Rename source-config to packaged-source
** Rename source-config to packaged-source-no-lib
* All xml files should be prefixed with test.  i.e. testsource, testsink
* Make sure all tests pass with new configuration",XD-928,Glenn Renfro,Refactor src/test/resources in Dirt
2810,Eric Bottard,Glenn Renfro,"Remove ModuleType.getModuleTypeByTypeName.  All code should use the enum.
",XD-927,Glenn Renfro,ModuleType  Refactor
2811,Gary Russell,Gary Russell,,XD-926,Gary Russell,Update Core Spring Dependency to 4.0.0.M3
2812,Eric Bottard,Eric Bottard,,XD-925,Eric Bottard,Investigate Swagger to generate REST API Documents
2813,Eric Bottard,Eric Bottard,"Similar to what is done for e.g. hadoop, reactor, and http, some of the classes in the .x package (namely gemfire, splunk, twitter) should go in dedicated (albeit small) projects. This would enable further modularization (see XD-915)",XD-924,Eric Bottard,Split integration.x in dedicated XD projects where appropriate
2814,Gary Russell,Glenn Renfro,"As a user, I'd like to be notified when a exception is thrown in a module so that I can tap into an error channel to receive the failures for each stream/module.

",XD-923,Glenn Renfro,Error Channel for streams modules that fail to process a message
2815,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"SingleNode server needs to stop cleanly with stopping both the admin server & container server. 

Also, all the tests that require SingleNode main server needs to handle the server shutdown appropriately.",XD-922,Ilayaperumal Gopinathan,Handle SingleNodeServer's stop()  method cleanly
2816,Glenn Renfro,Eric Bottard,"Not everyone may be familiar with MQTT, or esp. with MQTT inside Rabbit",XD-921,Eric Bottard,"Add more ""hands on"" example to MQTT doco"
2817,Gary Russell,Eric Bottard,"Was attempting to test mqtt, turns out I don't have the proper rabbitmq thing installed. So far so good, I get these kinds of exceptions:
{noformat}
Unable to connect to server (32103) - java.net.ConnectException: Connection refused
	at org.eclipse.paho.client.mqttv3.internal.TCPNetworkModule.start(TCPNetworkModule.java:75)
	at org.eclipse.paho.client.mqttv3.internal.ClientComms$ConnectBG.run(ClientComms.java:521)
	at java.lang.Thread.run(Thread.java:724)
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.eclipse.paho.client.mqttv3.internal.TCPNetworkModule.start(TCPNetworkModule.java:66)
	... 2 more
{noformat}

Problem is, I still get them after undeploying my ""mqtt | log"" stream",XD-920,Eric Bottard,MQTT source module does not cleanly undeploy
2818,David Turanski,David Turanski,json parameter is no longer required. Use --outputType=application/json instead,XD-919,David Turanski,Remove json parameter from twittersearch source
2819,,Eric Bottard,"See also XD-903, XD-915

A lot of dependencies have been added with the ""compile"" scope as an oversight over time. Some of them are only required at runtime, some may not be required anymore.",XD-918,Eric Bottard,Refine project (mainly dirt) dependencies
2820,liujiong,David Turanski,"Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example: 

{noformat:nopanel=true} source   --outputType=my.Foo  | sink --inputType=some.other.Bar   is likely invalid since XD doesn't know how to convert Foo->Bar.  {noformat}",XD-917,David Turanski,Make the parser aware of message conversion configuration
2821,David Turanski,David Turanski,"File source should output either the File itself (serialized File object) or the contents as a byte[]. This option is configured by a parameter --contents=true.  The byte[] may be converted to a String using XD Message Conversion, e.g., --output = text/plain;charset=UTF-8",XD-916,David Turanski,File source should be able to produce file contents or file reference
2822,Eric Bottard,Eric Bottard,"Once XD-887 is merged, gradually convert more modules.

Recipe:
1) Move the <module>.xml file to <module>/config/<module>.xml
2) Declare a :module.<type>.<module> gradle project
3) Move dependencies from dirt project to newly created module project
4) gradle build picks it up.

gradle clean build + manual test
Also have a look at gradle cleanEclipse eclipse",XD-915,Eric Bottard,Convert modules to be CP-aware
2823,,Mark Pollack,"See issue https://jira.springsource.org/browse/XD-862

The docs should be updated to include examples that show how to use the standard 'SpEL' based splitter, transformer, filters with #jsonPath expressions.",XD-914,Mark Pollack,Add documentation for #jsonPath functionality with SpEL based processors
2824,,Thomas Risberg,The XD build breaks with Gradle 1.8 due to some changes in dependency resolution.,XD-913,Thomas Risberg,The XD build breaks with Gradle 1.8
2825,,David Turanski,Users need to register custom message converters used by modules.,XD-912,David Turanski,Support for registering custom message converters
2826,Glenn Renfro,Glenn Renfro,Should keep the critical error count as close to zero as possible.,XD-911,Glenn Renfro,Reduce Sonar Critical Errors 
2827,Glenn Renfro,Glenn Renfro,"Offers the functionality to make http request to a web service. i.e. outbound http gateway.
Example implementations:
stream create --name foo --definition ""trigger |rest --reply-timeout=1 --url=http://earthquake.usgs.gov/earthquakes/feed/geojson/all/day|log""

stream create --name foos --definition ""trigger --payload=lat=34.0567006&lon=-84.34368810000001&site=all&smap=1&searchresult=Roswell%2C%20GA%2030076%2C%20USA#.UktzaWSG1Dd | rest --url=http://forecast.weather.gov/MapClick.php? |log""

",XD-910,Glenn Renfro,Add a Processor for Restful webservices
2828,,Luke Taylor,,XD-909,Luke Taylor,Support additional aggregate counter query options
2829,Luke Taylor,Luke Taylor,"It should be possible to supply a start or end date (or none for the present), plus a ""count"" value for the number of points required (i.e. after or prior to the given time).",XD-908,Luke Taylor,Add aggregate counter query by number of points
2830,Luke Taylor,Luke Taylor,,XD-907,Luke Taylor,Add aggregate counter year resolution query support
2831,Luke Taylor,Luke Taylor,,XD-906,Luke Taylor,Add aggregate counter monthly resolution query support
2832,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"
It looks like Container's ContainerStartedEvent and ContainerStoppedEvent are published from ContainerLauncher's context whereas the ContainerEventListeners are running in XDContainer's context. This makes the container start/stop events not getting processed.
",XD-905,Ilayaperumal Gopinathan,Container start/stop publish events are not getting processed
2833,Kashyap Parikh,Kashyap Parikh,"kparikh-mbpro:spring-xd kparikh$ grep -r 6379 * | grep java
spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/common/RedisRepositoriesConfig.java:			cf.setPort(6379);
spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/integration/GaugeHandlerTests.java:			cf.setPort(6379);
spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/integration/RichGaugeHandlerTests.java:			cf.setPort(6379);
spring-xd-dirt/src/test/java/org/springframework/xd/dirt/listener/RedisContainerEventListenerTest.java:			cf.setPort(6379);
",XD-904,Kashyap Parikh,Fix hardcoded redis port from tests
2834,,Eric Bottard,"The xd-dirt project should be split in at least 3 parts:
 - Classes and resources pertaining to the admin-server
 - Container server
 - Shared classes

Additionally, we may consider splitting the first two in half as well, having a separate project for CLI handling (and hence introduce 2 other projects for YARN, etc)
",XD-903,Eric Bottard,Split xd-dirt in 3 (or 5)
2835,Eric Bottard,Eric Bottard,"Tests that leverage [Redis|Rabbit]AvailableRule often create another connection factory in the test body but fail to close it.

Tests should properly close the resource. As an added benefit, the rule itself can expose the resource that it created for deciding whether to skip the test or not",XD-902,Eric Bottard,Properly close Redis/Rabbit connection factories in tests
2836,Thomas Risberg,Thomas Risberg,"We currently include jetty-util-6.1.26.jar but we need to add correct jar for different distributions - PHD uses jetty-util-7.6.10.v20130312.jar

Need to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro
",XD-901,Thomas Risberg,Wrong Jetty Util on classpath for WebHdfs
2837,Gary Russell,Gary Russell,"When INT-3133 is resolved, SpEL {{PropertyAccessor}} s are inherited from parent contexts.

Instead of adding the {{JsonPropertyAccessor}} to each module's context, add it to the parent instead.",XD-900,Gary Russell,Move SpEL PropertyAccessors to Module Parent Context
2838,Ilayaperumal Gopinathan,Mark Fisher,"currently xd-container will not start due to a DB connection failure if the xd-admin is not already running

In fact, if someone is not using Batch jobs at all with XD, they should not even need a DB connection for either xd-admin or xd-container to run

so... consider using LazyConnectionDataSourceProxy so a connection failure would only occur when the DataSource is actually invoked to retrieve a connection",XD-899,Mark Fisher,xd-container should start even if xd-admin is not running
2839,,Gunnar Hillert,,XD-898,Gunnar Hillert,Create Integration Tests for Batch Notifications
2840,liujiong,Gunnar Hillert,"We should support *java.io.file* payloads in order to support non-textual file and large text file payloads being uploaded to HDFS. 

Currently text file payloads are converted to a text stream in memory and, non-String payloads are converted to JSON first, using an ""object-to-json-transformer"". 

Ultimately we need to support streams such as ""file | hdfs"" where the actually payload being copied to HDFS is not necessarily JSON or textual.

Need to be able to support headers in the message that will indicate which HDFS file the data should be stored in.

",XD-897,Gunnar Hillert,The HDFS Sink should support copying File payloads
2841,David Turanski,David Turanski,"The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application/json or a java class name.",XD-896,David Turanski,Add --inputType and --outputType module parameters
2842,,David Turanski,,XD-895,David Turanski,Stories pertaining to Message Conversion
2843,,Gunnar Hillert,"Currently, for adhoc launching of Batch jobs you have to use:

{code}
stream create --name myTriggerStream --definition ""trigger > job:helloSpringXD""
{code}

For renewed triggering of the job you have to undeploy and then redeploy the job. It would be nice if there was possibly a slightly simpler way of doing this.

Just FYI - As a different approach you can also use the HTTP source:

{source}
job create --name myjob --definition ""myjob""
stream create --name myjobhttp --definition ""http > job:http""
http post --data ""{}""
{source}

",XD-894,Gunnar Hillert,Create an easier short-cut for launching adhoc Batch Jobs 
2844,,Ilayaperumal Gopinathan,"When clicking on a specific job execution from the job executions bar chart, the tool tips display isn't aligned with the job parameters. Please see the attachment.",XD-893,Ilayaperumal Gopinathan,XD UI: Job Parameters tool tips display needs to aligned
2845,Gunnar Hillert,James Williams,"In M3, the batch job behavior has changed. In M2, it was much easier to create an invoke a batch job. In M3, a trigger is required. Figuring that change out isn't a big deal but the behavior of this batch job in M3 throws a stack trace, yet it executes. 

In M2, this same batch job runs fine with no stack trace. 

Logs are attached. I can't see a difference in the container log property files from M2 to M3. Turning the log settings down will suppress the traces, but I was not expecting the traces since they did not show up in M2.

Stream Definitions:

job create --name pdfLoadBatchJob --definition ""batch-pdfload --inputPath='LOCAL_PDF_PATH' --hdfsPath='REMOTE_HDFS_PATH'""


stream create --name pdfloadtrigger --definition ""trigger > job:pdfLoadBatchJob""",XD-892,James Williams,Spring Batch Behavior change from M2 to M3
2846,Ilayaperumal Gopinathan,David Turanski,"For testing, it would be useful to access the deployed Module instances to connect sources and or sinks to a module's input and output channels, etc. This could be a simple as exposing the deployedModuleMap on ModuleDeployer or possibly something more elaborate if this level of granularity is generally useful for runtime administration.",XD-891,David Turanski,Provide a way to access currently deployed modules
2847,Ilayaperumal Gopinathan,Gunnar Hillert,"We probably need to look into some options to run our JavaScript tests (Jasmine) as part of the build process - some possibilities:

* Jasmine Gradle Plugin https://github.com/dzhaughnroth/jasmine-gradle-plugin
* Saga - http://timurstrekalov.github.io/saga/

Looks like Maven has slightly better support: http://searls.github.io/jasmine-maven-plugin/index.html

See also: XD-865",XD-890,Gunnar Hillert,Run JavaScript tests (Jasmine) as part of the build process
2848,Ilayaperumal Gopinathan,Mark Pollack,"This conflicts with and 'out of the box' hadoop installation that uses 8080 as the 'map reduce shuffle port'.

8088 sound ok?

",XD-889,Mark Pollack,Change default admin port from 8080
2849,,Glenn Renfro,,XD-888,Glenn Renfro,Remove org. in hsqldb dependency
2850,Eric Bottard,Eric Bottard,"Currently, a lot of jars that are on the classpath of xd-dirt are there to support modules.
We should move those to the lib/ construct of a module and remove them from the CP of dirt.

But this should not be done by simple ""mv"", as we'd lose version tracking and dependency management offered by gradle.

Pending a ""dependency-aware"" ModuleRegistry, we should be able to alter the build.gradle file so that it
- knows about individual modules (maybe handles them as project)
- copies its libs into the appropriate directory
- does not copy dependencies that are already legitimate dependencies of xd-dirt (this can be achieved by runtime introspection of the dependeny tree of both projects)

",XD-887,Eric Bottard,Package modules with their support jars
2851,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,,XD-886,Ilayaperumal Gopinathan,Fix package tangle between org.springframework.xd.dirt.plugins.job and org.springframework.xd.dirt.job
2852,Ilayaperumal Gopinathan,Gunnar Hillert,"Add Batch Job Listeners Automatically

* Each major listener category should send notifications to own channel (StepExecution, Chunk, Item etc.)
* Add attribute to disallow automatic adding of listeners",XD-885,Gunnar Hillert,Add Batch Job Listeners Automatically
2853,,Glenn Renfro,"If the spring batch database has already been initialized do not re-initialize for each test run.  

",XD-884,Glenn Renfro,Do not initialize spring batch schema on each test run
2854,,Glenn Renfro,In our tests the context is destroyed at the end of each module.  It should be destroyed at the close of the container.,XD-883,Glenn Renfro,Refactor the tests so that contexts are destroyed properly 
2855,Glenn Renfro,Glenn Renfro,"Set the enableJmx to false because contexts are not getting destroyed properly, and in some cases prevents testSystemPropertiesOverridesDefault from running successfully.",XD-882,Glenn Renfro,Disable the JMX setting in SingleNodeMainIntegrationTests.testConfiguration
2856,Andrew Eisenberg,Andrew Eisenberg,"We should consider moving to wire.js to encourage dependency injection in the UI Javascript code.

See here: https://github.com/cujojs/wire/blob/master/docs/get.md",XD-881,Andrew Eisenberg,Introduce wire.js into the XD admin UI
2857,Gary Russell,Gary Russell,,XD-880,Gary Russell,Update Java Version to 7
2858,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the ""data"" directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the ""data"" directory after each test completion.",XD-879,Ilayaperumal Gopinathan,Cleanup hsqldb data directory used by tests after each test completion
2859,Gary Russell,Jennifer Hickey,"The SI JMX MBeanExporter proxies the output channel created in a module context when JMX is enabled. We have to unwrap the proxy in StreamPlugin in order to add the tap. XD-877 temporarily introduced this code, but a more elegant solution is called for. Perhaps this will involve SI making addInterceptor an interface method.",XD-878,Jennifer Hickey,Remove code in StreamPlugin to extract target output channel from proxy
2860,Jennifer Hickey,Jennifer Hickey,"When JMX is enabled, the Module's output channel processed by StreamPlugin is a Proxy. Thus it fails the ""instanceof"" test used to apply the WireTap to the output channel. ",XD-877,Jennifer Hickey,Taps do not work when JMX is enabled
2861,,James Williams,"Spring batch workflows are great for complex hadoop operations but if I want to create a simple processor that executes some hadoop fs in groovy, it would be nice to do this:

{code}
<service-activator output-channel=""output"" input-channel=""input"">
   <hadoop:script id=""loadScript"" language=""groovy"">
	 def outputPath = ""${hdfsPath}""	
	 fsh.put(""-"", outputPath)  
   </hadoop:script>
</service-activator>
{code}

The goal of this hadoop script is to use in a stream like this:""file | script"" that puts a file byte for byte to hdfs. An enhanced hdfs sink that's optimized for binary data like images/pdfs might be more elegant but I was hoping that this would work. This script gets ignored by Spring XD. But even if it didn't, I am not sure the ""-"" stdin put would work as hoped. ",XD-876,James Williams,Create FsShell based module to copy a File to HDFS
2862,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"The admin Server's tomcat is not shutdown properly. There is an existing method shutdownCleanly() on AdminServer but the spring-xd-shell tests hang when we use this method to shutdown the admin server. 
",XD-875,Ilayaperumal Gopinathan,Handle AdminServer shutdown cleanly
2863,Luke Taylor,Gunnar Hillert,"It looks like we don't handle deletion of source files currently. We should provide some support for that - Maybe there is a way to into Spring Integration's PseudoTransactionManager support:

http://docs.spring.io/spring-integration/api/org/springframework/integration/transaction/PseudoTransactionManager.html

The *File Source* should possibly also support File archival functionality (But that might also be a dedicated processor?). Not sure where we want to set the semantic boundaries for the File Source.
",XD-874,Gunnar Hillert,"For file based item reader jobs, step/job completion message should have name of file sent on named channel"
2864,,Gunnar Hillert,"This story may need to be broken into several stories

Particularly for Batch scenarios one may not want to run a ""file-to-string-transformer"" on the payload file in the file source but rather handle/pass the file reference itself (local SAN etc.) - e.g. in case somebody drops a 2GB or in scenarios where one wants to push those large files into HDFS and run hadoop jobs on the data.

This is important for Batch Jobs as they need to access the file itself for the reader. 

We need to *keep in mind the various transports we support*. Not sure how Kryo handles file serialization. I would think we only need the File Meta Data to be persisted not the file-data itself (make that configurable??).
",XD-873,Gunnar Hillert,File Source - Provide option to pass on File object
2865,,Gunnar Hillert,"Just wanted to create story for this - so we can consider whether this should be addressed.

In at least 2 modules we use non-persisted states. We may want to consider making them persistent:
 
*Twitter Search* uses an in-memory *MetadataStore* that keeps track of the twitter ids. There exists a corresponding issue for Spring Integration:

""Create a Redis-backed MetadataStore""
See: https://jira.springsource.org/browse/INT-3085

*File Soure*'s File Inbound Channel Adapter uses a AcceptOnceFileListFilter, which uses an in-memory Queue to keep track of duplicate files.

",XD-872,Gunnar Hillert,Make in-memory meta data stores persistent
2866,David Turanski,Gunnar Hillert,"2 issues exist:

1) 

Current this does not create an error in the shell

{code}
stream create --name s1 --definition ""http | log""
stream create --name s2 --definition ""http | log""
{code}

On the server-side I see:

{code}
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:344)
	at sun.nio.ch.Net.bind(Net.java:336)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:199)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.jboss.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:366)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:290)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	... 3 more
{code}

2)
The Stream should not be saved to the StreamDefinitionRepo in case of an error.

",XD-871,Gunnar Hillert,No errors in Shell when creating stream with HTTP Source + already used port 
2867,Glenn Renfro,Mark Pollack,"Commands that pair up with the functionality described in XD-859

module list  (would list all modules in a table format)
module list --type=source  (would list only source modules)

and so on.",XD-870,Mark Pollack,Support for listing of modules in the Shell
2868,,Glenn Renfro,"i.e.  http | group1: filter | group1: transform | file 

then specifying anything labelled group1 goes to machineX",XD-869,Glenn Renfro,Colocate Modules using labels.
2869,Jon Brisbin,Mark Pollack,"We need to verify that we are seeing improved throughput when using the reactor based syslog adapter.  

A suggestion on a basic stream to perform a microbenchmark this would be using in-memory counters, singlenode with the stream definition ""syslog | counter"".

Based on the results of this microbenchmark, other stories may need to be created.",XD-868,Mark Pollack,Create microbenchmark performance test of reactor syslog adapter vs standard syslog adapter
2870,,Glenn Renfro,Parser creates a module compose command that allows a user to create a module of other modules.  This composed module can accept parameters.,XD-867,Glenn Renfro,Support the ability for a user to create composite modules that can accept parameters
2871,Glenn Renfro,Glenn Renfro,Get rid of all the thread.sleeps and code that supported them.,XD-866,Glenn Renfro,Remove remaining Thread.sleeps from the job tests
2872,,Andrew Eisenberg,The admin-ui currently has no unit tests.  Need to add a test suite and hook it up to the build so that tests are run on every build.,XD-865,Andrew Eisenberg,Add a test suite to the admin-ui
2873,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,We need to move the BatchJobExecutionsByJobName method to BatchJobsController as that seems appropriate,XD-864,Ilayaperumal Gopinathan,Move BatchJobExecutionsByJobName to BatchJobsController from BatchJobExecutionsController
2874,Gunnar Hillert,Mark Pollack,Needs some investigation on how the update information from Spring Batch listeners can be sent as a message across modules in a single node configuration as well as across JVMs in a distributed node configuration.,XD-863,Mark Pollack,Serialization of Spring Batch Context Objects
2875,Mark Fisher,Mark Pollack,"Similar to xpath with XML, there are now some initial support in SI that enable the use of filter/routers based on JSON Path expressions.  That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router/filter modules could use JSON Path.  json-path-filter/router are components that need to be created, perhaps others.

This story needs to be broken down further.",XD-862,Mark Pollack,First class JSON Path support
2876,,Mark Pollack,"This story will need to be broken down further.

The current code mixes together the type conversion that happens within a single JVM (for data that is passed on a local transport between modules) and serialization/deserialization between JVMs.  This should be separated.

There was a suggestion that we could perhaps use typed data channels in SI as a means implement the type conversion between modules.  The media-type conversion support in Spring 4 is another part of this solution.",XD-861,Mark Pollack,Type Conversion across modules
2877,Glenn Renfro,Mark Pollack,"From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors.  A brief description of them would also be nice - this might come from adding some metadata into the definition.

Finer grained description/implementation suggestion TBD",XD-859,Mark Pollack,Support for listing of modules in the REST API
2878,Jennifer Hickey,Jennifer Hickey,,XD-858,Jennifer Hickey,Upgrade to Spring Data Redis 1.1.0.RELEASE
2879,Eric Bottard,Eric Bottard,"Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems/locations. (HDFS /HTTP)",XD-857,Eric Bottard,"Refactor FileModuleRegistry as ""ResourceModuleRegistry"""
2880,Eric Bottard,Eric Bottard,"Similar to what has been done for e.g. FileSink, refactor metrics related sinks to use smart Thread.sleep() timings",XD-855,Eric Bottard,Change metrics assertions in integration tests to use smart Thread.sleep
2881,Jennifer Hickey,Eric Bottard,"The doc at http://docs.spring.io/spring-xd/docs/1.0.0.M3/reference/html/#_modules_and_spring refers to an old version of the counter sink, when it was still hardwired to use redis.
The text next to it that explains placeholders is out of date (with respect to the redis placeholders)",XD-854,Eric Bottard,Update doc about modules and spring
2882,,Gunnar Hillert,"Add serialVersionUID to the objects in package
org.springframework.integration.x.twitter:

* XDEntities
* XDUrlEntity
* XDHashTagEntity
* XDMentionEntity
* XDMediaEntity
* XDTickerSymbolEntity
* XDTweet

The absence creates warnings during compile time.",XD-853,Gunnar Hillert,Add definition of serialVersionUID to Twitter classes
2883,,Glenn Renfro,"Wildcard support for associating inbound and outbound channels with modules.  
The wild card will be represented by an asterisk '*'.
Example:

myEmailSource > tap:job:*	send message to all jobs
myEmailSource > tap:*		send message to all stream/job taps
myEmailSource > :*foo*		send message to all channels that contain the channels that contains the word 'foo'
tap:*bar > myEmailSource

",XD-852,Glenn Renfro,DSL needs to have wildcard support for taps
2884,,Glenn Renfro,"The syntax for both taps and job channels will be prefixed with the word tap.
* The parser will search both the all (stream and job for now) registries to find the ""name"".  
* If the name is present in only in one registry then that definition will be used.  
* If the name is  present both registries a syntax exception will be issued.
   - The user then can optionally specify which registry to use by adding a second token to the definition that specifies the type of channel the user wants.
	- i.e. 	tap:{stream}:streamName > mySink
* If the user attempts to place a job on the greater (left hand) side without specifying a notification a syntax error will be thrown.
Format: 
-- tap:[type]:name > $
-- $ > tap:[type]:name  
-- Example:
   tap:streamName >mySink
   tap:stream:streamName > mySink
   mySource|myProcessor > tap:stream:mySink
   myEmailSource > tap:job:jobName.step1
   myEmailSource > tap:jobName.step1
   tap:job:jobName-notifications > myEmailSink",XD-851,Glenn Renfro,Refactor DSL for Taps and Jobs Usage
2885,,Thomas Risberg,"Looks like there are some version mismatch issues with the build/packaging of the XD components. Looking in xd/lib I see the following which looks suspicious:

mqtt-client-0.2.1.jar
mqtt-client-1.0.jar

jackson-core-asl-1.9.13.jar
jackson-mapper-asl-1.9.12.jar

spring-integration-core-3.0.0.M3.jar
spring-integration-http-2.2.5.RELEASE.jar

spring-data-commons-1.6.0.M1.jar
spring-data-commons-core-1.4.0.RELEASE.jar
",XD-850,Thomas Risberg,JAR version mismatches
2886,David Turanski,David Turanski,The gemfire modules currently accept server host and port. Provide an option to specify a locator host and port,XD-849,David Turanski,Gemfire modules should support connection via locator
2887,,Will McQueen,"The README.md at:

  https://github.com/spring-projects/spring-xd/blob/master/README.md

...says:

""Before we accept a non-trivial patch or pull request we will need you to sign the contributor's agreement""

Navigating to the <contributor's agreement> link takes the user to the ICLA web page at:

https://support.springsource.com/spring_committer_signup

//exp: The Project field's dropdown should have an option for ""Spring XD""
//act: There's no ""Spring XD"" option",XD-848,Will McQueen,ICLA website is missing Spring XD project option
2888,Thomas Risberg,Thomas Risberg,"We should adjust our --hadoopDistro options to the ones supported in the new spring-data-hadoop 1.0.1.RELEASE - hadoop12 (default), cdh4, hdp13, phd1, hadoop20

This includes updating the wiki pages",XD-847,Thomas Risberg,Revise the available hadoopDistro options
2889,,Glenn Renfro,Tap '@' and using numbers instead of module names.,XD-846,Glenn Renfro,Remove deprecated tap syntax from the parser.
2890,,Glenn Renfro,"When using jobs, taps we no longer need to have the leading :.  i.e. :tap:foo.  We should only support tap:foo.",XD-845,Glenn Renfro,Remove support for the leading : on items that have a declared namespace
2891,Eric Bottard,Eric Bottard,"As part of running in Cloud Foundry, one quick workaround for the lack of ""classpath"" support would be to use the Spring Boot Loader special ClassLoader and jar-inside-a-jar support: https://github.com/spring-projects/spring-boot/tree/master/spring-boot-tools/spring-boot-loader",XD-844,Eric Bottard,Enable Spring Boot Loader support
2892,Dave Syer,Eric Bottard,"First take on this involves
- being able to deploy the two separate applications: xd-admin & xd-container
- being able to CF-service provided redis & rabbit for internal needs of XD
- to some extent, make modules smart and CF aware (e.g. http source uses correct port)",XD-843,Eric Bottard,Initial XD on CloudFoundry support
2893,Thomas Risberg,Thomas Risberg,"Add back ""classifier = 'dist'"" to distZip build target - it was was accidentally removed.",XD-842,Thomas Risberg,Add back classifier = 'dist' to distZip build target
2894,,Tobias Flohre,"Like just discussed after the Spring One session, it would be nice to have a packaging model for custom modules. Instead of putting all libs in one directory and an XML in another, it could be a fat jar including some metadata file pointing to either an XML or to a JavaConfig configuration class inside the jar.
Some more words why I think it's important to have something like that:
Spring XD can be very well used in the enterprise, and at least for job modules it's likely to have some dependencies. So what do you have to do now to deploy such a module? Build a jar with your build process, then get it from your repository, unpack it and somehow find the relevant XML to copy it into the appropriate folder, then inspect the POM to find out what all the dependencies are, direct and transient, and get them from your repository to copy them into the appropriate folder. And of course, copy the jar. And when using Spring XD in distributed mode, you have to do it several times.
With the approach mentioned above you just build your fat jar with your build process and distribute it to all your nodes, nothing complicated.

And if you implement it like that it's easy to have a JavaConfig support that's almost the same.",XD-841,Tobias Flohre,Create a packaging model for custom modules
2895,Patrick Peralta,Gary Russell,"As of M3...

{code}
javadoc: warning - Error fetching URL: http://static.springsource.org/spring-shell/docs/current/api/package-list
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/CompositeModuleRegistry.java:40: warning - @param argument ""cp"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/CompositeModuleRegistry.java:40: warning - @param argument ""file"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/JobFactoryBean.java:62: warning - Tag @link: can't find jobName in org.springframework.xd.dirt.plugins.job.JobFactoryBean
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/XDController.java:56: warning - @param argument ""<V>"" is not a type parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/XDController.java:56: warning - @param argument ""<T>"" is not a type parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/BatchJobAlreadyExistsException.java:32: warning - @param argument ""message"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/BatchJobLocator.java:32: warning - @DistributedJobService is an unknown tag.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/BatchJobLocator.java:32: warning - @DistributedJobService is an unknown tag.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/NoSuchBatchJobException.java:31: warning - @param argument ""message"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/ContainerOptions.java:30: warning - @param argument ""defaultTransport"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/ContainerOptions.java:30: warning - @param argument ""defaultAnalytics"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/OptionUtils.java:35: warning - @return tag has no arguments.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/Plugin.java:32: warning - Tag @see: reference not found: ModuleDeployer
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/MessageBus.java:53: warning - @param argument ""moduleInputChannel"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/MessageBus.java:72: warning - @param argument ""moduleOutputChannel"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/MessageBus.java:102: warning - @param argument ""moduleOutputChannel"" is not a parameter name.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-reactor/src/main/java/org/springframework/xd/integration/reactor/config/ReactorNamespaceUtils.java:46: warning - @return tag has no arguments.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/BatchJobLocator.java:32: warning - @DistributedJobService is an unknown tag.
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/BatchJobLocator.java:32: warning - @DistributedJobService is an unknown tag.
{code}

and

{code}
warning: [options] bootstrap class path not set in conjunction with -source 1.6
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/LocalMessageBus.java:132: warning: [rawtypes] found raw type: LocalMessageBus.SharedChannelProvider
		SharedChannelProvider channelProvider = aliasHint ? queueChannelProvider
		^
  missing type arguments for generic class LocalMessageBus.SharedChannelProvider<T>
  where T is a type-variable:
    T extends AbstractMessageChannel declared in class LocalMessageBus.SharedChannelProvider
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/LocalMessageBus.java:159: warning: [rawtypes] found raw type: LocalMessageBus.SharedChannelProvider
		SharedChannelProvider channelProvider = aliasHint ? queueChannelProvider
		^
  missing type arguments for generic class LocalMessageBus.SharedChannelProvider<T>
  where T is a type-variable:
    T extends AbstractMessageChannel declared in class LocalMessageBus.SharedChannelProvider
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDEntities.java:93: warning: [rawtypes] found raw type: List
	public List getUrls() {
	       ^
  missing type arguments for generic class List<E>
  where E is a type-variable:
    E extends Object declared in interface List
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDEntities.java:101: warning: [rawtypes] found raw type: List
	public List getHashTags() {
	       ^
  missing type arguments for generic class List<E>
  where E is a type-variable:
    E extends Object declared in interface List
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDEntities.java:109: warning: [rawtypes] found raw type: List
	public List getMentions() {
	       ^
  missing type arguments for generic class List<E>
  where E is a type-variable:
    E extends Object declared in interface List
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDEntities.java:117: warning: [rawtypes] found raw type: List
	public List getMedia() {
	       ^
  missing type arguments for generic class List<E>
  where E is a type-variable:
    E extends Object declared in interface List
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDEntities.java:126: warning: [rawtypes] found raw type: List
	public List getTickerSymbols() {
	       ^
  missing type arguments for generic class List<E>
  where E is a type-variable:
    E extends Object declared in interface List
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDEntities.java:37: warning: [serial] serializable class XDEntities has no definition of serialVersionUID
public class XDEntities implements Serializable {
       ^
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDUrlEntity.java:31: warning: [serial] serializable class XDUrlEntity has no definition of serialVersionUID
public class XDUrlEntity implements Serializable {
       ^
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDHashTagEntity.java:32: warning: [serial] serializable class XDHashTagEntity has no definition of serialVersionUID
public class XDHashTagEntity implements Serializable {
       ^
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDMentionEntity.java:32: warning: [serial] serializable class XDMentionEntity has no definition of serialVersionUID
public class XDMentionEntity implements Serializable {
       ^
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDMediaEntity.java:32: warning: [serial] serializable class XDMediaEntity has no definition of serialVersionUID
public class XDMediaEntity implements Serializable {
       ^
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDTickerSymbolEntity.java:31: warning: [serial] serializable class XDTickerSymbolEntity has no definition of serialVersionUID
public class XDTickerSymbolEntity implements Serializable {
       ^
/Users/gpr/Documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/XDTweet.java:34: warning: [serial] serializable class XDTweet has no definition of serialVersionUID
public class XDTweet implements Serializable {
       ^
{code}",XD-840,Gary Russell,Fix Compiler Warnings
2896,Eric Bottard,Eric Bottard,,XD-839,Eric Bottard,Close parent contexts when shutting down
2897,,Gunnar Hillert,,XD-838,Gunnar Hillert,Refactor out Trigger docs from the Batch Job chapter
2898,Andrew Eisenberg,Andrew Eisenberg,"In the XD UI, the list of jobs is refreshed from the server every 5 seconds.  There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive (ie- they remain on the page and don't disappear) after the list of jobs is refreshed.",XD-837,Andrew Eisenberg,Tipsy tooltip hovers are not responsive after jobs list is refreshed from server
2899,,Glenn Renfro,,XD-836,Glenn Renfro,Harden the requirements for the  DSL and refactor accordingly.
2900,,Gunnar Hillert,"http://localhost:8080/metrics/field-value-counters

{code}
<errors xmlns:atom=""http://www.w3.org/2005/Atom"">
<error logref=""HttpMessageNotWritableException"">
<message>
Could not marshal [PagedResource { content: [links: [<http://localhost:8080/metrics/field-value-counters/hashtags>;rel=""self""]], metadata: Metadata { number: 0, total pages: 1, total elements: 1, size: 0 }, links: [] }]: null; nested exception is javax.xml.bind.MarshalException - with linked exception: [com.sun.istack.SAXException2: unable to marshal type ""org.springframework.xd.rest.client.domain.metrics.MetricResource"" as an element because it is not known to this context.]
</message>
</error>
</errors>
{code}",XD-835,Gunnar Hillert,REST - Listing of FieldValueCounter not working
2901,,Ilayaperumal Gopinathan,"There are couple of issues here:

1) The admin server destroy() - close event's onApplicationEvent(ContextClosedEvent) listener has stop() to stop the admin server's tomcat instance. The stop() also calls the applicationContext's destroy() which loops again to stop.

2) With HSQLServer or any batch db server(in future), the admin server stop() also needs to handle the batch db server shutdown.",XD-834,Ilayaperumal Gopinathan,Handle XD admin server shutdown cleanly
2902,liujiong,Jennifer Hickey,"Currently this works:
stream create foo --definition ""tap:baz.time > log""
stream create baz --definition ""time | file""

But this doesn't:
stream create foo --definition ""tap:baz > log""
stream create baz --definition ""time | file""

This is because the parser translates references to ""tap:baz"" to named channel ""tap:baz.time"" (the name of the stream's first module). If the stream is not yet created, the parser cannot perform this translation. A fix for this will likely be related to the fix needed for XD-812.",XD-833,Jennifer Hickey,Allow tapping a stream prior to stream creation without specifying module name
2903,Jennifer Hickey,Mark Fisher,"Now that taps are just channels, we need to update the docs.

The preceding colon is no longer needed (and will be removed altogether), so all examples should be like this:

{code}
tap:foo > bar
{code}

",XD-832,Mark Fisher,Update docs for new Tap syntax
2904,Eric Bottard,Mark Fisher,,XD-831,Mark Fisher,Update docs to cover Module config and lib directory structure
2905,Andrew Eisenberg,Andrew Eisenberg,"Currently, the way that we are accessing JobExecutions from batch admin, the JobParameters are not being filled in.  We are using a {{org.springframework.batch.admin.service.JdbcSearchableJobExecutionDao}} to grab the job executions from the database. The database queries that it uses does not include the JobParameters (which is stored in a different table).

I think that this will require a change to batch admin in order to properly expose the parameters.",XD-830,Andrew Eisenberg,Expose Job parameters for JobExecutions
2906,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,We also would like to upgrade the hsqldb version on spring batch admin so that both are compatible.,XD-829,Ilayaperumal Gopinathan,Upgrade hsqldb version on XD batch admin to the latest
2907,Mark Fisher,Mark Fisher,"org.springframework.integration.x.bus.Bridge should now be called Binding

we can also move the INBOUND/OUTBOUND direction (or possibly the CONSUMER/PRODUCER role) into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of ""in"" and ""out"" as Strings in that same code",XD-828,Mark Fisher,rename Bridge to Binding and add direction
2908,David Turanski,David Turanski,"Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly (e.g., zero arg constructor). The twittersearch module should have a parameter --json true/false (default true) to control the output type.",XD-827,David Turanski,provide a property on twittersearch to enable the object-to-json transformer
2909,,Mark Pollack,"org.springframework.xd.shell.command.MailCommandTests in spring-xd-shell project.

I get failures relating to invalid username/password

INFO: Stream Name Stream Definition Status ----------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -------- mailstream imap --port=1044 --protocol=imap --folder=INBOX --username=johndoe --password=secret | file --dir=/tmp --name=FileSink1280066074228960855 --suffix=txt --charset=UTF-8 --binary=false deployed 13/09/04 11:32:11 WARN mail.ImapIdleChannelAdapter: error occurred in idle task javax.mail.AuthenticationFailedException: LOGIN failed. Invalid login/password at com.sun.mail.imap.IMAPStore.protocolConnect(IMAPStore.java:663) ",XD-826,Mark Pollack,Investigate failing tests in MailCommandTest
2910,Mark Pollack,Mark Pollack,"<int:channel id=""input""/>
<int:object-to-json-transformer input-channel=""input"" output-channel=""output""/>
<int:channel id=""output""/>",XD-825,Mark Pollack,Create object-to-json transformer processor
2911,Mark Fisher,Mark Fisher,"My current thinking is...

   ChannelRegistry -> MessageBus
   RabbitChannelRegistry -> RabbitMessageBus
   ...

Then, method names change like so:

   createInbound -> registerConsumer
   createOutbound -> registerProducer


",XD-824,Mark Fisher,Rename ChannelRegistry
2912,David Turanski,David Turanski,If true(default): filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.,XD-823,David Turanski,add discardDeletes property to twitterstream source
2913,Luke Taylor,David Turanski,When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp,XD-822,David Turanski,TupleBuilder.fromString() should not overwrite original id and timestamp fields
2914,Andrew Eisenberg,Andrew Eisenberg,"Currently, the url for accessing the XD UI is {{http://localhost:8080/admin-ui/index.html}}.  This feels messy and dated.  We should be able to access the ui without explicitly including the index.html, like this:

{code}
http://localhost:8080/admin-ui
{code}

",XD-821,Andrew Eisenberg,Change url to access UI from browser
2915,Glenn Renfro,Glenn Renfro,,XD-820,Glenn Renfro,Jobs and taps should not require a leading : since they have name spaces.
2916,,Ken Kruger,Would be nice to have a ServiceActivator Processor available so that if one had an existing Spring bean they could simply describe the bean id and method name - without going through the full complexity of creating a processing module.,XD-819,Ken Kruger,Add Service Activator Processor
2917,Andrew Eisenberg,Andrew Eisenberg,"The admin UI should be polling the server to automatically pick up any new jobs, executions, and instances.",XD-818,Andrew Eisenberg,UI should poll server for latest on job info
2918,Andrew Eisenberg,Andrew Eisenberg,"A user should be able to view some important details of the last execution of a job from a job list.  The {{/batch/jobs}} REST endpoint should provide extra fields not currently available in the {{JobInfo}} class.

At a minimum, I would like to see:

* startTime
* startDate
* last job parameters
* duration
* last job status",XD-817,Andrew Eisenberg,REST API for job listing should provide details on last execution 
2919,Andy Clement,Andy Clement,"Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time, rather than deploy time.  By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.",XD-816,Andy Clement,Support for composed streams
2920,,Mark Pollack,"Once spring-batch-admin 1.3.0.M1 is available, update the build to use it.  Likely to be Sept 7 or 9",XD-815,Mark Pollack,Updgrade to use spring-batch-admin 1.3.0 M1 when available
2921,,Andrew Eisenberg,"Now that the new batch admin api is taking shape, we need to rebase the XD web UI to use this.  It's more than just changing the http urls sent to the xd server since the new API is not identical to the old one.",XD-814,Andrew Eisenberg,Rebase UI on top of new batch admin API
2922,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"When an XD job is destroyed/deleted, the batch jobRepository entries for the job (associated JobInstances, JobExecutions etc.,) and the BatchJobLocator entries.",XD-813,Ilayaperumal Gopinathan,Destroying XD job should remove job's entries at batch job repositories/batch job locator
2923,Luke Taylor,Jennifer Hickey,"As of XD-685, we no longer have the ability to:
1) Tap a named channel, ala stream1=:foo > sink stream2= :tap:foo > sink
2) Tap a stream whose source is a named channel ala stream2=:tap:stream1 > sink
3) Tap a label ala stream1=http | obfuscator: transform --expression=payload.replaceAll('password','*') | file stream2=:tap:stream1.obfuscator > sink

Loss of named channel support is due to the fact that we are creating a WireTap on a module's local output channel only (thus we never tap named channels). We are not supporting labels because we only create a named channel called ""tap:stream.module"" on stream creation, so later creation of tap on stream1.obfuscator is referring to a non-existent named channel.",XD-812,Jennifer Hickey,Re-enable support for tapping labels and named channels
2924,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"We need a REST endpoint to launch a job.

Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller/service to launch the job.

One possible way is to use the trigger source to launch the job at XD.",XD-811,Ilayaperumal Gopinathan,Add REST endpoint for launching Job
2925,Jennifer Hickey,Jennifer Hickey,"The following sequence results in ""Dispatcher has no subscribers"" error  (stack trace below), because deleting stream2 disconnects stream1 from the foo channel. Current work on XD-685 has infrastructure for disconnecting just the channels involved in a stream, so should make it easier to fix this issue once merged. 

stream create stream1 --definition ""time > :foo""
stream create stream2 --definition ""http > :foo""
stream create stream3 --definition "":foo > file""
stream destroy stream2
// expect file sink to still get time, but instead blows up b/c
// deleteOutbound(""foo"") killed links b/w foo and both local output channels

Server stack trace:
10:47:11,921 ERROR task-scheduler-6 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time, type=source, group=stream1, index=0].output'.
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:680)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 24 more

10:47:12,924 ERROR task-scheduler-6 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time, type=source, group=stream1, index=0].output'.
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:680)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 24 more

10:47:13,926 ERROR task-scheduler-4 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time, type=source, group=stream1, index=0].output'.
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:680)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 24 more

10:47:14,928 ERROR task-scheduler-4 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time, type=source, group=stream1, index=0].output'.
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:680)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 24 more

10:47:15,930 ERROR task-scheduler-1 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time, type=source, group=stream1, index=0].output'.
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)
	at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
",XD-810,Jennifer Hickey,Deleting a stream with reference to named channel disconnects channel from all streams
2926,Janne Valkealahti,Janne Valkealahti,"We should provide a better shell integration when XD is run on Yarn.

1. yarn kill --id TAB completion
2. yarn submit, more options like app name
3. yarn list, filter by app states, etc
4. admin config server TAB completion for running xd apps on yarn",XD-809,Janne Valkealahti,Shell integration with XD on Yarn
2927,Thomas Risberg,Thomas Risberg,"This might mean we should adjust our hadoopDistro options to the ones supported in the new release - hadoop12 (default), cdh4, hdp13, phd1 and hadoop21",XD-808,Thomas Risberg,Update to spring-data-hadoop 1.0.1.RELEASE
2928,,Gunnar Hillert,"The parameters are not optimal for the counter name between ""Aggregate Counter"" ""Field Value Counter""

--counterName versus --name",XD-807,Gunnar Hillert,Shell: Standardize counter name parameter
2929,Eric Bottard,David Turanski,"Currently it's possible to do something like 
{code}
  http --prot=8888
{code}

It is possible to validate property names by parsing the module definition file(s) directly and matching property placeholders (or profile declarations that may be mapped to properties, etc). This must account recursively for imports as well. (I have some code in a branch that does this). 
",XD-806,David Turanski,Validate module properties
2930,,Gunnar Hillert,"For testing purposes it would be super-helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to ""Thread.sleep"".",XD-805,Gunnar Hillert,"Get notified when created named channel ""is ready"""
2931,David Turanski,Gunnar Hillert,"We need an abstraction in place to retrieve messages from a ""named channel"" programmatically.

Right now there is no implementation agnostic way of doing this (such as receiveMessage(), queueSize()).

This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to ""temp-files"" and non-essential sinks or sources etc. - e.g. 

{code}
:routeit > router --expression=payload.contains('a')?':foo':':bar'
{code}",XD-804,Gunnar Hillert,Add Named Channel API
2932,Glenn Renfro,Glenn Renfro,"This is to set the appropriate data source, so that the container will use admins batch repository.",XD-803,Glenn Renfro,Batch Jobs need container & admin profiles
2933,,Eric Bottard,,XD-802,Eric Bottard,Document splitter & aggregator processors
2934,,Ilayaperumal Gopinathan,"Based on the PR discussion: https://github.com/SpringSource/spring-xd/pull/270#commitcomment-4003291

We need to consider turning on multiline mode for pattern matching.",XD-801,Ilayaperumal Gopinathan,Turning on Regex Pattern multiline mode in JsonStringToObjectTransformer
2935,Glenn Renfro,Glenn Renfro,"Job channels need to have a namespace.  
i.e. job-somejobname.  Where the - is the delimiter for the namespace.  
The preference is to use the : instead of the -.  But XD-766 needs to be completed in order to support this.",XD-800,Glenn Renfro,Job channels need to denote a namespace
2936,Luke Taylor,Mark Pollack,"The current rabbitmq sink uses the attribute routing-key, which defaults to the name of the stream.  This should be change to use the attribute routing-key-expression so that the routing-key can be determined using SpEL.  This will enable a dynamic evaluation of the routing-key based on message payload/header.

*Implementation Suggestions*

This hopefully should be changing the XML description of the sink to 		

routing-key-expression=""${routingKey:'${xd.stream.name}'}

This way, the ${xd.stream.name} is surrounded by a single quote to indicate a string literal to SpEL in the default case.  

*How to verify it works.*

One of the simple uses of this is to create a routing key based on payload.  In a distributed word-count example, the hashcode of a word would be sent to a certain number of processing modules that would perform the count. The idea is that the same word is sent to the same node over and over again, in particular if in-memory counters or state is computed - using centralized redis counters this wouldn't be necessary in the case of only counter state.

The stream 

http | rabbit --routingKey=""'word-' + payload.hashCode() % 3""

is an example of a stream that can be used to verify that messages published to a direct exchange will have routing keys of the value word-0, word-1, and word-2.  Binding a queue to each of these routing keys, one can observe the contents of messages in the queue to make sure that words are being routed to the appropriate queue, e.g. publishing ""hello"" as the payload of an http request should always appear in the same queue.  The rabbitmq admin console can be used for this purpose.
",XD-799,Mark Pollack,Change rabbitmq sink to use routing-key-expression instead of routing-key
2937,Eric Bottard,Eric Bottard,,XD-798,Eric Bottard,Add support for ( ) grouping in Parser
2938,Gunnar Hillert,Gary Russell,https://sonar.springsource.org/drilldown/measures/7173?metric=package_tangle_index&rids%5B%5D=7717,XD-797,Gary Russell,Package Tangle Introduced by XD-790
2939,Eric Bottard,Eric Bottard,"Commands like ""stream deploy"" have changed over time to allow passing a ""--all"" option.

So it's either {{stream deploy foo}} or {{stream deploy --all}}. This has a number of drawbacks, given that these are the only 2 alternatives:
- Implementation code is cumbersome
- None of the options can be marked mandatory, yet one of them is required. This has to be checked in the command code itself
- TAB completion is less powerful as the shell doesn't know if we want the first or the second form.


Consider splitting those commands into two distinct commands, one as before and one literally named {{stream deploy all}}.",XD-796,Eric Bottard,"Create separate commands for ""--all"" shell commands"
2940,Eric Bottard,Eric Bottard,Once XD-785 is merged,XD-795,Eric Bottard,"Refactor mail and imap source into one ""mail"" module, leveraging Profiles"
2941,Gunnar Hillert,Gunnar Hillert,,XD-794,Gunnar Hillert,Add integration tests for SpEL and Groovy based routing
2942,Jennifer Hickey,Jennifer Hickey,,XD-793,Jennifer Hickey,Upgrade Spring Data Redis to 1.1 RC1
2943,Luke Taylor,Luke Taylor,,XD-792,Luke Taylor,Update twittersearch to use Spring Integration support
2944,Eric Bottard,Eric Bottard,,XD-791,Eric Bottard,Document mail related sources & sinks
2945,David Turanski,David Turanski,SingleNodeMain.launchSingleNodeServer(options) calls System.exit() causing a gradle buffer underflow. This is called from SingleNodeMainIntegrationTests. System.exit() should be called from the main method instead. ,XD-790,David Turanski,Cryptic gradle error running tests when XD SingleNode is running
2946,Mark Fisher,Mark Fisher,,XD-789,Mark Fisher,Add index-based access to TuplePropertyAccessor
2947,Glenn Renfro,Gunnar Hillert,"similar to ChannelRegistry:

- AbstractChannelRegistryTests that has the real tests
- subclasses for each impl provide the registry to be tested

Thus one test can run against multiple transports.",XD-788,Gunnar Hillert,Add Integration Tests to run JobCommands Tests against all transports
2948,Gunnar Hillert,Gunnar Hillert,"related to XD-779. 

* We need the ability to provide JSON serializable JobExecution information.
* Change from using JavaSerialization back to returning objects
",XD-787,Gunnar Hillert,Add a JobExecution DTO Object
2949,,Gunnar Hillert,Should it be fatal vs. warning?,XD-786,Gunnar Hillert,"Add Warning-level log to postProcessAfterInitialization if Job name is not ""job"""
2950,Eric Bottard,Eric Bottard,"This came up when working on email source.
There is <int-mail:imap-idle-channel-adapter> and <int-mail:inbound-channel-adapter>

It would be nice to be able to put those in two profiles and have one of the profile being activated from module options (e.g. email --polling=true|false)

Don't know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly :

<beans profile=""profile-[optionname]-[optionvalue]"">

Not sure if this is the same as XD-132",XD-785,Eric Bottard,Enable profile selection from module options
2951,David Turanski,David Turanski,"export XD_HOME=foo
gradle clean test 

build fails. Need to detected environment variables and override for the build",XD-784,David Turanski,Build needs to override $XD_* environment variables
2952,,Eric Bottard,See discussion at https://github.com/SpringSource/spring-xd/pull/240#discussion_r6045724,XD-783,Eric Bottard,Support higher level structure for complex module registry
2953,Eric Bottard,Eric Bottard,,XD-782,Eric Bottard,Add CompositeModuleRegistry
2954,,Eric Bottard,"It would be nice to be able to have modules that are simply made of:
 - Their context xml file
 - Some kind of manifest that expresses dependencies

and have the runtime take care of the deps",XD-781,Eric Bottard,Support a dependencies-manifest aware Module Registry
2955,,Eric Bottard,See https://github.com/SpringSource/spring-xd/pull/240#discussion_r6045724,XD-780,Eric Bottard,Avoid use of module name twice in location when using a custom modules
2956,Gunnar Hillert,Ilayaperumal Gopinathan,"Transport used: Redis

It looks like when the job is launched, the RedisChannelRegistry's composite handler tries to transform the JobLaunchingMessageHandler's output-channel (notifications) payload which is of type ""org.springframework.batch.core.JobExecution"".
and, This results in Infinite recursion (StackOverflowError).

Please see the stack trace here:

01:09:44,827 ERROR task-scheduler-1 redis.RedisQueueInboundChannelAdapter:148 - Error sending message
org.springframework.integration.MessageHandlingException: org.springframework.context.ApplicationContextException: Failed to start bean 'jobTriggerBean'; nested exception is org.springframework.integration.MessageHandlingException: error occurred in message handler [org.springframework.integration.x.redis.RedisChannelRegistry$CompositeHandler@26f8f92e]
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:76)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)
	at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter.access$3(RedisQueueInboundChannelAdapter.java:1)
	at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter$ListenerTask.run(RedisQueueInboundChannelAdapter.java:145)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'jobTriggerBean'; nested exception is org.springframework.integration.MessageHandlingException: error occurred in message handler [org.springframework.integration.x.redis.RedisChannelRegistry$CompositeHandler@26f8f92e]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:170)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:339)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:143)
	at org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:89)
	at org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1278)
	at org.springframework.xd.module.SimpleModule.start(SimpleModule.java:152)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:162)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:149)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:120)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)
	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:97)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:82)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:103)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:144)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:231)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:130)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)
	... 22 more
Caused by: org.springframework.integration.MessageHandlingException: error occurred in message handler [org.springframework.integration.x.redis.RedisChannelRegistry$CompositeHandler@26f8f92e]
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.xd.dirt.plugins.job.JobTriggerBean.executeBatchJob(JobTriggerBean.java:74)
	at org.springframework.xd.dirt.plugins.job.JobTriggerBean.start(JobTriggerBean.java:63)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:167)
	... 45 more
Caused by: org.springframework.integration.x.json.TypedJsonMapper$SmartJsonConversionException: Infinite recursion (StackOverflowError) (through reference chain: org.springframework.batch.core.JobExecution[""stepExecutions""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""jobExecution""]->org.springframework.batch.core.JobExecution[""stepExecutions""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""jobExecution""]->org.springframework.batch.core.JobExecution[""stepExecutions""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""j
...
...
>java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""jobExecution""]->org.springframework.batch.core.JobExecution[""stepExecutions""])
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:611)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:492)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:571)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:597)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:492)
	at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:119)
	at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:23)
	at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serializeWithType(AsArraySerializerBase.java:197)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:571)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:597)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:492)",XD-779,Ilayaperumal Gopinathan,"Infinite recursion (StackOverflowError) when trying to process JobLaunchingMessageHandler's ""notifications"" channel output"
2957,Glenn Renfro,Glenn Renfro,When the XD starts up and does not see its job repo it will create one in the${xd.home}/data directory.  When xd.home is not set in system properties the job repo creates a literal ${xd.home}/data directory.  ,XD-778,Glenn Renfro,${xd.home}/data shows up after gradlew build
2958,Eric Bottard,Gunnar Hillert,"Try:
{code}
stream create --name aa --definition ""time | log""
tap create --name t1 --definition ""tap aa.log | log""
{code}

Results in:

{code}
Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.NullPointerException
{code}",XD-777,Luke Taylor,Add validation on tap definitions that checks for module names that are part of the stream definition
2959,,Gunnar Hillert,"We should only allow ""tap list"" - currently ""tap list"" AND ""taps list"" are allowed but ""tap list"" does not show up under help.",XD-776,Gunnar Hillert,"Shell: Remove ""taps list"" command"
2960,Gunnar Hillert,Mark Fisher,"for an example, see comments here:
https://jira.springsource.org/browse/XD-671
",XD-775,Mark Fisher,Document router processor module
2961,Ilayaperumal Gopinathan,Glenn Renfro,"In order to hook up the to get access to all the jobs available the job registry has to be shared.  currently the only implmentation is is the MapJobRegistry.  
====
Testability.
====
The admin will need to be see all jobs created by its containers.",XD-774,Glenn Renfro,Need to create a Persistent-Job-Registry 
2962,liujiong,Gunnar Hillert,"When doing *xd:> http post* and press the *tab* key. One should get a list of available options. Right now nothing happens. I have to press *--* and then tab to get the options.

Interestingly, this works for *stream create* + *tab* key",XD-773,Gunnar Hillert,Tab support inconsistent for http post
2963,,Eric Bottard,See discussion at https://github.com/SpringSource/spring-xd/pull/250/files#r6034885,XD-772,Eric Bottard,Factor out duplicated SpEL / script logic
2964,liujiong,Gunnar Hillert,"User shall have the ability to get a listing of available named channels (order by name ascending) from the shell

* Add support to controllers
* Add tests",XD-771,Gunnar Hillert,Shell: Add named channel list command
2965,Glenn Renfro,Glenn Renfro,,XD-770,Glenn Renfro,Update Batch Job docs to cover triggers as a source
2966,liujiong,Gunnar Hillert,,XD-769,Gunnar Hillert,Add XMPP Sink
2967,Eric Bottard,Gunnar Hillert,,XD-768,Gunnar Hillert,Add Email Sink
2968,Eric Bottard,Gunnar Hillert,,XD-767,Gunnar Hillert,Add Email Source
2969,Glenn Renfro,Glenn Renfro,Also drop the enhanced portion of the EnhancedStreamParser.,XD-766,Glenn Renfro,Parser needs to handle a  ':' embedded in a name.
2970,,Glenn Renfro,Jobs will be started via trigger.  So we won't need the JobTriggerBean.,XD-765,Glenn Renfro,Remove AutoLaunch feature from batch jobs
2971,,Glenn Renfro,"Currently we have 2 trigger sources: trigger & cron-trigger.  The preference is to have a user to just use a single trigger source.  for example:
* trigger > :myjob
* trigger --cron='...' >:myjob
* trigger --fixedDelay='...' > :myjob

One option to handle this is to use spel to reference a bean and then have different trigger beans defined. i.e. trigger='cronTriggerBean'.  Each trigger bean would setup the channel with the correct poller.

",XD-764,Glenn Renfro,Consolidate Trigger Sources into a single Source
2972,Glenn Renfro,Glenn Renfro,"Triggers will be a source and no longer as a unique module.
* The following have to be removed:
** spring-xd-dirt:  
-- package: org.springframework.xd.dirt.plugins.trigger
-- META-INF: spring-xd/plugins/triggers.xml
-- org.springframework.xd.dirt.stream.TriggerPlugin

*The following beans will require updates to remove the trigger code
** spring-xd-dirt:  
--META-INF: spring-xd/internal/deployers.xml - Remove Triggerdeployer
--org.springframework.xd.dirt.plugins.job.JobPlugin - Remove the registrars for fixedDelay, fixedRate, Cron.  As well as the component selection, only need the job-modules-bean
--Update the tests to use the trigger as a source, instead of the trigger module.
** spring-xd-shell:
Remove trigger commands and associated tests

** xd controllers:
Remove trigger controllers and their associated tests 
This list cover most but not all the components affected.
--Success criteria--
Successful unit and integration tests.

",XD-763,Glenn Renfro,Remove Trigger Module Code 
2973,,Gunnar Hillert,"This is issue depends on XD-761

https://build.springsource.org/browse/XD-JDK8",XD-762,Gunnar Hillert,Add Spring XD Build Plan for Java 8 to Bamboo  
2974,,Gunnar Hillert,JavaDoc issues are causing the build to fail with Java 8,XD-761,Gunnar Hillert,Make Spring XD buildable with Java 8
2975,,Gunnar Hillert,https://sonar.springsource.org/drilldown/measures/7173?metric=package_cycles&rids%5B%5D=7717,XD-760,Gunnar Hillert,Fix Package Tangle between o.s.xd.dirt.event and o.s.xd.dirt.container
2976,Ilayaperumal Gopinathan,Mark Fisher,"The xd-singlenode script currently has '644' permissions unlike xd-admin and xd-container (which have '755'): 

{code}
-rwxr-xr-x  1 mark  staff  5899 Aug 26 16:19 xd-admin
-rwxr-xr-x  1 mark  staff  5955 Aug 26 16:19 xd-container
-rw-r--r--  1 mark  staff  5919 Aug 26 16:19 xd-singlenode
{code}
",XD-759,Mark Fisher,The xd-singlenode script should have execute permissions
2977,,Gary Russell,UDP and Legacy syslog sources emit a {{Map}}; reactor emits a POJO. Make them consistent and emit {{Tuple}}s.,XD-758,Gary Russell,Create Syslog -> Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple
2978,Eric Bottard,Mark Pollack,"Create a processing module based on SI's aggregator component.  The completion criteria for the aggregator should be a simple count of messages (e.g. received 50 messages) and a timeout so that messages don't stay in the aggregator module for more than 30 seconds. 

*Implementation suggestions*

Create an XML based processing module definition using the SI aggregator namespace.  Only the options to support the features in the description should be exposed as property placeholders.

*How to know it works*
A shell style integration test that has a source that sends a known amount of messages.  A ticktock like module would perhaps be a good example.  10 messages sent every 100ms with an aggregator set to a 'aggregate count' of 10, should have 1 message output (perhaps to file sink whose name is based on time as well, is that possible.).  A ticktock example with a 1 second delay and with the aggregator module set to have a timeout of 0.5 seconds will have only one message in the file (again assumign the file name has a timestamp/counter in the filename). ",XD-757,Mark Pollack,Create aggregator module
2979,Eric Bottard,Mark Pollack,"The splitter functionality in Spring Integration should be exposed to XD as a processing module.  The splitter should use a SpEL expression to specify how to split the message up.  

*Implementation Suggestions*

This should be a simple XML based module definition that has input/output channels and has the SpEL expression parameterized.  The default value of the SpEL expression should result in the message not being split.

*How to check it works*

The current file or tail input source can be used to split up the text in a file into words.  The tail module should be checked to see how many lines of text it will read into memory at once.  The file module node with the file-to-string transformer will only work for small files as it keep the whole file in memory.  

If there is a big memory inefficiency in using the tail file input source, create a new story to investigate how to have a file based input source that creates a message per line of text or something that is will not result in excessive memory usage.  ",XD-756,Mark Pollack,Create a splitter module
2980,,Gary Russell,"Use a profile or similar to only include the {{Environment}} conditionally (currently in module-common.xml.

Also

Jon Brisbin
one thing to keep in mind: we talked about having a properties file for XD that configured the RingBuffer et al in a non-default way

Jon Brisbin
e.g. no event loop Dispatchers…a ThreadPoolDispatcher with a large thread pool size (50 threads? 100?)…and maybe even two RingBufferDispatchers: input and output

Jon Brisbin
so we might want to change from strictly a default Environment bean to an EnvironmentFactoryBean with a specific configuration…thinking about it now I maybe should add a namespace element for the Environment",XD-755,Gary Russell,Reactor Environment Improvements
2981,David Turanski,Gary Russell,"{{container}} and {{event}}. {{XDContainer}} references and is referenced by {{ContainerStartedEvent}} (and stopped).

https://sonar.springsource.org/drilldown/measures/7173?metric=package_cycles&rids%5B%5D=7717

",XD-754,Gary Russell,Fix Class/Package Tangle Introduced by XD-353
2982,Glenn Renfro,Glenn Renfro,We need to have a properties section (documented as well) so that users can setup their jdbc connections for the various components.,XD-753,Glenn Renfro,JDBC property settings need to be made externally configurable
2983,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently the Job launcher launches all the batch jobs configured in the job module.

Please refer, ModuleJobLauncher's executeBatchJob().

This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name (group name).

Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.",XD-752,Ilayaperumal Gopinathan,Restrict Job launcher with more than one batch job configured in job module
2984,,Janne Valkealahti,Technically speaking of we want to integrate XD UI on Hadoop tools we should do it so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url(which is registered when application is deployed).,XD-751,Janne Valkealahti,XD UI on Yarn
2985,Janne Valkealahti,Janne Valkealahti,"1. We'll need a system which give better control of what yarn/xd containers are out there and what is a status of those containers.
2. We also need grouping of containers order to choose, prioritize and scale tasks.
3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn't give enough tools to know if container is ""alive"".",XD-750,Janne Valkealahti,Container and Grid Control
2986,,Janne Valkealahti,"We need to be able to talk to appmaster which will control the whole xd yarn app.

1. Choose the implementation? Thrift? Spring Int? Something else?
",XD-749,Janne Valkealahti,Comm protocol for appmaster
2987,,Janne Valkealahti,"1. How we talk to the XD instance(s) on Yarn
2. There is a rest interface which location can be exposed either via resource manager or appmaster
3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface implementation(i.e. thrift or spring int)",XD-748,Janne Valkealahti,Interacting with XD on Yarn
2988,Janne Valkealahti,Janne Valkealahti,"1. How XD Yarn application should be packaged and bootstrapped?
2. Where the code should be? Within xd itself or separate repo?",XD-747,Janne Valkealahti,Bootstrap XD on Yarn
2989,Glenn Renfro,Glenn Renfro,,XD-746,Glenn Renfro,Gradle Launch needs to use singlenodemain  vs. admin main
2990,Ilayaperumal Gopinathan,Mark Pollack,"The current XD JobController that returns a list of jobs has quite a different API signature than what is in spring-batch-admin.  To simplify the UI development, a new controller JobAdminController, will be created that lives under the request path /jobs/admin.  The goal is to return a the current JSON structure of spring-batch-admin /jobs/ request and make only minimal changes to implementations of controllers as found .  See #1 in the Doc (link to json output doc for spring batch).

*Implementation Suggestions*

There will need to be some SpringMVC setup that will enable the current style of spring-batch-admin controller requests to co-exist with the existing XD Controllers, e.g. the use of .json for json marshalling etc.  This may in fact be the bulk of time spend in this first story to integration spring-batch-admin style controllers into XD.

A new controller named JobAdminController that in the spring-xd-dirt project in the package org.springframework.xd.dirt.rest.  The JobAdminController will not need to follow the same HATEOAS style as the other controllers at this time.

The current controller in Spring Batch Admin looks like this
{code}
    @RequestMapping(value = ""/jobs"", method = RequestMethod.GET)
    public void jobs(ModelMap model, @RequestParam(defaultValue = ""0"") int startJob,
            @RequestParam(defaultValue = ""20"") int pageSize) {
        int total = jobService.countJobs();
        TableUtils.addPagination(model, total, startJob, pageSize, ""Job"");
        Collection<String> names = jobService.listJobs(startJob, pageSize);
        List<JobInfo> jobs = new ArrayList<JobInfo>();
        for (String name : names) {
            int count = 0;
            try {
                count = jobService.countJobExecutionsForJob(name);
            }
            catch (NoSuchJobException e) {
                // shouldn't happen
            }
            boolean launchable = jobService.isLaunchable(name);
            boolean incrementable = jobService.isIncrementable(name);
            jobs.add(new JobInfo(name, count, null, launchable, incrementable));
        }
        model.addAttribute(""jobs"", jobs);
    }
{code}

Something like
{code}
@RequestMapping(value = ""/jobs/admin/jobs"", method = RequestMethod.GET)
 public void jobs(ModelMap model, @RequestParam(defaultValue = ""0"") int startJob,
            @RequestParam(defaultValue = ""20"") int pageSize) {

       // We do *not* have to query the Spring Batch Admin “JobService” at this time, but
      //  instead use the  JobDeployer to get information about jobs launched by Spring XD

      Iterable<JobDefinition> jobDefinitions =  dobDeployer.findAll()

     // copy these over to a List<JobInfo> as best as possible, copy name over.  
     // not sure how ‘description’ is getting added to the JSON
      // pari
    }
{code}
*How to verify it works*
A sample job needs to be in the modules/job directory. JobCommandTests/AbstractJobIntegrationTest seems to have what is need to stage a job for 
",XD-745,Mark Pollack,Return the list of Jobs from spring-batch-admin
2991,Ilayaperumal Gopinathan,Mark Pollack,"We should depend on

		<dependency>
			<groupId>org.springframework.batch</groupId>
			<artifactId>spring-batch-admin-manager</artifactId>
			<version>${project.parent.version}</version>
		</dependency>
		<dependency>
			<groupId>org.springframework.batch</groupId>
			<artifactId>spring-batch-admin-resources</artifactId>
			<version>${project.parent.version}</version>
		</dependency>

we are using spring batch 2.2.0.RELEASE. 

We need to depend on spring-batch-admin version 1.3.0.BUILD-SNAPSHOT

 ",XD-744,Mark Pollack,Add dependency to spring batch admin in spring-xd-dirt
2992,Ilayaperumal Gopinathan,Mark Pollack,"Unlike in spring-batch-admin, in SpringXD all the jobs the /modules/jobs directory is not ‘visible’ to query when the server starts.  Jobs only become visible to XD’s ‘jobs list’ command once they have been ‘created’.  

Creating a Job in XD is an opportunity to specify additional values to any property placeholders in the job bean definition.  This isn’t part of spring-batch-admin.

We will not worry about the creation of job definition in this story.  Assume that they have been created already and that the GET for /jobs works as it does now for Spring XD. 

We should however, make sure that there is always a replacement of the job name in the job bean definition to match the ‘--name’ specified in the command line.  That is “job create --name myjob --description “thisfunkyjob”

will use ‘myjob to replace <job id=""${xd.stream.name}"" in the file thisfunkyjob.xml

*Implementation Suggestions*

This should hopefully just be a matter of changing job definition files to follow the naming pattern.

<job id=""${xd.stream.name}"" … />

*How to verify it works*

1. Create a JUnit integration style test that has ‘job create --name myjob --defintion “testJob”’ and then deploy the job.  The name ‘myjob’ should appear in the job execution table
",XD-743,Mark Pollack,"Ensure that when batch jobs are created, they are created with the job bean definition id equal to the ‘stream name’"
2993,,Mark Pollack,"Spring Batch Admin provides a complete, but outdated implementation style, which covers the full administrative lifecycle of batch jobs, their creation, stop/start, and retrieving information about previous job executions and the status of currently executing job executions.  SpringXD has a different way of deploying, starting, and stopping jobs - by sending messages to containers that run the batch job.  However, the reporting state of a job is still stored in a common job repository.  The purpose of this story is to take the first step to merging in the existing code base that focuses only on the retrieval of information from Spring Batch Admin’s Job controller.

The current ‘REST API’ style of these commands should stay as close to the original spring batch admin style as possible.  There are several reasons for this
1. It works, and time to springone is short, and we mgmt has expectations around deliverables that we must strive to meet.
2. It gives Andrew a working contract to start developing a UI
3. We can take on this technical debt, but refactor after RC1 and before GA while and deliver end-user functionality.  

Attached is the list of endpoints in spring batch admin ",XD-742,Mark Pollack,REST API for Job Management
2994,Mark Fisher,David Turanski,The above config contains beans that must be in a common parent context for the AdminServer and Modules. Hence not really global since the (Node) doesn't need them itself. So the name is a bit misleading. Come up with something better.,XD-741,David Turanski,Rename xd-global-beans.xml
2995,,David Turanski,Currently *Main class provide alternate static methods for parsing CLI options. One used for testing does not call System.exit() just throws an exception. This code should be moved to spring-xd-test to support integration testing.,XD-740,David Turanski,Remove Option parsing code used for tests from Servers
2996,David Turanski,David Turanski,"Remove System.setProperty() or System.getProperty() for internal xd properties. Use spring Environment abstraction instead. Also, replace ""."" in property names with '_' (XDPropertyKeys). This is compatible with environment variable names. 

As a result, XD should accept System properties or environment variables or command line options. Command line options should have highest precedence. Retain StandardEnvironment order wrt to System properties and environment variable. ",XD-739,David Turanski,Eliminate internal dependencies on System properties
2997,,David Turanski,"Rename XDContainer, ContainerMain, *ContainerLauncher, ContainerLauncherFactory and any variable or methodNames, bean names, etc. that refer to container in favor of the term 'Node'. Eliminate the dirt.container package, and move Node into .server",XD-738,David Turanski,Rename XDContainer and associated classes to Node
2998,Glenn Renfro,Glenn Renfro,"Trigger can send a message to a named channel.  For example:
trigger create --name mytrigger --definition ""trigger --cron='*/10 * * * * *' --message='Good Luck, we are all counting on you'""  --channel foo 

Where the --message contains the message that will be sent to foo job/component.",XD-737,Glenn Renfro,Trigger can send a message to a named channel
2999,Ilayaperumal Gopinathan,Glenn Renfro,"This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD.  

*Steps
  - Create a Branch in the BatchAdmin (we don't want to lose history)
  - Update the restful API's to XD standards.
  - Create bamboo task to push jars to artifactory
  - Update gradle.build to pull in the Batchadmin jars.
  - Expose the restful calls.",XD-736,Glenn Renfro,Expose restful services that allow users to view job statuses
3000,,Glenn Renfro,"The HSQLDB that stores the JobRepository needs to have its content exposed via TCP (network service) so that container has access to update the status of a job run.  
-Needs to have property that enumerates the host and port for the admin that is accessible by the user.
-If one is not specified it should default to localhost:9500.

*Testing:
- Unit Tests
- Bring up module and admin.  
    ^Verify that default host and port work
    ^Verify that container on different machine has access to admin


",XD-735,Glenn Renfro,Job Repo in container needs access to Admin's HSQLDB
3001,,Glenn Renfro,"When creating a job, a named channel will be created with a name of job.<your job name>  i.e. job.foo.
========
Required components:
- A Transform See XD-733
- JobPlugin needs to create the NamedChannel for the job and associate the transform.
   > Registrar.xml will need an input channel?
   > Name channel support will be required.
- Add --channel to job rest apis to notify system that a named channel is requested.  
*Unit Test

",XD-734,Glenn Renfro,A job will be associated with a named channel when the job is created.  
3002,Gunnar Hillert,Gunnar Hillert,"The JobLaunchRequest Transformer shall accept the following payloads:

* File
* JSON String
* Properties
* Map
* Tuple

Use/Migrate some of the logic from *JobParametersBean*, e.g. using the *DefaultJobParametersConverter*.

*Special Case File*

When handling a *File*, add special JobParameter *absoluteFilePath* populating it with *message.getPayload().getAbsolutePath()*

* Add unit tests


",XD-733,Gunnar Hillert,Create JobLaunchRequest Transformer
3003,Eric Bottard,Mark Pollack,"{code}
filter --expression=""payload.myfield.startsWith('foo')""
{code}

Example using index:

{code}
filter --expression=""payload.2.startsWith('foo')""
{code}

This should support nested keys as well:

{code}
filter --expression=""payload.myfield.subfield.startsWith('foo')""
{code}

This is related to https://jira.springsource.org/browse/XD-676 and that in turn depends on SI being able to configure SpEL",XD-732,Mark Pollack,Add PropertyAccessor for JSON fields in SpEL
3004,,David Turanski,Enhance bean naming strategy or provide a value for the property that binds to this,XD-731,David Turanski,Replace 'anonymous' node in XD module bean names
3005,Andrew Eisenberg,Mark Pollack,Configure embedded servlet container needs to know where to load the UI code.,XD-730,Mark Pollack,Add additional embedded servlet container config to load static UI resources
3006,Ilayaperumal Gopinathan,Mark Pollack,"The UI code will be sitting in one or more top level directories in the repository

This story will address the need to 

1) copy over the UI code into a location so that it can be picked up by the embedded servlet container when the distribution zip is 'unzipped'.  

After running ./xd-admin or ./xd-singlenode one should be able to hit the UI at http://localhost:8999/xd

(just an example)",XD-729,Mark Pollack,Package up the UI code when building the distribution so that it can be shown by xd-admin
3007,Ilayaperumal Gopinathan,Mark Pollack,"The UI code will be sitting in one or more top level directories in the repository

This story will address the need to 

1) copy over the UI code into a location so that it can be picked up by the embedded servlet container when running inside eclipse",XD-728,Mark Pollack,Display the UI from xd-admin container when doing development in eclipse
3008,Ilayaperumal Gopinathan,Mark Pollack,"Create a directory structure that best benefits UI development.  

The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story",XD-727,Mark Pollack,Create directory structures and move existing UI code into Spring XD repository
3009,,Ilayaperumal Gopinathan,"Register the module under test
Send a message to the sink using a test source and verify the sink contents - this requires checking an external resource - depends on the sink
",XD-726,Ilayaperumal Gopinathan,Test sink module in isolation
3010,,Ilayaperumal Gopinathan,"Register the module under test  and have access to a source channel that drives messages into the processor and a output channel where output messages are sent.  
Examples
Built-in Message conversion: send JSON to a processor module that accepts Tuples.
",XD-725,Ilayaperumal Gopinathan,Test processor module in isolation
3011,,Ilayaperumal Gopinathan,"Register the module under test and deploy the module
Verify output across all transports
Examples
Be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml, pass in some property file for parameters to be replaced, and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality.  Test that sending json, results in media-type header is set to json
Test that sending POJO -> POJO
Test that sending Tuple ->  Tuple
Test that sending a (JSON) String -> String
Test that sending raw bytes ->  raw bytes
",XD-724,Ilayaperumal Gopinathan,Test source module in isolation
3012,Eric Bottard,Eric Bottard,"There are a lot of Thread.sleep() calls with delays chosen in the 1-2 seconds range.

Change to a while loop with smaller pauses until a timeout is reached and give up.

This applies to verification code (e.g. verifying that a counter has expected value) as well as File setup, or http being ready to accept requests etc",XD-723,Eric Bottard,Change inconditionnal Thread.sleep() calls in tests to smarter incremental pauses
3013,Gunnar Hillert,Mark Pollack,"This is the other side of launching a job by sending a message.  The Job plugin should add listeners at the job/step level so that the job/step context information can be sent out on a channel.

:myjob.notifications is a suggested channel name that would be created automatically.",XD-722,Mark Pollack,Batch jobs send job and step events on channels 
3014,Glenn Renfro,Mark Pollack,"After the xd-singlenode process has started, create a new job that has dependencies not already in the parent application context, and then create and run a new job that uses the new module.

*Implementation Suggestions*
Develop in the test tree, we can put in the jar and config from https://github.com/SpringSource/spring-xd-samples/tree/master/batch-simple 

*How to verify it works.*
In a JUnit test case copy in a new job that has new dependencies, ..copy the lib and config directories into the location where the ModuleRegisty will pick it up.

Deploy a new job and check in the job repository that the job ran and was successful.

",XD-721,Mark Pollack,Deploy a new job module *after* XD-singlenode container has started.
3015,Eric Bottard,Mark Pollack,"After the xd-singlenode process has started, create a new module that has dependencies not already in the parent application context, and then create a stream that uses the new module.

*Implementation Suggestions*
Develop in the test tree, maybe of the xd-shell project, a new module.  the lib and config should be sititng around in a directory waiting to be copied into the appropriate spot.

Could try http://www.date4j.net/..The config file  would be similar to time.xml but use the date4j class.

*How to verify it works*
In a JUnit test case copy in a new module that has new dependencies, ..copy the lib and config directories into the location where the ModuleRegisty will pick it up.

Deploy a new stream, date4j | file and see if there are contents in the file.
",XD-720,Mark Pollack,Deploy a new source module *after* XD-singlenode container has started.
3016,Eric Bottard,Mark Pollack,"Convert a simple module, such as file, to further test that what was done in the previous story, “Use ParentLastClassLoader to create the Modules ApplicationContext.” works as expected.

*Implementation Suggestions*

Remove from build.gradle the dependency on spring-integration-file and place that jar inside a directory

./modules/source/file/lib 

place the current file.xml inside ./modules/source/file/config

*How to verify it works.*

1. Running tests that currently use the file source, e.g. in spring shell, should work as before
2. When deploying a stream file | log, we should be able to interrogate the channel registry and make sure it found the dependencies for the module, ModuleDescriptor should have a not-null URL[] property.",XD-719,Mark Pollack,Refactor the file source module to have lib/config directories
3017,Eric Bottard,Mark Pollack,"The ParentLastClassloader is located in the spring-hadoop project.  It will resolve classes first looking at the child context and then the parent.  This works well for XD since the we want and dependencies of the module to be considered first and if not found, resolve against the parent. It would be possible to even include other versions of .jars already in the parent classloaders (e.g. Spring Integration jars), but for now, we will not immediately test that case.

SimpleModule needs to change to that we can pass in the classloader to use for creating the application context. The current implementation creates a GenericApplicationContext as a field initializer...that should change to be in the ctor.

ModuleDeployer should implement .BeanClassLoaderAware.  The classloader passed in to the BeanClassLoaderAware callback will be used as the ‘parent’ when creating the ParentLastClassloader.  

The URL[] to pass into ParentLastClassloader should be ‘null’ or an empty array in this case of an older style module.  (Hopefully ParentLastClassloader  allows that type of fallback).

*Implementation Suggestions:*
The ModuleDeployer code is where the application context for the module is defined and instantiated.   Here is a possible impl path.

1. Assuming we can always use ParentLastClassloader (even for older style modules), then the ModuleDescriptor needs to return an array of URL[] locations for the module, getURL().  This is passed into the cto for SimpleModule.  The ctor then creates a new application context, creates the parentclassloader, sets the classloader on the application context and then proceeds as normal. 
2.AbstractModuleRegistry should try and load the resource from two possible locations, e.g. 

./modules/source/file/config/file.xml

or

./modules/source/file.xml

The module registry needs to be a bit smarter to know, ah, i see a config directory, let me try ./config/file.xml otherwise just ./file.xml


*How to verify it works.*

1. JUnit test in which one of the ModuleRegistry implementations points to a test directory that contains both old and new style modules.  FileModuleRegistry is probably a good choice here.  Need to test that the new getting for URL[] works as expected.

2. Existing tests should run as they did before, in particular the shell integration tests.",XD-718,Mark Pollack,Use ParentLastClassLoader to create the Modules ApplicationContext.
3018,Ilayaperumal Gopinathan,Mark Pollack,"$ ./xd-admin --transport redis
$ ./xd-container --transport redis
$ ./xd-container --transport redis

xd:>stream create --name httpStream --definition ""http | file""
Created new stream 'httpStream'
xd:>tap create --name httpTap --definition ""tap httpStream | counter""
Created and deployed new tap 'httpTap'
xd:>http post --target http://localhost:9000 --data ""helloworld""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
xd:>http post --target http://localhost:9000 --data ""helloworld""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
xd:>http post --target http://localhost:9000 --data ""helloworld2""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld2
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
helloworld2
xd:>http post --target http://localhost:9000 --data ""helloworld3""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
helloworld2
helloworld3
xd:>http post --target http://localhost:9000 --data ""helloworld3""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
helloworld2
helloworld3
xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
helloworld2
helloworld3
xd:>http post --target http://localhost:9000 --data ""helloworld3""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3
> 200 OK

xd:>http post --target http://localhost:9000 --data ""helloworld3""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3
> 200 OK

xd:>http post --target http://localhost:9000 --data ""helloworld3""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
helloworld2
helloworld3
xd:>http post --target http://localhost:9000 --data ""helloworld4""
> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld4
> 200 OK

xd:>! cat /tmp/xd/output/httpStream.out
command is:cat /tmp/xd/output/httpStream.out
helloworld
helloworld2
helloworld3
helloworld4
xd:>counter display --name httpTap
9
xd:>

however in the regular shell.

$ cat /tmp/xd/output/httpStream.out 
helloworld
helloworld
helloworld2
helloworld3
helloworld3
helloworld3
helloworld3
helloworld3
helloworld4


",XD-717,Mark Pollack,cat command doesn't work when same data is listed in file multiple times
3019,Jennifer Hickey,Jennifer Hickey,"A change was made in spring-data-redis to instantiate the shared Lettuce connection lazily instead of when the context is initialized. This caused TapCommandTests to hang due to a Netty worker thread trying to initialize the Lettuce connection (Lettuce uses Netty). The change was temporarily backed out of SDR, but we need to consider using a NettyExecutionHandler in NettyHttpInboundChannelAdapter or making the HTTP module's ""input"" channel an ExecutorChannel to avoid potentially long operations like from happening in an I/O thread.

Also, we need to address why this failure simply hangs the shell. Shell was hung waiting on IO here:
	at org.springframework.http.client.SimpleClientHttpResponse.getRawStatusCode(SimpleClientHttpResponse.java:47)
	at org.springframework.http.client.AbstractClientHttpResponse.getStatusCode(AbstractClientHttpResponse.java:32)
	at org.springframework.xd.shell.command.HttpCommands$1.hasError(HttpCommands.java:93)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:484)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:460)
	at org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:335)
	at org.springframework.xd.shell.command.HttpCommands.postHttp(HttpCommands.java:103)
	at sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:191)
	at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)
	atringframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:57)
	- locked <7fd3c7d40> (a java.lang.Class for org.springframework.shell.core.SimpleExecutionStrategy)
	at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)
	at org.springframework.xd.shell.AbstractShellIntegrationTest.executeCommand(AbstractShellIntegrationTest.java:99)
	at org.springframework.xd.shell.AbstractShellIntegrationTest.httpPostData(AbstractShellIntegrationTest.java:112)
	at org.springframework.xd.shell.command.TapCommandTests.testCreateAndDeployTap(TapCommandTests.java:56)

Full stack trace of server exception:

 Aug 19, 2013 9:59:00 AM org.jboss.netty.channel.SimpleChannelUpstreamHandler
    WARNING: EXCEPTION, please implement org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.exceptionCaught() for proper handling.
    org.springframework.integration.MessageHandlingException: org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis on localhost:6379; nested exception is com.lambdaworks.redis.RedisException: Unable to connect
    	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:76)
    	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)
    	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
    	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
    	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
    	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)
    	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
    	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
    	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
    	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)
    	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
    	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
    	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
    	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)
    	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
    	at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:121)
    	at org.springframework.integration.dispatcher.BroadcastingDispatcher.dispatch(BroadcastingDispatcher.java:112)
    	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
    	at org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:121)
    	at org.springframework.integration.channel.AbstractMessageChannel$ChannelInterceptorList.preSend(AbstractMessageChannel.java:248)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:173)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
    	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
    	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)
    	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)
    	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
    	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
    	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
    	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
    	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
    	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
    	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)
    	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$200(NettyHttpInboundChannelAdapter.java:59)
    	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:122)
    	at org.jboss.netty.handler.codec.http.HttpContentEncoder.messageReceived(HttpContentEncoder.java:81)
    	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:148)
    	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
    	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)
    	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
    	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:485)
    	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
    	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
    	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
    	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)
    	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
    	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)
    	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
    	at java.lang.Thread.run(Thread.java:680)
    Caused by: org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis on localhost:6379; nested exception is com.lambdaworks.redis.RedisException: Unable to connect
    	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:345)
    	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.initConnection(LettuceConnectionFactory.java:116)
    	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:325)
    	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:106)
    	at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81)
    	at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53)
    	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:173)
    	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)
    	at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)
    	at org.springframework.data.redis.core.DefaultZSetOperations.add(DefaultZSetOperations.java:41)
    	at org.springframework.data.redis.core.DefaultBoundZSetOperations.add(DefaultBoundZSetOperations.java:47)
    	at org.springframework.xd.store.AbstractRedisRepository.trackMembership(AbstractRedisRepository.java:202)
    	at org.springframework.xd.analytics.metrics.redis.RedisCounterRepository.increment(RedisCounterRepository.java:88)
    	at org.springframework.xd.analytics.metrics.redis.RedisCounterRepository.increment(RedisCounterRepository.java:82)
    	at org.springframework.xd.analytics.metrics.integration.MessageCounterHandler.process(MessageCounterHandler.java:28)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    	at java.lang.reflect.Method.invoke(Method.java:597)
    	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)
    	at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:97)
    	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:82)
    	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)
    	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:103)
    	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)
    	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:230)
    	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:129)
    	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)
    	... 84 more
    Caused by: com.lambdaworks.redis.RedisException: Unable to connect
    	at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
    	at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
    	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:339)
    	... 111 more
    Caused by: java.lang.IllegalStateException: await*() in I/O thread causes a dead lock or sudden performance drop. Use addListener() instead or call await*() from a different thread.
    	at org.jboss.netty.channel.DefaultChannelFuture.checkDeadLock(DefaultChannelFuture.java:342)
    	at org.jboss.netty.channel.DefaultChannelFuture.await(DefaultChannelFuture.java:231)
    	at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:166)
    	... 113 more",XD-716,Jennifer Hickey,TapCommandTests hangs when using a lazily instantiated Lettuce connection
3020,Jennifer Hickey,Jennifer Hickey,Upgrade Lettuce to 2.3.3 and subsequently Netty to 3.6.6,XD-715,Jennifer Hickey,Upgrade Lettuce and Netty
3021,Eric Bottard,David Turanski,The above method is invoked before the shared context is refreshed. preProcess... is more accurate,XD-714,David Turanski,Rename Plugin.postProcessSharedContext to preProcessSharedContext
3022,David Turanski,David Turanski,,XD-713,David Turanski,Support for @Configuration based module definitions
3023,,David Turanski,,XD-712,David Turanski,"Document/diagram runtime architecture, container and module lifecycle"
3024,Eric Bottard,David Turanski,"Register in MBeanExportingPlugin.
",XD-711,David Turanski,MBeanServer should not be declared in module common configuration
3025,Eric Bottard,David Turanski,"Update JavaDocs in Plugin interface to clearly describe the Plugin contract, i.e.,  where in the lifecycle each method is invoked",XD-710,David Turanski,Update JavaDocs in Plugin interface
3026,Eric Bottard,David Turanski,"Remove unnecessary code that adds beans to shared context after refresh
Scheduler should not be in common.xml - register it in TriggerPlugin.postProcessSharedContext()",XD-709,David Turanski,Refactor TriggerPlugin 
3027,David Turanski,David Turanski,"SingleNodeMain(){
  	parent = new AC(..)
   		AdminMain.launch(parent);
   		ContainerMain.launch(parent);
}

This should make startup processing more consistent and symmetrical
",XD-708,David Turanski,Add SingleNodeMain class 
3028,David Turanski,David Turanski,"Control transport - Deploy/Undeploy requests
Message transport - Inter module communication

Currently complicated because starting a Job for example currently uses message transport vs control transport. Testing scenarios require local control and ability to switch to various message transports.

One option is to change the interpretation of transport command line arg depending on SingleNode, Admin, or Container. e.g.
SingleNode --transport rabbit (always use local for control messages)
Admin (requires --transport, message transport does not apply)
Container (enforces the same transport for message and control. Local optimization done via composite module)

The other option is use a separate transport for control vs messages. 
Either way need to rationalize the design with respect to control and module messages
",XD-707,David Turanski,Support use of separate control and message transports
3029,,David Turanski,,XD-706,David Turanski,Stories related to initialization and configuration of Admin and Container processes
3030,Glenn Renfro,Mark Pollack,"*Description*  When a job is ‘created’ in SpringXD, a ‘control-channel’ for that job is also created.  The listener for that channel will receive a message, be able to take the ‘jobParameters’ and other launch information from the message, and be able to launch/run the job.

NOTE: I can see a few other stories that should probably be made to break this up after writing it. I put estimate of 10 for now, but we should break this up.  Here are some suggestions

1. create ‘data only’ JobParametersBean equivalent with primitive types
2. create jobLauncher source
3. create jobParameterTransformer processor
4. Refactoring of ChannelRegistry’s aliasHing to use a callback strategy.


*Implementation Suggestions*

job create --name helloWorldJob --definition ""myjob --somePropertyToOverride=someValue

* This would not execute the batch job immediately, but instead register the job definition and deploys a “jobLauncher” and the job definition to an XD-Container.

* The XD-Container that receives the deploy request message will create a module application context, will also create a channel with the Channel registry named after the job, e.g. :myJob.  This should be a pub/sub channel from the point of view of the middleware.  From the point of view of the spring integration channel, it should ideally be of the executor channel.  There is a limitation in the current implementation of ChannelRegistry now as ‘createInbound’ only creates direct channels.  The boolean ‘aliasHint’ should probably be extended to some type of callback that creates a channel.  The aliasHint was added to address the case of LocalChannelRegistry creating or looking up a queue backed channel or a direct channel.
There will be a consumer on the SI channel in the module application context that will be responsible for getting the job launch information and launching the job.  The launching of the job may need to be explicitly done in a separate thread if direct channels are created by the ChannelRegistry.  The contents of the message should be something similar to the current “JobParametersBean”, it needs to be easily serializable with simple types via JSON over the wire.  The current impl of “JobParametersBean” has ObjectMapper, so that may require a bit of reworking.  The handler of the message will use the jobLauncher to launch the job, using the information in the JobParametersBean.

* The ‘myjob’ can then be launched by sending a message, perhaps this is handled by having a jobLauncher source

jobLauncher [--jobParameters <jobParameters>] [--dateFormat <dateFormat>] [--numberFormat <numberFormat>] [--makeUnique <makeUnique>]  > :myJob

e.g. with no-args

jobLauncher  > :myJob

*How to verify it works*

With the test HelloSpringXDTasklet, we should be able to create the job

job create --name helloSpringXD --definition ""myjob""

This will not launch the job (as mentioned in the ‘implementation’ section.

It would then be launched by 

jobLauncher  > :myJob

where jobLauncher is a new source.

Ideally would like to be able to test a data driven triggering.  This would require a new file source that doesn’t use the file-to-string-transformer, but lets a File object be the payload.

file | jobParameterTransformer > :myJob
",XD-705,Mark Pollack,A batch job can be launched by sending a message on a channel
3031,Jennifer Hickey,Jennifer Hickey,Need to support Rabbit virtual host property in properties file and as args to Rabbit source and sink,XD-704,Jennifer Hickey,User should be able to specify Rabbit virtual host
3032,Gunnar Hillert,Mark Pollack,"The current code is creating an in-memory job repository for each batch job that is launched.  This makes it impossible to query the tables in the job repository across the cluster.  A single job repository that is backed by a file need to be shared across all jobs that are a launched.

*Implementation Suggestions*
* The XDAdmin server should create the job repository schema, if not found, in a HSQLDB database, when it starts up
* The bean definitions should be added to the same context that the analytics are being loaded in as it is already shared across xd-admin/xd-container.  The ‘analytics’ context should be renamed to something more generic, ‘shared parent context’ or something.
* There is some clean up (removal) of the code in the current JobPlugin, META-INF/spring-xd/plugins/job/common.xml wouldn’t be needed anymore.  That might be all, not sure.

*How to verify it works*
* A JUnit test that verifies the spring batch tables were created in the job repository when xd-admin is launched.  This would require deleting the backing db file before instantiating singlenode/xd-admin/xd-container.

* If you start the xd-container it should be able to find the necessary DataSource/JobRepository beans information to be able to contact the database.  We don’t have DI style JUnit tests so this will required getting a reference to the xd-container and it’s application context, and performing ‘getBean(JobRepository.class)’



",XD-703,Mark Pollack,JobRepository should be persistent and shared across xd-admin/xd-container
3033,Ilayaperumal Gopinathan,Mark Fisher,"(NOTE: even if we do want to prevent the use of module names for stream names, we obviously need to avoid a StackOverflowError)

to reproduce:

start the xd-singlenode container

start the xd-shell, and type the following:

{code}
xd:>stream create time --definition ""time | log""
{code}

that should produce an Internal Server Error output message

check the xd-singlenode console, and find:

{code}
SEVERE: Servlet.service() for servlet [xd] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.StackOverflowError] with root cause
java.lang.StackOverflowError
	at java.lang.StringValue.from(StringValue.java:24)
	at java.lang.String.<init>(String.java:178)
	at org.springframework.xd.dirt.stream.dsl.Token.<init>(Token.java:46)
	at org.springframework.xd.dirt.stream.dsl.Tokenizer.lexIdentifier(Tokenizer.java:195)
	at org.springframework.xd.dirt.stream.dsl.Tokenizer.process(Tokenizer.java:62)
	at org.springframework.xd.dirt.stream.dsl.Tokenizer.<init>(Tokenizer.java:41)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:65)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)
	at org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)
	at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)
	at org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:74)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)
	at org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)
	at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)
	at org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:74)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)
	at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)
	at org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)
	at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)
	at org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)
	...ad nauseum
	
{code}
",XD-702,Mark Fisher,stack overflow when trying to create a stream with the same name as a module
3034,,David Turanski,"After an initial attempt which was not ready for M2 we are rethinking our strategy. One of the fundamental things we have come to realize is that its important to treat serialization and type conversion as separate concerns.

Serialization:
 A core principle is the consumer should by default receive exactly what the producer sent:
   -   If the producer sends a byte[] payload then no serialization is required.  
   -   A String payload can use simple byte conversion, taking the Charset into account
   -  Transporting an Object uses whatever serialization is configured (json, xml, avro, protocol buffer, java.io, msgpack, etc.). 

The actual serialization performed for each message must be shared with the producer and consumer. I.e., the consumer needs to know which case above applies to each payload. Currently we are using the MessageHeaders.CONTENT_TYPE defining custom mime types for this (The designated header is subject to change)

Conversion:
    - The consumer optionally defines one or more content-types (read MimeType) it can accept in order of preference. If no conversion succeeds, we can either give them the byte[] payload or throw an exception (configurable?).  Examples:

- Consumer accepts a Java Object (application/x-java-object;type=example.Foo).  Assume for simplicity, the consumer may send a JSON String, or a Foo.  On the receiving end we need to distinguish a String payload containing a JSON representation of Foo from a serialized Foo payload. If the payload is a String, we need to know that its original content is application/json. We are currently using a 2nd ""original-content-type"" message header to supply this information.  So in the first case we have (conceptually) content-type: ""XD plain text"" , original-content-type ""application/json"".  In the second case we have content-type: ""XD Serialized JSON"" original-content-type not used in this case since the serialized JSON includes type information (using Jackson conventions which are a bit brittle). 

-If the producer type is different from the accepted type, we use the conversion service and the consumer must register appropriate converters. 

A twist for XD that may be generally relevant is that some optimization is possible when we know the bytes represent JSON:

-  Tuple conversion:  Since we serialize using JSON and we know how to transform JSON <->Tuple,  we can convert any Object  payload or any JSON String to a Tuple.  We can avoid the two step deserialization+conversion,  e.g.   1) Foo->JSON->Foo 2) Foo->Tuple. ",XD-701,David Turanski,Refactor Message conversion in ChannelRegistrySupport
3035,David Turanski,David Turanski,"Remove 
<bean id=""idGenerator"" class=""org.springframework.xd.dirt.container.UUIDGenerator"" />  (container.xml)

Delete org.springframework.xd.dirt.container.UUIDGenerator
remove compile dependency on eaio from build.gradle",XD-700,David Turanski,Remove XD UUIDGenerator in favor of the new SI provided one
3036,,Ilayaperumal Gopinathan,"When trying to undeploy/destroy a tap that has reference to an already deleted stream fails with the following exception:
Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD116E:(pos 4): unrecognized stream reference '<stream_name at the tap defintion>'.

As expected, the StreamConfigParser's lookupStream fails to find the stream name as the stream doesn't exist in the repository. 

In this scenario, what is a better way to handle the tap operations. 
Should we undeploy the tap when the stream is destroyed? ( though I don't see an easy way to find the taps that use a specific stream).",XD-699,Ilayaperumal Gopinathan,Handling tap operations on a tap that has reference to a deleted stream
3037,,David Turanski,Automate running integration tests on all supported transports,XD-698,David Turanski,Shell integration tests should be able to be run across all transports
3038,,David Turanski,Should be simple to test in isolation but also across transports (stream testing),XD-697,David Turanski,"Support the ability to test individual sources, sinks, and processors"
3039,,David Turanski,,XD-696,David Turanski,"Update Gemfire, Transport, and Job Launch docs"
3040,Jennifer Hickey,Jennifer Hickey,Spring Data Redis 1.1 M2 added the ability to use RedisTemplate with binary data. We should switch to that instead of the no-op serializer we were forced to implement previously.,XD-695,Jennifer Hickey,Upgrade SDR to get rid of temporary no-op serializer
3041,,Glenn Renfro,we should check the actual deployment requests were built correctly for each module in the testCreateUndeployAndDeleteOfStream test.  Currently we just use the anyListOf check.,XD-694,Glenn Renfro,Need to check the deployment requests in StreamsControllerIntegrationTest
3042,Ilayaperumal Gopinathan,Eric Bottard,,XD-693,Eric Bottard,Add deploy/undeploy commands for taps
3043,Mark Fisher,David Turanski,,XD-692,David Turanski,http source module should copy Content-Type header to SI MessageHeaders.CONTENT_TYPE
3044,David Turanski,Mark Pollack,Make the default value of enableJmx false until we have tested/documented JMX functionality,XD-691,Mark Pollack,Change JMX option to reference 'enableJmx' instead of 'disableJmx'
3045,Eric Bottard,Eric Bottard,"AbstractDeployer has 4 subclasses, 3 of which override e.g. deploy() making the boilerplate factorization ineffective.

Introduce an intermediate class for those deployers that support the concept of an instance (Stream, Tap, Job to some extent)",XD-690,Eric Bottard,"Simplify ""instance"" deployment code "
3046,David Turanski,David Turanski,"
String -> byte[] (string.getBytes()) 
byte[] -> byte[] (no serialization)
Pojo -> configured serialization

",XD-689,David Turanski,Support serialization/deserialization of Message payloads across JVMs across all transports.
3047,,Winston Koh,"stream create --name test1 --definition ""http --port=8827 | gemfire-server""
Created new stream 'test1'

stream create --name test2 --definition ""http --port=8828 | gemfire-json-server""
Created new stream 'test2'

even if gemfire server is not started, streams are successfully created. This behavior is inconsistent with hdfs where if hdfs connection is not available, creating stream using 'http | hdfs' will fail.

",XD-688,Winston Koh,error messages not thrown when creating gemfire sink without starting gemfire server
3048,,Winston Koh,"xd:>stream create --name testgemfire --definition ""http --port=8887 | gemfire""


16:20:28,503  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/streams"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'region' defined in null: Could not resolve placeholder 'regionName' in string value ""${regionName}""",XD-687,Winston Koh,provide user friendly messages when dealing with invalid gemfire sink
3049,Mark Fisher,Gary Russell,"Provide some syntax allowing multiple tap points to be directed to a named channel.

e.g. 
tap foo.4 > namedTap
tap bar.2 > namedTap

or

:tap.foo > counter",XD-686,Gary Russell,Support Named Taps (or Similar)
3050,Jennifer Hickey,Gary Russell,"Taps are currently source modules.

They could be refactored to simply bridge the tapped module's tap pub/sub topic directly (with conversion) to the first tap module's input channel.

Note - ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it's no longer a module we'll need special handling to stop/remove the tap adapter.",XD-685,Gary Russell,Refactor Taps to Avoid Transport Hop
3051,Mark Pollack,Mark Fisher,"also, the current behavior is broken; it checks if the property is set but does not actually check whether it's true or false",XD-683,Mark Fisher,Change jmxDisabled option to jmxEnabled and do not enable by default
3052,Glenn Renfro,Mark Fisher,"The expression currently appends ""."" + ${suffix} (where the default suffix is 'out').

If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.",XD-682,Mark Fisher,Modify file sink to avoid dot with empty suffix
3053,,David Turanski,"See 
https://github.com/dturanski/spring-xd/commit/18302ec62a85d5fd8918beb26cf19968d4a63a2d",XD-681,David Turanski,DSL Parser should check for invalid stream parameters
3054,,Glenn Renfro,This example should require no code. Just the basic XML.,XD-680,Glenn Renfro,Add Simple Batch  Sample to Spring XD Samples repo
3055,,Mark Pollack,"Please put in suggestions for the current .settings file.

Maybe one suggestion is to not format on save?",XD-679,Mark Pollack,Update settings file and reformat existing codebase.
3056,David Turanski,David Turanski,,XD-678,David Turanski,change accepted-media-types to accpted-content-types
3057,David Turanski,Jennifer Hickey,"xd:>tap destroy mytap
16:44:41,850  WARN Spring Shell client.RestTemplate:524 - DELETE request for ""http://localhost:8080/taps/mytap"" resulted in 400 (Bad Request); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD116E:(pos 4): unrecognized stream reference 'foo'
tap foo.http | log

Tap is then still listed when I do a ""tap list""",XD-677,Jennifer Hickey,Cannot destroy tap if tapped stream is already destroyed
3058,Mark Fisher,Mark Fisher,"Example using name:

{code}
filter --expression=""payload.myfield.startsWith('foo')""
{code}

Example using index:

{code}
filter --expression=""payload.2.startsWith('foo')""
{code}

This should support nested keys as well:

{code}
filter --expression=""payload.myfield.subfield.startsWith('foo')""
{code}
",XD-676,Mark Fisher,add PropertyAccessor for Tuple fields in SpEL
3059,Eric Bottard,Eric Bottard,"Because StringToJsonNodeTransformer expects a String as input, one cannot chain json related processors.

A simple solution would be to also accept Jackson IN and forward it directly in that case.",XD-675,Eric Bottard,Cannot chain json-field-value-filter & json-field-extractor
3060,Gunnar Hillert,Gunnar Hillert,,XD-674,Gunnar Hillert,Add Spring Batch word-count Sample to Spring XD Samples repo 
3061,,Mark Fisher,"the value for --target is required (there is no default), but the hint for that option states otherwise:

{code}
xd:>http post --target
http post --target
required --target: the location to post to; default if option not present: 'http://localhost:9000'
{code}
",XD-673,Mark Fisher,http post in shell incorrectly mentions default of --target option
3062,Eric Bottard,Mark Fisher,"should go thru the list of all commands available and make sure that a simple ""not connected"" message is returned instead of something like this:

{code}
org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:8080"":Unexpected end of file from server; nested exception is java.net.SocketException: Unexpected end of file from server
    at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:498)
....
{code}
",XD-672,Mark Fisher,Ugly error messages in shell when not connected
3063,Mark Fisher,Mark Fisher,"It should be possible to create streams like the following which rely upon named channel support and dynamic routing capabilities:

{code}
http | somerouter
:x > xtransformer | hdfs
:y > ytransformer | hdfs
{code}

The 'somerouter' processor could return ""x"" or ""y"" which determines the downstream path for each message.

This should be implemented in such a way that any developer adding a router module would only need to deal with existing Spring Integration semantics (in this case, only considering the return of ""x"" or ""y"" - whether it be SpEL or a POJO method invocation). Perhaps in the plugin that modifies a module context, we could simply add a new ChannelResolver implementation (by adding that ChannelResolver as a bean and/or a BeanPostProcessor that configures that as the resolver for any router, if necessary). That ChannelResolver would have a reference to the ChannelRegistry so that the router actually sends its messages to those shared channels. The shared channels themselves would have been created as long as a valid downstream flow has been defined.",XD-671,Mark Fisher,Add support for dynamic routing
3064,Eric Bottard,Eric Bottard,Provide Shell TAB completion when referencing an existing entity,XD-670,Eric Bottard,TAB completion for existing entities
3065,,Eric Bottard,Not only should it not use Joda (see XD-668) but the passing of dates currently relies on default formatting,XD-669,Eric Bottard,AggregateCounterTemplate should not use Joda
3066,,Eric Bottard,The Rest-Client project should not impose Joda to the user.,XD-668,Eric Bottard,Rest-Client should not force usage of Joda Time
3067,Gary Russell,Gary Russell,"Currently, the initial tap module accepted media types are not retrieved from the module when creating the tap.",XD-667,Gary Russell,Add Accepted Media Type Support to Tap
3068,Gary Russell,Gary Russell,Redis transport headers are not removed in taps.,XD-666,Gary Russell,Remove Redis Transport Headers from Tapped Stream
3069,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"It would be nice to have ""lastHours"" and ""lastDays"" options for aggregatecounter display command.",XD-665,Ilayaperumal Gopinathan,"AggregateCounter display command options with ""lastHours"" and ""lastDays"""
3070,Mark Fisher,Mark Pollack,,XD-664,Mark Pollack,File sink filename should default to having a '.out' suffix.
3071,Thomas Risberg,Thomas Risberg,"Keep getting the following warning:

WARN Spring Shell conf.Configuration:817 - fs.default.name is deprecated. Instead, use fs.defaultFS

Should switch to use the runtime value of the FS_DEFAULT_NAME_KEY constant based on Hadoop version used.",XD-663,Thomas Risberg,Use correct FS_DEFAULT_NAME_KEY constant based on Hadoop version used
3072,Ilayaperumal Gopinathan,Jennifer Hickey,"I see the following output on the shell if I create a job and reference a non-existent trigger. There's a big stack trace in the server log, but nothing on the shell side indicating failure. A subsequent ""jobs list"" also shows the job. The same thing happens if I deploy an undeployed Job after deleting its associated Trigger.

$ job create --name helloWorldJob --definition ""myjob --trigger=nonexistenttrigger""
Successfully created and deployed job 'helloWorldJob'",XD-662,Jennifer Hickey,No indication of failure in shell when deploying job referencing nonexistent trigger
3073,Gunnar Hillert,Gunnar Hillert,,XD-661,Gunnar Hillert,Batch Jobs: Add the ability to provide JobParameters
3074,David Turanski,Mark Pollack,,XD-660,Mark Pollack,Rename spring-xd-shell to xd-shell
3075,Gary Russell,Gary Russell,Remove the {{NoOpRedisSerializer}} and use the non-serialization feature of M2.,XD-658,Gary Russell,Update to Spring-Data-Redis 1.1.0.M2
3076,,David Turanski,,XD-657,David Turanski,Support polling configuration for named channel queues in CLI
3077,Jennifer Hickey,Gary Russell,"Consider 2 Admins/Containers that are using discrete Redis instances but a shared Rabbit instance for the transport.

If two different streams are deployed on each, but with the same stream name, the Rabbit queues will be common (e.g. foo.0), causing crosstalk.

Stream names must be unique across all container instances sharing Rabbit infrastructure.

I am not sure what the solution is; two instances of the *same* stream *do* need common queues but instances of different streams need a qualifier of some kind (container name?). I guess it's not *that* big of an issue because, if they're sharing infrastructure, they're likely to be sharing a stream repo too - in which case you'd need unique stream names.",XD-656,Gary Russell,"Intra-Module ""Pipe"" Naming"
3078,David Turanski,Mark Pollack,"Instead of 

xd:>http post --target http://localhost:9898 --data ""hello world""
> POST (text/plain;charset=UTF-8) http://localhost:9898 hello world
> 200 OK
> Content-Length: 0
> Connection: keep-alive
> 
Success sending data 'hello world' to target 'http://localhost:9898'


have

xd:>http post --target http://localhost:9898 --data ""hello world""
> POST (text/plain;charset=UTF-8) http://localhost:9898 hello world
> 200 OK


or better yet

xd:>http post --target http://localhost:9898 --data ""hello world""
> 200 OK POST (text/plain;charset=UTF-8) http://localhost:9898 hello world




 
",XD-655,Mark Pollack,Trim output from http post shell command to two lines
3079,liujiong,David Turanski,"Support pubsub named channels… the story could be a bit more general though: enable channel creation (with configurable settings) via the REST API and shell

>namedchannel create foo --domain PUBSUB",XD-654,David Turanski,Support explict named channel creation with configurable settings via the REST API and Shell
3080,David Turanski,David Turanski,"Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",XD-653,David Turanski,Configure Jackson ObjectMappers to Allow Single Quotes 
3081,,Jennifer Hickey,"The doc says the name option is ""the absolute path to the directory to monitor for files"" but it actually seems to be the name of a dir in /tmp/xd/input. Not sure which is the correct behavior. Also, ""name"" as an option name seems a little vague. Maybe something like ""--directory""?

Also, if I set --duplicates=true, it actually prevents duplicates (setting prevents-duplicates to true)",XD-652,Jennifer Hickey,File Source Name and Duplicates options not working as documented
3082,,Andrew Eisenberg,"Any kind of sophisticated artifact retrieval mechanism in XD will need to grab more than one kind of artifact at once.  For example, if I want to see all taps, streams, triggers, and jobs (ie- everything), I need to make 4 http requests.

I can imagine dashboards that need to display information on artifacts of multiple kinds.

There will also need to be a way to pass a query to return a sub-set of artifacts, but that should be designed separately.",XD-651,Andrew Eisenberg,End point to retrieve a list of all XD artifacts of all kinds
3083,,Andrew Eisenberg,"After running gradle -> refresh source folders on the spring-xd-module project in Eclipse, there is an error because the {{src/test/java}} folder is missing.

Solution is to add a placeholder file.",XD-650,Andrew Eisenberg,Eclipse build path error after running gradle -> refresh source folders in Eclipse
3084,Jennifer Hickey,Mark Pollack,This will come back in M3 once we iron out the issues.,XD-649,Mark Pollack,Remove 'substream' from the documentation
3085,Eric Bottard,Eric Bottard,"As we overwrote changes to file source by mistake, let's add some regression tests, esp. to the file location.

Plan on extending the utility source and sink functionality",XD-648,Eric Bottard,Regression test on file source
3086,David Turanski,Eric Bottard,"Current implementation converts to a String.

See if we can emit raw payload (given that we also emit content-type header)

Setting to 8 points, as this may have lots of implications down the line though",XD-647,Eric Bottard,HTTP source should emit raw payload
3087,,Eric Bottard,"support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean.

Consider splitting RichGauge in two flavors: arithmetic and exponential.

Involves quite some work at the repository, handler and REST level though... ",XD-646,Eric Bottard,Split RichGauge in 2
3088,Jennifer Hickey,Jennifer Hickey,"Need to undo the recent add of rabbit.properties to xd-common.xml. Tried to work around this by configuring rabbit-container with only the PPC it needs (pointing to only rabbit.properties), but this caused issues with redis-analytics later requiring redis.properties. Would be nice to have a way for redis-analytics to contribute redis.properties or something similar...


Also, strictly speaking, the local admin server does not even need redis.properties, let alone rabbit.properties, so we should find a cleaner way to configure this.",XD-645,Jennifer Hickey,Find a way to contribute redis.properties to Rabbit Container PPC
3089,Jennifer Hickey,Jennifer Hickey,I modified rabbit.hostname in rabbit.properties and xd-container still attempted to find Rabbit at localhost with --transport rabbit. Looks like the PPC for xd-container and xd-admin is not pointing to rabbit.properties,XD-644,Jennifer Hickey,Connection props in rabbit.properties ignored by xd-admin and xd-container
3090,Thomas Risberg,Thomas Risberg,"We need to add support for matching column names with underscores like ""user_name"" and map them to camel case style keys like ""userName"" in the JdbcMessagePayloadTransformer.",XD-643,Thomas Risberg,Map column names with underscore to camelCase style keys for JDBC sink
3091,Mark Pollack,Mark Pollack,"Figure 1 here https://github.com/SpringSource/spring-xd/wiki/Architecture should also show Rabbit as an option, since otherwise people will think we are tied to redis.",XD-642,Mark Pollack,Update architecture diagram to show rabbit in addition to redis to communicate between admin and containers
3092,Andy Clement,Andy Clement,"This is a follow on from XD-592. In that bug we fixed up the ability to use tap with pipe.  Tap when used as a source channel should also work (and should deploy in a more optimized fashion since source channels can be directly connected to the subsequent module, creation of a pass-through tap instance isn't necessary).  This test shows the syntax that should work and the current information about how it fails:

{code}
public void testTapSourceChannel() throws IOException {
  FileSink sink1 = newFileSink();
  FileSink sink2 = newFileSink();

  stream().create(""myhttp"",
    ""http --port=9314 | transform --expression=payload.toUpperCase() | filter --expression=true > :foo"");

  // fails with: java.lang.IllegalArgumentException: bean 'myhttp.1' is already
  // registered but does not match the required type
  tap().create(""wiretap1"", ""tap myhttp.transform > transform --expression=payload.replaceAll('a','.') | %s"", sink1);

  // fails in TapDefinition ctor with: java.lang.IllegalArgumentException:
  // streamName cannot be empty or null
  tap().create(""wiretap2"", ""tap :foo > transform --expression=payload.replaceAll('a','.') | %s"", sink2);

  httpPostData(""http://localhost:9314"", ""Dracarys!"");
}
{code}

I suspect part of the problem initially lies with the code around EnhancedStreamParser that builds the module deployment requests from the Ast parsed from the input DSL string.  Whether a source channel was originally specified with 'tap' is captured in that Ast but that knowledge doesn't appear to be getting used.

",XD-641,Andy Clement,Problem with tapping and > (source channels)
3093,Thomas Risberg,Jennifer Hickey,"Trying to use xd-container with PHD, and therefore need to start with --hadoopDistro. I get the following error:

$ bin/xd-container --hadoopDistro phd1
17:11:20,305 ERROR main server.ContainerMain:59 - ""--hadoopDistro"" is not a valid option
",XD-640,Jennifer Hickey,Cannot start xd-container with the --hadoopDistro option
3094,Eric Bottard,Jennifer Hickey,"I had the following interaction with the shell. It does work if I do ""hadoop fs rm /xd/tweets --recursive"". Either the order shouldn't matter or the doc should be more clear on placement of the option.

xd:>hadoop fs rm /xd/tweets
To remove directory, please use fs rm --recursive instead
xd:>hadoop fs rm --recursive /xd/tweets
java.lang.IllegalArgumentException: Failed to convert '/xd/tweets' to type boolean for option 'recursive'
Cannot convert /xd/tweets to type Boolean.
",XD-639,Jennifer Hickey,Update error message for usage of hadoop rm with --recursive option
3095,,Jennifer Hickey,"When using the shell, I forgot to configure the Hadoop URL via ""hadoop config fs --namenode hdfs://pivhdsne:8020""

I then did:
xd:>hadoop fs ls /xd/tweets
You must set fs URL before run fs commands

The error message should tell me how to set the URL (via the hadoop config command). I had to go back to the documentation to figure it out. It's also not entirely grammatically correct.",XD-638,Jennifer Hickey,Unclear error message using hadoop fs shell commands without configuring a URL
3096,Gary Russell,Gary Russell,"Factor out common Redis/Rabbit {{ChannelRegistry}} code.

Also, factor out common inbound/tap code (very similar).

Change transport nternals to Use AbstractTransformer instead of {{ARPMH}} and {{BridgeHandler}}.",XD-637,Gary Russell,Channel Registry Refactoring
3097,Gary Russell,Gary Russell,"The {{AbstractReplyProducingMessageHandler}} in the Rabbit transport exposes the internal transport content-type, if none existed on the original transported message.",XD-636,Gary Russell,x-xd-* Transport Content-Type Leakage
3098,David Turanski,David Turanski,pollers should standardize on fixed-delay vs fixed-rate. The value should accept a property with a standard name like 'interval',XD-635,David Turanski,OOTB source modules with poller should use fixed-delay
3099,Thomas Risberg,Thomas Risberg,Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 - this could lead to classpath problems if we include both.,XD-634,Thomas Risberg,Fix guava dependency for hadoop20 and phd1 
3100,Gary Russell,Gary Russell,Consistency with JMS Source.,XD-633,Gary Russell,Rabbit Source - Make Default QueueName == Stream Name
3101,Eric Bottard,Gunnar Hillert,"E.g. allow for posting of JSON data stored in local files.

* Allow users to specify the *content-type*.
* Ensure that Unicode data (UTF) posts correctly.",XD-632,Gunnar Hillert,Shell: HTTP Post - Allow posting of local file contents
3102,Gunnar Hillert,Gunnar Hillert,"The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename *JobCommandTests* to *JobCommandsTests* as it tests class *JobCommands*. Please check all tests in that package for correct naming.",XD-631,Gunnar Hillert,Pluralize test classes in package org.springframework.xd.shell.command
3103,Eric Bottard,Andy Clement,"There are some asserts in StreamCommandTests that are commented out (see the TODOs in there). These asserts are verifying the contents of the various sinks employed in the tests. I am finding that if the tests are run all together with the asserts enabled (run all StreamCommandTests), some of the assertions fail, with something like:

{code}
org.junit.ComparisonFailure: expected:<[DRACARYS!
]> but was:<[]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)

{code}

When run individually the tests succeed. Not sure if it is timing (checking sinks before they've been written to) or something else...",XD-630,Andy Clement,StreamCommandTests - asserting sink contents sometimes failing
3104,,Andy Clement,"{code}
mystream = http | transform --payload=expression.toUpperCase() > :foo
tap mystream.transform | log
{code}
This appears to fail because we can't tap into whatever was created to represent the named channel 'foo'. There is an @Ignore test in StreamCommandTests called testTappingModulesVariationsWithSinkChannel() which checks this.

(The parser is currently resolving 'tap mystream.transform' to 'tap --channel=foo'.)",XD-629,Andy Clement,Problem with tapping on a module using a named sink channel
3105,,Glenn Renfro,,XD-628,Glenn Renfro,Streams created without a '|' (substreams) are being typed by the parser as a Job
3106,,Andrew Eisenberg,"Run the shell command {{stream list}} and you get the following error:

{code}
xd:>stream list
Command failed org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Unrecognized field ""metadata"" (class org.springframework.xd.rest.client.domain.StreamDefinitionResource$Page), not marked as ignorable (3 known properties: , ""links"", ""content"", ""page""])
 at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@30721965; line: 1, column: 148] (through reference chain: org.springframework.xd.rest.client.domain.Page[""metadata""]); nested exception is com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field ""metadata"" (class org.springframework.xd.rest.client.domain.StreamDefinitionResource$Page), not marked as ignorable (3 known properties: , ""links"", ""content"", ""page""])
 at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@30721965; line: 1, column: 148] (through reference chain: org.springframework.xd.rest.client.domain.Page[""metadata""])
{code}

You get a similar error when running any of the following:

{code}
tap list
trigger list
job list
{code}",XD-627,Andrew Eisenberg,"shell command ""stream list"" fails"
3107,Gunnar Hillert,Gunnar Hillert,"The *http post* command uses the default MediaType by the RestTemplate, which in return triggers the default *StringHttpMessageConverter* which itself uses the default charset *ISO-8859-1*.

This creates issues when posting special characters.",XD-626,Gunnar Hillert,Shell: RestTemplate not posting using UTF-8 
3108,,Gary Russell,,XD-625,Gary Russell,Revert XD-624 When SI 3.0.M3 is Available
3109,Gary Russell,Gary Russell,"WARN log emitted because the embedded connection factory does not get an application event publisher.

Will be fixed in SI M3 (INT-3107).",XD-624,Gary Russell,Use External Connection Factory in TCP Syslog Source
3110,,Winston Koh,"currently, we can specify any bogus url using 'hadoop config fs --namenode' without any warning.

e.g.
hadoop config fs --namenode hdfs://localhost:8888

doing a 'hadoop fs ls /' will catch the error and throw exception. Ideally, we should catch the bogus url error early in the 'hadoop config fs' command. similar to 'admin config server --uri'",XD-623,Winston Koh,catch erroneous hadoop config fs --namenode url early
3111,Gary Russell,Gary Russell,"/home/gpr/Documents/github/spring-xd/spring-xd-analytics/src/main/java/org/springframework/xd/store/AbstractRedisRepository.java:196: warning - @param argument ""the"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/AbstractPlugin.java:93: warning - @return tag has no arguments.
/home/gpr/Documents/github/spring-xd/spring-xd-rest-domain/src/main/java/org/springframework/xd/rest/client/util/RestTemplateMessageConverterUtil.java:63: warning - Tag @link: reference not found: StreamDefinitionResource.Page
/home/gpr/Documents/github/spring-xd/spring-xd-rest-client/src/main/java/org/springframework/xd/rest/client/TapOperations.java:40: warning - @param argument ""control"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/OptionUtils.java:29: warning - @parame is an unknown tag.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/MissingRequiredDefinitionException.java:38: warning - @param argument ""name"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/StreamServer.java:102: warning - @return tag has no arguments.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/TapDefinition.java:57: warning - @return tag has no arguments.
/home/gpr/Documents/github/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/AbstractPlugin.java:93: warning - @param argument ""group"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/AbstractPlugin.java:93: warning - @param argument ""index"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/AbstractPlugin.java:101: warning - @param argument ""group"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/AbstractPlugin.java:101: warning - @param argument ""index"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/json/TypedJsonMapper.java:133: warning - @return tag has no arguments.
/home/gpr/Documents/github/spring-xd/spring-xd-shell/src/main/java/org/springframework/xd/shell/util/UiUtils.java:60: warning - @CloudApplication is an unknown tag.
/home/gpr/Documents/github/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleJsonMarshaller.java:26: warning - @param argument ""tupleToStringConverter"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleJsonMarshaller.java:26: warning - @param argument ""stringToTupleConverter"" is not a parameter name.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl/DSLException.java:89: warning - @return tag has no arguments.
/home/gpr/Documents/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl/StreamLookupEnvironment.java:60: warning - @return tag has no arguments.
",XD-622,Gary Russell,Fix JavaDoc Warnings
3112,,Gunnar Hillert,"Currently, you have to set the default name node every time your start the shell. We should do 2 things: 

- Provide a default Name node Set Default Hadoop Name Node for Shell: hdfs://localhost:8020
- Should we provide some form of persistence? It kind of sucks that you have to re-specify the name node every time the shell starts up

{code}
xd:>hadoop fs ls /
You must set fs URL before run fs commands
{code}
",XD-621,Gunnar Hillert,Set Default Hadoop Name Node for Shell
3113,Mark Pollack,Mark Pollack,Model the API more akin to SpringXDOperations api.,XD-620,Mark Pollack,"Refactor test cases to move away from inheritance model of utility methods for streams, counters "
3114,Ilayaperumal Gopinathan,Mark Pollack,,XD-619,Mark Pollack,Add list command for AggregateCounter
3115,Mark Pollack,Mark Pollack,,XD-618,Mark Pollack,Update to Spring Shell 1.1.0.M1 release
3116,,Mark Pollack,"Was following the (now updated) directions for gemfire-cq source.

xd:> stream create --name stocks --definition ""http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')""
xd:> stream create --name cqtest --definition ""gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | file""
xd:> http post --target http://localhost:9090 --data ""{""symbol"":""VMW"", ""price"":73}""

The double quotes were causing a problem with xd-singlenode

Aug 06, 2013 5:38:15 PM org.jboss.netty.channel.SimpleChannelUpstreamHandler
WARNING: EXCEPTION, please implement org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.exceptionCaught() for proper handling.
org.springframework.integration.transformer.MessageTransformationException: org.springframework.integration.MessageHandlingException: org.springframework.integration.transformer.MessageTransformationException: Expected a ':' after a key at 22 [character 23 line 1]
	at org.springframework.integration.transformer.MessageTransformingHandler.handleRequestMessage(MessageTransformingHandler.java:73)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)

Using single quotes inside the json brackets worked, need to investigate.",XD-617,Mark Pollack,Making an http post with json double quoted will hang the shell.
3117,,Mark Fisher,,XD-616,Mark Fisher,document rabbit source
3118,Janne Valkealahti,Winston Koh,"when automating tests for creating http|hdfs stream, I run into an issue where CommandResult object always set success=true even if the actual hadoop shell command fail.

== valid hdfs url
getShell().executeCommand(""hadoop config fs --namenode hdfs://localhost:8020"");
CommandResult cr = getShell().executeCommand(""hadoop fs ls /"");

== output
Found 2 items
drwxr-xr-x   - administrator supergroup          0 2013-08-05 17:18 /user
drwxr-xr-x   - administrator supergroup          0 2013-08-05 17:18 /xd

CommandResult [success=true, result=null, exception=null]

== invalid hdfs url
getShell().executeCommand(""hadoop config fs --namenode hdfs://localhost:8021"");
CommandResult cr = getShell().executeCommand(""hadoop fs ls /"");

== output
Bad connection to FS. command aborted. exception: Call to localhost/127.0.0.1:8021 failed on connection exception: java.net.ConnectException: Connection refused
CommandResult [success=true, result=null, exception=null]

Ideally, we should set success=false if hadoop command fail and if hadoop command succeeds, we should set success=true and populate result= output from hadoop command instead of result=null

",XD-615,Winston Koh,CommandResult return sucess even if hadoop shell command fails
3119,Gary Russell,Gary Russell,"Content-Type during transport transit is not the same as the content-type within modules.

""Real"" transports always use byte[] which may contain raw byte[] from a source, a byte[] converted from a String (which may or may not already contain JSON), or a byte[] containing JSON converted by the transport on the outbound side.

The transport needs to convey which of these was applied on the outbound side so it can properly reconstruct the message.

Retain any content-type header that already exists in the message, and restore it.

For Rabbit, use normal SI/Rabbit headers to convey this information.

For Redis, add the information to the byte[].",XD-614,Gary Russell,Conversion Enhancements
3120,Ilayaperumal Gopinathan,Jennifer Hickey,"When using Redis store, stored deployed streams should be deployed on container restart.",XD-613,Jennifer Hickey,Deployed streams should be restarted on container start
3121,Mark Fisher,Mark Pollack,"https://github.com/springsource/spring-xd/wiki/Sinks

should have 'rabbit' added to the list and also the corresponding section that shows some basic usage.",XD-612,Mark Pollack,Create a rabbit sink module and documentation
3122,Mark Pollack,Mark Pollack,"http://static.springsource.org/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#sources

should have 'file' added to the list and also the corresponding section that shows some basic usage.",XD-611,Mark Pollack,Documentation for file source
3123,Gary Russell,Mark Pollack,"http://static.springsource.org/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#sources

should have 'jms' added to the list and also the corresponding section that shows some basic usage.",XD-610,Mark Pollack,Documentation for jms source
3124,Gary Russell,Mark Pollack,"http://static.springsource.org/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#sources

should have 'rabbit' added to the list and also the corresponding section that shows some basic usage.",XD-609,Mark Pollack,Documentation for rabbit source
3125,Gunnar Hillert,Gunnar Hillert,,XD-608,Gunnar Hillert,Fix text-table rendering
3126,Eric Bottard,Eric Bottard,,XD-607,Eric Bottard,"Integration tests for ""DSL Reference"" examples"
3127,,Eric Bottard,"This may be an issue following the search/replace from curl to Shell, but for example, this documentation line does not work:

http post --target http://localhost:9000 --data ""{\""symbol\"":\""VMW\"",\""price\"":72.04}""

The backslash prior to quote is left in the payload (and hence Jackson chokes on it)

We need clear rules about quoting at the shell level",XD-606,Eric Bottard,Document JSON quoting behavior in shell
3128,Eric Bottard,Eric Bottard,"The RichGauge section does not mention the ""alpha"" parameter in redis output, nor does it explain its meaning.",XD-605,Eric Bottard,Rich Gauge doco is outdated
3129,Gary Russell,David Turanski,"xd:>stream create ticktock --definition ""time | log"" --deploy true
18:45:13,310  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/streams"" resulted in 400 (Bad Request); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is already a stream named 'ticktock'

xd:>stream destroy ticktock
18:45:16,505  WARN Spring Shell client.RestTemplate:524 - DELETE request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.NullPointerException


Caused by: java.lang.NullPointerException
	at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:143)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:97)


",XD-603,David Turanski,NPE on stream destroy
3130,Gary Russell,Gary Russell,,XD-602,Gary Russell,Fix ChannelRegistry Cleanup During Module Undeploy
3131,,Winston Koh,"./xd-container [OK]
./xd-container --transport redis [OK]
./xd-container --transport rabbit [OK]
./xd-container --transport local [FAIL]

wkoh-mbp:bin administrator$ ./xd-container --transport local
Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.jolokia.jvmagent.spring.SpringJolokiaAgent#0': Invocation of init method failed; nested exception is java.lang.NumberFormatException: For input string: ""${xd.jmx.port}""
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1488)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:626)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)
	at org.springframework.xd.dirt.server.ContainerMain.launch(ContainerMain.java:89)
	at org.springframework.xd.dirt.server.ContainerMain.main(ContainerMain.java:72)
Caused by: java.lang.NumberFormatException: For input string: ""${xd.jmx.port}""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Integer.parseInt(Integer.java:449)
	at java.lang.Integer.parseInt(Integer.java:499)
	at org.jolokia.jvmagent.JolokiaServerConfig.initConfigAndValidate(JolokiaServerConfig.java:211)
	at org.jolokia.jvmagent.JolokiaServerConfig.init(JolokiaServerConfig.java:84)
	at org.jolokia.jvmagent.JolokiaServerConfig.<init>(JolokiaServerConfig.java:68)
	at org.jolokia.jvmagent.spring.SpringJolokiaAgent.afterPropertiesSet(SpringJolokiaAgent.java:78)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1547)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1485)
	... 11 more",XD-601,Winston Koh,./xd-container  --transport local throws NumberFormatException
3132,Ilayaperumal Gopinathan,David Turanski,,XD-600,David Turanski,"Add deploy/undeploy/destroy 'all' commands for all applicable resources (streams, tap, job & trigger,)"
3133,Thomas Risberg,Gary Russell,"When importing Spring-XD as a gradle project, in STS, while building the model, we get

Root exception:
java.lang.IllegalArgumentException: Project location doesn't exist: 
.../spring-xd/spring-xd-hadoop/hadoop11

./gradlew eclipse creates these directories, but the plugin needs them before running that task

The problem seems to be that these ""projects"" are not really projects.

Perhaps a quick fix would be to commit these directories (with a dummy file) ??",XD-599,Gary Russell,Gradle Import Broken by Hadoop Pseudo Projects
3134,David Turanski,David Turanski,"Need to investigate why this is happening, normally setting 
{code:xml}
<gfe:client-cache close=""false""/>
{code}
prevents the (singleton) cache from closing when the application context is closed. ",XD-598,David Turanski,Gemfire cache closed when a gemfire module is undeployed
3135,Glenn Renfro,Glenn Renfro,"When running an ad-hoc job without the use of a trigger (adhoc or named).  The user has to wait for job to complete before receiving a success.  We need to launch a job and get a success back to the user letting them know the job has been launched.

for example --immediate",XD-597,Glenn Renfro,Ad-Hoc Job needs to have option for launch and forget
3136,Gunnar Hillert,Gunnar Hillert,"Add CONTRIBUTING.md file, use the Spring Integration file as the basis.",XD-596,Gunnar Hillert,Add CONTRIBUTING.md file
3137,Eric Bottard,Ilayaperumal Gopinathan,"We need to fix the github wiki to use the xd shell command prompt ""xd:>"".",XD-595,Ilayaperumal Gopinathan,"Fix wiki documentation to use xd shell command prompt to read ""xd:>"""
3138,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"We need to add list/delete commands for the metrics:

InMemoryAggregateCounter
FieldValueCounter
Gauge
RichGauge

Currently, the AbstractMetricsController class has the delete method to delete the metric from the repository. We can probably use the same for all the metrics.",XD-594,Ilayaperumal Gopinathan,Create list/delete commands for all the metrics
3139,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Add ""counter delete"" shell command. This also requires implementation of DELETE rest end point at CountersController.",XD-593,Ilayaperumal Gopinathan,"Add ""counter delete"" shell command"
3140,,Andy Clement,"Start of a test program that can be placed in StreamCommandTests:

{code}
@Test
public void testTappingAndChannels() {
  executeStreamCreate(""myhttp"",""http --port=9314 | transform --expression=payload.toUpperCase() | log"",true);
  executeStreamCreate(""tap"",""tap @myhttp.1 | log"",true);		
  executeStreamCreate(""tap_new"",""tap myhttp.1 > log"",true);				
  executeCommand(""http post --data Dracarys! --target http://localhost:9314"");
  // TODO verify both logs output DRACARYS!
}

{code}

In the test program see two taps. One using the older style and one using the newer style and '>' so that there is no real tap module source, the log module just gets its input channel wired directly to myhttp.1 (the output of transform).  They should be doing the same thing.  However when run the output for tap_new is missing, all I see is:

{code}
11:39:36,055  WARN New I/O worker #28 logger.tap:141 - DRACARYS!
11:39:36,059  WARN New I/O worker #28 logger.myhttp:141 - DRACARYS!
{code}

No errors are reported, there is just no output for tap_new.",XD-592,Andy Clement,Problems with advanced tapping
3141,Thomas Risberg,Mark Pollack,"The current flow of gradle tasks is confusing.  Suggest the following changes to simplify the flow.

1. Move the current task logic in zipXD to distZip
2. Have distZip depend on dist
3. Update the 'how to build docs' on the wiki
4. Make sure that the distZip task only shows up once in the list of gradle target. ",XD-591,Mark Pollack,Improve build file distribution tasks
3142,Mark Pollack,Mark Pollack,Keep track of named streams that were create and use @After to destroy them.,XD-589,Mark Pollack,Create AbstractStreamIntegrationTest that will destory streams that were created during test method execution
3143,Luke Taylor,Eric Bottard,"Both Luke's original code and my refactored PR[1] (which uses same code snippet) seem to behave strangely.

Stored values seem fine, but the getCounts() method seems phony.

To test:
1) stream create foo --definition ""time|log""
2) tap create bar --definition ""tap@foo | aggregatecounter""
3) curl -H ""application/json"" http://localhost:8080/metrics/aggregate-counters/bar

this gives default bucketing (hourly) but chances are that they are empty. ",XD-588,Eric Bottard,RedisAggregateCounterRepository doesn't give proper results back
3144,Glenn Renfro,Glenn Renfro,,XD-587,Glenn Renfro,Create a abstract base class for rest controllers
3145,Mark Pollack,Luke Taylor,,XD-586,Luke Taylor,Document queue channel capacity configurable when using local transport
3146,David Turanski,David Turanski,"The upgrade to Jackson 2.2 included the following change to the build script
{code}
project('spring-xd-dirt') {
	description = 'Spring XD DIRT'
	configurations {
	  [runtime,testRuntime]*.exclude group: 'org.codehaus.jackson'
	}
{code}

Spring social twitter template depends on these classes
",XD-585,David Turanski,Deploying with twittersearch source throws Jackson ClassDefNotFound exception
3147,,David Turanski,"The documented gemfire-cq example (https://github.com/springsource/spring-xd/wiki/Sources#wiki-gemfire-cq) fails:

xd:>stream create --name cqtest --definition ""gemfire-cq --query=""Select * from /Stocks where symbol=
'VMW'"" | file""
You cannot specify option 'name' when you have also specified '' in the same command
xd:>stream create --name cqtest --definition ""gemfire-cq --query=Select * from /Stocks where symbol='
VMW' | file""
10:01:46,249  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/str
eams"" resulted in 400 (Bad Request); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 26): unexpected
 data in stream definition '*'
gemfire-cq --query=Select * from /Stocks where symbol='VMW' | file
                          ^
",XD-584,David Turanski,Parsing stream definition with parameter containing single quotes not working
3148,Gary Russell,David Turanski,"This has been observed intermittently with Redis transport by myself and others when sending a message to a valid stream. Not sure how to recreate it yet.

11:27:10,082 ERROR ThreadPoolTaskScheduler-1 redis.RedisQueueInboundChannelAdapter:126 - Error sending message
org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'org.springframework.context.support.GenericApplicationContext@3f73865d.input'.
",XD-583,David Turanski,Dispatcher Has No Subscriber Error when posting a message to a stream
3149,Eric Bottard,Luke Taylor,"Sending data to an incomplete stream which is created using a named sink channel only works when using Redis (or Rabbit?, not tested). Since the in-memory version doesn't use a queue, it will fail if you are using xd-singlenode.

We should use a queue channel with unlimited capacity to allow messages to be sent before the full stream is created.",XD-582,Luke Taylor,Support named channels when using local transport
3150,Eric Bottard,Mark Pollack,"results in both in-memory and redis based definitions of RichGaugeService - can't satisfy autowiring because there are two candidates.

Had to change --analytics=memory to get the application context to load.",XD-581,Mark Pollack,"configuration conflict when using ""--transport"", ""local"", ""--store"", ""redis"", ""--disableJmx"", ""true"", ""--analytics"", ""redis"""
3151,,Eric Bottard,"From https://github.com/SpringSource/spring-xd/pull/161:

""The command shell needs to also support different hadoop distribution options. Perhaps the shell just uses a relative path to the location of xd/lib/""",XD-580,Eric Bottard,XD Shell needs to support multiple Hadoop distros
3152,Thomas Risberg,Mark Pollack,,XD-579,Mark Pollack,Modify startup script of xd shell to allow specifying hadoop distro to use
3153,Thomas Risberg,Mark Pollack,"http://localhost:8080:>hadoop config fs --namenode webhdfs://localhost:50070
http://localhost:8080:>hadoop fs ls /
Hadoop configuration changed, re-initializing shell...
run HDFS shell failed. Message is: org/mortbay/util/ajax/JSON

This was on a hadoop 1.0.1 install

The hdfs http interface was available

$ curl -i ""http://localhost:50070/webhdfs/v1/tmp?op=GETFILESTATUS""
HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked
Server: Jetty(6.1.26)

{""FileStatus"":{""accessTime"":0,""blockSize"":0,""group"":""supergroup"",""length"":0,""modificationTime"":1365015846724,""owner"":""mpollack"",""pathSuffix"":"""",""permission"":""777"",""replication"":0,""type"":""DIRECTORY""}}
",XD-578,Mark Pollack,Can't access HDFS using webhdfs protocol
3154,,Mark Pollack,,XD-577,Mark Pollack,"In documentation, replace usage of 'raw' hadoop command with shell 'hadoop' commands"
3155,Gunnar Hillert,Mark Pollack,,XD-576,Mark Pollack,Change banner of shell to say only 'xd'
3156,Eric Bottard,Mark Pollack,"The current http command is of the form

http://localhost:8080:>post httpsource --target http://localhost:9090 --data 10


It isn't intuitive to think 'post', rather the command can be 

http post --target http://localhost:9090 --data 10

which will allow us to have support for other http verbs and cleanly separate the namespace from 'hadoop' etc.

The RestShell from which this came was only concerned with http actions, so the leading command classification probably seemed superfluous.
",XD-575,Mark Pollack,Change http command to post data by putting 'http' as the main command option
3157,Ilayaperumal Gopinathan,Mark Pollack,"e.g. http://localhost:8080:>post httpsource --target http://localhost:9090 --data 10

I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.",XD-574,Mark Pollack,Replace usage of 'raw' curl with shell command to post http data in documentation
3158,Mark Pollack,Mark Pollack,,XD-572,Mark Pollack,Prepare Blog post for XD M2
3159,Ilayaperumal Gopinathan,Mark Pollack,"Expected usage (ATM) would be

// sink channel called foo
http | transform --expression=payload.toUppercase() > :foo
// source channel called foo
:foo > count | file",XD-571,Mark Pollack,Create shell integration test for named chanels
3160,Ilayaperumal Gopinathan,Mark Pollack,"DSL should be able to parse what is below, need tests (CLI integration tests) to ensure it is being mapped to an executeable stream.

myIntricateFlow = transform --expression=payload.toUppercase() | transform --expression=payload.toLowercase()
http | myIntricateFlow | file
obfuscateName = transform --expression=payload.replaceAll(""${name}"",XXX)
twitter --query=Bieber | obfuscateName --name=Justin | file
",XD-570,Mark Pollack,Test composition  / parameterize composition of modules
3161,Luke Taylor,Mark Pollack,"Create a reproducible series of steps or shell integration test.
",XD-569,Mark Pollack,Investigate failures to start a stream when using named channels.
3162,Glenn Renfro,Mark Pollack,,XD-568,Mark Pollack,Documentation for deleting triggers
3163,Glenn Renfro,Mark Pollack,,XD-567,Mark Pollack,Documentation for fixed rate triggers
3164,Thomas Risberg,Mark Pollack,,XD-566,Mark Pollack,Document JDBC module
3165,Thomas Risberg,Mark Pollack,Show how to select a specific hadoop distribution when starting embedded/standalone XDContainer.,XD-565,Mark Pollack,Documentation for using a specific Hadoop distribution
3166,,Mark Pollack,,XD-564,Mark Pollack,Upgrade sink and processor modules to use new conversion service
3167,David Turanski,Mark Pollack,"make sure nothing is broken - spot check using.

1) ticktock
2) twitter
3) gemfire


",XD-563,Mark Pollack,Regression test existing functionality of stream/taps based on introduction of new conversion functionality
3168,,Mark Pollack,,XD-562,Mark Pollack,Documentation for use of conversion service and creating custom processing modules that use the Tuple data structure.
3169,Glenn Renfro,Mark Pollack,"reproduce
1) Create a bad stream definition name 'bad'
Try to recreate with the same name, but correct stream definitions.  The system will report that the stream already exists.

",XD-561,Mark Pollack,Failure when creating/deploying stream leaves invalid stream registry/definitions in the Repository implementations.
3170,Glenn Renfro,Glenn Renfro,"After XD-554 the ModuleJobExecutor.start does not get called.  Thus jobs that are ""run one time"" do not fire.",XD-560,Glenn Renfro,Ad-hoc Jobs do not start
3171,Gunnar Hillert,Mark Pollack,,XD-559,Mark Pollack,Send failing sonar build message to spring-xd mailing list.
3172,,Luke Taylor,"There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers (CounterResource, GaugeResource). The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",XD-558,Luke Taylor,Create IntegralMetric and IntegralResource types
3173,,Eric Bottard,"It seems the html rendering of documentation is using a variable width font for some of the code (esp. [source,sh] apparently) rendering.

Weird thing though is that when mouse hovering over some of them, they went back to fixed width. See screenshot.

http://static.springsource.org/spring-xd/docs/current-SNAPSHOT/reference/html/#_start_the_runtime_and_the_xd_shell
",XD-557,Eric Bottard,HTML Doco has font issues for [source]
3174,,Andrew Eisenberg,"XD instances will not accept xhr requests from browsers whose page origin does not match the XD instance.  

As an example, the Kodiak UI is served from a different process (and url) than the XD instance.  When users open the Kodiak UI in a browser, requests from the browser to the XD instance, but these requests will fail due to cross-site scripting limitations.

CORS (Cross-Origin Resource Sharing) is a way to get around this.  We can configure the server to accept requests from browsers whose origins are not the XD instance.

I have this working in a local branch and will submit a pull request.


More information:
CORS Spec: http://www.w3.org/TR/cors/
SPR-9278 CORS support for SpringFramework
",XD-556,Andrew Eisenberg,CORS support
3175,Eric Bottard,Mark Fisher,"the top-level URL works via simple curl (without an Accept header) or the browser:

{code}
> curl http://localhost:8080

{""links"":[{""rel"":""streams"",""href"":""http://localhost:8080/streams""},{""rel"":""triggers"",""href"":""http://localhost:8080/triggers""},{""rel"":""jobs"",""href"":""http://localhost:8080/jobs""},{""rel"":""taps"",""href"":""http://localhost:8080/taps""},{""rel"":""counters"",""href"":""http://localhost:8080/metrics/counters""}]}
{code}

However, trying any of those links then fails, e.g.:

{code}
> curl http://localhost:8080/streams

<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><errors xmlns:ns2=""http://www.w3.org/2005/Atom""><error logref=""HttpMessageNotWritableException""><message>Could not marshal [PagedResource { content: [links: [&lt;http://localhost:8080/streams/mqttdemo&gt;;rel=&quot;self&quot;]], metadata: Metadata { number: 0, total pages: 1, total elements: 1, size: 20 }, links: [] }]: null; nested exception is javax.xml.bind.MarshalException
 - with linked exception:
[com.sun.istack.internal.SAXException2: unable to marshal type &quot;org.springframework.xd.rest.client.domain.StreamDefinitionResource&quot; as an element because it is not known to this context.]</message></error></errors>
{code}
",XD-555,Mark Fisher,make application/json the default output type for the REST API?
3176,Gary Russell,Gary Russell,"Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start.

In the Stream plugin, wire the module into the {{ChannelRegistry}} during post processing, instead of using the {{ChannelRegistrar}}.",XD-554,Gary Russell,Separate Module Context Refresh from Context Start
3177,Eric Bottard,Eric Bottard,"Seems like the current file source results from an initial POC.
Very few things can be parameterized, including the polled directory that needs to be in /tmp/xxx

To be useful in production, we might want to revisit",XD-553,Eric Bottard,Add additional options to File source
3178,Eric Bottard,Kashyap Parikh,"{{stream list}} shell command should display status of the stream (deployed, undeployed)",XD-552,Kashyap Parikh,Add status column for 'stream list'  shell command result
3179,Gunnar Hillert,Gunnar Hillert,,XD-551,Gunnar Hillert,"Add ""trigger list"" support to Spring XD Shell"
3180,,Eric Bottard,"FieldValueCounterHandler was first written to support setting several fields at once, but the current constructor / field-value-counter.xml does not use it.

Either leverage that feature or simplify code",XD-550,Eric Bottard,Leverage fieldNameToCounterNameMap in FieldValueCounterHandler
3181,Ilayaperumal Gopinathan,Eric Bottard,,XD-549,Eric Bottard,Display a Rich Gauge
3182,Ilayaperumal Gopinathan,Eric Bottard,,XD-548,Eric Bottard,Display a Gauge
3183,Ilayaperumal Gopinathan,Eric Bottard,,XD-547,Eric Bottard,Display an Aggregate Counter
3184,Ilayaperumal Gopinathan,Eric Bottard,,XD-546,Eric Bottard,Display a Field Value Counter
3185,Eric Bottard,Eric Bottard,,XD-545,Eric Bottard,Display a counter
3186,Mark Pollack,Eric Bottard,"Most of the infrastructure and code cleanup has been done for In-Memory Analytics. The only remaining issue is that, by including memory-analytics.xml from common.xml, we're actually creating e.g. a new InMemoryCounterRepository that is different from the one present in the Admin process space.

This story involves fixing that. It may actually be done as part of XD-353, handling the ""local"" transport as a special case (context inheritance) rather than import based on xd.transport",XD-544,Eric Bottard,Fix In-Memory Analytics
3187,,Gunnar Hillert,,XD-543,Gunnar Hillert,Handle Pagination in Spring XD Shell
3188,Gary Russell,Gary Russell,"Currently many methods take module, group, index - defining a module instance; group and index can be encapsulated in {{Module}} so one arg can be passed around.",XD-542,Gary Russell,Refactor Module to Encapsulate Group and Index
3189,,Glenn Renfro,,XD-541,Glenn Renfro,Add Message Source for error messages returned to users
3190,Mark Fisher,Gary Russell,"Use an 'undeploy' topic to broadcast undeploy requests to all containers.

Applies to Redis and Rabbit transports, not local.

Also, rename {{ModuleDeploymentRequest}} to {{ModuleOperationRequest}} with an enum {{DEPLOY}}, {{UNDEPLOY}}.",XD-540,Gary Russell,Broadcast Undeploy Requests
3191,Jennifer Hickey,Jennifer Hickey,Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre-release of SDR 1.1 M2.,XD-539,Jennifer Hickey,Investigate using Redis txs and pipeline for Inbound/Outbound Q Adapter perf improvements
3192,Mark Pollack,Mark Pollack,"This requires to boostrap the singlenode admin server in process, submit commands to the shell programmatically, and assert on the results of executing the command.",XD-538,Mark Pollack,Develop infrastructure to enable testability of commands
3193,Eric Bottard,Eric Bottard,"This story corresponds to 3) & 4) in discussion below.


		Currently, sink xml files define the Repository (hardcoded to be redis) and the services (tied to Redis as well!)
		I want to:
		1) Move those definitions out of the sink files, to somewhere shared by both admin and container
		2) Make them aware of some configuration parameter (similar to the --store command line option)

		3) Get rid of so-called Service layer (doesn't do much right now, and logic would better live in the 'Handler' IMO)
		4) Have REST controllers depend on XRepository in all cases",XD-537,Eric Bottard,Refactor analytics to get rid of Services
3194,Glenn Renfro,Mark Pollack,"creating job defs, deploying jobs, undeploying jobs, deleting job defs",XD-536,Mark Pollack,Create shell integration tests for job lifeycle
3195,,Mark Pollack,"creating triggers, deleting triggers",XD-535,Mark Pollack,Create shell integration tests for trigger lifeycle
3196,Ilayaperumal Gopinathan,Mark Pollack,"creating taps, deleting",XD-534,Mark Pollack,Create shell integration tests for tap lifeycle
3197,Kashyap Parikh,Mark Pollack,"create, delete, deploy streams...",XD-533,Mark Pollack,Create shell integration tests for stream lifeycle
3198,Gunnar Hillert,Mark Pollack,Existing code: https://github.com/ghillert/springone2012,XD-532,Mark Pollack,Adapt SpringOne 2012 UI code from keynote demo of election results to use XD
3199,Mark Fisher,Mark Pollack,,XD-531,Mark Pollack,Check for high CPU usage with syslog-tcp-reactor module
3200,Jon Brisbin,Mark Pollack,Still keep existing one.,XD-530,Mark Pollack,Create XD module for syslog-tcp-reactor 
3201,,Mark Pollack,,XD-529,Mark Pollack,Review existing Reactor syslog codec implementation
3202,Jon Brisbin,Mark Pollack,,XD-528,Mark Pollack,Create SI components that wrap Reactor's TCP server
3203,,Mark Pollack,,XD-527,Mark Pollack,Create new implementations of existing infrastructure (syslog adapters and TaskExecutors)
3204,Mark Fisher,Eric Bottard,"Currently, living at the root of the project, those files don't benefit from IDE SI awareness.
Make it so that they belong to a java project which sees the correct version of the SI jars used.
Has impact on the build.gradle file",XD-526,Eric Bottard,Make module files classpath aware
3205,Eric Bottard,Eric Bottard,Thinking about using the official SpringSource rules as a template,XD-525,Eric Bottard,Provide .settings formatting rules so that they're shared
3206,Eric Bottard,Eric Bottard,,XD-524,Eric Bottard,Update jobs section to use shell
3207,Andy Clement,Eric Bottard,"Tried to create a module named ""tcp-poll"" and got this:
XD108E:(pos 3): missing expected character '-'
tcp-poll --host=54.208.22.193 --port=8081 | log


I believe this should be supported, and indeed we have several module names of this form already",XD-523,Eric Bottard,Parser blows on modules names with '-'
3208,,Andrew Eisenberg,"From the shell:

{code}
> stream create --name aaa --definition ""time|log""
Created new stream 'aaa'

> tap create --name aa --definition ""tap aaa | log""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD111E:(pos 8): Unexpected token.  Expected 'dot(.)' but was 'pipe(|)'
tap aaa | log

>tap create --name aa --definition ""tap aaa . log""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is already a tap named 'aa'
{code}

Looks like the first tap was created even though there was a parse error.  And so the second attempt to create the tap failed due to an existing tap.",XD-522,Andrew Eisenberg,Cannot create tap if you have already tried to create an invalid one of same name
3209,Glenn Renfro,Glenn Renfro,Right now it treats it as a new parameter start and fails.,XD-521,Glenn Renfro,The parser should be able to handle a parameter name with a '-' hyphen embedded.
3210,,Glenn Renfro,,XD-520,Glenn Renfro,"All parameters for modules need to use ""hump case"" formerly camel hump"
3211,,Glenn Renfro,We need to fail fast.,XD-519,Glenn Renfro,Modules need to validate their parameters at create time.  
3212,David Turanski,David Turanski,,XD-518,David Turanski,Upgrade to Jackson 2.2.2
3213,,Eric Bottard,"Standalone Admin currently has no shiny banner as container has.
More importantly, it does not say which port it's listening on, the transport used, etc.",XD-517,Eric Bottard,Add Server Runtime Info to Banner
3214,,Eric Bottard,Container currently does that.,XD-516,Eric Bottard,Admin should fail immediately if Rabbit is not running
3215,,Eric Bottard,"Currently, process is left running and if logs / sysout are not monitored, you have no clue",XD-515,Eric Bottard,Address already in use for tomcat/hsqldb should fail completly
3216,,Gunnar Hillert,Create proper test coverage for Controllers,XD-514,Gunnar Hillert,Create proper test coverage for Controllers
3217,Kashyap Parikh,Kashyap Parikh,CI job will run integration tests that are tagged for CI build.,XD-513,Kashyap Parikh,Add CI job in bamboo to run XD integration tests
3218,Kashyap Parikh,Kashyap Parikh,"Since most of the xd.shell.itests will do more then one thing (deploy a stream, start it, add a tap, add a job, stop, etc) we decided to decouple writing testcases with running it. Test cases will be written in spring-shell scriptlets. Scriptlets are json files with command and expectedResult as tokens.  Here's an example:

{code}
{ ""testscript"": 
 [ {""command"" : ""stream create --definition ""http | file"" --name http2file"",
    ""result"" : ""Created new stream 'http2file'""},
   {""command"" : ""stream list"",
    ""result"" : ""...""}
 ]
}
{code}

A parser will parse scriptlets, executes it and asserts on expected results. 

",XD-512,Kashyap Parikh,Create XD shell integration test parser
3219,Kashyap Parikh,Kashyap Parikh,"Add top level utility methods to manage XD runtime (deploy, start and stop). These methods will be used by underlying integration tests to control runtime test environment.

",XD-511,Kashyap Parikh,Create XD integration test framework
3220,,Gunnar Hillert,,XD-510,Gunnar Hillert,Ensure that each controller's list() returns PagedResources
3221,Eric Bottard,Eric Bottard,"the test for findAll often fails for me when running inside gradle. (Could not reproduce inside eclipse)

I already tried fixing it by using a different redis key space, but to no avail.
One explanation would be if gradle runs tests concurrently, but my understanding is that it does not.",XD-509,Eric Bottard,Investigate intermittent failure of RedisStreamDefinitionRepositoryTests
3222,Gunnar Hillert,Mark Pollack,See XD-477,XD-508,Mark Pollack,Support pagination in list() command for triggers
3223,Gunnar Hillert,Mark Pollack,See XD-477,XD-507,Mark Pollack,Support pagination in list() command for taps
3224,Glenn Renfro,Mark Pollack,See XD-477,XD-506,Mark Pollack,Support pagination in list() command for jobs
3225,,Ilayaperumal Gopinathan,"XD-482 addresses the use of camel case in 'fixed-delay' job module parameter name. and, we need to fix the same for other module parameters wherever '-' is being used. ",XD-505,Ilayaperumal Gopinathan,"Fix XD modules parameters with ""-"" to use camel case"
3226,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"We need to determine where this information could fit in.
It can be either in ""README"" at the project home page or ""Getting started"" wiki page.",XD-504,Ilayaperumal Gopinathan,"Add ""How to Build Spring-XD"" instructions to the documentation"
3227,Glenn Renfro,Glenn Renfro,"Also, if you deploy the Job it will fail, but then you can't delete the job.",XD-503,Glenn Renfro,Jobs are created even though they have an invalid definition
3228,Glenn Renfro,Ilayaperumal Gopinathan,"Shell command to delete a trigger. 

Note: this command will only remove the trigger definition not modifying the jobs that use the trigger.",XD-502,Ilayaperumal Gopinathan,Delete a trigger from Shell
3229,,Glenn Renfro,"	public StreamPlugin(){
		postProcessContextPath = CHANNEL_REGISTRY;
	}

Subclasses should not directly update superclass fields.",XD-501,Glenn Renfro,Stream Plugin cleanup
3230,Glenn Renfro,Glenn Renfro,,XD-500,Glenn Renfro,If a job is created that uses a trigger that has not been created and deployed it throws a 500 error instead of a 400
3231,Glenn Renfro,Glenn Renfro,,XD-499,Glenn Renfro,Cron Jobs stop firing when a named trigger is created and deployed
3232,Eric Bottard,Eric Bottard,"Current behavior is to just have a prompt of ""unknown:>""

I think any return value of a @CliCommand method is not shown b/c the whole infrastructure is not up at that time",XD-498,Eric Bottard,Better UX when admin is not running
3233,Glenn Renfro,Eric Bottard,"Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains.

One solution would be to add Jackson 2 to the Sonar ""classpath"", but I did not manage to do that.

",XD-497,Eric Bottard,Fix Sonar build!
3234,David Turanski,David Turanski,"DefaultFormattingConversionService provides Collection -> Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, getTuple(List<Tuple> list) would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.",XD-496,David Turanski,Disable Collection to Object conversion in DefaultTuple
3235,Gary Russell,Gary Russell,,XD-495,Gary Russell,Document MQTT Source and Sink
3236,Gunnar Hillert,Mark Pollack,"Save : Save a XYZDefinition - method used to be 'create'
Delete : Delete a XYZDefinition - method used to be called 'destroy'
Deploy : Deploy a XYZDefinition
Undeploy : Undeploy a XYZDefinition
List : List a XYZDefinition
       Returns PagedResources<XYZDefinitionResource>
Display : Get specific information about a XYZDefinition

Create other stories for each Controller and include in this weeks sprint
",XD-494,Mark Pollack,Implement common set of controller methods
3237,Luke Taylor,Mark Pollack,"Only ‘create’ in TapDeployer has some additional code to check if the stream exists, could take place in another location.",XD-493,Mark Pollack,"Remove duplicate code in ResourceDeployer implementations, create abstract base class."
3238,Luke Taylor,Mark Pollack,To be consistent with Spring Data Repository method names.,XD-492,Mark Pollack,Rename create to 'save' in ResourceDeployer
3239,Eric Bottard,Mark Pollack,"Favor using custom  exceptions instead of using Assert.notNull, review usage and make changes.  Eg. if a stream can't be found (or another definition) a 'XYZNotFoundException' instead of Assert.Null on the return value of a findOne method
",XD-491,Mark Pollack,Exception Consistency
3240,Gunnar Hillert,Mark Pollack,"StreamController to not access the repository instance directly, all access to go through StreamDeployer
",XD-490,Mark Pollack,StreamDeployer to implement ResourceDeployer
3241,Gunnar Hillert,Mark Pollack,Rename existing Tap class to something else.,XD-489,Mark Pollack,Introduce distinction between TapDefinition and Tap (the instance)
3242,Gunnar Hillert,Mark Pollack,"See implementation used for Steams and apply to jobs, taps, triggers.",XD-488,Mark Pollack,Rename controllers to have pluralized named (e.g. JobsController)
3243,Eric Bottard,Mark Pollack,"See implementation used for Steams and apply to jobs, taps, triggers.",XD-487,Mark Pollack,StreamsController to return paged results for list() 
3244,Eric Bottard,Mark Pollack,"Resource objects should be returned from all controller methods.
MVC Tests should be added to check returned values.",XD-486,Mark Pollack,All controllers to return XYZResource objects not the raw domain objects.
3245,Kashyap Parikh,Mark Pollack,"We need a few steps
1. Investigate if we need to move off Spring Shell 1.0 dependency, e.g. need to use code in Spring Shell 2.0 branch
2. If we need to use code in Spring Shell 2.0 branch, we need to release a Spring Shell 1.1 M1 release with appropriate code changes.  Create stories related to Shell release.
3. Determine and document the basic recipe for doing integration tests.
4. Create stories to provide integration tests for each existing command",XD-485,Mark Pollack,Create stories to enable the use of Spring Shell's 2.0 branch testing facilities 
3246,,Mark Pollack,,XD-484,Mark Pollack,Create required infrastructure to easily perform integration testing of shell commands
3247,Glenn Renfro,Glenn Renfro,,XD-483,Glenn Renfro,Job Delete/Destroy Command for shell
3248,Glenn Renfro,Glenn Renfro,Need to change the name from fixed-delay to fixed_delay or fixedDelay.  System rejects the '-'.,XD-482,Glenn Renfro,When creating a job with the fixed-delay parameter in the shell command fails
3249,Glenn Renfro,Glenn Renfro,,XD-481,Glenn Renfro,Running Job with time delay (non cron) launches 2 instances before job is supposed to fire
3250,Glenn Renfro,Glenn Renfro,"In a scenario where we are using the same job definition i.e. Job.xml and we create Job Instance Foo.  If I create and deploy Foo2 using Job.xml  I will see only 2 job definitions(correct), but I will see the job run 3 times.  If I create Foo3 & deploy, I will see 3 job definitions(correct), but the jobs will run 5 times.  ",XD-480,Glenn Renfro,In certain scenarios a job can be redeployed more than once
3251,Gary Russell,David Turanski,Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.,XD-479,David Turanski,Add conversion support to ChannelRegistrar and ChannelRegistry 
3252,David Turanski,David Turanski,A module can declare one ore more payload types it will accept. This will inform the runtime re. automatic payload conversion.  This can be done in the module XML configuration and processed by StreamPlugin,XD-478,David Turanski,Add accepted type logic to module
3253,Eric Bottard,Eric Bottard,"Spring HATEOAS is here to help.
Nonetheless, there are currently a number of outstanding issues, namely:

https://github.com/SpringSource/spring-hateoas/pull/98
https://jira.springsource.org/browse/SPR-10262#comment-91685
https://github.com/SpringSource/spring-hateoas/pull/94

Creating a issue here for future reference",XD-477,Eric Bottard,Support pagination in list() command for streams
3254,,Shaozhen Ding,"This only happened with distributed mode that uses redis as store. The single mode which uses in memory store works fine.

Step to reproduce:

Create stream:
curl -X POST -d ""name=httptest"" -d ""definition=http|log"" http://localhost:8080/streams

redis 127.0.0.1:6379> keys *httptest*
1) ""modules:httptest""
2) ""streams.httptest""
3) ""stream.definitions.httptest""

Delete Stream:
curl -X DELETE http://localhost:8080/streams/httptest

redis 127.0.0.1:6379> keys *httptest*
1) ""streams.httptest""
2) ""stream.definitions.httptest""

stream still there not deleted

Recreate the stream
curl -X POST -d ""name=httptest"" -d ""definition=http|log"" http://localhost:8080/streams

Got:
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><errors xmlns:ns2=""http://www.w3.org/2005/Atom""><error logref=""StreamAlreadyExistsException""><message>There is already a stream with name 'httptest'</message></error>",XD-476,Shaozhen Ding,The stream definition is not deleted in redis container when the stream is destroyed
3255,,Thomas Risberg,We need a sink that can write data in Avro serialized format. This story is for investigating what we would need to do to support that. The Spring Integration Kafka adapter provides Avro support for Kafka.,XD-475,Thomas Risberg,Avro sink for HDFS
3256,Thomas Risberg,Thomas Risberg,We need a generic script that can do JSON to tab-delimited text transformation for data written to HDFS/HAWQ external tables. Users should be able to specify columns/fields to be included.,XD-474,Thomas Risberg,Create JSON to tab-delimited text transformer script
3257,Thomas Risberg,Thomas Risberg,we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopDistro=phd1,XD-473,Thomas Risberg,Modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use
3258,Thomas Risberg,Thomas Risberg,we need to modify build adding two sub-projects for spring-xd-hadoop: one for hadoop 1.1.2 and one for phd1 (Pivotal HD) to pull in transitive dependencies for correct Hadoop distro,XD-472,Thomas Risberg,Add spring-xd-hadoop distro specific sub-projects
3259,,Thomas Risberg,"we need a batching JDBC channel adapter (int-jdbc:outbound-channel-adapter is not batching statements AFAICT)
",XD-471,Thomas Risberg,Batching JDBC channel adapter
3260,Thomas Risberg,Thomas Risberg,"we need a JDBC sink for writing to HAWQ (using int-jdbc:outbound-channel-adapter and postgresql JDBC driver)
",XD-470,Thomas Risberg,Create JDBC sink
3261,Thomas Risberg,Thomas Risberg,spring-data-hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros/versions and we should make use of that.,XD-469,Thomas Risberg,Upgrade to spring-data-hadoop 1.0.1.RC1
3262,,Thomas Risberg,,XD-468,Thomas Risberg,"Providing support for using different Hadoop distributions, including Pivotal HD"
3263,,Luke Taylor,"There's a lifecycle problem when a tap creation fails (e.g. because the DSL syntax is wrong). Subsequent attempts to create the tap will fail with an error:

 [{""links"":[],""logref"":""MessageHandlingException"",""message"":""org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=nullChannel, sends=0, receives=0]] with key 'xd.tap1:type=MessageChannel,name=nullChannel,index=1,module=log'; nested exception is javax.management.InstanceAlreadyExistsException: xd.tap1:type=MessageChannel,name=nullChannel,index=1,module=log""}]

Disabling JMX solves the issue.


reproduce
Create a bad stream definition name 'bad'
Try to recreate with the same name, but correct stream definitions.  The system will report that the stream already exists.",XD-467,Luke Taylor,JMX shouldn't register taps or streams if the creation fails
3264,David Turanski,David Turanski,Support toString() to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations.  Also provide toTuple(String json). This supports seamless mapping JSON<->Tuple in XD,XD-466,David Turanski,Add JSON conversion to tuple
3265,Eric Bottard,Luke Taylor,"For example, using tcpdump I can see both an exception and message information:

'HTTP/1.1 500 Internal Server Error
Server: Apache-Coyote/1.1
Content-Type: application/json;charset=UTF-8
Transfer-Encoding: chunked
Date: Fri, 12 Jul 2013 13:38:26 GMT
Connection: close

275
[{""links"":[],""logref"":""MessageHandlingException"",""message"":""org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=nullChannel, sends=0, receives=0]] with key 'xd.tap1:type=MessageChannel,name=nullChannel,index=1,module=log'; nested exception is javax.management.InstanceAlreadyExistsException: xd.tap1:type=MessageChannel,name=nullChannel,index=1,module=log""}]

However the client only shows:

http://localhost:8080:>tap create --name ""tap1"" --definition ""tap@test1.file | log"" --deploy true
14:38:26,113  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/taps"" resulted in 500 (Internal Server Error); invoking error handler
Error creating tap 'tap1'

The error doesn't seem to be logged in the XD Admin server either, so the information is effectively lost.

",XD-465,Luke Taylor,Shell should display error messages returned from the server
3266,Janne Valkealahti,Janne Valkealahti,This is a master ticker tracking work enabling XD to run on Hadoop as Yarn application.,XD-464,Janne Valkealahti,Deploy Spring XD on Hadoop YARN
3267,,Glenn Renfro,,XD-462,Glenn Renfro,User wants a list of currently executing jobs
3268,,Glenn Renfro,,XD-461,Glenn Renfro,User wants to be able to know what triggers are associated with a job
3269,,Glenn Renfro,,XD-460,Glenn Renfro,The user needs the ability to pause and resume triggers based on a calendar.
3270,,Glenn Renfro,"A pause means that a trigger will wait to fire its job until after the pause is removed.  It does not apply the misfire behavior.
",XD-459,Glenn Renfro,The user needs the ability to pause and resume triggers ad-hoc.
3271,,Glenn Renfro,"  Commonly called Calendar support
",XD-458,Glenn Renfro,User wants the ability to exclude certain days (like holidays) for a trigger to fire.
3272,,Glenn Renfro," In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.",XD-457,Glenn Renfro,User wants to setup a priority for triggers. 
3273,,Glenn Renfro,,XD-456,Glenn Renfro,User wants the ability to limit the total number of jobs running simultaneously
3274,,Glenn Renfro,,XD-455,Glenn Renfro,User wants the ability to limit the total number of jobs a trigger can have running simultaneously
3275,,Glenn Renfro,,XD-454,Glenn Renfro,User wants the ability to persist the state of a Trigger Instance
3276,,Glenn Renfro,,XD-453,Glenn Renfro,Use wants the ability to persist Trigger Context
3277,,Glenn Renfro,,XD-452,Glenn Renfro,User wants the ability to persist the final state of a job (success or failure)
3278,,Andrew Eisenberg,"If we want spring-xd to support interactions through a UI, then it would make sense that we should support the UI coming from a separate origin.  This way, the UI could remain a separate project and be served from wherever we want.

So, we would need to add the header to *all* outgoing REST responses. We may also need to add a {{Access-Control-Allow-Methods}} header as well.

In the short term, the {{Access-Control-Allow-Origin}} header could be hard coded to a specific url (I'm using http://localhost:9889 for now), but in the long term we would need this configurable.",XD-451,Andrew Eisenberg,Add a Access-Control-Allow-Origin header to responses in order to support cross-origin requests
3279,,Andrew Eisenberg,"The following will retrieve the names of all module types (eg- sources, sinks, jobs, processors, triggers). 

{code}
GET /module-types/
{code}

I'm expecting that the plural would be used, but singular would work as well.

The following gets modules of a given type:
{code}
GET /module-types/{type}
{code}

This would be similar to the {{/modules/}} call in XD-265, but it would only return modules of the specified type.

",XD-450,Andrew Eisenberg,Retrieve description of all registered modules by type
3280,,Glenn Renfro,"2 options are:
1) Fire the trigger immediate - Launch the job when trigger can gather the resources necessary start the job
2) Do nothing - Ignore this job fire time and catch 

this scenario can occur if XD is down or resources (threads) are not available at the time a job is to be launched. ",XD-449,Glenn Renfro,The user needs the ability to set up a misfire policy for a Trigger
3281,,Glenn Renfro,,XD-448,Glenn Renfro,The user needs the ability to set up a end-time where the trigger should no longer be in effect.
3282,Gary Russell,Gary Russell,,XD-447,Gary Russell,Add an MQTT Sink
3283,,Luke Taylor,"When running with ""./gradlew launch"" I get a 500 error when I try to re-deploy an undeployed stream. A subsequent create or destroy also fail

http://localhost:8080:>stream create --definition ""time | log"" --name ticktock
Created new stream 'ticktock'
http://localhost:8080:>stream undeploy --name ticktock
Un-deployed stream 'ticktock'
http://localhost:8080:>stream deploy --name ticktock
13:02:09,936  WARN Spring Shell client.RestTemplate:524 - PUT request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.web.client.HttpServerErrorException: 500 Internal Server Error
http://localhost:8080:>stream deploy --name ticktock
13:03:11,453  WARN Spring Shell client.RestTemplate:524 - PUT request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.web.client.HttpServerErrorException: 500 Internal Server Error
http://localhost:8080:>stream undeploy --name ticktock
13:03:54,576  WARN Spring Shell client.RestTemplate:524 - PUT request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.web.client.HttpServerErrorException: 500 Internal Server Error
http://localhost:8080:>stream undeploy --name ticktock
13:04:48,872  WARN Spring Shell client.RestTemplate:524 - PUT request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.web.client.HttpServerErrorException: 500 Internal Server Error
http://localhost:8080:>stream create --definition ""time | log"" --name ticktock
13:04:52,066  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/streams"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.web.client.HttpServerErrorException: 500 Internal Server Error
http://localhost:8080:>stream destroy --name ticktock
13:05:14,207  WARN Spring Shell client.RestTemplate:524 - DELETE request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.web.client.HttpServerErrorException: 500 Internal Server Error

",XD-446,Luke Taylor,Investigate stream lifecycle issues with redis store
3284,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"We need to have the ability to set read timeout for http request.

This is already implemented here: https://github.com/SpringSource/rest-shell/",XD-445,Ilayaperumal Gopinathan,Add support to set the read timeout for http request
3285,Gary Russell,Gary Russell,"Dependent servers should be required on the CI server, but optional on developer systems.",XD-444,Gary Russell,Make Redis/Rabbit @Rules Conditional
3286,Gary Russell,Gary Russell,,XD-443,Gary Russell,Add MQTT Source
3287,Andy Clement,Andy Clement,Once issues like XD-438 have been completed the wiki doc will need updates to reflect the current behaviour and syntax options.,XD-442,Andy Clement,More DSL work: Documentation updates for new format
3288,,Andy Clement,"With support for substreams/parameterized streams now in the parser it will be possible to create a stream that cannot be deployed: it may not fit the source/processor*/sink structure or it is a parameterized stream with no default values for parameters. Need to check how XD is going to handle these - after creating them, attempting to 'deploy' them should return appropriate errors. (They should exist in the stream directory).",XD-441,Andy Clement,More DSL work: checking behaviour for non-deployable streams
3289,Andy Clement,Andy Clement,"The new parser supports | for connecting regular modules and & for connecting job steps. The modules in the ast that were connected with & are tagged but nothing is currently using that information (it doesnt get into the module deployment request). We need to think about using this data: policing the modules that are being deployed to ensure they are job steps, for example.",XD-440,Andy Clement,More DSL work: using and policing & for job step lists
3290,,Andy Clement,"Following stream parsing there is now a stream resolution stage that chases down substream references and fills in parameterization. The 'lookup' of streams is done through implementors of the StreamLookupEnvironment interface. Currently the parser implements this itself but it is really a job for the stream directory.  The parser implementation doesn't know about stream deletions, for example, so may still resolve streams that no longer exist.",XD-439,Andy Clement,More DSL work: hooking up stream directory
3291,Luke Taylor,Andy Clement,"The DSL changes under XD-369 now build stream Ast objects that can include a source and sink channel:

{code}
// Source Channel
:mystream.foo > count | log

// Sink Channel
http | count > :foo
{code}

These new fields in the Ast object need to be copied into the module deployment request objects and then used at the destination as the channels for wiring things together.  Currently the only channels used are the .NNN numeric channels where NNN is the index of the module in the stream definition. The source/sink channels are 'extra' channels that need creating - the source channel acting as a real source for the next module in the chain whilst the sink channel acts as a sink output for the last channel in the chain.  

I can think of two ways to handle the implementation:
- In order to police the stream structure as ""source | processor* | sink"" maybe special SourceChannel and SinkChannel modules are created to represent these channels and when deployment happens the deployer understands that they don't represent a real request to deploy a module but simply the channels to wire up to the adjacent module.

- Carry source/sink channel info in the existing module definitions. But then the verification of source/processor*/sink structure will need modification to say a source isn't necessary if the first processor has a source channel attached and a sink isn't necessary if the last processor has a sink channel attached.
",XD-438,Andy Clement,More DSL work: exploiting source/sink channels
3292,Glenn Renfro,Gunnar Hillert,"Looking at the latest Sonar run we have 3 package tangles in Spring XD:

https://sonar.springsource.org/drilldown/measures/7717?metric=87",XD-437,Gunnar Hillert,Fix Package Tangles
3293,,David Turanski,"Currently spring-xd-dirt has direct dependencies on Redis and Rabbit. Consider moving transport dependent classes to separate jars with ""runtime"" dependencies",XD-436,David Turanski,Decouple transport from DIRT
3294,Luke Taylor,Luke Taylor,The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren't broken by changes.,XD-435,Luke Taylor,Create tests to load the standard runtime app context configurations
3295,,Gary Russell,"As a user, I'd like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics.

*Notes:*
* Spring-AMQP {{RabbitAdmin}} now has a {{getQueueProperties()}} method which returns the number of consumers so it may be possible to use it for this purpose.
* Consider the possibility of _producers_ and/or _queues_ still containing data
* Consider the scenario even after the topics/queues are cleaned-up, what to do with fanout exchange?

*Some Further Thoughts*
* Consider using the upcoming Spring AMQP REST API {{RabbitManagementTemplate}} if the timing is not right, we could temporarily invoke the rabbit REST API directly.
* Should be optional; perhaps via {{stream destroy foo --clean}}
* Should this be done by the admin? Or, via a new plugin handling module undeployments - in the rabbit case, undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange, since we undeploy left->right, everything can be cleaned up on the consumer side.
* Third option would be new methods on the bus {{cleanConsumer}} etc invoked by the {{StreamPlugin}}
* Down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so, we'd need the admin url(s) for the cluster.",XD-434,Gary Russell,Consider removing the Topic/Queues when deleting the Stream
3296,,Gary Russell,"If Redis is not running, the container fails to initialize in {{ContainerMain.launch()}} because the connection factory attempts to eagerly connect.

If RabbitMQ is not running, the container fails to initialize in {{AbstractContainerLauncher.launch()}}.

Make the failure behavior consistent from a user perspective and add a spring-retry {{RetryTemplate}} to retry container startup.",XD-433,Gary Russell,Homogenize Container Initialization Failures 
3297,,David Turanski,XD-162 requires registering message converters with the ChannelRegistry. End user needs to configure this statically as the Spring configuration is not exposed.,XD-432,David Turanski,User wants to configure MessageBus
3298,David Turanski,David Turanski,,XD-431,David Turanski,Make String conversion optional with local transport
3299,Mark Fisher,Gary Russell,Avoid the need for {{--jmxPort=xxxx}} when running both a {{Container}} and {{Admin}} on the same server,XD-430,Gary Russell,Use a Different Default Jolokia Port for Admin Vs. Container
3300,Eric Bottard,Mark Pollack,"time source is used in some examples, but it isn't documented explicitly, eg. --interval option in seconds.",XD-429,Mark Pollack,Document time source
3301,,Mark Pollack,"See http://static.springsource.org/spring-xd/docs/1.0.x-SNAPSHOT/reference/html/#_test_the_deployed_module_3
",XD-428,Mark Pollack,Update Creating a Sink Module section to use Shell commands instead of curl 
3302,,Mark Pollack,See http://static.springsource.org/spring-xd/docs/1.0.x-SNAPSHOT/reference/html/#_test_the_deployed_module,XD-427,Mark Pollack,Update Creating a Source Module section to use Shell commands instead of curl 
3303,,Mark Pollack,"""test the deployed module"" sub-section uses curl.",XD-426,Mark Pollack,Update Creating a Processor Module section to use Shell commands instead of curl 
3304,,Mark Pollack,,XD-425,Mark Pollack,Update Samples syslog ingestion section to use Shell commands instead of curl 
3305,,Mark Pollack,,XD-424,Mark Pollack,Update Analytics Rich Gauge section to use Shell commands instead of curl 
3306,,Mark Pollack,,XD-423,Mark Pollack,Update Analytics Gauge section to use Shell commands instead of curl 
3307,,Mark Pollack,,XD-422,Mark Pollack,Update Analytics Field Value Counter section to use Shell commands instead of curl 
3308,,Mark Pollack,,XD-421,Mark Pollack,Update Analytics Counter section to use Shell commands instead of curl 
3309,Luke Taylor,Mark Pollack,Add section to Analytics chapter on use of AggregateCounter.  The example should show the use of the shell to create the tap that uses the AggregateCounter.,XD-420,Mark Pollack,Documentation for AggregateCounter
3310,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#taps

The existing docs should be made to show a real stream being created with filter and/or transformer and then a tap that goes to logging.  

The shell syntax to also stop/undeploy a tap should be shown here as well since the lifecycle is discussed.",XD-419,Mark Pollack,Taps introduction section should show use of shell to create a real stream and a real tap using the shell
3311,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#gemfire
",XD-418,Mark Pollack,Update Sink's GemFire section to use Shell commands instead of curl 
3312,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp_sinks",XD-417,Mark Pollack,Update Sink's TCP section to use Shell commands instead of curl 
3313,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#hdfs",XD-416,Mark Pollack,Update Sink's HDFS section to use Shell commands instead of curl 
3314,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#file_sinks",XD-415,Mark Pollack, Update Sink's File section to use Shell commands instead of curl 
3315,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#log_sinks",XD-414,Mark Pollack,Update Sink's Log section to use Shell commands instead of curl 
3316,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#script",XD-413,Mark Pollack,Update Processors Script section to use Shell commands instead of curl 
3317,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#json-field-extractor",XD-412,Mark Pollack,Update Processors JSON Field Extractor section to use Shell commands instead of curl 
3318,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#transform",XD-411,Mark Pollack,Update Processors Transform section to use Shell commands instead of curl 
3319,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#filter
http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#json-value-filter",XD-410,Mark Pollack,Update Processors Filter & JSon Filed Value Filter section to use Shell commands instead of curl 
3320,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp",XD-409,Mark Pollack,Update Sources TCP section to use Shell commands instead of curl 
3321,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#syslog",XD-408,Mark Pollack,Update Source Syslog section to use Shell commands instead of curl 
3322,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#gemfire-cq",XD-407,Mark Pollack,Update Sources Gemfire CQ section to use Shell commands instead of curl 
3323,,Mark Pollack,"See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#twittersearch",XD-406,Mark Pollack,Update Sources twitter search section to use Shell commands instead of curl
3324,,Mark Pollack,http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tail,XD-405,Mark Pollack,Update Sources tail section to use Shell commands instead of curl
3325,Eric Bottard,Mark Pollack,"The documentation in the Running in Distributed Mode chapter should discuss that the distributed runtime can use essentially any middleware to communicate between nodes.  This functionality is provided by the core ChannelRegistry abstraction.  A new intro paragraph shoul convey that it isn't a 'redis' only or 'rabbitmq' only system.

There should be ""Installing RabbitMQ"" and ""Starting RabbitMQ"" sections to match those for Redis.

""Starting Spring XD in Distributed Mode"" should cover how to configure the system to select to use Redis or Rabbit.",XD-404,Mark Pollack,"Update documentation section ""Running in Distributed Mode"" to show use of RabbitMQ in addition to Redis"
3326,Luke Taylor,Mark Pollack,"See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#http



",XD-403,Mark Pollack,Update Sources section to use Shell commands instead of curl
3327,Eric Bottard,Mark Pollack,"There are existing commands that can be taken from 

https://github.com/SpringSource/spring-hadoop-samples

or 

https://github.com/SpringSource/impala

that can be used for this",XD-402,Mark Pollack,Create a command to browse the HDFS file system
3328,Ilayaperumal Gopinathan,Mark Pollack,"the current streams chapter

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams

shows using curl to post some data to a http source module, 

curl -d ""hello"" http://localhost:9000

create a shell command so curl doesn't have to be used.

https://github.com/SpringSource/rest-shell

has a command already developed for this.",XD-401,Mark Pollack,Create a shell command to post data to an http port for use with the http source module
3329,Luke Taylor,Mark Pollack,"the current streams chapter

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams

shows creation and deleting streams using CURL - switch to use shell.  Also add listing of a stream.

there is also an example of creating a stream, this should be replaced as well.
",XD-400,Mark Pollack,Update Streams Chapter to use shell commands instead of curl
3330,Luke Taylor,Mark Pollack,"The chapter on how to start up the shell should ocme right after ""start the runtime"" and before ""create the stream""",XD-399,Mark Pollack,Update Getting Started chapter to include a section on starting the shell.
3331,Luke Taylor,Mark Pollack,"See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#getting-started

",XD-398,Mark Pollack,Update Getting Started chapter to use Shell commands instead of curl
3332,Mark Pollack,Mark Pollack,"This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia.

in particular showing how some existing metrics for inbound message channel adapters or the 'inbound' channel of the stream, that indicate the number of messages processed per section.  

",XD-397,Mark Pollack,Document Monitoring & Management Features
3333,Glenn Renfro,Mark Pollack,"This should likely be in the ""start the runtime"" section of Getting Started section.",XD-396,Mark Pollack,Add section to documentation that shows command line options available for each server
3334,,Mark Pollack,,XD-395,Mark Pollack,"The shell introduced a fundamental new way to interact with the system, all use of CURL in examples needs to change to use the shell."
3335,,Janne Valkealahti,"Currently you need to define a port which tomcat will use to bind to. If XD is embedded or run in a Hadoop it is not possible to know which port should be used. Current embedded tomcat version is able to use the 0-port trick for it to choose free port.

Real binded port can be asked from a connector using below example.

org/springframework/xd/dirt/stream/StreamServer.java:
public int getLocalPort() {
  return this.tomcat.getConnector().getLocalPort();
}


Also I believe Streamserver should provide a method to ask what is the real url to connect to or atleast what streamserver thinks what it is. This will make life much easier for components empedding spring-xd.
",XD-393,Janne Valkealahti,Allow Streamserver/tomcat to chooce free port
3336,Glenn Renfro,Glenn Renfro,,XD-392,Glenn Renfro,Create a stubbed out job controller 
3337,,David Turanski,"-New exception types are starting to appear in XD. Need to define what types of exceptions should be thrown for common scenarios. Assuming XD is all RTEs, we will wrap thrown exceptions to RTEs or defined sub types. What standards should apply?",XD-391,David Turanski,Refactor exception classes
3338,Thomas Risberg,Mark Pollack,"As part of the Hadoop World demonstration work, the flow of data using XD from twitter to be analyzed by HAWQ as done.  Part of this work had the data going into HDFS that HAWQ was able to query using external tables.

The work for this story is to identify the concrete technical tasks/stories to be created do deliver and document this functionality in XD.

",XD-388,Mark Pollack,Create design document for implementation strategy for ingesting data from twitter into HDFS that can be analyzed by HAWQ
3339,,David Turanski,Used to track necessary refactoring or design review tasks,XD-387,David Turanski,Technical Debt
3340,Eric Bottard,Eric Bottard,"Some (java) files are currently missing headers.

The plugin at https://github.com/hierynomus/license-gradle-plugin can help, but initial trial revealed that:

- skipExistingHeaders does not seem to be honored. We may then need to use a year construction like 2001-${current} or force all files to have ${current} year. Don't know the legal implications of this
- Default source sets encompass all files ""in the classpath"" basically, so that means .xml as well as .properties files for example. It would seem logical to add header to those as well, but I don't think this is what we do on other projetcs.",XD-386,Eric Bottard,Automate copyright header management
3341,Eric Bottard,Eric Bottard,Have proper exceptions for common error cases on Stream creation/deployment and propagate those to clients correctly.,XD-385,Eric Bottard,Error handling on Streams
3342,Gunnar Hillert,David Turanski,,XD-384,David Turanski,Implement list() method on TapDeployer()
3343,Gunnar Hillert,David Turanski,,XD-383,David Turanski,Implement list() method on TapController
3344,David Turanski,David Turanski,see StreamsRepository as an example. This includes in memory and Redis implementations,XD-382,David Turanski,Create TapRepository
3345,David Turanski,David Turanski,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit,XD-381,David Turanski,add create() and deploy() methods to TapDeployer
3346,,David Turanski,"see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit

create TapsController if necessary",XD-380,David Turanski,add create() and deploy() methods to TapsController
3347,Eric Bottard,David Turanski,"see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit

Refactor current DefaultStreamDeployer",XD-379,David Turanski,add create() and deploy() methods to StreamDeployer
3348,Eric Bottard,David Turanski,"see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit

create optionally deploys",XD-378,David Turanski,add create() and deploy() methods to StreamsController
3349,Glenn Renfro,David Turanski,"see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit

Create the deployer if it doesn't exist.",XD-377,David Turanski,add create() and deploy() methods to JobDeployer
3350,Glenn Renfro,David Turanski,"see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit

Create the controller if it doesn't exist. Test with MvcTest",XD-376,David Turanski,add create() and deploy() methods to JobsController
3351,Ilayaperumal Gopinathan,David Turanski,,XD-375,David Turanski,Command to delete tap
3352,Gunnar Hillert,David Turanski,,XD-374,David Turanski,Command to list taps
3353,Ilayaperumal Gopinathan,David Turanski,To store it's definition and optionally deploy with --autostart flag,XD-373,David Turanski,Command to create a tap
3354,Glenn Renfro,David Turanski,Deploy an existing job. Must exist in the JobsRepository,XD-372,David Turanski,Command to deploy a job
3355,Glenn Renfro,David Turanski,optional --autostart switch to also deploy the job,XD-371,David Turanski,Command for creating a job
3356,Eric Bottard,David Turanski,Deploy a named stream. The stream must exist in the StreamRepository,XD-370,David Turanski,Add command for deploying a Stream
3357,Andy Clement,Andy Clement,"Extend the DSL in the following ways:

- stream naming, use <name>'='
{code}
mystream = http | file
{code}

- module aliasing (for later referencing) use <label>':'
{code}
mystream = http | t1: transform --expression=payload.toUpperCase() | t2: transform --expression=payload.toLowerCase()
{code}

- sequence of job steps with '&'
{code}
mybigjobby = step1 --option=value & step2 --option=value
{code}

- Channels for sources and sinks, use '>', channels references prefixed ':'
{code}
// sink channel called foo
http | transform --expression=payload.toUppercase() > :foo
// source channel called foo
:foo > count | file
{code}

- Qualify channels with a stream ':'<stream>'.'<channel>
{code}
mystream = http | transform --expression=payload.toUppercase() > :foo
:mystream.foo > count | log
{code}


- Reusable substreams, define then reuse
{code}
myIntricateFlow = transform --expression=payload.toUppercase() | transform --expression=payload.toLowercase()

http | myIntricateFlow | file
{code}

- Parameterized substreams, use $XX or ${XX} to indicate parameters
{code}
obfuscateName = transform --expression=payload.replaceAll(""${name}"",XXX)

twitter --query=Bieber | obfuscateName --name=Justin | file
{code}

- Tapping (still not 100% happy about the format here)
{code}
mystream = http | filter | t1: transform XXX | t2: transform YYY | file

// These are then equivalent (tapping on a module is effectively tapping a channel, hence the '>')
tap filter > count | file
tap mystream.filter > count | file

mystream = http | filter > :foo

tap :foo > count | file
tap :mystream.foo > count | file
{code}
I'd still like to thing about removing 'tap' and using a symbol (perhaps '@', but @:mystream.foo is a little odd)

still not covered, topological constraints on the stream components.",XD-369,Andy Clement,Further DSL extensions
3358,Luke Taylor,Luke Taylor,"This is currently too chatty. It should be possible to use a single connection for each ""increment"" operation.",XD-368,Luke Taylor,Improve connection handling in RedisAggregateCounterService.
3359,Mark Pollack,Mark Pollack,"Get closure on open discussion points for REST API wrt to streams, taps and jobs.
",XD-367,Mark Pollack,"Final review of REST API structure document for streams, taps and jobs"
3360,,Mark Pollack,"when posting the DSL to create a spring batch job
e.g. ""trigger job.xml --option1=foo""

it should be stored (in redis) so that a listing of XD job definitions can be retrieved.",XD-366,Mark Pollack,Create a XD job definition
3361,David Turanski,Mark Pollack,Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties.  Need to determine a strategy such that multiple PPCs can be used.,XD-365,Mark Pollack,Support having multiple property placeholders defined in different modules
3362,Gunnar Hillert,Mark Pollack,Redis based.,XD-364,Mark Pollack,Create TriggerDefinition Repository 
3363,Ilayaperumal Gopinathan,Mark Pollack,,XD-363,Mark Pollack,Add support for creating fixed delay/ fixed rate triggers
3364,Ilayaperumal Gopinathan,Mark Pollack,,XD-361,Mark Pollack,Create a trigger from Shell
3365,Glenn Renfro,Mark Pollack,,XD-360,Mark Pollack,Add support for creating a spring batch job that references a named trigger
3366,Glenn Renfro,Mark Pollack,,XD-359,Mark Pollack,Add support for creating a spring batch job that has an embedded trigger expression
3367,,Mark Pollack,Simple cron based triggers,XD-358,Mark Pollack,Add support for creating named cron triggers
3368,Glenn Renfro,Gunnar Hillert,"It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the commonApplicationContext and BeanDefinitionAddingPostProcessor for common cases, instead exposing a simple addBeanDefinition method to sub-classes.""",XD-357,Gunnar Hillert,Creating a base class for Plugins 
3369,Ilayaperumal Gopinathan,Mark Pollack,"startup scripts on windows should be tested, xd-admin, xd-container, xd-shell.",XD-356,Mark Pollack,Test startup scripts on windows
3370,,Mark Fisher,"Need to understand how individual modules may or may not share Dispatchers that are part of the parent context.  If modules have their own dispatchers, those also need to be configurable.",XD-355,Mark Fisher,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context"
3371,,Mark Fisher,,XD-354,Mark Fisher,Investigate Reactor-based Dispatchers in the common ApplicationContext that can be used by Modules
3372,David Turanski,Eric Bottard,"- Container context should be separate from Admin Context in local mode (consistency across transports). Provide a LocalChannelRegistry to bridge deploy and undeploy channels to the ModuleDeployer

- Verify Plugins are not in common module context. They are only needed by the ModuleDeployer not the Modules.

- Add global-beans Config for beans to be shared among admin and container (and available to modules). This would be set as the parent context where needed. (Currently ‘analytics-context.xml’ and JobRepository shared by Admin and modules)

- Fix ModuleDeployer sets parentContext twice
- Rename common.xml to module-common.xml

NOTE: Analytics parent only required in local mode

- Write unit tests to verify configurations are as expected. Correct bean implementations and no stray beans or redundant instances where not needed

- Decouple Command options from System properties (in general XD property names), this gives us some flexibility in mapping to properties or profiles where appropriate
",XD-353,Eric Bottard,Clean up Spring Configuration
3373,Luke Taylor,Luke Taylor,,XD-352,Luke Taylor,In-memory implementation of aggregate counter
3374,Luke Taylor,Luke Taylor,,XD-351,Luke Taylor,Support daily query resolution in redis aggregate counter
3375,Luke Taylor,Luke Taylor,,XD-350,Luke Taylor,Support hourly resolution in redis aggregate counter
3376,,Gunnar Hillert,"Currently Jobs can be either executed using cron expression or immediately at once. We should also support the one-time scheduling of jobs in the future.

Would this possibly require us to implement schedule-persistence? That could severely impact story-points.",XD-349,Gunnar Hillert,Trigger - Add support for date-based one-time execution
3377,Ilayaperumal Gopinathan,Gunnar Hillert,Trigger - Add support for fixed-delay interval,XD-348,Gunnar Hillert,Trigger - Add support for fixed-delay interval
3378,,Ilayaperumal Gopinathan,"With the performance test run, the numbers (messages sent/received per second) keep varying as there are 
""redis client connection timeout exceptions"" (Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out) at both redis inbound/outbound channel adapters as I increase the total number of messages being processed (max. 10K/second).
Some of the exception messages for the review:
1) With connection pool (at Redis outbound):
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool; nested exception is com.lambdaworks.redis.RedisException: Unable to connect
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:95)
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:36)
at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:318)
at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:109)
at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81)
at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:157)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:137)
at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)
at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:71)
at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:67)
at org.springframework.xd.perftest.redis.outbound.RedisQOutboundChannelAdapter.handleMessageInternal(RedisQOutboundChannelAdapter.java:71)
at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
... 17 more
Caused by: com.lambdaworks.redis.RedisException: Unable to connect
at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool$LettuceFactory.makeObject(DefaultLettucePool.java:252)
at org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1181)
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:93)
... 29 more
Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379
at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137)
at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
2) Without connection pool (at Redis inbound):
Caused by: com.lambdaworks.redis.RedisException: Unable to connect
at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:321)
... 12 more
Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379
at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137)
at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
... 3 more",XD-347,Ilayaperumal Gopinathan,Investigate Redis connection timeout issues when running performance test
3379,,Zachariah Young,"I would like to see a module created that supports complex event processing.  I have reviewed GemFire Continuous Query but was not able to find a feature for time windows.

I have used Esper in the past for this type of processing.",XD-346,Zachariah Young,Esper based Complex Event Processing module
3380,Luke Taylor,Luke Taylor,,XD-345,Luke Taylor,"Replace ""gardenhose"" doc with new ""twitterstream"""
3381,,David Turanski,,XD-344,David Turanski,Add BatchMbeanExporter for batch modules
3382,David Turanski,David Turanski,The object naming is still not ideal for XD since SI conventions add some noise. Likely  need to design and implement a custom naming strategy,XD-343,David Turanski,Investigate JMX object naming of deployed modules and inbound/outbound channel adapters.
3383,Thomas Risberg,Thomas Risberg,"There is some conflicting Servlet API jars on the claspath that needs cleanup. Building and running with xd-singlenode script gave this error:

Jun 27, 2013 3:18:16 PM org.apache.coyote.http11.AbstractHttp11Processor process
SEVERE: Error processing request
java.lang.NoSuchMethodError: javax.servlet.ServletContext.getEffectiveSessionTrackingModes()Ljava/util/Set;
	at org.apache.catalina.connector.CoyoteAdapter.postParseRequest(CoyoteAdapter.java:674)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:402)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:680)
",XD-342,Thomas Risberg,Fix classpath error caused by multiple conflicting servlet-api jars
3384,Ilayaperumal Gopinathan,David Turanski,Document jmx command line options and refer to jolokia,XD-341,David Turanski,Document JMX features
3385,Thomas Risberg,Thomas Risberg,We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.,XD-340,Thomas Risberg,Create script to extract table data from JSON based on a given HAWQ table structure
3386,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Investigate how efficiently we can integrate profiler into the performance test.,XD-339,Ilayaperumal Gopinathan,Investigate using profiler when doing the performance testing
3387,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Create a load generator script which can generate messages at specific

1) Rate
2) Payload
3) Concurrency

to a specific tcp/udp port where a syslog adapter is listening.",XD-338,Ilayaperumal Gopinathan,Create tcp/udp load generator script for XD performance testing
3388,Ilayaperumal Gopinathan,Mark Fisher,,XD-337,Mark Fisher,Test connection pooling on Redis blocking/nonblocking operations
3389,Glenn Renfro,Mark Fisher,,XD-336,Mark Fisher,Document Splunk source sink
3390,Mark Fisher,Mark Fisher,"updated story points to 14 since 5 of us just participated in a 2 hour call, and we still need to discuss ""topology"" support after some dev spikes later this week",XD-335,Mark Fisher,Review DSL
3391,Eric Bottard,Mark Fisher,,XD-334,Mark Fisher,Document the structure of the REST API
3392,Eric Bottard,Mark Pollack,"TODO as part of this (see XD-537): 

* Get rid of so-called Service layer in analytics project (doesn't do much right now, and logic would better live in the 'Handler' IMO)
* Have REST controllers depend on XRepository in all cases",XD-332,Mark Pollack,Retrieve information for an aggregate counter
3393,Luke Taylor,Mark Pollack,"TODO as part of this (see XD-537): 

* Get rid of so-called Service layer in analytics project (doesn't do much right now, and logic would better live in the 'Handler' IMO)
* Have REST controllers depend on XRepository in all cases",XD-331,Mark Pollack,Retrieve information for a Rich Gauge
3394,Luke Taylor,Mark Pollack,"TODO as part of this (see XD-537): 

* Get rid of so-called Service layer in analytics project (doesn't do much right now, and logic would better live in the 'Handler' IMO)
* Have REST controllers depend on XRepository in all cases",XD-330,Mark Pollack,Retrieve information for a Gauge
3395,Eric Bottard,Mark Pollack,"TODO as part of this (see XD-537): 

* Get rid of so-called Service layer in analytics project (doesn't do much right now, and logic would better live in the 'Handler' IMO)
* Have REST controllers depend on XRepository in all cases",XD-329,Mark Pollack,Retrieve information for a Field Value Counter
3396,Eric Bottard,Mark Pollack,,XD-328,Mark Pollack,Retrieve information for a Counter
3397,,Mark Pollack,"For a sink/source/processor this would be (among other things) message rate, number of messages",XD-327,Mark Pollack,Retrieve monitoring information for a specfied module
3398,,Mark Pollack,,XD-326,Mark Pollack,Add command to get listing of all modules
3399,,Mark Pollack,,XD-325,Mark Pollack,Add command to get listing of a module
3400,,Mark Pollack,,XD-324,Mark Pollack,Retrieve description of a single module
3401,,Mark Pollack,,XD-323,Mark Pollack,Add command for listing of taps
3402,,Mark Pollack,,XD-322,Mark Pollack,Support for DELETE of taps
3403,David Turanski,Mark Pollack,POST?,XD-321,Mark Pollack,Add create() and deploy() to TapsController
3404,,Mark Pollack,,XD-320,Mark Pollack,Support for GET of /taps
3405,,Mark Pollack,,XD-319,Mark Pollack,Add command for deleting a tap
3406,Glenn Renfro,Mark Pollack,"This would be based off the spring-integration-extenstions splunk project.  The use of this adapter for storing tweet data is in
https://github.com/markpollack/springone

We should be able to reproduce the use case as done in that demo",XD-318,Mark Pollack,Create Splunk sink module
3407,Gunnar Hillert,Gunnar Hillert,,XD-317,Gunnar Hillert,Add Documentation Chapter on Executing Batch Jobs
3408,,Glenn Renfro,"Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions.  An example of this is when leaving out the channels in the module definitions, we see NoSuchBeanExceptions and IllegalArgumentExceptions thrown based on which module and what channel is missing. ",XD-316,Glenn Renfro,Create a common exception framework for XD
3409,Eric Bottard,Eric Bottard,"The shell should be an 'executable' delivered out of the box in much the same way that xd-container and xd-admin are right now. If we follow how redis/mongo distribut the shell, it sits side by side with the other binaries",XD-315,Eric Bottard,"Package Shell ""binary"" next to xd-admin and xd-container"
3410,,Gary Russell,Expose runtime stats for core components.,XD-314,Gary Russell,"Add @ManagedComponent. Metric, Operation etc to Appropriate DIRT Classes"
3411,David Turanski,Gary Russell,"Global option?

Override for individual modules? module types?",XD-313,Gary Russell,Add Spring/Integration MBean Exporters to Module ApplicationContexts
3412,David Turanski,Gary Russell,"WAR Vs. JVM Jolokia Agent

Jolokia Vs. JVM MBeanServer

Probably needs support for Spring Profiles.",XD-312,Gary Russell,Add Jolokia Agent Depending on Run Mode
3413,David Turanski,Gary Russell,Probably needs support for Spring Profiles.,XD-311,Gary Russell,Optionally Add Spring/Integration MBean Exporters to Common ApplicationContext
3414,,Jennifer Hickey,"See XD-194 for additional considerations. Zip support should be similar to uber-jar, or possibly replace uber-jar support.",XD-309,Jennifer Hickey,Users should be able to package custom modules as a single zip file
3415,,Glenn Renfro,,XD-308,Glenn Renfro,User wants ability to test multiple processors in a chain
3416,,Glenn Renfro,,XD-307,Glenn Renfro,User to send a message directly to module and receive a message from a module
3417,,Glenn Renfro,"Examples:
1. Be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml, pass in some property file for parameters to be replaced, and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality.  
2. Test for as many source types as is 'reasonable', e.g. MQTT/TCP testing might be harder than say rabbitmq.
3. Test that sending json, results in media-type header is set to json
4. Test that sending POJO,   ""  POJO
5. Test that sending Tuple, ""   Tuple
6. Test that sending raw bytes, "" raw bytes
",XD-306,Glenn Renfro,User wants ability to test sources
3418,,Glenn Renfro,Handled by 1245,XD-305,Glenn Renfro,User wants ability to test sinks
3419,,Glenn Renfro,"Be able to point to the processor xml file, e.g. modules/processors/transformer.xml, and have access to a source channel that drives messages into the processor and a output channel where output messages are send.  The outbound channel is queue backed.

Test sending JSON to a processor module that uses Tuples.
",XD-304,Glenn Renfro,User wants ability to test processors
3420,,Glenn Renfro,So that we can validate the message content in the stream,XD-303,Glenn Renfro,User wants ability to create a in-process sink or tap
3421,,Glenn Renfro,To send a pre-set message to process(es),XD-302,Glenn Renfro,User wants ability to create a mock source
3422,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"It would be nice if we have a git repo for Spring XD performance testing.

This would enable us to have a common repository (rather than inside spring-xd as a subproject) for all performance related code specific to any module, message middleware etc., 
",XD-301,Ilayaperumal Gopinathan,Request to create a repo for Spring XD performance testing
3423,,Eric Bottard,"This includes ease of setup, user friendly error reporting, etc.",XD-300,Eric Bottard,Improve user experience when XD fails to start
3424,Andy Clement,Eric Bottard,"See http://stackoverflow.com/questions/17157068/counter-analytics-in-springxd

The underlying issue is stream creation with a name already taken though",XD-299,Eric Bottard,Creating a tap with same name as existing streams results in infinite loop
3425,Luke Taylor,Luke Taylor,"Twitter's streaming APIs have more capabilities than just the plain statuses/sample.json. In particular we should support the filter.json option and the use of ""track"" (https://dev.twitter.com/docs/streaming-apis/parameters#track) as well as other request parameters (delimited, language etc).",XD-298,Luke Taylor,Refactor gardenhose into more generic twitterstream source
3426,Janne Valkealahti,Jennifer Hickey,"I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file (in case I collected more data than my demo could handle and needed to split it up).",XD-297,Jennifer Hickey,File sink should support rollover
3427,Ilayaperumal Gopinathan,Luke Taylor,"The changes for XD-144 mean that log4j files are no longer in the library jars. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn't.",XD-296,Luke Taylor,Add log config file to gemfire in final distro
3428,Ilayaperumal Gopinathan,Deejay,"The container application loads {{redis.properties}}, but for some reason the values are ignored, and defaults are used instead.

Repro steps:
# Unpack Spring XD 1.0.0.M1 to a machine with no running Redis instance
# Change /xd/config/redis.properties to specify a different hostname
# Run /xd/bin/xd-container
# Observe error about inability to connect to Redis on localhost

Workaround
* Pass -Dredis.hostname={desired IP} as a JVM parameter",XD-295,Deejay,redis.properties values ignored
3429,Gary Russell,Gary Russell,,XD-294,Gary Russell,Apply JavaDoc HotFix
3430,Ilayaperumal Gopinathan,Gunnar Hillert,"We should ensure that each Package of Spring XD is documented. Right now the created JavaDoc looks barren:

http://static.springsource.org/spring-xd/docs/1.0.0.M1/api/

 ",XD-293,Gunnar Hillert,Ensure package-info.java is present for each package
3431,Ilayaperumal Gopinathan,Verrol Adams,"The installation script for redis fails on Ubuntu64 when trying to untar the redis distribution.  The script uses REDIS_ZIPNAME instead of REDIS_ZIP_PATH.  

This bug will be seen on any Linux 64 bits platform and looking at the code, even Linux 32 bits platform.",XD-292,Verrol Adams,Redis 'install-redis' script fails on Ubuntu64
3432,Mark Fisher,Frank Tyler,"Steps to reproduce:

1.  curl -d ""http | log"" http://localhost:8080/streams/testHttp

2.  curl -X DELETE http://localhost:8080/streams/testHttp

3.  curl -d ""http | log"" http://localhost:8080/streams/testHttp

org.jboss.netty.channel.ChannelException: Failed to bind to: 0.0.0.0/0.0.0.0:9000",XD-291,Frank Tyler,HTTP Source still listens on port 9000 after removal.
3433,,Ilayaperumal Gopinathan,"Currently, the RedisQueueInboundChannelAdapter has blocking operation when pulling the messages out of redis queue and this is not performant. 

There are few ideas from the discussion to make it better:

1) Get more items from the redis queue per connection
2) We will also have compression of messages(at the channel registry) before being sent to the redis queue 

We also need to investigate what redis connection strategy makes the RedisQueueInboundAdapter better. ",XD-290,Ilayaperumal Gopinathan,Redis backed container's RedisQueueInboundChannelAdapter is not performant
3434,,Mark Pollack,See https://github.com/kevinweil/elephant-bird,XD-288,Mark Pollack,Support writing to HDFS using Thrift
3435,,Mark Pollack,See https://github.com/kevinweil/elephant-bird,XD-287,Mark Pollack,Support writing to HDFS using Protocol Buffers
3436,,Mark Pollack,,XD-286,Mark Pollack,Support writing to HDFS using a SequenceFile with compression
3437,,Mark Pollack,the key used in writing key-value pairs should be able to be specified declaratively.,XD-285,Mark Pollack,Provide a strategy interface to obtain the key used when writing SequenceFiles 
3438,,Mark Pollack,,XD-284,Mark Pollack,Support writing to HDFS using a SequenceFile using AvroSerialization
3439,,Mark Pollack,,XD-283,Mark Pollack,Support writing to HDFS using a SequenceFile using WritableSerialization
3440,Thomas Risberg,Mark Pollack,"Writing POJOs using CDK Data (Avro)

We should support both partitioned and un-partitioned.  This story addresses only un-partitioned.

Document limitations in terms of which Java types are supported and not supported by the Avro serialization
",XD-282,Mark Pollack,The HDFS Sink should support writing POJOs to HDFS using Avro Serialization
3441,Janne Valkealahti,Mark Pollack,"The classname for the codec would be used to instantiate it.  Note, the ReflectionUtils or CompressionCodeFactory should be used to be efficient.",XD-281,Mark Pollack,Support writing to HDFS using a custom codec
3442,Janne Valkealahti,Mark Pollack,"snappy codec can be included in the distribution.

for more info http://blog.cloudera.com/blog/2011/09/snappy-and-hadoop/

Depends on using a file container format such as sequence or avro files.",XD-280,Mark Pollack,Support writing to HDFS using the Snappy codec
3443,Janne Valkealahti,Mark Pollack,"note, the LZO codes are GPL-licensed, so can't be included in the distribution.
It is splittable, which makes it a good candidate for writing without any additional data file container structure such as sequence or avro files.",XD-279,Mark Pollack,Support writing to HDFS text file using the LZO codec
3444,,Mark Pollack,,XD-278,Mark Pollack,Support writing to HDFS using the GZipCodec
3445,Janne Valkealahti,Mark Pollack,"The BZip2 codec is splittable, making it a common choice.",XD-277,Mark Pollack,Support writing to HDFS text file using the BZip2Codec
3446,,Mark Pollack,"This could be an optimization, to be verified, that delegating the writing operations to Reactor (e.g. with a backing ringbuffer implementation) will increase the throughput performance.  Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.",XD-276,Mark Pollack,Investigate throughput performance writing to HDFS
3447,,Mark Pollack,"This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block (64Mb often) will result in increased performance vs. not aggregating data for writes.",XD-275,Mark Pollack,Support for in-memory grouping/aggregation of data before writing to HDFS
3448,,Mark Pollack,"Based on message processing, a header in a Message can be added that contains the output file name.  This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. ",XD-274,Mark Pollack,Headers in a Message that will indicate which HDFS file the data should be stored in.
3449,,Mark Pollack,"The file name should allow the use of date and time patterns, either JDK or Joda (TBD).",XD-273,Mark Pollack,File name should support common date and time format strings
3450,,Mark Pollack,"A strategy that will automaticaly roll over files based time of day.

For example

New files will be created every hour, or every 6 hours etc.

The directory for files can also be rotated so that directory structures such as

/data/{year}/{month}/{day}

can easily be supported with a minimum of configuration.

",XD-272,Mark Pollack,A rotation file policy based on time
3451,,Mark Pollack,"A strategy to roll over files that allows the user to choose between 
1) the size of the file
2) the number of events/items in the file
3) an idle timeout value that if exceeded, will close the file",XD-271,Mark Pollack,The HDFS Sink should support a number of rollover options
3452,Janne Valkealahti,Mark Pollack,"A file that is in the process of being written to should have a customized suffix added to the name, e.g. 'temp'.

Once the file is closed, the suffix is removed and replaced with another value - default value can be dependent on the serialization format used, but can be customized",XD-270,Mark Pollack,The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files
3453,Glenn Renfro,Michael Minella,"h2. Narrative
As XD, I need a persistent way to register job definitions (beyond the map registry implementation provided by Spring Batch).  

h2.  Acceptance Criteria
# XD should be able to register, unregister, and find job definitions via the registry.
# The registry should be backed by Redis so that it is persistent.",XD-269,Michael Minella,Create JobDefinition repository
3454,Eric Bottard,Eric Bottard,"Command line arguments (and especially their default values) are currently scattered around different places.

The aim is to regroup those in a common place (*Options classes make sense).

Also, not very happy with how System properties are used as a vehicle for options.transport / options.home",XD-268,Eric Bottard,Streamline command-line arg management
3455,,Michael Minella,"h2. Narrative
As an XD developer, I need to be able to use a batch job to stream data as a source.

h2.  Acceptance Criteria
# Implement the ability for a job to be defined as a source in the DSL
# Add the configurations for the batch infrastructure transparently to the user
# Add the ability to specify if the job is stateful (picks up where it left off if it stops or restarts at the beginning).",XD-267,Michael Minella,Job as a Source
3456,,Eric Bottard,"So that clients (e.g. Shell or custom user program) are insulated from REST details (ala Cloud Foundry).

May go even further if we want a Java DSL for stream definitions (that may reuse Batch command POJOs btw):
Difference between:
xdClient.createStream(""mystream"", ""http --port=9000 | file"") and

import static stuff.*;

StreamDef stream = http().port(9000).pipe(file());
xdClient.createStream(""mystream"", stream);",XD-266,Eric Bottard,Create java client lib over REST API
3457,,Eric Bottard,"GET /streams/{streamname}/modules
   and
GET /streams/{streamname}/modules/{modulename}

The former returning links to the latter
",XD-265,Eric Bottard,Retrieve description of all registered modules 
3458,Eric Bottard,Eric Bottard,,XD-264,Eric Bottard,Spring MVC infrastructure tests
3459,Eric Bottard,Eric Bottard,"Pagination support, maybe querying by name as well",XD-263,Eric Bottard,Support GET /streams
3460,Eric Bottard,Eric Bottard,,XD-262,Eric Bottard,Convert current REST servlet to Spring MVC
3461,Eric Bottard,Thomas Risberg,,XD-261,Thomas Risberg,Add command for deleting a stream
3462,Glenn Renfro,Thomas Risberg,,XD-260,Thomas Risberg,Add command for listing streams
3463,David Turanski,Thomas Risberg,,XD-259,Thomas Risberg,Add command for tap creation
3464,Eric Bottard,Thomas Risberg,,XD-258,Thomas Risberg,Add command for stream creation
3465,Eric Bottard,Thomas Risberg,This is the basic setup of the commands file - no specific command implementations,XD-257,Thomas Risberg,Create the base implementation for XDCommands for the shell
3466,Eric Bottard,Thomas Risberg,,XD-256,Thomas Risberg,Create a banner page for XD Shell
3467,Eric Bottard,Thomas Risberg,Set up a basic Spring Shell project for XD Shell,XD-255,Thomas Risberg,Set up a project for XD Shell
3468,Eric Bottard,Thomas Risberg,"For stream creation we need to be able to specify:

source
sink
processor
 - filter
 - transformer
 - script
 etc.
",XD-251,Thomas Risberg,Add support for stream creation
3469,Eric Bottard,Thomas Risberg,,XD-250,Thomas Risberg,Set up a project for XD REST client library
3470,Eric Bottard,Thomas Risberg,"Need to create a basic client library to provide easier access to the XD REST API.
",XD-249,Thomas Risberg,Initial client library for XD REST API
3471,Eric Bottard,Thomas Risberg,"Need to create a basic Spring Shell implementation to provide easier access to the XD REST API via an XD REST API Client library.
",XD-248,Thomas Risberg,Provide a Spring Shell implementation for XD
3472,Jennifer Hickey,Thomas Risberg,Running on Cloud Foundry (and other managed environments) we need to be able to specify a Redis password in addition to host and port.,XD-247,Thomas Risberg,Need to be able to specify password for Redis
3473,Michael Minella,Michael Minella,"h2. Narrative
As a user of XD, I want to be able to use a job as a source.  To do so, we need the output of a job to be written to a message channel

h2.  Acceptance Criteria
# Create a new ItemWriter in the Spring Batch project to write to a Spring Integration message channel.",XD-246,Michael Minella,MessageChannelItemWriter
3474,Michael Minella,Michael Minella,"h2. Narrative
As a developer, I need a way to deploy job configurations as well as the related custom code to XD.

h2.  Acceptance Criteria
# Provide the ability to register jobs that have been deployed as modules via something like {{curl -d ""job"" http://localhost:8080/streams/myJob}} where job is the name of the job definition located in /modules/job and myJob is the name of the resulting registered job
# Confirm that both ""regular"" jobs and Spring Hadoop based jobs can be packaged/run.",XD-245,Michael Minella,Deploy Batch Jobs on XD
3475,Gunnar Hillert,Michael Minella,"h2. Narrative
As the XD system, I need to be able to execute a job (or potentially a stream) based on a given condition (time, data existence, etc).  This story is intended is for a local trigger implementation but remote triggers will also need to exist.

h2.  Acceptance Criteria
# Implement the ability to register a time based trigger {{trigger <CRON_STRING>}} for example
# Implement the ability to register a file existence based trigger {{trigger <PATH>}} for example
# Implement the ability to execute a job via an anonymous trigger: {{job_name @ <CRON_STRING OR PATH>}}
# Implement the ability to execute a job via a job via the previously registered trigger: {{job_name @ trigger_name}}
",XD-244,Michael Minella,Create a Trigger
3476,Gary Russell,Mark Pollack,,XD-242,Mark Pollack,Add JMS source module
3477,Mark Pollack,Mark Pollack,,XD-241,Mark Pollack,Type conversion and co-location of modules
3478,Mark Pollack,Mark Pollack,,XD-240,Mark Pollack,Throughput optimized TCP based adapters based on Reactor TCP project
3479,Mark Pollack,Mark Pollack,"* As a user, I can view average performance statistics for each module involved in my stream, aggregated across a cluster
** Batch/Integration stats (Message send/receive counts, avg execution time, queue stats, error rates, job stats, etc)
** Implies grouping individual SI/Batch components by module
** Metrics exposed in JMX and JSON through Jolokia?
 Existing monitoring tool for visualization and reporting vs custom dashboard
* As a user, I can alert against these metrics and setup relevant control actions
** TODO what makes sense as auto-responses to control actions? Auto-scaling of XD nodes, more fine-grained message queue throttling, etc
* As a user, I can view performance of the XD system
** Expose metrics of interest to the internal workings of XD, particularly throughput/storage in transport mechanism
* As a user, I can correlate module statistics with XD system stats and node stats
** Should be doable with external monitoring system
* As a module developer, I can diagnose module performance issues by tracing a single message through a stream
** Trace individual messages, average message throughput would be interesting to end users too if not too expensive to trace
** Visualization through Spring Insight?
** Don't want to get too far into replacing a profiler
* As a module developer, I can add custom metrics to my module for export to the mgmt system
** Way to hook into the module-grouped metric exports
",XD-239,Mark Pollack,Epic For Distributed Monitoring Stories
3480,Mark Pollack,Mark Pollack,"When a module is deployed, it should run in its own isolated classpath.  The current code has all dependencies in a single classpath, taken from the lib directory at startup.  This has a number of drawbacks, one of the most important is the batch jobs can not be contributed to the system at runtime.  The work for this epic is decoupled from any module deployment story.  The assumption is that there will be a directory layout as shown below.

Current layout

./modules/.
|-- common
|-- job
|-- processor
|-- sink
|-- source
|-- trigger

And inside source
|-- source
|   |-- file.xml
|   |-- gemfire-cq.xml
|   |-- gemfire.xml
|   |-- http.xml
|   |-- jms.xml
|   |-- mqtt.xml
|   |-- rabbit.xml
|   |-- syslog-tcp.xml
|   |-- syslog-udp.xml
|   |-- tail.xml
|   |-- tap.xml
|   |-- tcp.xml
|   |-- time.xml
|   |-- twittersearch.xml
|   |-- twitterstream.xml


Using an example of the source directory from the current layout.e.g ./modules/source/file, the new layout would be

./modules/source/file/lib/spring-integration-file.jar
./modules/source/file/config/file.xml


We should support both the new and old layout styles simultaneously.

There what is under 'file' directory is the 'package'  No .zip, war, is required.",XD-238,Mark Pollack,Deploying Custom Code
3481,Mark Pollack,Mark Pollack,,XD-237,Mark Pollack,Spring Batch jobs should be able to be deployed to the DIRT runtime and managed.
3482,Luke Taylor,Mark Pollack,"An aggregate counter rolls up counts into discrete time buckets.  There is an existing POC implementation in Java based off the library
https://github.com/thheller/timed-counter 

The README there has a good description of the desired feature set.",XD-236,Mark Pollack,Create an Aggregate Counter
3483,Mark Pollack,Mark Pollack,,XD-235,Mark Pollack,"Modules (sinks, processors, sources) should be able to be easily tested inside the IDE using JUnit "
3484,Mark Pollack,Mark Pollack,,XD-234,Mark Pollack,"Support various output format, e.g. Avro, SequenceFile, more advanced rollover options."
3485,Mark Pollack,Mark Pollack,,XD-233,Mark Pollack,Create an shell to control all aspect of stream/job management
3486,Mark Pollack,Mark Pollack,,XD-232,Mark Pollack,A HATEOAS designed REST API using Spring HATEOAS library.
3487,Luke Taylor,Mark Fisher,"we have a prototype gardenhose adapter that was built directly upon RestTemplate (streaming on a background thread), but Spring Social Twitter has an issue on its 1.1 roadmap that is relevant:
https://jira.springsource.org/browse/SOCIALTW-2
",XD-231,Mark Fisher,Add Twitter gardenhose source module
3488,Mark Fisher,Mark Fisher,"configurable parameters should include the queue-name(s) and optional binding key pattern

connection info, such as host and port, should also be configurable but with defaults (localhost and default port), and that should likely fallback to a rabbit.properties file in the $XD_HOME/config directory",XD-230,Mark Fisher,Add RabbitMQ source module
3489,Mark Fisher,Mark Fisher,,XD-229,Mark Fisher,Add RabbitMQ-based implementation of ChannelRegistry
3490,Eric Bottard,Tomasz Pik,"In documentation attached to M1, in Streams/Introduction section, there's
{noformat}
http --port 8091 | file --dir=/tmp/httpdata/
{noformat}
while it should be:
{noformat}
http --port=8091 | file --dir=/tmp/httpdata/
{noformat}
missing ""{{=}}"" in {{http}}",XD-228,Tomasz Pik,Missing '=' in example of http stream
3491,Jennifer Hickey,Mark Pollack,This is needed for the use of the webhdfs:// scheme to talk to HDFS over http.,XD-227,Mark Pollack,Add jetty-util-6.1.26.jar and jsr311-api-1.1.1.jar as required jars so they will be on the XD classpath
3492,Gunnar Hillert,Ilayaperumal Gopinathan,"We need to cleanup some of the duplicate gradle tasks that bundle spring-xd distributions. 

Currently, distXD does the copy of distributions from ""spring-xd-dirt"", ""redis"" and ""spring-xd-gemfire-server"" projects into ""$rootDir/dist/spring-xd"".

And, the task ""zipXD"" makes the zip archive.

These tasks should be combined with the ""distZip"" & ""docZip"" tasks.

We also need to remove the duplicate artifacts configuration from these tasks.",XD-226,Ilayaperumal Gopinathan,Cleanup and Optimize gradle tasks to bundle spring-xd distribution
3493,Mark Fisher,Mark Fisher,"for example, when using the 'twittersearch' source module, the ""hashTags"" are nested within ""entities"", and the value for hashTags is itself an object with a ""text"" field, so the following would be needed to count the actual value of interest:

{code}
tap @ tweets | field-value-counter --fieldName=entities.hashTags.text
{code}
",XD-225,Mark Fisher,field-value-counter should support nested fieldNames
3494,Andy Clement,Andy Clement,"parameter values that include spaces need to be quoted, but this becomes overly complex in this kind of case.  Here is what you want to say:

{code}
http --port=9995 | filter --expression=payload.matches('hello world')
{code}

With the rule 'parameter values that contain spaces must be quoted' it would be this:

{code}
http --port=9995 | filter --expression='payload.matches('hello world')'
{code}

But then to include single quotes within a single quoted string you need to use two of them: '' - so it becomes

{code}
http --port=9995 | filter --expression='payload.matches(''hello world'')'
{code}

Less than ideal.



",XD-224,Andy Clement,Reduce necessity for quoting in parameter values in DSL expressions
3495,Jennifer Hickey,Jennifer Hickey,"https://github.com/SpringSource/spring-xd/wiki/Creating-a-Source-Module uses the SI twittersearch inbound channel adapter, which is no longer going to work once Twitter disallows anonymous searches. 

Ideally we update the example to use a new version of SI-twitter that adds support for this (as opposed to the XD workaround.)",XD-223,Jennifer Hickey,Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues
3496,Luke Taylor,Mark Pollack,curl -X DELETE http://localhost:8080/streams/ticktock,XD-222,Mark Pollack,Add docs for Deleting a simple stream.
3497,Eric Bottard,Mark Pollack,"The issue arises because the link:document[Label] asciidoc macro is meant for ""external documents"" and creates {{<ulink>}} in docbook / {{<a href=""document"">}} in html, whereas we want {{<link linkend=""anchor"">}} / {{<a href=""doc#anchor>}} resp. We also want it to continue working in github live view.

I guess what could work is to have the macro (either override the link macro or create our own if github supports that) that looks like :
{{link:document#anchor[Label]}}  (the #anchor works out of the box in asciidoc and should work in github) but override it for the html and docbook backends to render to the correct form.

The thing is, there are several ways to create/override macros (and templates they render to), some of which make sense to our setup:
- having asciidoc.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27)
- having docbook.conf/html.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27)
- defining macros using attributes (http://asciidoc.org/userguide.html#_setting_configuration_entries)

I tried all of those, but to no avail. These DO WORK with plain asciidoc, but not with our toolchain. Don't know if the problem is with asciidocTOR or with the gradle wrapper though.



",XD-221,Mark Pollack,Links in asciidoctor generated HTML+docbook documentation are broken
3498,Mark Fisher,Mark Fisher,Those property keys should then be provided as defaults for the placeholders in source/twittersearch.xml,XD-220,Mark Fisher,Add twitter oauth properties file to config dir
3499,David Turanski,David Turanski,,XD-219,David Turanski,Surpress tap WARNING message in local mode
3500,,Mark Pollack,,XD-218,Mark Pollack,Add support to load a twitter.properties file in the source
3501,Jennifer Hickey,Jennifer Hickey,"The transform, filter, and script processor modules support passing in a properties-location for script variables. We need a default location on the classpath for users to provide custom properties files.",XD-217,Jennifer Hickey,Add config dir to classpath to support custom properties-locations
3502,Andy Clement,Mark Pollack,,XD-216,Mark Pollack,Add support for tap foo.bar syntax in the DSL
3503,,Luke Taylor,"Since the changes for XD-202, twittersearch requires authentication. Need to update the docs to reflect this.",XD-215,Luke Taylor,Add authentication information to twittersearch source doc
3504,Andy Clement,Mark Pollack,The asciidoc wiki should have a section (included in the _Sidebar.asciidoc as well) that describes the general usage of the DSL syntax.,XD-214,Mark Pollack,Create documentation on the general DSL syntax
3505,Gary Russell,Gary Russell,,XD-213,Gary Russell,Temporarily add toString() Logic in Local Mode Inter-Module Comms
3506,Ilayaperumal Gopinathan,David Turanski,"Currently StreamServer has setPort, but no way for end user to set it. ",XD-212,David Turanski,Add http port command line option to AdminMain
3507,Luke Taylor,Mark Pollack,,XD-211,Mark Pollack,Document the log sink
3508,,Mark Pollack,There shouldn't be a need to do a mkdir -p before sending data to a file sink.,XD-210,Mark Pollack,"If output directory does not exist for a file sink, by default allow it to be created"
3509,Mark Pollack,Jennifer Hickey,"The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",XD-209,Jennifer Hickey,Create or document existing project template for custom module creation
3510,Luke Taylor,Mark Pollack,,XD-208,Mark Pollack,Document the file sink
3511,Mark Fisher,Mark Pollack,"The config file modules/sink/hdfs.xml has a hardcoded value to locate the namenode.

	<hdp:configuration register-url-handler=""false"">
		fs.default.name=hdfs://localhost:9000
	</hdp:configuration>

the fs.default.name proprety should be configurable and we should also support loading an external configuration file using 

   <hdp:configuration properties-location=""${xd.home}/config/hadoop.properties"">

   </hdp:configuration>

",XD-207,Mark Pollack,Provide configurable properties for hdfs sink.
3512,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the system property xd.home is set as JVM_OPTS (via SPRING_XD_ADMIN_OPTS) into xd-admin & xd-container scripts.

Inside the ContainerMain & AdminMain, we need to check if this system property is set and use it. It seems like, this check is missing now.",XD-206,Ilayaperumal Gopinathan,XD AdminMain & ContainerMain should check xd.home property from scripts
3513,Mark Pollack,Jennifer Hickey,"Filter, Transform, and Script modules all assume the provided script is written in Groovy. 

This is partly due to the fact that the ""lang"" attribute of <int-script:script> can't be set to a property value (i.e. lang=""${lang:groovy}""), which would allow users to pass in the expected language. Or perhaps we could use a SPEL expression or script to pick the language based on the file extension?",XD-205,Jennifer Hickey,Processor modules should support scripts in languages other than groovy
3514,Jennifer Hickey,Jennifer Hickey,Fill in https://github.com/SpringSource/spring-xd/wiki/Processors,XD-204,Jennifer Hickey,Document processor modules
3515,Ilayaperumal Gopinathan,Jennifer Hickey,"I don't see that we have automated tests for the modules we provide out-of-the-box.  We could make the modules folder an Eclipse project (which would also help solve XD-198) and add some integration tests similar to those documented here:

https://github.com/SpringSource/spring-xd/wiki/Creating-Custom-Modules",XD-203,Jennifer Hickey,Provided modules should be integration tested
3516,Mark Fisher,Mark Fisher,,XD-202,Mark Fisher,Update twittersearch module for Twitter 1.0 API retirement
3517,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Currently the XD scripts are broken in windows. ,XD-201,Ilayaperumal Gopinathan,Fix XD scripts on windows
3518,David Turanski,David Turanski,"Creating a tap throws an exception. In local mode: Cannot resolve reference to bean 'redisConnectionFactory' while setting constructor argument; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'redisConnectionFactory' is defined  But also fails when using redis.
",XD-200,David Turanski,Creating a tap throws an exception
3519,Gary Russell,Gary Russell,"While deleting a stream doesn't remove any taps right now, we should be able to explicitly delete a tap.

Determine whether the current DELETE works and, if not, make it so.",XD-199,Gary Russell,Ensure the DELETE Operation can Delete a Tap
3520,Mark Fisher,Gary Russell,"{{curl -X POST -d ""time --interval=3 | transform | log"" http://localhost:8080/streams/test}}

results in the following stack trace in the DEBUG log. It's apparently benign, but ugly...

{code}
2013-06-06 10:43:36,875 [task-scheduler-1] DEBUG: org.springframework.scripting.support.ResourceScriptSource - class path resource [transform.groovy] could not be resolved in the file system - current timestamp not available for script modification check
java.io.FileNotFoundException: class path resource [transform.groovy] cannot be resolved to URL because it does not exist
	at org.springframework.core.io.ClassPathResource.getURL(ClassPathResource.java:177)
	at org.springframework.core.io.AbstractFileResolvingResource.lastModified(AbstractFileResolvingResource.java:170)
	at org.springframework.scripting.support.ResourceScriptSource.retrieveLastModifiedTime(ResourceScriptSource.java:101)
	at org.springframework.scripting.support.ResourceScriptSource.getScriptAsString(ResourceScriptSource.java:79)
	at org.springframework.integration.scripting.RefreshableResourceScriptSource.<init>(RefreshableResourceScriptSource.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:121)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:280)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1035)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:939)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:485)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:271)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:616)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:148)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1035)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:939)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:485)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:271)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1360)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1118)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:517)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:294)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:225)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:291)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:589)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:925)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:472)
	at org.springframework.xd.module.SimpleModule.start(SimpleModule.java:97)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:120)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:108)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)
	at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:84)
	at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:57)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:102)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:230)
	at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:129)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)
	at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)
	at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)
	at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter.access$4(RedisQueueInboundChannelAdapter.java:1)
	at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter$ListenerTask.run(RedisQueueInboundChannelAdapter.java:110)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
{code}

",XD-198,Gary Russell,Documentation for developing streams in the IDE needs to mention including scripts dir to project classpath
3521,Jennifer Hickey,Mark Pollack,"This will enable arbitrary processing logic to be used in a processing step.

See http://blog.springsource.org/2011/12/08/spring-integration-scripting-support-part-1/

<int:service-activator ...>
  <script:script lang=""groovy"" location=""file:scripts/groovy/myscript.groovy"">
</int:service-activator>

would be the essence of the module.  Probably 'lang' gets detected from the file extension.",XD-197,Mark Pollack,"Create a scriptProcessor module that allows the execution of a groovy (potentially jruby,jython) based SI Service Activator"
3522,Andy Clement,Andy Clement,"Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL.  This will provide a stable base on which to quickly iterate on syntax.
",XD-196,Andy Clement,replace the hacky parser with a good one
3523,Gary Russell,Gary Russell,"When running in local mode (no Redis) {{time | tcp}} no longer works.

Change the {{time}} source to emit the date as a String, while allowing an option to emit a {{Date}} object.",XD-195,Gary Russell,The {{time}} Source Should Emit String by Default
3524,,Jennifer Hickey,"If a user needs to deploy a module containing custom code, they have to build a jar for the lib dir and somehow deploy the app context file separately to a modules dir.  This is a bit inconvenient to build from a project, since context files in src/main/resources typically get built into a jar.

Might be better to accept both jar and xml files in the modules dir, though that brings up the issue of classpath isolation.",XD-194,Jennifer Hickey,Users should be able to package custom modules into a single jar
3525,Eric Bottard,David Turanski,"Currently internal config files are in META-INF/spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. META-INF/spring/xd",XD-193,David Turanski,Need more unique resource locations for XD internal configuration
3526,Luke Taylor,Mark Pollack,"With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.",XD-192,Mark Pollack,Update getting started documentation to use xd-singlenode start script.
3527,Mark Fisher,Mark Fisher,"XD-106 included detailed logging about the Redis metadata within the RedisContainerListener, but it seems as though that info could be logged somewhere closer to the establishment of a Redis connection for the XD runtime (and could be logged even if this listener, whose main role is to capture Container-related events, is not enabled).",XD-191,Mark Fisher,Move Redis connection metadata logging into the code closest to establishing that connection
3528,Mark Pollack,Eric Bottard,"The --embeddedX options are a bit confusing in code right now, as the Admin can embed the Container and vice-versa.
I guess we should only keep the Admin>Container side of things.",XD-190,Eric Bottard,Cleanup embedded container story
3529,,Jennifer Hickey,,XD-189,Jennifer Hickey,Investigate running XD on Cloud Foundry
3530,Jennifer Hickey,Mark Pollack,"a stream such as time | filter --script=oddMinuteFilter.groovy | file 

would load the groovy script 'oddMinuteFilter.groovy' that is located in the directory modules/processor or perhaps in modules/processor/scripts.

Not sure the benefit of having a subdirectory below processor just for scripts.",XD-188,Mark Pollack,Add  directory to classpath in server startup scripts so groovy based processors can be easily referenced by name without a resource uri prefix
3531,David Turanski,Ilayaperumal Gopinathan,"This script will launch XD admin along with the module container.

As part of this implementation, we will also remove the embedded options for XD admin & container scripts.",XD-187,Ilayaperumal Gopinathan,Create XD script for xd-single node
3532,David Turanski,David Turanski,Create StreamDeployer that does not depend on an adapter implementation,XD-186,David Turanski,Create a pipe protocol independent StreamDeployer
3533,David Turanski,David Turanski,The current StreamServer depends on RedisStreamDeployer. Call this RedisStreamServer and extract interface to allow alternate implementations,XD-185,David Turanski,Refactor StreamServer to an interface and create Redis and Local implementations
3534,Gary Russell,Mark Pollack,,XD-184,Mark Pollack,Add unregistration support to the channel registry
3535,David Turanski,Mark Pollack,,XD-183,Mark Pollack,Create localChannelProtocol.xml that will load all the SI specific implementations to suppor the XD container runtime and administration
3536,David Turanski,Mark Pollack,The redis specific beans that are defined in the current launcher.xml should move into this configuration file.   ,XD-182,Mark Pollack,Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration
3537,David Turanski,Mark Pollack,"launcher.xml can make use of the system property xd.pipeProtocol inside an import statement.  This determines which version of the XD infrastructure to load, for example what ChannelRegistry implementation, Local or Redis based, or specific message listener containers. 

File name conventions should be used, so if the option passed in from the command line is --pipeProtocol localChannel

then the XML filename looked for has the 'Protocol' suffix applied, e.g. localChannelProtocol, and is loaded via the classpath.

Redis and Local will not be the only options, other implementations will be provided in the future, e.g. Rabbit, and the user may be able to provide their own implementations of these infrastructure classes (an advanced task).  ",XD-181,Mark Pollack,Update launcher.xml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location.
3538,David Turanski,Mark Pollack,"The name 'pipeProtocol' is tentative.  

1. The command line scripts for xd-admin and xd-container would support a --pipeProtocol option, with the default being to use Redis.  (Otherwise use xd-singlenode).
2. The xd-admin and xd-container scripts will use the value of pipeProtocol to set the java system property xd.pipeProtocol when launching the app.
",XD-180,Mark Pollack,"The command line for xd-admin and xd-container to support an additional option, pipeProtocol, that is used to determine the middleware for sending admin requests and data between processing steps"
3539,David Turanski,Mark Pollack,"The xd-singlenode script will launch a main application that creates both the admin node (to process http admin requests) and the container node (to execute modules for data processing) within in the same process 

the xd-admin script will launch a main application that creates only the admin node (remove current embeddedContainer options)

the xd-container script will launch a main application that creates only the container node (as it is now)",XD-179,Mark Pollack,"Have three startup scripts, xd-singlenode, xd-admin, and xd-container"
3540,David Turanski,Mark Pollack,The current incrementAndGet approach based off redis will not easily be applicable in local model deployment,XD-178,Mark Pollack,DefaultContainer should have a default constructor that generates a UUID
3541,Mark Pollack,Mark Pollack,,XD-177,Mark Pollack,Easily switch between a single process that performs all admin and processing tasks to one that has a dedicated admin processes and distributed processing containers.
3542,Luke Taylor,Luke Taylor,"This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter ""alpha"" to the gauge data (https://en.wikipedia.org/wiki/Exponential_moving_average). If not set it would default to the current behaviour (simple mean), otherwise it would calculate the exponential moving average in place of the mean.",XD-176,Luke Taylor,Support exponential moving average in RichGauge 
3543,Ilayaperumal Gopinathan,Mark Pollack,"2-3 containers (separate processes) that the stream: syslog | tcp 
1 container (separate process) that aggregates the data sent from those conainers, tcp | severityFilter | hdfs






",XD-175,Mark Pollack,Create and document a syslog aggregation example
3544,Luke Taylor,Mark Pollack,"The use case is to write custom code that does processing on a specific domain class (perhaps from twitter adapter) or a tuple.  Need to package up this code so that it can be used inside XD.
",XD-174,Mark Pollack,Document how to create a custom processor module.
3545,Jennifer Hickey,Mark Pollack,"Document how to take an existing input/output channel adapters in spring integration and add them as a XD source/sink module.

Should be as end-user focused, step by step guide as possible.

Consider including a getting started gradle/pom.xml ",XD-173,Mark Pollack,Document how to create a custom input/output module for existing SI channel adapters
3546,Mark Pollack,Mark Pollack,"bottom home page - list of projects
data/integration category landing pages - related projects.
",XD-172,Mark Pollack,Create links to SpringXD on other pages of springsource.org site
3547,Gunnar Hillert,Mark Pollack,"A minimal project page of a 'top level project' page that has basic information of docs and links to the github wiki page. 
No need to list maven coordinates.",XD-171,Mark Pollack,Create project home page for SpringXD on springsource.org/spring-xd
3548,Jennifer Hickey,Mark Pollack,"Add more structure, more easily find the reference guide.  The style that is here 
https://github.com/snowplow/snowplow/wiki
is nice.
",XD-170,Mark Pollack,Home wiki page improvements
3549,Jennifer Hickey,Jennifer Hickey,Trying to run XD offline results in an error in redis.xml because the cloudfoundry schema file is missing.  We need to add the cf-runtime jar to the classpath to resolve this.,XD-169,Jennifer Hickey,XD should run offline
3550,Gunnar Hillert,Mark Pollack,,XD-168,Mark Pollack,Decide on location to host http reference documentation and automate upload in build scripts
3551,Gunnar Hillert,Mark Pollack,,XD-167,Mark Pollack,Script to generate reference documentation from wiki and include in .zip distribution
3552,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"We need to have the XD container & admin reading the registry specific property based on the registry type selected. 

From Mark F, on one of the code review comments:

Maybe rather than having redis, rabbit, etc. properties all within a container.properties we should rely upon naming conventions instead. Specifically, we could have a single configurable property for the type of channel registry (""redis"", ""rabbit"", or ""local"" being possible values), and then we could use something like:

<import resource=""config/${registry.type}.xml""/>

<context:property-placeholder location=""config/${registry.type}.properties""/>",XD-166,Ilayaperumal Gopinathan,Create config support based on channel registry type
3553,Ilayaperumal Gopinathan,Jennifer Hickey,We should have an externally editable log4j config file in a conf dir and the default should log to a file (presumably in a logs dir),XD-165,Jennifer Hickey,xd-container and xd-admin should log to a file out of the box
3554,Glenn Renfro,Mark Fisher,"Validate that modules have required channels declared according to their type.  Currently the stream deployer accepts processors with no input, but the stream doesn't complete. We should fail earlier and more loudly.",XD-164,Mark Fisher,Validate processing modules declare the required channels
3555,Mark Fisher,Mark Fisher,"example:

{code}
a | (b | c) | d
{code}

...where b and c modules are deployed together as a composite module.

There are 2 options (maybe more) for how we could handle that. One would be defining a CompositeModule type that simply bridges the channels (b's output to c's input in this example). The second option would be to deploy those together on the same node as modules but using the LocalChannelRegistry between them.
",XD-163,Mark Fisher,Enable grouping of modules for co-located deployment
3556,David Turanski,Mark Fisher,"The conversion should be based on content-type headers, similar to the way Spring's HttpMessageConverters work (with mime types).

Also, the map of available converters should be extensible while including the most common defaults (for JSON, XML, etc). We most likely want to add a few of our own content types also (e.g. for Tuples).

Most likely, this logic and the configuration methods for extending the converter map, belong in AbstractChannelRegistry since it should be common across all implementations (i.e. the logic should be the same regardless of the transport used after-serialization/before-deserialization).",XD-162,Mark Fisher,Create design document for implementation strategy to support message conversion in ChannelRegistry
3557,Gary Russell,Gary Russell,,XD-161,Gary Russell,Add HTTP Delete Stream Operation
3558,Gunnar Hillert,Jennifer Hickey,"The wiki repo contains a script, gen-docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. 

We should consider using maven (or gradle, but there is currently an issue documented in build.gradle) to generate this and other reference docs and publish them automatically as part of a nightly build.",XD-160,Jennifer Hickey,Publish golo themed docs documentation to static.springsource.org as part of nightly build
3559,Andy Clement,Gary Russell,"Parameter parsing does not work if an argument contains '--'.

For example:

{code}
... | transform --expression=42 | transform --expression=--payload |...
{code}

Also, I was surprised that this worked..

{code}
| transform --expression=new StringBuilder(payload).reverse() |
{code}

... but this didn't...

{code}
| transform --expression='new StringBuilder(payload).reverse()' |
{code}

I think we need to tokenize the argument (with ' if contains spaces) and remove any surrounding '...' from the result. This means if someone wants a SpEL literal they would have to use something like 

{code}--expression=''Hello, world!''{code}

resulting in a SpEL literal 'Hello, world!'",XD-159,Gary Russell,Parameter parsing does not work if an argument contains '--'.
3560,Glenn Renfro,Mark Pollack,"This will allow for a simple way to shutdown the server via an HTTP call.  Support for security is a separate story. The end goal is to have some shell scripts distributed that can issue HTTP requests to shutdown the xd-admin and xd-container servers.

The newest version of Jolokia has the ability to boostrap itself inside an application context vs. requiring a java agent.  I suspect using the application context approach will provide us with more flexibility (e.g. property replacement etc) but not sure.",XD-158,Mark Pollack,Expose shutdown operation over http
3561,Luke Taylor,Mark Pollack,In both cases there are multiple application contexts that can be running in the process.  The JMX Managed bean should call 'close' on those application contexts.  The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.,XD-157,Mark Pollack,Verify use of JMX managed bean to shutdown cleanly the xd-admin and xd-container servers
3562,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,We would like to have Redis driven from a config property file under XD_HOME.,XD-156,Ilayaperumal Gopinathan,Create config support for Redis
3563,Jennifer Hickey,David Turanski,A processor module that accepts either the location of a groovy script resource or an inline script (string). Also some discussion about a default classpath location for scripts. ,XD-155,David Turanski,Add a groovy script processor module
3564,Mark Pollack,Gunnar Hillert,"Shouldn't we have something like a ContextRefreshedEvent Listener and output some informational messages to the console, so the user knows the Container is up (Which contexts. Maybe even print a link to the docs))? Maybe even some simple ascii art (for demos)? Right now it looks somewhat barren.

Redis provides something similar.

This may even go hand in hand to provided a better configuration model (storing common config parameters centrally)


{code}
   _____            _              __   _______  
  / ____|          (_)             \ \ / /  __ \ 
 | (___  _ __  _ __ _ _ __   __ _   \ V /| |  | |
  \___ \| '_ \| '__| | '_ \ / _` |   > < | |  | |
  ____) | |_) | |  | | | | | (_| |  / . \| |__| |
 |_____/| .__/|_|  |_|_| |_|\__, | /_/ \_\_____/ 
        | |                  __/ |               
        |_|  v1.0.0.M1      |___/   eXtreme Data

Using Redis at localhost:6379    
The Server (PID: 12345) is now ready on http://myserver:123/streams

Documentation: https://github.com/SpringSource/spring-xd/wiki
       
{code}",XD-154,Gunnar Hillert,Provided console output of started server
3565,Luke Taylor,David Turanski,Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.,XD-153,David Turanski,create a gauge module
3566,David Turanski,David Turanski,Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.,XD-152,David Turanski,Create rich gauge module
3567,Mark Pollack,Gunnar Hillert,"Presently, Spring XD does not ship Windows binaries for Redis. However, Microsoft is actively working [1] on supporting Redis on Windows. You can download Windows Redis binaries from:

https://github.com/MSOpenTech/redis/tree/2.6/bin/release 

[1] http://blogs.msdn.com/b/interoperability/archive/2013/04/22/redis-on-windows-stable-and-reliable.aspx",XD-151,Gunnar Hillert,Add Redis binaries for Windows
3568,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, Bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives'. We need to have a way to set the final distribution archive as one of the gradle 'configurations' in our build.gradle and refer it inside bamboo artifacts.",XD-150,Ilayaperumal Gopinathan,Publish Spring XD final distribution zip as part of Bamboo artifactory plugin
3569,Jennifer Hickey,Mark Pollack,"Publishing an html version of the guide that uses the 'toc2' style format, table of contents on the left.

Looks like a 'stylesheet factory' http://asciidoctor.org/docs/produce-custom-themes-using-asciidoctor-stylesheet-factory/  needs to be installed.

From the theme showcase, http://themes.asciidoctor.org/preview/, the 'golo' theme has a toc2 style.

In the root of the git repo for the wiki is a build.gradle file that uses the asciidoctor gradle plugin, but it doesn't support using a single file with import as input. (See See https://github.com/asciidoctor/asciidoctor-gradle-plugin/issues/15 )

The mvn plugin does support this, so maybe using mvn is an option or just a bash script.",XD-149,Mark Pollack,Create asciidoc toolchain script to create a 'toc2' style html output
3570,Jennifer Hickey,Gunnar Hillert,"Redis is not running we get a nasty stacktrace:

{code}
~/dev/git/spring-xd/dist/spring-xd/xd/bin (master)] ➔ ./xd-container 
13/05/29 16:17:15 INFO support.ClassPathXmlApplicationContext: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@851052d: startup date [Wed May 29 16:17:15 EDT 2013]; root of context hierarchy
13/05/29 16:17:16 INFO xml.XmlBeanDefinitionReader: Loading XML bean definitions from class path resource [META-INF/spring/launcher.xml]
13/05/29 16:17:16 INFO xml.XmlBeanDefinitionReader: Loading XML bean definitions from class path resource [META-INF/spring/redis.xml]
13/05/29 16:17:17 INFO support.DefaultListableBeanFactory: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4934ce4a: defining beans [org.springframework.context.support.PropertySourcesPlaceholderConfigurer#0,redisConnectionFactory,org.springframework.xd.dirt.launcher.RedisContainerLauncher#0]; root of factory hierarchy
13/05/29 16:17:17 INFO support.DefaultListableBeanFactory: Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4934ce4a: defining beans [org.springframework.context.support.PropertySourcesPlaceholderConfigurer#0,redisConnectionFactory,org.springframework.xd.dirt.launcher.RedisContainerLauncher#0]; root of factory hierarchy
Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [META-INF/spring/redis.xml]: Invocation of init method failed; nested exception is com.lambdaworks.redis.RedisException: Unable to connect
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1488)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:626)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)
	at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)
	at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)
	at org.springframework.xd.dirt.launcher.RedisContainerLauncher.main(RedisContainerLauncher.java:68)
	at org.springframework.xd.ContainerMain.main(ContainerMain.java:68)
Caused by: com.lambdaworks.redis.RedisException: Unable to connect
	at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
	at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.initConnection(LettuceConnectionFactory.java:108)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.afterPropertiesSet(LettuceConnectionFactory.java:86)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1547)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1485)
	... 13 more
Caused by: java.net.ConnectException: Connection refused: localhost/127.0.0.1:6379
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:150)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:680)
{code}

I think it would be helpful to provide users with some helpful advice e.g.:

Redis does not seem to be running at 'localhost/127.0.0.1:6379'. Did you start or install Redis? Please see for further help http://foo/bar


",XD-148,Gunnar Hillert,Improve User Experience when Redis is not running
3571,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Currently redis project uses application plugin to bundle distribution. This also includes 'java plugin' which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ,XD-147,Ilayaperumal Gopinathan,Remove use of application plugin for redis project
3572,Gary Russell,Gary Russell,"Currently, the TCP source/sink use specific beans for the serializer/deserializer options; when profiles are available, they should be used to avoid having to declare a bean of each type.",XD-146,Gary Russell,Change TCP Source/Sink to Use Profiles
3573,David Turanski,Gary Russell,The TCP source supports inbound binary data. We currently have to go through unnecessary byte[]->String->byte[] conversion.,XD-145,Gary Russell,Add Support for Binary Payloads in RedisQueueOutboundChannelAdapter
3574,Luke Taylor,Gary Russell,"If, say, xd-dirt is ahead of a local config on the classpath, it's log4j.properties is found first.",XD-144,Gary Russell,Remove Log4j Properties/XMLs from Projects
3575,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,We need to have an externalized property file(under xd/conf/) for the xd-container & admin scripts to use as options. ,XD-143,Ilayaperumal Gopinathan,Create externalized property file to support connectivity to redis
3576,Jennifer Hickey,Gary Russell,The {{ModuleDeployer}} calls {{getBeansOfType}} before the context has had its {{PropertySourcesPlaceholderConfigurer}} attached. This can cause issues with {{FactoryBean}} s with placeholders in constructor args because the unresolved placeholder is used when the {{FactoryBean}} is pre-instantiated to determine the type of object it will serve up.,XD-142,Gary Russell,StreamServer Context Lifecycle Issues
3577,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Currently, the install-redis script uses relative path to determine redis source  dist file. Since this is error prone, we need to fix it.",XD-141,Ilayaperumal Gopinathan,install-redis script should not use relative path to determine redis source dist
3578,Gary Russell,Gary Russell,"The syslog source currently is hard-coded to use udp on port 11111.

Need to parameterize the port and provide an option to use TCP.",XD-140,Gary Russell,Parameterize syslog Source; Add Support for TCP
3579,Ilayaperumal Gopinathan,Mark Pollack,"Building XD should not be part of the out first out of the box experience, but we should include some instructions on what targets are available, such as distXD.",XD-139,Mark Pollack,Update README.txt to include instructions on how to build
3580,Mark Pollack,Mark Pollack,,XD-138,Mark Pollack,Prepare blog post for M1
3581,Mark Pollack,Mark Pollack,,XD-137,Mark Pollack,Release Spring XD 1.0 M1
3582,Luke Taylor,Mark Pollack,Pointers to other documentation on how to install hadoop. ,XD-136,Mark Pollack,Documentation that points on how to install hadoop
3583,Mark Pollack,Mark Pollack,"Show overall flow of data in a stream, the server components 'admin' and 'container'.  How modules are deployed.",XD-135,Mark Pollack,Documentation on XD Architecture
3584,Luke Taylor,Mark Pollack,Asciidoc/doctor might have one as part of it toolchain,XD-134,Mark Pollack,Investigate link checking tool for user guide
3585,Gunnar Hillert,Mark Pollack,Similar to what would show up on structure101 reports.,XD-133,Mark Pollack,Fail Sonar CI build if there are any package tangles violated.
3586,Mark Pollack,Mark Pollack,"To allow for groups of beans to be defined or not in the container that runs a module.

When deploying a stream (e.g. via the REST API), it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",XD-132,Mark Pollack,Profile support for modules
3587,Jennifer Hickey,Jennifer Hickey,,XD-131,Jennifer Hickey,Upgrade Lettuce to 2.3.2
3588,Jennifer Hickey,Mark Pollack,,XD-130,Mark Pollack,Remove container entry in Redis when the application context event to shutdown the container is fired
3589,Gunnar Hillert,Mark Pollack,,XD-129,Mark Pollack,Documenation for building/starting redis servers
3590,Gary Russell,Mark Pollack,Based off SI tcp inbound adapter.  This will allow for event fowarding.,XD-128,Mark Pollack,Create TCP sink module
3591,Gary Russell,Mark Pollack,"Based off SI tcp inbound adapter.  This will allow for event forwarding that can select among the existing SI serialized/deserializer options.
",XD-127,Mark Pollack,Create TCP source module
3592,Eric Bottard,Mark Pollack,"This will eventually be supplied by the admin server, but for now write it up by hand in the documentation",XD-126,Mark Pollack,"Documentation for sources, sinks, modules should define which attributes are required and which optional"
3593,Mark Pollack,Mark Pollack,,XD-125,Mark Pollack,Stream documentation review
3594,Jennifer Hickey,Mark Pollack,"Need to shutdown cleanly, no exception messages are shown.  Order of components in the stream should be shut down from 'first to last'  (opposite of creation)",XD-124,Mark Pollack,Clean shutdown of redis in xd-container
3595,Winston Koh,Ilayaperumal Gopinathan,"We currently have the manually created XD scripts. This makes it difficult to maintain as the lib path is error prone with the changes. We need to make sure that the properties such as lib path etc., are dynamically updated.",XD-123,Ilayaperumal Gopinathan,XD scripts lib path needs to be dynamic
3596,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,"Spring-integration version is changed to 3.0.0.M2 and since we manually create the XD scripts, they still point to the 3.0.0.BUILD-SNAPSHOT version.

As discussed, we also need to have a better strategy on updating the lib directory inside the XD scripts.",XD-122,Ilayaperumal Gopinathan,XD scripts need to have spring-integration milestone versions updated
3597,Winston Koh,Ilayaperumal Gopinathan,,XD-121,Ilayaperumal Gopinathan,Add pre-compiled redis distributions for the selective OS platforms
3598,Gunnar Hillert,Mark Fisher,,XD-120,Mark Fisher,Find and eliminate package-level cycles across XD projects
3599,Thomas Risberg,Thomas Risberg,The current default is hdfs://localhost:9000 but most new distributions/installs use 8020,XD-119,Thomas Risberg,HDFS sink should default to hdfs://localhost:8020
3600,Mark Fisher,Mark Fisher,"This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing (should accept --interval for the seconds between time messages).",XD-118,Mark Fisher,replace testsource with time and testsink with log
3601,Mark Fisher,Mark Fisher,This will enable the use of groovy scripts within modules.,XD-117,Mark Fisher,add spring-integration-groovy to container dependencies
3602,Mark Fisher,Mark Fisher,It should provide an 'expression' param for SpEL and have a default value of true (accept everything).,XD-116,Mark Fisher,add SpEL 'filter' processor
3603,Mark Fisher,Mark Fisher,It should provide an 'expression' param for SpEL and have a default pass-thru of the payload.,XD-115,Mark Fisher,add SpEL 'transform' processor
3604,Winston Koh,Ilayaperumal Gopinathan,"This assumes the redis source tar is available under $rootDir/redis/redis-2.6.13.tar.gz

The install script does the following:

- Check the platform OS & arch
- unzip the tar, compile the sources",XD-114,Ilayaperumal Gopinathan,Add install script for Redis
3605,Mark Fisher,Gary Russell,,XD-112,Gary Russell,Update XD to Use SI 3.0.0.M2
3606,Ilayaperumal Gopinathan,Mark Pollack,"The final directory structure should look like

<install-dir>/xd
<install-dir>/redis
<install-dir>/gemfire

inside the XD directory 

/xd/bin - which has xd-container and xd-admin scripts
/xd/lib

inside the gemfire directory
/gemfire/bin - has the gemfire-server script
/gemfire/lib 

inside the redis directory is 

/redis/redis-latest-v.x.y.z.tar
/redis/README
/readis/install-redis  - script that does the basic 4 commands to install redis.


There should be a gradle task that runs after the distZip task, that will take the contents of different project directories, script diretories and 'redis-binary' directories and creates the final layout for the distribution.",XD-111,Mark Pollack,Create final distribution zip across multiple projects
3607,Ilayaperumal Gopinathan,Mark Pollack,"This is in the AdminMain and ContainerMain.  

Can get the environment property directly in java code unless provided explicitly on the command line using --xdHomeDir.",XD-110,Mark Pollack,"Remove use of system property xd.home to define location for install location, rely on environment variable XD_HOME"
3608,Mark Pollack,Mark Pollack,,XD-109,Mark Pollack,Documentation for starting Spring XD servers
3609,Ilayaperumal Gopinathan,Mark Pollack,"We are packaging separate scripts to start XDAdmin and XDContainer.  The Gradle application plugin will generate an unwanted 'spring-xd-dirt' scripts, this should be removed from the bin directory when creating a distribution zip.",XD-108,Mark Pollack,Build script should not package 'spring-xd-dirt' scripts 
3610,Jennifer Hickey,Mark Pollack,"A ctrl-c of xd-admin results in exception messages about disconnecting from redis.

14:16:07,327 ERROR task-scheduler-1 handler.LoggingHandler:136 - org.springframework.data.redis.RedisSystemException: Redis command interrupted; nested exception is com.lambdaworks.redis.RedisCommandInterruptedException: Command interrupted
",XD-107,Mark Pollack,Clean shutdown of redis in xd-admin
3611,Gunnar Hillert,Mark Pollack,"$ ./xd-container 
processing module 'Module [name=file, type=sink]' from group 'tailtest' with index: 1
processing module 'Module [name=tail, type=source]' from group 'tailtest' with index: 0


Logging of 'processing module' should have log level, time..",XD-106,Mark Pollack,Container server does not log a message that it has started or stopped successfully
3612,Ilayaperumal Gopinathan,Mark Pollack,should contain apache licence,XD-105,Mark Pollack,Add LICENSE to be included in root directory of distribution
3613,Ilayaperumal Gopinathan,Mark Pollack,should explain basic layout of the distribution,XD-104,Mark Pollack,Add README to be included in root directory of distribution
3614,Mark Pollack,Mark Pollack,"This will launch the RedisContainerLauncher, in future will be able to select from a variety of middleware options.",XD-103,Mark Pollack,Create XDAdmin server to start container launcher
3615,Mark Pollack,Mark Pollack,"Provide optional command line arg to embed the container launcher, aka - xd-admin server. 


XDContainer.sh --embeddAdmin",XD-102,Mark Pollack,Create XDContainer class to start stream server
3616,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,,XD-101,Ilayaperumal Gopinathan,Add gradle tasks that build and bundle the redis server
3617,Mark Pollack,Mark Pollack,"The Tuple classes in Reactor follow the more traditional data structure concept of Tuples, an immutable fixed length sequence of values where each value can have different types.  They are ordered and can often be access by index.

An example in a static language is the Tuple class found in .NET http://msdn.microsoft.com/en-us/library/system.tuple.aspx or in Scala http://www.tutorialspoint.com/scala/scala_tuples.htm

Using this standard definition of a Tuple, they do not support named values.  There is also a different tuple class instance for each length, e.g. Tuple<T1,T2>, Tuple<T1,T2,T3>.

The Tuple class in XD is more like a record or named tuple. 

Python has a named tuple concept - http://docs.python.org/2/library/collections.html#collections.namedtuple

and http://stackoverflow.com/questions/1490413/languages-that-allow-named-tuples shows that other languages use the term 'Record' for a 'named tuple' - Haskell, Standard ML, OCaml, and F#.

http://en.wikibooks.org/wiki/F_Sharp_Programming/Tuples_and_Records#Defining_Records

So boiling it all down, to avoid conflicts of names, and also to open up the possibility of using Reactor tuples as keys (instead of strings for names), we should change the name to either NamedTuple or Record.  ATM, there is no direct relationship between Reactor's Tuple and NamedTuple (such as inheritance) and so probably Record is the way to go.


",XD-100,Mark Pollack,Rename Tuple class in spring-xd-tuple
3618,Gunnar Hillert,Mark Pollack,"https://build.springsource.org/browse/XD-SONAR-34

Caused by: java.lang.ClassNotFoundException: org.sonar.api.Plugin
        at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)
        at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:244)
        at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:230)
        ... 94 more",XD-99,Mark Pollack,Sonar build is failing
3619,David Turanski,Mark Pollack,For people who are familiar with Spring/Spring Integration provide documents that show how to add additional input sources/sinks.,XD-98,Mark Pollack,Documentation on the module system and how to contribute new modules
3620,David Turanski,David Turanski,"A Flow or a processor component may require routing semantics. Currently the stream assumes a single input and output for each module. A Flow may support multiple outputs - Switch routing that is - Recipient list is not currently supported (another subtask?). We need to support semantics like:

a |[output.foo:c,output.bar:d,default:e]",XD-97,David Turanski,The ability to route within streams
3621,David Turanski,David Turanski,This should be a core feature of any Spring based module. The plugin should be able to import explicitly referenced beans. This minimizes potential side effects of making the module a child context and is simpler than declaring a shared context (parent) of the application and the module. Provide namespace support for flow:,XD-96,David Turanski,The ability to import beans referenced in the main context into a module
3622,David Turanski,David Turanski,"Currently modules are assumed to be in classpath:/META-INF/spring/integration/module/${flow}.xml. To reuse modules defined with DIRT  may require more flexibility.  e.g., 

<int-flow:flow root-path=""file:///dirt/module""/>",XD-95,David Turanski,The ability to override default module path for the plugin or an individual flow
3623,David Turanski,David Turanski,"Test and document e.g. ""http | flow1 | flow2 | file""",XD-94,David Turanski,Document The ability to use flows in streams
3624,David Turanski,David Turanski,"Normalize and refactor as needed functionality currently included in 
 - spring-integration-core (LocalChannelRegistry)
 - spring-integration-module (Module types upon which Flow are built)
 - xd-module (Depend Module types common to DIRT and Spring Integration)
 - spring-integration-flow (Flow specific types, namespace support, etc)",XD-93,David Turanski,Normalize and refactor component packaging decomposition
3625,Mark Pollack,Mark Pollack,,XD-92,Mark Pollack,Modularize spring integration flows at a high level of granularity to promote re-use and composability
3626,David Turanski,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-91,Mark Pollack,Documentation for field value taps
3627,David Turanski,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-90,Mark Pollack,Documentation for rich gauge taps
3628,Luke Taylor,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-89,Mark Pollack,Documentation for gauge taps
3629,David Turanski,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-88,Mark Pollack,Documentation for counter taps
3630,Luke Taylor,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-87,Mark Pollack,Documentation that introduces taps
3631,Thomas Risberg,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-86,Mark Pollack,"Documentation for ""twittersearch | file"" processing"
3632,David Turanski,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-85,Mark Pollack,"Documentation for ""gemfirecq | file"" processing"
3633,David Turanski,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-84,Mark Pollack,"Documentation for ""http | gemfire"" processing"
3634,Thomas Risberg,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-83,Mark Pollack,"Documentation for ""tail | hdfs"" processing"
3635,,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-82,Mark Pollack,"Documentation for ""tail | file"" processing"
3636,Gary Russell,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-81,Mark Pollack,"Documentation for ""syslog | file"" processing"
3637,Luke Taylor,Mark Pollack,"Put on the guide as a section in an 'input-stream' wiki page.


",XD-80,Mark Pollack,"Documentation for ""http | hdfs"" processing"
3638,Luke Taylor,Mark Pollack,"Put on the guide as a section in an 'streams' wiki page.

End user focused, no need to mention spring underpinning, impl details.

",XD-79,Mark Pollack,End user guide for data streams
3639,,Mark Pollack,"Put on the guide as a section in an 'input sources' wiki page.

https://github.com/springsource/spring-xd/wiki/GuideGettingStarted

",XD-78,Mark Pollack,"Documentation for ""http | file"" processing"
3640,Mark Pollack,Mark Pollack,,XD-76,Mark Pollack,Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server
3641,Ilayaperumal Gopinathan,Mark Pollack,for linux and mac,XD-75,Mark Pollack,Add redis bundle to distribution zip file
3642,Gary Russell,Mark Pollack,,XD-74,Mark Pollack,Create XD module for tail file adapter
3643,Winston Koh,Winston Koh,"in additional to existing tests that check for redis connection, we need to add tests that start/stop stream server. ",XD-73,Winston Koh,add test to start/stop stream server
3644,Mark Fisher,Mark Pollack,stream should be able to ingest data from http ,XD-72,Mark Pollack,Provide a http source
3645,Luke Taylor,Mark Pollack,"The Java UUID class is known not to be the fasted implementation available. 

See https://github.com/stephenc/eaio-uuid and http://mvnrepository.com/artifact/com.eaio.uuid/uuid for high perf impls.  ",XD-71,Mark Pollack,Remove UUID from Tuple class or replace with more efficient implementation
3646,Mark Pollack,Mark Pollack,"Adopt Asciidoc as the markdown syntax, useful for generating pdf and more feature rich than standard github flavored markdown.  Loosely following the conventions of https://community.jboss.org/wiki/TheHolyGrailAsciiDocOnGitHubToDocBookTrain that have generate docbook/pdf docs from the Asciidoc wiki.

The asciidoctor project is a key element in the adoption of AsciiDoc for use as the format in github, it is the rendering engine used by github for AsciiDoc.  See http://asciidoctor.org/docs/asciidoc-writers-guide/ for guidance.

",XD-70,Mark Pollack,Create general structure for AsciiDoc based wiki and Spring XD guide.
3647,Mark Pollack,Mark Pollack,"Based on a single process Spring Batch job, ETL of data from HDFS to MongoDB.",XD-69,Mark Pollack,Export of data from HDFS to MongoDB
3648,Mark Pollack,Mark Pollack,"Based on a single process running a Spring Batch job, support the ETL of data from HDFS to a RDBMS",XD-68,Mark Pollack,Export of data from HDFS to a relational database
3649,Winston Koh,Winston Koh,"- Host the Spring XD distributable zip somewhere that is accessible by external http request.
- Create brew formula for Spring XD install while specifying redis as dependency. 
- starting up stream server upon successful brew install

couple of questions:
- should we name the brew task springxd? (name not taken yet)
- should we start the stream server as part of the brew install process?
- should we specify redis as a recommended dependency? user can pass in 'brew install springxd --without-redis' to skip redis installation. by default, 'brew install springxd' will install redis as well.",XD-67,Winston Koh,Submit a brew-based install for Spring XD
3650,Luke Taylor,Luke Taylor,"The value is mutable so this causes problems if storing metrics in a HashSet, for example.",XD-66,Luke Taylor,Gauge and Counter hash and equals should not depend on values
3651,David Turanski,Mark Pollack,Update a gemfire region.,XD-65,Mark Pollack,Gemfire Sink to update a gemfire cache.
3652,,Mark Pollack,,XD-63,Mark Pollack,Document tuple data structure on XD wiki
3653,Michael Minella,Mark Pollack,Do not require a POJO in order to do end-to-end processing in a batch step.,XD-62,Mark Pollack,Use the tuple data structure to process data in a spring batch step 
3654,Winston Koh,Mark Pollack,"The gradle application task should get us most of the way to create a distributable artifact akin to what you see when downloading tomcat/jetty etc.

Now there is a launch task

task(launch, dependsOn: 'classes', type: JavaExec) {
		main = 'org.springframework.xd.dirt.stream.StreamServer'
		classpath = sourceSets.test.runtimeClasspath
	}


The same main should be referenced in the application plugin, a task to create a .zip distributable is needed.

Ideally would be nice to 
1. download .zip
2. unzip
3. cd spring-xd/bin
4. xdserver start


and gracefully shutdown later with 

5. xdserver stop

I don't know if we can/should bundle redis, I think we should bundle it.

The scripts can be for unix/linux and for windows.  

Discuss a brew based install as well.
",XD-61,Mark Pollack,Create distributable artifact that contains server application and start/stop scripts
3655,Mark Pollack,Mark Pollack,"The difference between saving a new metric and updating an existing one needs to be defined.  Suggest that if we try to save when an existing counter is already in the database to throw exception, such as DataIntegrityViolationException.",XD-60,Mark Pollack,"Saving a metric (Counter, Gauge..) with an existing name should throw an exception"
3656,Mark Pollack,Mark Pollack,"Nested tuple structures shoudl be supported,  getTuple(int index), getTuple(String name)",XD-59,Mark Pollack,Tuple should support storing nested tuples
3657,Mark Pollack,Greg Turnquist,Trying to build spring-xd for the first resulted in lots of errors inside STS (I had an empty .m2 repo).,XD-58,Greg Turnquist,build.gradle doesn't handle a small handful of libraries
3658,Mark Fisher,Mark Fisher,,XD-57,Mark Fisher,add counter module
3659,Mark Pollack,Mark Pollack,Replace the use of Jedis with Lettuce as it has higher performance,XD-56,Mark Pollack,Switch to use Lettuce driver for Redis
3660,Mark Pollack,Mark Pollack,"A Spring Integration based @ServiceActivator that counts the occurrence of field names, from either a tuple data structure or a POJO, using the Spring XD metrics support.",XD-55,Mark Pollack,SI ServiceActivator for an XD Metrics backed Field Value Counter
3661,Mark Pollack,Mark Pollack,A Spring Integration based @ServiceActivator that counts the number of messages using the Spring XD metrics support,XD-54,Mark Pollack,XD Metrics backed Message Counter
3662,Mark Pollack,Mark Pollack,Start to explore how the DSL can cover both advanced (non-linear) spring integration flows as well as spring batch jobs.,XD-53,Mark Pollack,Design and document desired high level DSL for configuring data processing in XD
3663,Mark Fisher,Mark Fisher,,XD-52,Mark Fisher,add twitter search source module
3664,Mark Fisher,Mark Fisher,,XD-51,Mark Fisher,Add xd.stream.name property in StreamPlugin
3665,Mark Fisher,Mark Fisher,"syntax:

{code}
tap @ somechannel --key=value | somecounter
{code}
",XD-50,Mark Fisher,Add tap support to DIRT
3666,Gunnar Hillert,Mark Fisher,"Currently these implementations are in the spring-xd-dirt module, but they should be moved into spring-integration-redis. We are already depending upon Spring Integration 3.0 snapshots since the ChannelRegistry implementation is not yet at a milestone, so this should be okay for the Redis Channel Adapters also - until Spring Integration M2 is released.",XD-49,Mark Fisher,Move Redis Queue Channel Adapters into spring-integration-redis
3667,Mark Fisher,Mark Fisher,,XD-48,Mark Fisher,Parameterizable streams
3668,Mark Fisher,Mark Fisher,,XD-47,Mark Fisher,HDFS sink module
3669,Luke Taylor,Mark Pollack,"There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class and/or base class.",XD-45,Mark Pollack,Remove the expiry of keys in Redis based repositories
3670,Luke Taylor,Mark Pollack,RedisCounterRepository and RedisGaugeRepository have duplicated code that needs to be factored out into a one place.  One such duplication is the determination of the key name to use for persistence.  This should be abstracted out into a strategy helper class.,XD-44,Mark Pollack,Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence
3671,Luke Taylor,Mark Pollack,This provides common CRUD behavior and a shared interface that can be useful in testing scenarios.  ,XD-43,Mark Pollack,Metric repositories should support Spring Data CrudRepository interface
3672,Mark Fisher,Mark Fisher,,XD-42,Mark Fisher,RedisChannelRegistry
3673,Gary Russell,Gary Russell,,XD-41,Gary Russell,Add JUnit @Rule so Tests Fail Fast with Clear Messaging if Redis Not Available
3674,Mark Fisher,Mark Pollack,Gradle application plugin is a good starting point.  this should be the main server that would host SI based modules to do syslog->file ingestion (as an example),XD-40,Mark Pollack,Build script that creates an executable server as an artifact
3675,Mark Fisher,Mark Pollack,,XD-39,Mark Pollack,Add integration capability to the runtime nodes
3676,Mark Pollack,Mark Pollack,TODO: break out into sub-task or other stories.,XD-38,Mark Pollack,Support in HDFS writing features for compression and popular serialization formats
3677,Thomas Risberg,Mark Pollack,multi project build. - look to Spring Framework for source of starting point.,XD-37,Mark Pollack,Gradle based multi-project build
3678,Mark Fisher,Mark Pollack,,XD-36,Mark Pollack,SI Outbound HDFS Channel Adapter
3679,Gunnar Hillert,Mark Pollack,bamboo based,XD-35,Mark Pollack,Create CI process for XD build
3680,David Turanski,Mark Fisher,"This should be usable within a single JVM process.
Lives within shared application context of the process.
",XD-33,Mark Fisher,Implement LocalChannelRegistry
3681,Mark Fisher,Mark Fisher,"Define the ChannelRegistry interface.
",XD-32,Mark Fisher,Create base Channel Registry abstraction
3682,Mark Pollack,Mark Pollack,"A field-value counter is useful for bar chart graphs, Strings on x-axis and count on y-axis.  Maps well to zset in redis. Implementations for in-memory and redis.",XD-31,Mark Pollack,Create field-value counters
3683,Mark Pollack,Mark Pollack,A simple counters can increment/decrement a number.  Implementations for in-memory and redis.,XD-30,Mark Pollack,Create a simple counter service
3684,Luke Taylor,Mark Pollack,"A rich gauge stores a number and also rmd, min, max. Implementations for in-memory and redis.",XD-29,Mark Pollack,Create rich gauge service
3685,Mark Pollack,Mark Pollack,A gauge just stores a number.  Implementations for in-memory and redis.,XD-28,Mark Pollack,Create simple gague service
3686,David Turanski,Mark Pollack,,XD-27,Mark Pollack,Gemfire CQ module for ingestion
3687,Ilayaperumal Gopinathan,Mark Pollack,,XD-26,Mark Pollack,Basic Performance Test For syslog injestion
3688,Mark Fisher,Mark Pollack,"Initial simple handcoded implementation for straight through pipe and filter model, e.g. a | b | c",XD-24,Mark Pollack,Create pipes and filters DSL for ingestion
3689,Mark Fisher,Mark Pollack,,XD-23,Mark Pollack,add file source and sink modules
3690,Mark Fisher,Mark Pollack,A module groups together a collection of spring configuration files.,XD-22,Mark Pollack,Create Module base abstractions
3691,Mark Fisher,Mark Pollack,Consider which properties of the syslog namespace need to use property placeholders,XD-21,Mark Pollack,Create syslog.xml file for module registry
3692,Mark Fisher,Mark Pollack,,XD-20,Mark Pollack,DIRT Runtime that deploys an application context across multiple nodes using redis.
3693,Mark Pollack,Mark Pollack,,XD-18,Mark Pollack,Websocket based taps
3694,Mark Pollack,Mark Pollack,,XD-17,Mark Pollack,Reactor based websocket ingestion
3695,Mark Pollack,Mark Pollack,,XD-15,Mark Pollack,Deploy against Amazon EMR
3696,,Mark Pollack,create enough of a design to develop additional stories.,XD-14,Mark Pollack,Design for deploying XD on EC2
3697,Gary Russell,Mark Pollack,,XD-13,Mark Pollack,Tail file channel adapters
3698,Mark Pollack,Mark Pollack,,XD-12,Mark Pollack,Jolokia based aggregator for cluster monitoring
3699,David Turanski,Mark Pollack,,XD-11,Mark Pollack,Initial work that uses the module architecture from DIRT 
3700,Mark Pollack,Mark Pollack,"When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.",XD-10,Mark Pollack,Reactor based http ingestion
3701,Gary Russell,Mark Pollack,,XD-9,Mark Pollack,Basic implementation of a reactor based tcp server
3702,Gary Russell,Mark Pollack,Have a syslog.xml config file that can be added to a module and registered with a module registry.,XD-8,Mark Pollack,Syslog Ingestion
3703,Mark Pollack,Mark Pollack,The tuple data structure should be backward compatible in functionality for use in spring batch.  Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.,XD-7,Mark Pollack,Tuple data structure
3704,David Turanski,Mark Pollack,,XD-6,Mark Pollack,Channel Registry
3705,Mark Pollack,Mark Pollack,Simple file writer that has existed in the spring hadoop samples.,XD-2,Mark Pollack,HDFS Core writing helper classes
3706,Michael Minella,Mark Pollack,Base integration of core HDFS writer functionality with Spring Batch.,XD-1,Mark Pollack,HDFS ItemWriter
